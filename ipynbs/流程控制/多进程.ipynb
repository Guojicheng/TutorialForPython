{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python多进程编程\n",
    "\n",
    "python受GIL限制,无法利用到多核,要使用多核提高cpu的利用率这种时候最简单的方式就是使用多进程实现突破GIL限制.\n",
    "\n",
    "换言之python多进程的价值体现在CPU密集型作业上.\n",
    "\n",
    "进程(Process)是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体.\n",
    "\n",
    "\n",
    "## python调用系统fork\n",
    "\n",
    "Unix/Linux操作系统提供了一个fork()系统调用.普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。\n",
    "\n",
    "子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。\n",
    "\n",
    "python`os`模块封装了`fork()`(unix-like系统).事实上在类unix系统下,python的多进程都是基于fork的,而windows下情况就不一样了.\n",
    "\n",
    "## windows下的多进程局限性\n",
    "\n",
    "在windows下,由于没有fork,python的多进程模块`multiprocessing`必须要有`if __name__=='__main__':`也就是说它无法在非入口模块下使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process (1372) 开始...\n",
      "父进程 (1372) 产生了子进程: (1377).\n",
      "子进程: (1377) 它的父进程是: (1372).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('Process ({}) 开始...'.format(os.getpid()))\n",
    "# Only works on Unix/Linux/Mac:\n",
    "pid = os.fork()\n",
    "if pid == 0:\n",
    "    print('子进程: ({}) 它的父进程是: ({}).'.format(os.getpid(), os.getppid()))\n",
    "else:\n",
    "    print('父进程 ({}) 产生了子进程: ({}).'.format(os.getpid(), pid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用concurrent.futures进行高层抽象的多进程操作\n",
    "\n",
    "在python3中,模块`concurrent.futures`提供了一些更加简单易用的多进程操作,它主要利用进程池.\n",
    "\n",
    "这个库支持多线程和多进程,接口一样,只是使用的对象不同而已.\n",
    "\n",
    "`concurrent.futures`提供两种编程模型:\n",
    "\n",
    "+ 并行任务模型\n",
    "\n",
    "    单独任务独立使用自己的过程和数据,多任务独立并行计算\n",
    "\n",
    "+ MapReduce模型\n",
    "\n",
    "    为各个进程分发数据执行相同的过程\n",
    "\n",
    "### 并行任务模型\n",
    "\n",
    "这个模型使用`submit`提交任务到上下文管理器,之后使用返回对象的`result()`方法阻塞io等待任务完成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor,as_completed\n",
    "from random import randrange\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arcfour(key, in_bytes, loops=20):\n",
    "    \"\"\"rc4算法\"\"\"\n",
    "    kbox = bytearray(256)  # create key box\n",
    "    for i, car in enumerate(key):  # copy key and vector\n",
    "        kbox[i] = car\n",
    "    j = len(key)\n",
    "    for i in range(j, 256):  # repeat until full\n",
    "        kbox[i] = kbox[i-j]\n",
    "\n",
    "    # [1] initialize sbox\n",
    "    sbox = bytearray(range(256))\n",
    "\n",
    "    # repeat sbox mixing loop, as recommened in CipherSaber-2\n",
    "    # http://ciphersaber.gurus.com/faq.html#cs2\n",
    "    j = 0\n",
    "    for k in range(loops):\n",
    "        for i in range(256):\n",
    "            j = (j + sbox[i] + kbox[i]) % 256\n",
    "            sbox[i], sbox[j] = sbox[j], sbox[i]\n",
    "\n",
    "    # main loop\n",
    "    i = 0\n",
    "    j = 0\n",
    "    out_bytes = bytearray()\n",
    "\n",
    "    for car in in_bytes:\n",
    "        i = (i + 1) % 256\n",
    "        # [2] shuffle sbox\n",
    "        j = (j + sbox[i]) % 256\n",
    "        sbox[i], sbox[j] = sbox[j], sbox[i]\n",
    "        # [3] compute t\n",
    "        t = (sbox[i] + sbox[j]) % 256\n",
    "        k = sbox[t]\n",
    "        car = car ^ k\n",
    "        out_bytes.append(car)\n",
    "\n",
    "    return out_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.60s\n",
      "elapsed time: 3.00s\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "clear = bytearray(b'1234567890' * 100000)\n",
    "t0 = time()\n",
    "cipher = arcfour(b'key', clear)\n",
    "print('elapsed time: %.2fs' % (time() - t0))\n",
    "result = arcfour(b'key', cipher)\n",
    "assert result == clear, '%r != %r' % (result, clear)\n",
    "print('elapsed time: %.2fs' % (time() - t0))\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crypto_process(size, key):\n",
    "    in_text = bytearray(randrange(256) for i in range(size))\n",
    "    cypher_text = arcfour(key, in_text)\n",
    "    out_text = arcfour(key, cypher_text)\n",
    "    assert in_text == out_text, 'Failed arcfour_test'\n",
    "    return size\n",
    "    \n",
    "def main(workers=None):\n",
    "    JOBS = 12\n",
    "    SIZE = 2**18\n",
    "\n",
    "    KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\"\n",
    "    STATUS = '{} workers, elapsed time: {:.2f}s'\n",
    "    if workers:\n",
    "        workers = int(workers)\n",
    "    t0 = time()\n",
    "\n",
    "    with ProcessPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        to_do = []\n",
    "        for i in range(JOBS, 0, -1):\n",
    "            size = SIZE + int(SIZE / JOBS * (i - JOBS/2))\n",
    "            job = executor.submit(crypto_process, size, KEY)\n",
    "            to_do.append(job)\n",
    "\n",
    "        for future in as_completed(to_do):\n",
    "            res = future.result()\n",
    "            print('{:.1f} KB'.format(res/2**10))\n",
    "\n",
    "    print(STATUS.format(actual_workers, time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384.0 KB\n",
      "362.7 KB\n",
      "341.3 KB\n",
      "320.0 KB\n",
      "298.7 KB\n",
      "277.3 KB\n",
      "256.0 KB\n",
      "234.7 KB\n",
      "213.3 KB\n",
      "192.0 KB\n",
      "170.7 KB\n",
      "149.3 KB\n",
      "1 workers, elapsed time: 18.30s\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362.7 KB\n",
      "384.0 KB\n",
      "320.0 KB\n",
      "341.3 KB\n",
      "277.3 KB\n",
      "298.7 KB\n",
      "234.7 KB\n",
      "256.0 KB\n",
      "192.0 KB\n",
      "213.3 KB\n",
      "149.3 KB\n",
      "170.7 KB\n",
      "2 workers, elapsed time: 12.87s\n"
     ]
    }
   ],
   "source": [
    "main(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320.0 KB\n",
      "341.3 KB\n",
      "362.7 KB\n",
      "384.0 KB\n",
      "234.7 KB\n",
      "256.0 KB\n",
      "277.3 KB\n",
      "298.7 KB\n",
      "149.3 KB\n",
      "170.7 KB\n",
      "192.0 KB\n",
      "213.3 KB\n",
      "4 workers, elapsed time: 10.09s\n"
     ]
    }
   ],
   "source": [
    "main(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MapReduce模型\n",
    "\n",
    "这种模式可能更加被大家熟悉,同一个流程,将容器中的数据一条一脚放入子进程运算,最终也结果也会被放入容器中.最后可以将收集来的数据在主进程中进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    "def is_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, False]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[is_prime(i) for i in PRIMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.35 s ± 870 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [is_prime(i) for i in PRIMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ProcessPool_prime(PRIMES= PRIMES ,workers=4):\n",
    "    with ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "        total = []\n",
    "        for prime in executor.map(is_prime, PRIMES):\n",
    "            #print('%d is prime: %s' % (number, prime))\n",
    "            total.append(prime)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, False]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProcessPool_prime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.82 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ProcessPool_prime(workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用进程池进行相对底层的多进程操作\n",
    "\n",
    "进程池的方式很适合批量创建子进程.\n",
    "\n",
    "对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。\n",
    "\n",
    "请注意输出的结果，task 0，1，2，3是立刻执行的，而task 4要等待前面某个task完成后才执行，这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制。如果改成`p = Pool(5)`就可以同时跑5个进程。\n",
    "\n",
    "由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。\n",
    "\n",
    "除了使用apply_async方法外,还有apply，map和map_async可以用于线程池的计算,编程模型也是如`concurrent.futures`一样分为两类\n",
    "\n",
    "+ 并行任务模型\n",
    "    + apply 单一任务布置\n",
    "    + apply_async 非阻塞单一任务布置\n",
    "+ MapReduce模型\n",
    "    + map 同系统的map方法\n",
    "    + map_async 非阻塞的map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os, time, random\n",
    "\n",
    "def long_time_task(name):\n",
    "    print('运行任务 %s (%s)...' % (name, os.getpid()))\n",
    "    start = time.time()\n",
    "    time.sleep(random.random() * 3)\n",
    "    end = time.time()\n",
    "    print('任务 %s 执行了 %0.2f 秒.' % (name, (end - start)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "父进程 1372.\n",
      "运行任务 0 (1432)...\n",
      "运行任务 1 (1433)...\n",
      "运行任务 2 (1434)...\n",
      "运行任务 3 (1435)...\n",
      "等待所有子进程完成...\n",
      "任务 3 执行了 0.69 秒.\n",
      "运行任务 4 (1435)...\n",
      "任务 1 执行了 1.39 秒.\n",
      "任务 4 执行了 0.94 秒.\n",
      "任务 0 执行了 1.81 秒.\n",
      "任务 2 执行了 2.42 秒.\n",
      "所有子进程完成了.\n"
     ]
    }
   ],
   "source": [
    "print('父进程 %s.' % os.getpid())\n",
    "p = Pool(4)\n",
    "for i in range(5):\n",
    "    p.apply_async(long_time_task, args=(i,))#创建非阻塞子进程用这个\n",
    "print('等待所有子进程完成...')\n",
    "p.close()\n",
    "p.join()\n",
    "print('所有子进程完成了.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map:  [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "imap:\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "64\n",
      "49\n",
      "81\n",
      "apply: 100\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-91c8d158aee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# make worker sleep for 10 secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# raises multiprocessing.TimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/LIB/CONDA/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from time import sleep\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "# start 4 worker processes\n",
    "pool = Pool(processes=4)\n",
    "print(\"map: \",pool.map(f, range(10)))\n",
    "print(\"imap:\")\n",
    "for i in pool.imap_unordered(f, range(10)):\n",
    "    print(i)\n",
    "\n",
    "# evaluate \"f(10)\" asynchronously\n",
    "res = pool.apply_async(f, [10])\n",
    "print(\"apply:\",res.get(timeout=1))             # prints \"100\"\n",
    "\n",
    "# make worker sleep for 10 secs\n",
    "res = pool.apply_async(sleep, [10])\n",
    "print(res.get(timeout=1))             # raises multiprocessing.TimeoutError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取进程池中的运算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg: hello 0\n",
      "msg: hello 1\n",
      "msg: hello 2\n",
      "end\n",
      "end\n",
      "end\n",
      "::: done hello 0\n",
      "::: done hello 1\n",
      "::: done hello 2\n",
      "Sub-process(es) done.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def func(msg):\n",
    "    print(\"msg:\", msg)\n",
    "    time.sleep(1)\n",
    "    print(\"end\")\n",
    "    return \"done \" + msg\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "result = []\n",
    "for i in range(3):\n",
    "    msg = \"hello %d\" %(i)\n",
    "    result.append(pool.apply_async(func, (msg, )))\n",
    "pool.close()\n",
    "pool.join()\n",
    "for res in result:\n",
    "    print(\":::\", res.get())\n",
    "print(\"Sub-process(es) done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更底层的多进程编程\n",
    "\n",
    "标准库中的multiprocessing模块就是跨平台版本的多进程模块。\n",
    "\n",
    "multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "父进程 1372.\n",
      "子进程要开始啦.\n",
      "子进程 test (1444)...\n",
      "子进程 test (1444)...\n",
      "子进程 test (1444)...\n",
      "子进程结束.\n",
      "父进程1372进行中...\n",
      "父进程1372进行中...\n",
      "父进程1372进行中...\n",
      "父进程结束啦\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "#子进程要执行的代码\n",
    "def run_proc(name):\n",
    "    for i in range(3):\n",
    "        print(u'子进程 %s (%s)...' % (name, os.getpid()))\n",
    "    print(u'子进程结束.')\n",
    "\n",
    "print(u'父进程 {}.'.format(os.getpid()))\n",
    "p = Process(target=run_proc, args=('test',))\n",
    "print(u'子进程要开始啦.')\n",
    "p.start()\n",
    "for i in range(3):\n",
    "    print(u'父进程{pid}进行中...'.format(pid = os.getpid()))\n",
    "p.join()\n",
    "print(u\"父进程结束啦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Process作为父类自定义子进程\n",
    "\n",
    "Process的子类需要重写`run`方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "class Processor(Process):\n",
    "\n",
    "    def __init__(self, queue, idx):\n",
    "        super(Processor, self).__init__()\n",
    "        self.queue = queue\n",
    "        self.idx = idx\n",
    "\n",
    "    def return_name(self):\n",
    "        ## NOTE: self.name is an attribute of multiprocessing.Process\n",
    "        return \"Process idx=%s is called '%s'\" % (self.idx, self.name)\n",
    "\n",
    "    def run(self):\n",
    "        self.queue.put(self.return_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: Process idx=0 is called 'Processor-57'\n",
      "RESULT: Process idx=1 is called 'Processor-58'\n",
      "RESULT: Process idx=2 is called 'Processor-59'\n",
      "RESULT: Process idx=3 is called 'Processor-60'\n",
      "RESULT: Process idx=4 is called 'Processor-61'\n"
     ]
    }
   ],
   "source": [
    "processes = list()\n",
    "q = Queue()\n",
    "for i in range(0,5):\n",
    "    p=Processor(queue=q, idx=i)\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "for proc in processes:\n",
    "    proc.join()\n",
    "    ## NOTE: You cannot depend on the results to queue / dequeue in the\n",
    "    ## same order\n",
    "    print(\"RESULT: {}\".format(q.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()简单。\n",
    "\n",
    "join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。\n",
    "\n",
    "可以看到我们的父进程进行完了子进程才进行.其实当执行start方法的时候我们就已经把进程创建好并给他任务了. 虽然进程启动了,但我们并不能知道它啥时候运算完成.这时候用join方法来确认是否执行完了(通过阻塞主进程),也就是起个等待结果的作用."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进程间通信\n",
    "\n",
    "如何让进程间通信呢,其实原理上来讲就是构造一个独立的数据结构来存放结果来参与通信\n",
    "\n",
    "有两种方式,最常用的一种是用队列\n",
    "\n",
    "### 先进先出队列Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(q):\n",
    "    q.put([42, None, 'hello'])\n",
    "\n",
    "q = Queue()\n",
    "p = Process(target=f, args=(q,))\n",
    "p.start()\n",
    "print(q.get())    # prints \"[42, None, 'hello']\"\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "个稍微复杂一点的例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put A to queue...\n",
      "Put B to queue...\n",
      "Put C to queue...\n",
      "Get A from queue.\n",
      "Get B from queue.\n",
      "Get C from queue.\n",
      "Done!\n",
      "\n",
      "所有数据都写入并且读完\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import os, time, random\n",
    "\n",
    "# 写数据进程执行的代码:\n",
    "def write(q):\n",
    "    for value in ['A', 'B', 'C']:\n",
    "        print('Put %s to queue...' % value)\n",
    "        q.put(value)\n",
    "        time.sleep(random.random())\n",
    "# 读数据进程执行的代码:\n",
    "def read(q):\n",
    "    # pr进程里是死循环，无法等待其结束，只能强行终止:\n",
    "    while True:\n",
    "        if not q.empty():\n",
    "            value = q.get(True)\n",
    "            print('Get %s from queue.' % value)\n",
    "            time.sleep(random.random())\n",
    "        else:\n",
    "            q.put(\"Done!\")\n",
    "            break\n",
    "\n",
    "# 父进程创建Queue，并传给各个子进程：\n",
    "q = Queue()\n",
    "pw = Process(target=write, args=(q,))\n",
    "pr = Process(target=read, args=(q,))\n",
    "# 启动子进程pw，写入:\n",
    "pw.start()\n",
    "# 等待pw结束:\n",
    "pw.join()\n",
    "# 启动子进程pr，读取:\n",
    "pr.start()\n",
    "pr.join()\n",
    "print(q.get())\n",
    "print('\\n所有数据都写入并且读完')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个进程间,父进程创建一个队列给各个子进程,子进程接收父进程的队列作为参数运行. 运行过程中将结果存入队列最后运行完后将”done!”存入队列,由父进程接收."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生产者消费者模型\n",
    "\n",
    "队列最常见的用处就是在生产者消费者模式中作为数据缓冲区.以下就是一个生产者消费者模式的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from multiprocessing import Process, Queue,Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Producer(Process):\n",
    "    \"\"\"生产者\"\"\"\n",
    "    def __init__(self,q,con,name):\n",
    "        super(Producer,self).__init__()\n",
    "        self.q = q\n",
    "        self.name = name\n",
    "        self.con = con\n",
    "        print(\"生产者{self.name}产生了\".format(self=self))\n",
    "\n",
    "    def run(self):\n",
    "        count = 3 #只生产满3轮,要不然就会无限循环出不去了\n",
    "        while count>0:\n",
    "            #global writelock\n",
    "            self.con.acquire()\n",
    "            if self.q.full():\n",
    "                print(\"队列满了,生产者等待\")\n",
    "                count-=1\n",
    "                self.con.wait()\n",
    "\n",
    "            else:\n",
    "                value = random.randint(0,10)\n",
    "                print(\"{self.name}把值{self.name}:{value}放入了队列\".format(self=self,value=value))\n",
    "                self.q.put(\"{self.name}:{value}\".format(self=self,value=value))\n",
    "            self.con.notify()\n",
    "        self.con.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Consumer(Process):\n",
    "    \"\"\"消费者\"\"\"\n",
    "    def __init__(self,q,con,name):\n",
    "        super(Consumer,self).__init__()\n",
    "        self.q = q\n",
    "        self.name = name\n",
    "        self.con = con\n",
    "        print(\"消费者{self.name}产生了\".format(self=self))\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            #global writelock\n",
    "            self.con.acquire()\n",
    "            if self.q.empty():\n",
    "\n",
    "                print(\"队列空了,消费者等待\")\n",
    "                self.con.wait()\n",
    "            else:\n",
    "                value = self.q.get()\n",
    "\n",
    "                print(\"{self.name}从队列中获取了{self.name}:{value}\".format(self=self,\n",
    "                                                                         value=value))\n",
    "                self.con.notify()\n",
    "            self.con.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生产者P1产生了\n",
      "生产者P2产生了\n",
      "消费者C1产生了\n",
      "P1把值P1:1放入了队列\n",
      "P1把值P1:2放入了队列\n",
      "P1把值P1:9放入了队列\n",
      "P1把值P1:1放入了队列\n",
      "P1把值P1:8放入了队列\n",
      "P1把值P1:10放入了队列\n",
      "P1把值P1:5放入了队列\n",
      "P1把值P1:8放入了队列\n",
      "P1把值P1:6放入了队列\n",
      "P1把值P1:9放入了队列\n",
      "队列满了,生产者等待\n",
      "队列满了,生产者等待\n",
      "C1从队列中获取了C1:P1:1\n",
      "P1把值P1:2放入了队列\n",
      "队列满了,生产者等待\n",
      "C1从队列中获取了C1:P1:2\n",
      "P2把值P2:7放入了队列\n",
      "队列满了,生产者等待\n",
      "队列满了,生产者等待\n",
      "C1从队列中获取了C1:P1:9\n",
      "P2把值P2:0放入了队列\n",
      "队列满了,生产者等待\n"
     ]
    }
   ],
   "source": [
    "q = Queue(10)\n",
    "con = Condition()\n",
    "p1 = Producer(q,con,\"P1\")\n",
    "p1.start()\n",
    "p2 = Producer(q,con,\"P2\")\n",
    "p2.start()\n",
    "c1 = Consumer(q,con,\"C1\")\n",
    "c1.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 管道Pipes\n",
    "\n",
    "既然是管道,那就肯定有两端,有方向,分成单向管道和双向管道了.\n",
    "\n",
    "看一个最简单的双向管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "parent_conn, child_conn = Pipe()\n",
    "p = Process(target=f, args=(child_conn,))\n",
    "p.start()\n",
    "print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "稍微复杂的例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put ['h1 reader~'] to pip...\n",
      "Get ['h1 reader~'] from pip.\n",
      "hi writer~~\n",
      "\n",
      "所有数据都写入并且读完\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "import os, time, random\n",
    "\n",
    "# 写数据进程执行的代码:\n",
    "def write(conn):\n",
    "    value = [\"h1 reader~\"]\n",
    "    print('Put %s to pip...' % value)\n",
    "    conn.send(value)\n",
    "    time.sleep(1)\n",
    "\n",
    "# 读数据进程执行的代码:\n",
    "def read(conn):\n",
    "    # pr进程里是死循环，无法等待其结束，只能强行终止:\n",
    "    value = conn.recv()\n",
    "    print('Get %s from pip.' % value)\n",
    "    conn.send(\"hi writer~~\")\n",
    "\n",
    "\n",
    "\n",
    "# 父进程创建Pipe，并传给各个子进程：\n",
    "parent_conn, child_conn = Pipe()\n",
    "pw = Process(target=write, args=(parent_conn,))#起点\n",
    "pr = Process(target=read, args=(child_conn,))#终点\n",
    "# 启动子进程pw，写入:\n",
    "pw.start()\n",
    "# 等待pw结束:\n",
    "pw.join()\n",
    "# 启动子进程pr，读取:\n",
    "pr.start()\n",
    "pr.join()\n",
    "print(parent_conn.recv())\n",
    "print('\\n所有数据都写入并且读完')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出管道的限制相对多些,必须要建立连接才能交换数据,一出一进这样子,这也是为啥队列用的比较多."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 静态数据共享\n",
    "\n",
    "\n",
    "python里面的全局变量也只管到他自己的进程,如果要让一个静态的数据在每个子进程中都可以调用.那么需要用到模块中的几个方法:\n",
    "\n",
    "+ Value, Array\n",
    "\n",
    "    静态数据位共享,静态数组共享,本质就是在内存中开辟一块用于共享的空间,Value和Array都必须使用C类型保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415927\n",
      "[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "\n",
    "num = Value('d', 0.0)\n",
    "arr = Array('i', range(10))\n",
    "\n",
    "p = Process(target=f, args=(num, arr))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "print(num.value)\n",
    "print(arr[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高级共享multiprocessing.Manager\n",
    "\n",
    "之前介绍了queue,pipe,array和value,这些都太具体底层,有没有什么方法可以像处理python容器一样\n",
    "简单地处理数据共享的问题呢?multiprocess提供一个manager模块.\n",
    "\n",
    "Manager()返回的manager对象控制了一个server进程，此进程包含的python对象可以被其他的进程通过proxies来访问。从而达到多进程间数据通信且安全。\n",
    "\n",
    "Manager支持的类型有\n",
    "\n",
    "+ list\n",
    "+ dict\n",
    "+ Namespace\n",
    "+ Lock\n",
    "+ RLock\n",
    "+ Semaphore\n",
    "+ BoundedSemaphore\n",
    "+ Condition\n",
    "+ Event\n",
    "+ Queue\n",
    "+ Value\n",
    "+ Array。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "0=0\n",
      "1=1\n",
      "2=2\n",
      "3=3\n",
      "4=4\n",
      "5=5\n",
      "6=6\n",
      "7=7\n",
      "8=8\n",
      "9=9\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def worker(d, key, value):\n",
    "    d[key] = value\n",
    "\n",
    "\n",
    "mgr = multiprocessing.Manager()\n",
    "d = mgr.dict()\n",
    "jobs = [ multiprocessing.Process(target=worker, args=(d, i, i*2))\n",
    "         for i in range(10)\n",
    "         ]\n",
    "for j in jobs:\n",
    "    j.start()\n",
    "for j in jobs:\n",
    "    j.join()\n",
    "print ('Results:' )\n",
    "for key, value in enumerate(dict(d)):\n",
    "    print(\"%s=%s\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "namespace对象没有公共的方法，但是有可写的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(x=10, y='hello')\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "manager = multiprocessing.Manager()\n",
    "Global = manager.Namespace()\n",
    "Global.x = 10\n",
    "Global.y = 'hello'\n",
    "print(Global)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
