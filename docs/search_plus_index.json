{"./":{"url":"./","title":"Introduction","keywords":"","body":"python攻略 Python是一门既容易上手又强大的编程语言.--Python官方教程 起因 Python3.5+攻略,3.5以后新加了大量特性和语法糖,关键的关键字async和await和其代表的原生的协程. typehint,zipapp等实用工具再加上本身字符串的语义变化和metaclass的语法变化. Python3.5已经可以说是一门与2难以兼容的新语言了. 虽然Python2于3其设计思路和数据模型没有本质变化,但这些变化足以让人不适应. 而新的实用工具也让我看到了全面迁移向Python3的意义.为了自己熟悉Python3也为了安利.才有了这样一份攻略. 为什么不是3.6或3.7 2017年初Python3.6版本发布了,它也确实有些令人欣喜的语法糖,但并没有3.5的冲击巨大,且都有替代方式实现.基于3.5写的代码可以保证在Python3.6上使用,而相反却不行. 3.5之后版本的特性也会写出来,但会做出标记,如果以后哪个版本又有了关键字层面或者大的语法层面的改变,本教程也会迁移过去. 怎么利用这份攻略学习Python3.5+ 首先,忘记Python2.7,忘记3.5-的Python怎么用的,从头开始学.本教程也不会有与之前的对比.一切从新开始 其次,边做边练,本教程没有习题,但比较重要的部分通常都有示例代码,本教程的也完全是使用jupyter notebook编写,可以自行去代码仓库拉下来亲自跑一遍. 善用help()方法,本教程不会大量罗列api,列出来的一定都是相对比较重要的,没有列出的api细节请自己help()查看 作者本人在写这份攻略的时候,出发点就是希望记录学到的东西,日后一旦忘记就可以在这里快速找到.因此可以看到本文章节分的比较细. 本教程通篇阅读当然可以,但更加推荐将其作为工具书,碰到问题了查一下.这样使用可能更加高效. 目标读者 本攻略的目标读者主要是那些正在使用Python,又想熟悉Python3的程序员.如果你懂Python2,但是想迁移到Python3.5+也没问题.在动笔写这本攻略的时候,大多数专业Python程序员,包括我自己, 用的还是Python2,因此如果文中出现来自Python3的特性,读者可能会感到陌生.但我也会不会做出解释,记住就行.本攻略的主要目的之一是为了充分地展现Python3.5+的魅力, 如何让本攻略的代码在旧版本里正常运行这种问题我是不会回答的. 本攻略中的大多数例子稍做修改(甚至不用修改)就可以在Python2.7里面跑起来,但是有些例子,如果追求向下兼容,就会需要大量的重写,这太麻烦了.本攻略也没打算向下兼容. 但因为Pyhon语言的核心概念是不会变的.Python3本质上也不是一门全新的语言,因此如果会2.7那很多东西都可以快速理解上手. 非目标读者 希望速成的读者 本文的作者相信踏踏实实一步一个脚印是做任何事情的唯一捷径.本教程也被设计成百科全书的样式.光是写作,作者就一个人断断续续写了快3年. 全教程对有一定编程基础的读者来说阅读下来应该是1周左右的量(前提是耐得下心思).而没有编程基础的读者可能读起来会比较吃力,这样连看带消化可能要看上几个月. 当然通篇阅读并不是本文推荐的阅读方式,这个是后话. 其他语言编程习惯\"根深蒂固\"的老程序员和伸手党新人 这几年由于ai技术和大数据技术的火爆,不少老程序员和新手将目光投入到了Python这门语言上,这个趋势当然是好事,有更多的人了解Python,想学习Python当然是pythoner所希望的, 但回顾历史,大学扩招带来了大量劣质大学生,知乎,bilibili等小众社区开方注册带来了大量水军.社区的质量和其成员的质量息息相关.上面提到的这两种人会将社区带向不好的方向,我希望不是我的攻略带他们进的这个领域. 不是很推荐的读者 0基础新人读者 老实说这本攻略是那种比较枯燥无味的读物,的可读性很糟糕.很可能第一部分--工具链的环境配置一节就会劝退大量新人,这可就罪过了.因此不推荐0基础新人,读这个攻略的新人推荐 先去了解下操作系统中的环境变量部分的基本知识 读一本Python的科普型书,比如这本与孩子一起学编程,当然其他相对专业些的书或教程比如官方教程只要读的下去的读过最好. 本教程的内容范围和组织结构 很多人讲Python开发就是搭乐高积木,只要会调包就能用好Python,某种意义上来说这种说法是对的.Python的官方仓库已经有6万多个包,其中有大量非常优质的包. 但本文不是讲怎么调包调啥包的文章,本文写作内容的边界: Python及其标准库 Python在特定领域的准标准库如数学统计领域的numpy,pandas 特定重要领域中的一种选择方案,比如web编程中的sanic,jinja2. 文章将会划分为篇,每一篇下面的单位是章,章下面是节,篇下面可以没有章,这种情况就顺延.篇,章下面都会开头的介绍文字和结尾的结语.介绍用于总体上概括其所属的内容而结语用于介绍一些豆知识,相关的好用第三方库和个人的相关看法,希望读者喜欢. 每一节则是单独的一篇文章.我尽量让各个部分内聚避免耦合,这样可以不用按顺序,但有些确实需要有其他方面基础的那就没办法了,我会在每节开始的部分给出预备知识的超链接方便查看. 每一节中都会有1~3级标题,不会再往下分出4级标题.同时1级标题只会是一节的标题. 总结下就是如下的树状结构 篇-| |-章-| |-节-| |- 1级标题-| |-2级标题-| |-3级标题 或者 篇--| |-节-| |- 1级标题-| |-2级标题-| |-3级标题 在文末会有一个术语表附录,将文中出现的术语做一个总结,如果有的话也会给出wiki链接 下面是每篇的简单介绍 工具链篇 介绍Python社区多年经营并发展出的规范及对应的开发辅助工具 语法篇 介绍Python优雅严谨的语法和惯用法 嵌入与扩展篇 Python常用作胶水语言为一些传统高性能库提供前端,这篇介绍Python与C/C++语言以及Fortain的交互方式. 深入虚拟机篇(整理中) 介绍Python的执行器(也就是虚拟机)的一些知识. 高性能编程篇(构思中) 本篇的重点是如何利用python及相关工具,发挥出机器和python解释器的极限性能. 基础应用篇 介绍python在一些比较普遍通用领域,如时间处理,数据处理,通信,简单运维方面的应用 人机交互篇 介绍python用于构建应用,通过各种工具构建逻辑与用户间接口的过程.主要分为命令行应用,gui应用和web应用 架构与算法篇(整理中) 介绍如何使用动态的Python结合传统上以静态语言为基础来设计的设计模式,数据结构,算法这类技术的内容 数学与统计应用篇(整理中) 介绍使用numpy,pandas做简单数学与统计工作的方法 目前更新是在2018年的6月8日,现在更新好后内容上来说对之前的有所删减,希望在未来3年中可以填完这个大坑 贯穿全文的排版约定 难度分级 由于每个人对使用Python的场景不同,用法不同,需求不同,因此通常我们都只是使用了Python的子集,这没什么不好,同时也为本攻略的编写提出了一个要求--分级 这边给出的分级方案是相对分级,具体说就是在篇/章/节/中1~3级标题中命名以*为开头,为标题的就是相对其他同级的来说进阶一些的内容,这些内容可以选择着看;而使用**开头的的则是相对最基础最重点的内容.需要加深记忆 篇/章/的标题在每个篇/章的介绍页, 向上兼容 本文基于3.5版本,但一旦有新版本出现,那新特性也会被添加进来.为了区分这部分向上兼容的部分,会在标题的末尾中使用[3.6]这样的字样标识出来 ps 一些比较关键的点会使用加粗斜体的PS:字样标识出来 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:27:23 "},"工具链篇/":{"url":"工具链篇/","title":"工具链篇","keywords":"","body":"工具链篇 python论历史比java都要久,但在这波人工智能大潮之前,它只是个小范围流行于学界,在工业界也少有支持者的小众语言;但其最知名的用户是google了,并且在一段时间内python之父还是google员工,python也可以说是google的干儿子,可以说python的发展过程中,google也出了不少力.同时python的开发管理使用的是一种民主提议讨论,中央集权决定是否采用的方式.这种背景总结下来就是: 学界背景--使其开发相对严谨 社区成员相对纯粹--不容易受到外界不良风气影响 工业上有大公司在一定程度上的支持--有应用场景才会有动力发展,也有机会实践 集中式的管理--不容易出现碎片化的问题 在这些背景下,python才有条件发展出一套相对来说成熟稳定的开发工具链. 开发过程无非是这样一个流程: 安装环境 | 安装依赖 | 写代码 | 调试 | debug | 分发部署 | 性能调优迭代 python在每个环节都有对应的工具,而且相对成熟稳定,也几乎不存在多种选择,这其实是一件非常有助于开发的事情,可以让开发者专注于开发而非工具的选择. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/运行环境.html":{"url":"工具链篇/运行环境.html","title":"运行环境","keywords":"","body":"运行环境 python的运行环境当然是只要去官网下载对应版本安装即可,注意,我们这边只讲3.5以上的版本,因此不要下载错了!安装好后要注意环境变量的配置,具体的可以参看官方说明. Anaconda集成环境 更好的工具是使用Anaconda集成环境,这样就可以省去很多配置环境呀,配置依赖的问题,它也可以自动将你的python环境放入系统环境变量,省去了手工配置的麻烦.国内访问Anaconda会比较坑爹,好在有清华的镜像 Anaconda是一个全平台的常用于科学计算的python继承环境包.自带虚拟环境工具,python的版本管理和包管理.用它来安装python可以保证python的隔离性,并且它自带的包足够全面好用.如果嫌弃它太重,那么可以安装miniconda.依然是全平台支持,只是少了自带的包而已,清华提供的下载地址在https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/. Anaconda的就是下载好后bash (windows就是直接双击打开了)然后一路设置就好(完全可以全默认). Anaconda的配置 换源 在墙内的我们最好将清华的源添加至默认,清华的源除了提供了anaconda自己维护的包源外还提供了几个常用的第三方源,包括Conda Forge,msys2,bioconda,menpo. 使用命令行设置 清华源的帮助文档上已经写清楚了如何通过命令行添加源. conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/ conda config --set show_channel_urls yes 使用配置文件设置 linux,mac用户编辑~/.condarc,windows用户编辑C:\\Users\\\\.condarc,输入如下内容即可. channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/ - defaults show_channel_urls: yes 配置代理 如果已经配置了conda的国内镜像,name通常是不需要再做其他设置的.但如果一些包依然需要使用代理,那么同样可以在其配置文件.condarc中设置使用代理. proxy_servers: http: http://myname:mypwd@proxy-blabla.fr:8080 https: https://myname:mypwd@proxy-blabla.fr:8080 需要注意的是pip和conda都不能使用socks5代理. 虚拟环境 我们希望项目的环境依赖是独立隔离的,每个项目间各自不会影响其他的项目,最成熟传统的做法就是使用虚拟环境了.虚拟环境可以理解为node.js中npm工具的本地安装,他会把用到的包包括python的虚拟机都放到你指定的目录下,在一个terminal进程中只要你激活了那个虚拟环境,你用到的与python相关联的东西就都是虚拟环境中的了. python3中自带了工具pyvenv(PEP 405)来构建虚拟环境,而如果希望统一的管理虚拟环境,则Anaconda提供的虚拟环境功能可能更加合适 pyvenv使用方法 pyvenv 创建虚拟环境到指定目录 source /bin/activate 使用虚拟环境,在windows下是 /bin/activate.bat 激活后会看到你的命令行每行前面多出一个(venv)字样，表示你在使用虚拟环境 deactivate 退出虚拟环境 Anaconda虚拟环境和多版本的管理 ananconda也有虚拟环境工具,而且可以通过虚拟环境实现多版本python的管理使用,也就是说Anaconda的虚拟环境工具除了创建虚拟环境,还是python的版本控制工具. 创建虚拟环境 conda create -n python= [collection] 输入以上命令我们就建立了一个以为名字的虚拟环境,并且代码和虚拟机都将放在/envs/文件夹下.我们需要指定python的版本,如果想顺便把一些要用的包装了,可以在[collection]位置加上要的包. 激活虚拟环境 Anaconda的虚拟环境激活不需要我们记住虚拟环境创建在哪里,只要记住名字就行 在linux或者mac上使用source activate ,在windows上使用activate 即可,需要注意的是windows下的powershell shell有一个bug,无法激活虚拟环境,要使用的话记得切换到cmd. 退出虚拟环境 在linux或者mac上使用source deactivate,在windows上使用deactivate就可以退出当前的虚拟环境了 查看有哪些虚拟环境 conda env list 要删除一个虚拟环境 conda remove -n --all *关于pypy pypy是现今活下来的cpython外最好的python实现,它使用jit技术,因此比cpython快的不是一星半点.有测试pypy的io效率与node相当,而cpu密集型任务如果使用python自带的数据结构也比原生cpython快上2~3倍.现在对python3.5有个beta版本的支持,目前还不太完善. 抛开这些不说,pypy的c扩展能力很差,许多带c扩展的模块要么无法在其上使用,要么比在cpython上慢很多.因此可以关注,但并不推荐使用 *关于docker docker有官方的python镜像,我们可以直接取来用,如何使用这个镜像创建python应用的镜像并运行可以看我的这篇文章,具体的docker怎么用,那是另一个故事了. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:51:56 "},"工具链篇/包的安装管理与分发.html":{"url":"工具链篇/包的安装管理与分发.html","title":"包的安装管理与分发","keywords":"","body":"包的安装管理与分发 现代的编程场景早已从单打独斗的个人行为转向了多人合作集体行为.而现代编程语言也都有模块化支持以适应模块化的项目编程.python作为一门历史悠久的现代编程语言拥有让许多优秀的第三方包.现如今多数优质的第三方模块都注册在pip上可以很方便的下载安装.而github的兴起也促进了python社区的繁荣,每年都会有很多新的优秀的第三方模块进入pythoner的视野中. 历史悠久的同样意味着历史包袱.与javascript的npm相比,pip并不优秀,而由于python的版本割裂问题,也造成了许多第三方库无法向后兼容,但由于python语言尽量坚持一致性原则和实用至上的理念,python的第三方包相对整体质量更高也更易于定制.因此可以说python的包管理在现今看来依然是实用高效的. python方便的模块引入语法简洁实用,配合第三方库可以让用户有着如同玩乐高积木一般的优秀体验.javascript的ES6语法中模块引入语法很大程度上借鉴了python的模块语法. 本文需要先了解 什么是模块/包 模块/包的导入方法 安装包的方法: python安装包其实很简单,只要将包下载好放入sys.path可以查找到的路径即可.社区为了统一,封装,自动化这一过程,规定了两种用于安装包的文件setup.py和setup.cfg以及与这套规范配套的标准库工具distutils,而后随着社区的发展,一个对distutils进行封装扩展的新工具setuptools诞生了,现在setuptools基本已经成为了标准库工具distutils的替代品. 安装定义文件(setup.py) 安装脚本setup.py就类似npm的package.json,它负责设定包的基本信息和依赖,以下是一个官方的例子的改版 setup.py: # 一般用setuptools from setuptools import setup, find_packages,Command # 维持不同平台文件相同的编码 from codecs import open import distutils from os import path import os import subprocess here = path.abspath(path.dirname(__file__)) # 用同文件夹下的README.rst文件定义长介绍 with open(path.join(here, 'README.rst'), encoding='utf-8') as f: long_description = f.read() # 用同文件夹下的requirements.txt文件定义运行依赖 with open(path.join(here, 'requirements.txt'), encoding='utf-8') as f: REQUIREMETS = f.readlines() packages=find_packages(exclude=['contrib', 'docs', 'test']) class CoverageCommand(Command): description = \"覆盖率\" user_options = [ (\"output=\",\"o\",\"选择报告的输出方式\") ] def initialize_options(self): self.cwd = None self.output = '' def finalize_options(self): self.cwd = os.getcwd() if self.output and self.output not in (\"report\",\"html\"): raise Exception(\"Parameter --output is missing\") def run(self): assert os.getcwd() == self.cwd, 'Must be in package root: {self.cwd}'.format(self=self) command = ['/usr/bin/env', 'python', '-m', 'coverage'] if self.output: command.append('{self.output}'.format(self=self)) else: command.append('report') self.announce('Running command: {command}'.format(command = str(command)), level=distutils.log.INFO) subprocess.check_call(command) class TestCommand(Command): description = \"测试\" user_options = [] def initialize_options(self): self.cwd = None def finalize_options(self): self.cwd = os.getcwd() def run(self): assert os.getcwd() == self.cwd, 'Must be in package root: {self.cwd}'.format(self=self) command = ['/usr/bin/env', 'python', '-m', 'coverage','run' ,'--source=score_card_model', '-m', 'unittest', 'discover', '-v', '-s', 'test'] self.announce('Running command: {command}'.format(command = str(command)), level=distutils.log.INFO) subprocess.check_call(command) setup( name='score_card_model', version='0.0.1', description='A sample Python project', long_description=long_description, # 项目地址 url='https://github.com/pypa/sampleproject', # 作者信息 author='The Python Packaging Authority', author_email='pypa-dev@googlegroups.com', # 维护者信息 maintainer = \"\", maintainer_email = \"\", # 指定可用的平台,一般有c扩展的可能会用到 platforms = [\"any\"], # 许可证信息 license='MIT', # 分类信息,具体看 https://pypi.python.org/pypi?%3Aaction=list_classifiers classifiers=[ # 发展时期,常见的如下 # 3 - Alpha # 4 - Beta # 5 - Production/Stable 'Development Status :: 3 - Alpha', # 开发的目标用户 'Intended Audience :: Developers', # 属于什么类型 'Topic :: Software Development :: Build Tools', # 许可证信息 'License :: OSI Approved :: MIT License', # 目标python版本 'Programming Language :: Python :: 2', 'Programming Language :: Python :: 2.7', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.3', 'Programming Language :: Python :: 3.4', 'Programming Language :: Python :: 3.5', ], # 关键字 keywords='sample setuptools development', # 指定用到的模块,find_packages会找到同文件夹下的模块,用`exclude`指定排除的模块 packages=packages, # 运行时使用的依赖 install_requires=REQUIREMETS, # 是否支持直接引用zip文件,这是setuptools的特有功能 zip_safe=False, # 额外环境的依赖,一般不单独用文件指出 # for example: # pip install -e .[dev,test] # extras_require={ # 'dev': ['check-manifest'], # 'test': ['coverage'], # }, # 指定可执行脚本,如果安装,脚本会被放到默认安装路径 #scripts=[\"scripts/test.py\"], # 模块如果有自带的数据文件,可以用package_data指定 #package_data={ # 'sample': ['package_data.dat'], #}, # 指定模块自带数据所在的文件夹 data_files=[('./', ['requirements.txt'])], # 定义自定义命令 cmdclass = { 'coverage':CoverageCommand, 'test':TestCommand } ) *关于版本号 pep-440定义了符合python规范的版本号格式.当然了这不是强制要求,你要是喜欢也可以按npm的规范定义版本号,或者自己定义一套规范.最重要的是不能有歧义而且便于管理.当然了更加推荐按照pep-440的规范定义版本号. *定义setup.py的子命令 类似package.json,setup.py也可以定义子命令,就是相比node.js的要稍微麻烦些.需要继承setuptools.Command, 需要重写其中的元素: description 描述字符串 user_options 保存子参数设置的列表,每个元素为一个3元的元组,第一位为全称(--xxx),第二位为简称(-o),第三位为描述文字 [(\"output=\",\"o\",\"选择报告的输出方式\")] 其中的方法 initialize_options(self) 初始化子参数self.output = '' finalize_options(self) 判断命令行与设置的匹配与否和后续操作if self.output and self.output not in (\"report\",\"html\"): raise Exception(\"Parameter --output is missing\") run(self) 运行逻辑 assert os.getcwd() == self.cwd, 'Must be in package root: 安装包 在上面的步骤定义完成后只要执行python setup.py install就会将这个包安装到python安装目录下的site-packages文件夹中 包管理 python最常用的包管理工具就是官方的pip,当然Anaconda的conda命令也可以作为包管理工具使用,而且可能更加方便一些,但其实conda命令下载安装python的包也是用的pip. pip pip是python的官方第三方包管理工具(PEP 453)，收录了大部分的第三方包。多数自带python的系统如mac osx， ubuntu都已经有现成的pip安装着了。如果确实没有pip可以去https://pip.pypa.io/en/latest/installing.html#python-os-support 下载get-pip.py文件,下载到本地后，cd到同一文件夹下使用python get-pip.py安装.基本上不会有人不装pip,因为如果不用它,python就少了很多便利性 pip基本使用: pip命令可以单独作为脚本命令使用如pip list,也可以配合python解释器使用python -m pip list 后一种方式的好处是可以在不同的python环境使用pip,pip会自己把模块安装到指定python的第三方包文件夹下 安装模块 pip install packageName 下载并安装最新的版本 pip install packageName==1.0.0下载并安装指定版本 pip install 'packageName>=1.0.0 下载并安装至少某个版本以上的版本的包 pip install url #从指定网址资源安装 pip install path #指定本地位置安装 pip install --find-links=url 从指定url下载安装 pip install --find-links=path 从指定path下载安装 pip install --upgrade packageName 更新一个已经安装过的过期模块 从需求文件安装模块 pip freeze > requirements.txt 将当前pip管理的模块信息存储进文本文件 pip install -r requirements.txt 从文本文件安装依赖的模块 卸载 pip uninstall 查找 pip search 查看模块信息 pip show 查看pip管理了哪些模块 pip list pip list --outdated 查看过期的模块 配置pip pip的配置通常保存在~/.pip/pip.conf中,如果在你的机器上这个路径不存在,你可以自己创建进行配置. pip的国内源设置 感谢天朝的伟大电子长城,我们很多时候无法练到pypi的服务器,还好国内豆瓣有个一直在维护的镜像站可以提供源作为替代 如何设置呢? 在你的pip的配置文件中更新上如下内容: [global] index-url = http://pypi.douban.com/simple trusted-host = pypi.douban.com pip的代理设置 另一种方式就是翻墙,翻墙的话就是靠代理了,在你的pip的配置文件中更新上如下内容: [global] proxy=server:port 通过pip安装本地包 pip工具支持直接安装本地的模块,像wheel打包过的模块就可以直接使用pip安装 pip install somedir/xxxxxx.wheel conda 包管理工具 Anaconda的定位是数据科学工具箱,它其实并不局限于python. 我们的pip和conda并不冲突,而conda实际上也是依赖于pip工具的,用conda的好处是: 有些复杂的安装过程他会帮你省去, 可以用它安装一些Anaconda公司的商业工具 它对于包版本的追踪更加细致. 可以用它安装一些不是python包的工具,尤其一些C/C++工具,比如windows下的minwg. 和pip一样,conda list是查看已安装包信息的工具 而查找包还是conda search 要安装也还是conda install,只是它可以加上参数--name 来为特定环境跨环境安装包 而删除包就和pip有所不同了,它使用的是conda remove 命令. *包分发 无论使用哪种方式管理python的第三方模块,如果想将自己的包分发出去与别人共享,都应该使用官方的pypi平台.和npm一样,作为开发者,你需要先注册才可以上传代到代码库.注册的时候注意,password必须大于16位,PGPkeyID可以不填. 表单提交好后登入邮箱验证即可注册完成. 将包注册到pypi服务器 完成pypi上的注册,并定义好setup.py脚本后就可以将自己写的模块上传到pypi服务器上了. 注册包 cd到 项目根目录 python setup.py register 用刚才注册的信息来注册本台电脑 注意直接这样会有可能报错,因为和原来有个名字太接近了. 我们应该先检查下名字 pip search 用来查看有哪些相关的包,我们得确定没有重名 上传 Python setup.py sdist upload 分发模块 setuptools支持的分发格式可以在python官网查看,打包方式都是使用 python setup.py *使用wheel分发模块 本部分主要以wheel为例. wheel是官方钦定的包分发格式,它本质上是一个zip包,使用.whl作为扩展名.wheel包的分发模式并不是为中心化的pypi设计的,而是为了方便点对点的传播,因此wheel模块更多的是本地安装 现有支持wheel的模块: 现有支持wheel的模块已经不少,而且很多wheel是为了针对不同操作系统而额外打包的.pypi官方的wheel支持列表可以在http://pythonwheels.com/找到,而许多科学计算工具在windows下的wheel可以在http://www.lfd.uci.edu/~gohlke/pythonlibs/找到 将模块打包成wheel wheel提供了一个bdist_wheel作为 setuptools 的扩展命令，这个命令可以用来生成wheel包。 python setup.py bdist_wheel pip提供了对wheel的支持,setup.cfg 可以用来定义wheel打包时候的相关信息. *本地架设pypi服务器 很多时候我们会有这样一种需求,我们希望我们的包私有或者在小范围内传播,这时候我们就可以架设本地的pypi服务器了 本地架设pypi服务器可以使用pypiserver或者localshop他们用法差不多,不同之处在于前者更轻些,而后者除了可以本地架设pypi服务器外还可以自动镜像pypi的包仓库. *工具安利 pmfp(python3.5以上可用)是我写的一个仿照npm的包管理统一平台,目前在测试阶段,但已经可用,它封装了pip,setuptools,pyvenv,zipapp等工具的操作,并设定了几个常用框架的模板,有兴趣的同学可以尝试使用,顺便帮我找找bug,这个工具我并没有写测试,而是打算用边用边测的形式逐步完善它.希望有同学一起帮我完成这个项目,不胜感激! 关于重复造轮子 python提倡任何事务总有一种最好的方式实现,并不鼓励重复造轮子(虽然事实上python重复的轮子相当多,官方与社区也总会有意见不统一的情况发生).自己写一些模块固然可以,但最好还是先看看有没有现成的实现. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:51:42 "},"工具链篇/交互环境jupyter/":{"url":"工具链篇/交互环境jupyter/","title":"交互环境jupyter","keywords":"","body":"*交互环境Jupyter python是一门脚本语言,它可以按行执行.当你安装好了python环境后,在你的terminal中输入python就可以进入一个所谓的交互环境,你敲一行代码它执行一行代码. 交互环境已经被证明是非常有用的工具,现如今即便是java在java9中都有了交互环境支持.但老实说python的默认交互环境不好用,很原始很不智能. Jupyter项目脱胎于ipython项目--一个更加友好的python交互环境工具.目前已经发展成了一个多功能的交互环境.这个交互环境的主要目标用户是数据科学家.他们不同于一般开发者或者脚本小子,需要在交互环境下代码可以做修改,可以插入文本标记语言做更加专业的注释,需要可以插入latex公式,需要可以在交互界面直接展示可视化的成果,同时希望这个工具可以方便他们优化代码性能,甚至处理一些大规模分布式计算的需求. 这些需求造就了现在的jupyter项目.它也是数据科学家python技术栈中必定存在的一员. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:54:30 "},"工具链篇/交互环境jupyter/基于web的可交互运行环境jupyter.html":{"url":"工具链篇/交互环境jupyter/基于web的可交互运行环境jupyter.html","title":"基于web的可交互运行环境jupyter","keywords":"","body":"基于web的可交互运行环境jupyter 写了这么久还没介绍我写这些的平台,jupyter notebook Jupyter 是ipython notebook 脱离ipython项目后的一个独立项目.不同于notebook, Jupyter已经不再只是python的交互执行框架, 而是致力于多语言通用的交互执行. 在以前 notebook作为ipython的一个子项目就受到许多人的喜爱和追捧,当时就已经可以通过多种途径利用它执行其他非python语言. 现在Jupyter 与ipython分家后,这一特性得到了更好的支持. 现在的Jupyter只负责交互执行,而执行的是什么语言其实是由其执行核心--kernel 来实现的,而现在的ipython可以自带其执行python版本的python核心. 本文也会顺带介绍几种支持Jupyter的优秀的语言. 至于ipython部分会单独拉出来讲,毕竟很多很实用 Jupyter的安装: Jupyter 现在是独立安装.当然,你依然需要装有python 和 pip. $pip install jupyter 如果你用brew 安装的python3,那么自然的 $pip3 install jupyter 运行 $jupyter notebook 当然了,没有kernel是没法运行的 *Jupyter的多语言支持 在这里你可以看到目前支持的语言. 下面介绍几个比较值得安装的的kernel安装: 本文中介绍的的kernel只在mac下测试安装成功,在linux下应当都能成功,但windows下未必. 欢迎朋友们写下其他平台的经验,我看到也会进行修改,谢谢 通用依赖 几乎所有kernel都需要zeromq和openssl这两个库,他们都可以用brew安装 brew install zeromq brew install openssl Jupyter 对于各个语言的支持其实都是通过所谓的核(kernel)来实现的,操作核的命令是jupyter kernelspec 和常规一样, list 查看已有核的状态 install 安装一个核,不过一般来说这些核都不是用这个方法装的 remove/uninstall 移除一个核 python2与python3并存 安装依赖 python的kernel自然依赖于python. 对于新手来说python2和python3并存本身就是件比较纠结蛋碎的事儿,mac下一般会用homebrew安装两个版本 (当然也会有人安装其他比如pypy之类,那个咱不管) $brew install python $brew install python3 如果是这样安装,那python python2 python3对应的便是不同版本的python如下表(可能版本不同有些许不同) 命令 python来源 pip命令 库位置 python brew 安装的 python pip /usr/local/lib/python2.7/site-packages python2 brew 安装的 python pip /usr/local/lib/python2.7/site-packages python3 brew 安装的 python3 pip3 /usr/local/lib/python3.4/site-packages 安装kernel 分别安装ipython,在各自环境下执行 $pip install ipython[all] $ipython kernelspec install-self $pip3 install ipython[all] $ipython kernelspec install-self 测试下 打开Jupyter: jupyter notebook 可以在new看到里面出现Python 2和Python 3两个可选项 pypy 事实上jupyter并没有专门的pypy核心,但其实要用pypy比其他的都简单,我们通过ipython kernelspec list找到自己原本的python核所在的目录,进去这个目录找到核文件夹,我们把它复制一份改名叫pypy,然后在pypy环境中pip安装jupyter,这样原本的python的核就会被替换掉,我们只要给这俩核的文件夹名和其中的kernel.json中的display_name对掉下就好了 Golang Go语言是谷歌几年前推出的一门编译型语言,它以简洁优雅高,高开发效率,高可维护性和善于处理高并发而著称 Go有一套完善的开发流程和语言规范,目前这个kernel还有许多不支持的地方,因此只是安装着而已,没有实际作用 安装依赖 go语言: go语言只要用homebrew安装即可 $brew install go 安装好后要在~/.bash_profile内添加以下语句(中你的go项目位置)后resource下激活或者重启计算机 export GOPATH=你的go项目位置#GOPATH可以有多个,用:隔开,其中第一个回存放 go get 命令下载的库文件会放在第一个位置上 如果你希望你的 export PATH=${GOPATH//://bin:}/bin:$PATH gophernotes 这是一个go语言的解释器,可以写一句执行一句,它也自带一个交互命令行工具 安装: 首先它依赖go的一个包叫做goimports,安装的话墙外很简单 $ go get golang.org/x/tools/cmd/goimports 但墙外我们就得用这个 它的安装默认是依赖zmq2.2.x,但我想大多数人都装的是zmq4.x吧,所以只要这么安装 $ go get -tags zmq_4_x github.com/gophergala2016/gophernotes 安装kernel $mkdir -p ~/.ipython/kernels/gophernotes 然后去你的第一个GOPATH下找到/src/github.com/takluyver/igo/kernel/文件夹,之后复制进.ipython/kernels/gophernotes 之后修改其中的kernel.json,将其中的$GOPATH替换成自己的的gopath 测试下 切换Kernel到Golang 1.5 :import \"fmt\" word := \"world\" \"world\" fmt.Sprintf(\"hello %s\",word) \"hello world\" channels msg := make(chan string) (chan string)(0xc820072060) go func() {msg message := \"ping\" 例子 :import \"fmt\" fmt.Print(\"1\") 11 go语言可以看这篇来学习 Javascript(node.js) 安装依赖 node.js $ brew install node 安装kernel $ sudo npm install -g ijavascript $ sudo npm install -g --save-dev babel-preset-es2015 配套设施--balel babel是一个将ES6标准的js代码转换为可在浏览器中运行的ES5代码的工具.我们可以安装ibabel来使用它 $ sudo npm install -g jp-babel@0.0.6 注意要用老版本,因为新版的babel有bug 测试下 切换Kernel到JavaScript(Node.js) var Animal = { createNew: function(){ var animal = {} animal.sleep = function(){ return \"Zzzzz\" } return animal } } var Dog = { createNew: function(name){ var dog = Animal.createNew()//继承 dog.name = name dog.makeSound = function(){ return \"wangwang\" } return dog } } a=Dog.createNew(\"doggy\") a.makeSound() 'wangwang' R 似乎是很受数据科学家由其统计出身的人欢迎的一种语言.但是语法别扭,个人不喜欢,但是还是得学习 安装依赖 R 下载新版(3.22)R语言安装包 然后双击安装 安装kernel install.packages(c('rzmq','repr','IRkernel','IRdisplay'), repos = c('http://irkernel.github.io/', getOption('repos'))) IRkernel::installspec() 测试下 写个身高的简单统计计算吧: 先安装sca包: > install.packages(\"sca\") 切换Kernel到R: library(sca) height=c(1.75,1.82,1.78,1.93,1.77) weight=c(69,80,78,96,65) age=c(19,21,20,26,17) group_A=data.frame(height,weight,age) print(group_A) sum_h=sum(group_A$height)#身高求和 cat(\"身高和:\",sum_h,\"\\n\") cat(\"分布:\\n\") cat(percent(group_A$height/sum_h),\"\\n\") cat(\"身高均值\",mean(group_A$height),\"\\n\") sum_w=sum(group_A$weight)#体重求和 cat(\"体重和:\",sum_w,\"\\n\") cat(\"分布:\\n\") cat(percent(group_A$weight/sum_w),\"\\n\") cat(\"体重均值\",mean(group_A$weight),\"\\n\") height weight age 1 1.75 69 19 2 1.82 80 21 3 1.78 78 20 4 1.93 96 26 5 1.77 65 17 身高和: 9.05 分布: 19 % 20 % 20 % 21 % 20 % 身高均值 1.81 体重和: 388 分布: 18 % 21 % 20 % 25 % 17 % 体重均值 77.6 Scala Scala应该是后起语言中的新星了,同时支持面向对象编程和函数式编程的特性让它分外耀眼,而拥有类型推断又让它显得十分简洁优雅. 它与Java间的联系又让它因为有衬托对比而显得格外讨喜. 安装依赖 自然要安装scala了 brew install scala 留意安装的是什么版本 安装kernel 虽然列表中推荐的是iscala 但还有一个更加简单的方式--jupyter-scala** 这个方法就是简单无脑的下载下来然后运行脚本 2.10版本的scala下载这个 2.11版本的下载这个 解压到一个安全的位置然后运行其中bin文件夹下的的jupyter-scala脚本自动完成安装 用 $ipython kernelspec list 查看是否有scala211或者scala210这样的输出,有的话之后运行 $ipython console --kernel scala211 这样再用jupyter notebook进入就能找到Scala 2.11了 当然这样如果以后scala升级了那就无法使用最新版本了,解决方法就是自己本地编译 测试下 写个简单的尾递归求阶乘 切换Kernel到Scala 2.11 def factorial(n:Int):Int = { if(n >0) n * factorial(n-1) else 1 } defined \u001b[32mfunction \u001b[36mfactorial\u001b[0m factorial(5) \u001b[36mres1\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m120\u001b[0m 学习scala可以去这里 Spark 安装依赖 Spark 这个不必多介绍,大数据的主流工具之一,安装可以看我以前的帖子 安装kernel github上下载源文件 cd 进入源文件根目录,然后 $sbt compile $sbt pack 编译好后执行 $(cd kernel/target/pack && make install) 之后你的home文件夹下会多出一个/local的文件夹,其中kernel文件夹存放jar文件 bin/sparkkernel是启动脚本 如果都成功了,那么运行 ~/local/bin/sparkkernel 应该可以看到kernel运行了 与jupyter链接 cd ~/.ipython/kernels/ mkdir spark touch spark/kernel.json 改写kernel.json为 { \"display_name\": \"Spark 1.2.1 (Scala 2.10.4)\", \"language\": \"scala\", \"argv\": [ \"///local/bin/sparkkernel\", \"--profile\", \"{connection_file}\" ], \"codemirror_mode\": \"scala\" } 这样就可以用本地模式测试代码了 测试下 切换Kernel到Spark1.6.0 写一个用mapreduce求pi的函数: val NUM_SAMPLES = 10000 val count = sc.parallelize(1 to NUM_SAMPLES).map{i => val x = Math.random() val y = Math.random() if (x*x + y*y Pi is roughly 3.132 写个简单的线性回归: 将数据下载到同级目录 import org.apache.spark.mllib.regression.LabeledPoint import org.apache.spark.mllib.regression.LinearRegressionModel import org.apache.spark.mllib.regression.LinearRegressionWithSGD import org.apache.spark.mllib.linalg.Vectors val data = sc.textFile(\"source/lpsa.data\") val parsedData = data.map { line => val parts = line.split(',') LabeledPoint(parts(0).toDouble, Vectors.dense(parts(1).split(' ').map(_.toDouble))) }.cache() val numIterations = 100 val model = LinearRegressionWithSGD.train(parsedData, numIterations) // Evaluate model on training examples and compute training error val valuesAndPreds = parsedData.map { point => val prediction = model.predict(point.features) (point.label, prediction) } val MSE = valuesAndPreds.map{case(v, p) => math.pow((v - p), 2)}.mean() println(\"training Mean Squared Error = \" + MSE) // Save and load model model.save(sc, \"myModelPath\") val sameModel = LinearRegressionModel.load(sc, \"myModelPath\") training Mean Squared Error = 6.207597210613578 学习spark可以参考官方文档 Itorch(lua) Itorch这是一个lua的机器学习框架,用的虽然不多但既然是学这个的又蛮喜欢lua那就一并写上吧 安装依赖 Torch 安装: curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash git clone https://github.com/torch/distro.git ~/torch --recursive cd ~/torch; ./install.sh 这样就可以安装torch到~/torch下了 然后在.bash_profile中写入 . /Users/huangsizhe/torch/install/bin/torch-activate 这样就可以使用torch了 打开torch的交互shell: $th 安装kernel git clone https://github.com/facebook/iTorch.git cd iTorch luarocks make 测试下 切换Kernel到iTorch: function fib(n) if n fib(20) 10946 更多的lua和torch教程可以点击对应链接查看 C/C++ 想象下C++这种竟然可以依靠强大的LLVM和Clang实现脚本化,是不是很激动~~ 安装依赖 cling从这里下载对应版本的安装包,解压到希望的位置即可 设定一下环境变量CLING_EXE=你的cling安装目录下cling的具体位置 安装 下载https://github.com/minrk/clingkernel,cd进去后 python setup.py install 安装成功后执行 jupyter kernelspec install cling 测试下 切换Kernel到C++: #include printf(\"Hello World!\\n\") Hello World! (int) 13 .rawInput void test() {//方法 printf(\"just a test\"); } .rawInput test() just a test auto func = [](int a, int b) -> int { return a+b; };//c++11中的匿名函数 func(2, 3) (int) 5 .rawInput class Rectangle {//类 private: double w; double h; public: Rectangle(double w_, double h_) { w = w_; h = h_; } double area(void) { return w * h; } double perimiter(void) { return 2 * (w + h); } }; .rawInput Rectangle r = Rectangle(5, 4); r.area() (double) 20.0000 scheme 安装这个是为了学这本书,作为Lisp的方言,scheme确实不简单.我安装的是基于ipython的calysto_scheme 安装 再github上下载https://github.com/Calysto/calysto_scheme然后只要cd到目录 python3 setup.py install 测试 求斐波那契数列 (begin (define (factorial n) (define (iter product counter) (if (> counter n) product (iter (* counter product) (+ counter 1)))) (iter 1 1)) (factorial 10) ) 3628800 (begin (define fib (lambda (n) (cond ((= n 0) 1) ((= n 1) 1) (else(+ (fib (- n 1)) (fib (- n 2)) ) ) ) ) ) (fib 5) ) 8 haskell 传说中的语言,想了解的可以看一本萌系的书 通过它学习函数式编程几乎是业界共识吧(笑) 安装 ihaskell只能在类unix系统上安装,安装也简单,mac下直接 git clone http://www.github.com/gibiansky/IHaskell cd IHaskell ./macos-install.sh 然后等就行了 测试下: Kernel切换到haskell: import IHaskell.Display data Color = Red | Green | Blue instance IHaskellDisplay Color where display color = return $ Display [html code] where code = concat [\"Look!\"] css Red = \"red\" css Blue = \"blue\" css Green = \"green\" Red Green Blue / Custom IHaskell CSS. / / Styles used for the Hoogle display in the pager / .hoogle-doc { display: block; padding-bottom: 1.3em; padding-left: 0.4em; } .hoogle-code { display: block; font-family: monospace; white-space: pre; } .hoogle-text { display: block; } .hoogle-name { color: green; font-weight: bold; } .hoogle-head { font-weight: bold; } .hoogle-sub { display: block; margin-left: 0.4em; } .hoogle-package { font-weight: bold; font-style: italic; } .hoogle-module { font-weight: bold; } .hoogle-class { font-weight: bold; } / Styles used for basic displays / .get-type { color: green; font-weight: bold; font-family: monospace; display: block; white-space: pre-wrap; } .show-type { color: green; font-weight: bold; font-family: monospace; margin-left: 1em; } .mono { font-family: monospace; display: block; } .err-msg { color: red; font-style: italic; font-family: monospace; white-space: pre; display: block; } unshowable { color: red; font-weight: bold; } .err-msg.in.collapse { padding-top: 0.7em; } / Code that will get highlighted before it is highlighted / .highlight-code { white-space: pre; font-family: monospace; } / Hlint styles / .suggestion-warning { font-weight: bold; color: rgb(200, 130, 0); } .suggestion-error { font-weight: bold; color: red; } .suggestion-name { font-weight: bold; } Look! / Custom IHaskell CSS. / / Styles used for the Hoogle display in the pager / .hoogle-doc { display: block; padding-bottom: 1.3em; padding-left: 0.4em; } .hoogle-code { display: block; font-family: monospace; white-space: pre; } .hoogle-text { display: block; } .hoogle-name { color: green; font-weight: bold; } .hoogle-head { font-weight: bold; } .hoogle-sub { display: block; margin-left: 0.4em; } .hoogle-package { font-weight: bold; font-style: italic; } .hoogle-module { font-weight: bold; } .hoogle-class { font-weight: bold; } / Styles used for basic displays / .get-type { color: green; font-weight: bold; font-family: monospace; display: block; white-space: pre-wrap; } .show-type { color: green; font-weight: bold; font-family: monospace; margin-left: 1em; } .mono { font-family: monospace; display: block; } .err-msg { color: red; font-style: italic; font-family: monospace; white-space: pre; display: block; } unshowable { color: red; font-weight: bold; } .err-msg.in.collapse { padding-top: 0.7em; } / Code that will get highlighted before it is highlighted / .highlight-code { white-space: pre; font-family: monospace; } / Hlint styles / .suggestion-warning { font-weight: bold; color: rgb(200, 130, 0); } .suggestion-error { font-weight: bold; color: red; } .suggestion-name { font-weight: bold; } Look! / Custom IHaskell CSS. / / Styles used for the Hoogle display in the pager / .hoogle-doc { display: block; padding-bottom: 1.3em; padding-left: 0.4em; } .hoogle-code { display: block; font-family: monospace; white-space: pre; } .hoogle-text { display: block; } .hoogle-name { color: green; font-weight: bold; } .hoogle-head { font-weight: bold; } .hoogle-sub { display: block; margin-left: 0.4em; } .hoogle-package { font-weight: bold; font-style: italic; } .hoogle-module { font-weight: bold; } .hoogle-class { font-weight: bold; } / Styles used for basic displays / .get-type { color: green; font-weight: bold; font-family: monospace; display: block; white-space: pre-wrap; } .show-type { color: green; font-weight: bold; font-family: monospace; margin-left: 1em; } .mono { font-family: monospace; display: block; } .err-msg { color: red; font-style: italic; font-family: monospace; white-space: pre; display: block; } unshowable { color: red; font-weight: bold; } .err-msg.in.collapse { padding-top: 0.7em; } / Code that will get highlighted before it is highlighted / .highlight-code { white-space: pre; font-family: monospace; } / Hlint styles / .suggestion-warning { font-weight: bold; color: rgb(200, 130, 0); } .suggestion-error { font-weight: bold; color: red; } .suggestion-name { font-weight: bold; } Look! 一些技巧 !用来执行shell命令 比如!cat a.txt可以查看a.txt的内容 利用这个技巧配合atom等有命令行工具的文本编辑器可以实现对编译语言的编译和运行 魔法命令%(不是所有都有,ipython的一定有) 输入%magic可以查看有哪些魔法命令 尽量不要让jupyter打印循环或者递归,如果出错可能会卡死,下次也打不开,处理方法是用文本编辑器打开ipynb文件,直接删除对应的cell内容和打印内容 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 15:27:59 "},"工具链篇/交互环境jupyter/ipython与魔法命令/ipython与魔法命令.html":{"url":"工具链篇/交互环境jupyter/ipython与魔法命令/ipython与魔法命令.html","title":"ipython与魔法命令","keywords":"","body":"ipython与魔法命令 python语言的动态特性让它十分适合做科学计算,但原生的shell实在不给力,于是ipython应运而生,简单说ipython就是一个交互环境,但它确实的提高了码代码的效率,尤其与从他分离出去的jupyter notebook配合,可以实现程序,文档,演示的混合编辑.附带的宏命令机制魔法命令也是很好的补充,可以简单的实现一些单纯python要很麻烦才能实现的功能,与它的子项目ipyparallel配合更是可以简单实现多核并行运算,算是对cpython线程锁的一个弥补,它还支持内嵌Cython等扩展,非常强大. 本文主要讲它的使用和设置方法,以及魔法命令 默认的魔法命令 魔法命令都以%或者%%开头,可以理解为ipython里定义的宏或者内置方法,以%开头的成为行命令，%%开头的称为单元命令。行命令只对命令所在的行有效，而单元命令则必须出现在单元的第一行，对整个单元的代码进行处理。 执行%lsmagic可以查看关于各个命令的说明，而在命令之后添加?可以查看该命令的详细说明。 %lsmagic Available line magics: %alias %alias_magic %autocall %automagic %autosave %bookmark %cat %cd %clear %colors %config %connect_info %cp %debug %dhist %dirs %doctest_mode %ed %edit %env %gui %hist %history %killbgscripts %ldir %less %lf %lk %ll %load %load_ext %loadpy %logoff %logon %logstart %logstate %logstop %ls %lsmagic %lx %macro %magic %man %matplotlib %mkdir %more %mv %notebook %page %pastebin %pdb %pdef %pdoc %pfile %pinfo %pinfo2 %popd %pprint %precision %profile %prun %psearch %psource %pushd %pwd %pycat %pylab %qtconsole %quickref %recall %rehashx %reload_ext %rep %rerun %reset %reset_selective %rm %rmdir %run %save %sc %set_env %store %sx %system %tb %time %timeit %unalias %unload_ext %who %who_ls %whos %xdel %xmode Available cell magics: %%! %%HTML %%SVG %%bash %%capture %%debug %%file %%html %%javascript %%js %%latex %%markdown %%perl %%prun %%pypy %%python %%python2 %%python3 %%ruby %%script %%sh %%svg %%sx %%system %%time %%timeit %%writefile Automagic is ON, % prefix IS NOT needed for line magics. 用!调用系统命令 ipython可以很方便的调用系统命令,只要用!就行 !ls \u001b[31mcount_file0.txt\u001b[m\u001b[m \u001b[31mcount_file1.txt\u001b[m\u001b[m \u001b[31mcount_file2.txt\u001b[m\u001b[m \u001b[31mcount_file3.txt\u001b[m\u001b[m \u001b[31mcount_file4.txt\u001b[m\u001b[m \u001b[31mcount_file5.txt\u001b[m\u001b[m \u001b[31mcount_file6.txt\u001b[m\u001b[m \u001b[31mcount_file7.txt\u001b[m\u001b[m \u001b[31mcount_file8.txt\u001b[m\u001b[m \u001b[31mcount_file9.txt\u001b[m\u001b[m \u001b[31mipython_with_magic_command.ipynb\u001b[m\u001b[m \u001b[1m\u001b[36mipython_with_magic_command_files\u001b[m\u001b[m \u001b[31mmyfib.py\u001b[m\u001b[m \u001b[31mmyfib.pyc\u001b[m\u001b[m \u001b[31mnotebook格式转换工具.ipynb\u001b[m\u001b[m \u001b[1m\u001b[36msource\u001b[m\u001b[m \u001b[1m\u001b[36msrc\u001b[m\u001b[m \u001b[31m在Ipython_Notebook中的代码调试与优化.ipynb\u001b[m\u001b[m \u001b[31m基于web的可交互运行环境jupyter.ipynb\u001b[m\u001b[m \u001b[31m多进程并行计算.ipynb\u001b[m\u001b[m 有用的命令 %pwd %pwd命令可以获取当前目录的信息 %pwd '/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForJupyter/ipynbs' %cd %cd 可以跳转到目标目录,tab键可以补完 画图设置%matplotlib inline 事实上这个命令是%matplotlib, inline是它的参数,这条命令的作用是指定%matplotlib输出图像的环境,最常用的就是inline,让它内嵌在notebook中显示,同时也可以有别的,比如 %matplotlib osx(注意看平台,像osx明显是mac专属,gtk需要windows下gtk环境,wx也需要wx环境),qt,tk,inline,notebook应该是可以放心使用的),一般inline足够好了 %matplotlib --list Available matplotlib backends: ['tk', 'gtk', 'gtk3', 'wx', 'qt', 'qt4', 'qt5', 'osx', 'nbagg', 'notebook', 'agg', 'inline', 'ipympl'] %matplotlib inline import pylab as pl pl.seed(1) data = pl.randn(100) pl.plot(data); 可以配合 %config InlineBackend.figure_format=\"svg\"做图片输出格式的设置 %config InlineBackend.figure_format=\"svg\" %matplotlib inline pl.plot(data); 将cell的输出保存到对象%%capture result 输出的内容会被以string的形式保存在stdout属性上 show()方法可以看到实际输出的内容 %%capture result print([1,2,3]) result.stdout '[1, 2, 3]\\n' result.show() [1, 2, 3] 写入文件 %%writefile %%writefile hello.py #coding:utf-8 print(\"hello\") Overwriting hello.py 载入已有文件%load # %load hello.py print(\"hello\") hello 执行已有文件%run %run hello.py hello *自定义魔法命令 ipython是允许自定义魔法命令的,而且也不复杂,我们看个例子, from __future__ import print_function from IPython.core.magic import (Magics, magics_class, line_magic, cell_magic, line_cell_magic) # The class MUST call this class decorator at creation time @magics_class class MyMagics(Magics): @line_magic def lmagic(self, line): \"my line magic\" print(line) return line @cell_magic def cmagic(self, line, cell): \"my cell magic\" print(cell[:10]) return line, cell @line_cell_magic def lcmagic(self, line, cell=None): \"Magic that works both as %lcmagic and as %%lcmagic\" if cell is None: print(\"Called as line magic\") return line else: print(\"Called as cell magic\") return line, cell # In order to actually use these magics, you must register them with a # running IPython. This code must be placed in a file that is loaded once # IPython is up and running: ip = get_ipython() # You can register the class itself without instantiating it. IPython will # call the default constructor on it. ip.register_magics(MyMagics) %lmagic 123 123 '123' %%cmagic 1234 1234 1234 1234 1234 1234 ('', '\\n1234\\n1234\\n1234\\n1234') %%lcmagic 124 1234 Called as cell magic ('124', '\\n1234') 我们可以把自己的魔法命令放在profile_default的startup文件夹下 一个组实用的自定义魔法命令 下面是个比较实用的自定义魔法命令,它的主要作用是利用子进程调用其他python解释器执行python脚本. %%writefile src/startup.py #coding:utf-8 from __future__ import print_function from IPython.core.magic import (Magics, magics_class, line_magic, cell_magic, line_cell_magic) from IPython.core.interactiveshell import InteractiveShell from IPython.lib.pretty import pretty as _pretty sh = InteractiveShell.instance() def pretty(obj): import numpy as np if isinstance(obj, np.ndarray): return np.array2string(obj, separator=\", \") else: return _pretty(obj) # The class MUST call this class decorator at creation time @magics_class class MyMagics(Magics): @line_magic def goodlook_list(self, line): \"\"\" %col number_of_column code \"\"\" pos = line.find(\" \") n = int(line[:pos]) code = line[pos+1:] result = pretty(sh.ev(code)).split(\"\\n\") max_width = max(len(line) for line in result) + 3 result = [line.ljust(max_width) for line in result] result = \"\\n\".join([\"\".join(result[i:i+n]) for i in xrange(0, len(result), n)]) print(result) @line_magic def exec_py2(self, line): \"\"\" pass all the arguments to a new python2 process \"\"\" import subprocess cmd = \"python \" + line subprocess.Popen(cmd, shell=True) @line_magic def exec_py3(self, line): \"\"\" pass all the arguments to a new python3 process \"\"\" import subprocess cmd = \"python3 \" + line subprocess.Popen(cmd, shell=True) @line_magic def exec_pypy(self, line): \"\"\" pass all the arguments to a new pypy process \"\"\" import subprocess cmd = \"pypy \" + line subprocess.Popen(cmd, shell=True) ip = get_ipython() # You can register the class itself without instantiating it. IPython will # call the default constructor on it. ip.register_magics(MyMagics) Writing startup.py Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 15:26:40 "},"工具链篇/交互环境jupyter/在Ipython_Notebook中的代码调试与优化.html":{"url":"工具链篇/交互环境jupyter/在Ipython_Notebook中的代码调试与优化.html","title":"在Ipython_Notebook中的代码调试与优化","keywords":"","body":"在Ipython Notebook中的代码调试与优化 jupyter 是科学计算工具,那代码的调优就是它的一个重点了,python本身的运算能力其实很令人着急的,但通过分析计算瓶颈和用numpy,cython等工具优化代码,python也可以拥有非常高的运算效率(其实是C的功劳) 本文的先验知识有: 代码调试 性能调优 使用Cython为python加速 使用numba为python加速 调试代码 异常抛出精简 python报异常从来都是一大段,很难看也很难看懂,可以使用%xmode Plain和%xmode Verbose来在精简模式和运来模式间切换 def f1(a,b): return a/b def f2(x): a = x b = x-1 return f1(a,b) %xmode Plain Exception reporting mode: Plain f2(1) Traceback (most recent call last): File \"\", line 1, in f2(1) File \"\", line 6, in f2 return f1(a,b) File \"\", line 2, in f1 return a/b ZeroDivisionError: division by zero %xmode Verbose Exception reporting mode: Verbose f2(1) --------------------------------------------------------------------------- ZeroDivisionError Traceback (most recent call last) in () ----> 1 f2(1) global f2 = in f2(x=1) 4 a = x 5 b = x-1 ----> 6 return f1(a,b) global f1 = a = 1 b = 0 in f1(a=1, b=0) 1 def f1(a,b): ----> 2 return a/b a = 1 b = 0 3 def f2(x): 4 a = x 5 b = x-1 ZeroDivisionError: division by zero %debug用户调试错误 使用%debug会在报错时进去调试模式,在调试模式中我们可以 输入变量名来获取变量的情况, 输入up来进入上一层查看 要退出输入quit即可 运行时间检查 计算机再怎么算的慢也是比人快的多的,人的直觉并不能很好的感知到一个程序运行的快不快慢不慢,这种时候就要用时间检查工具. ipython中常用的就是%timeit 命令了 %timeit sum(map(lambda x:x**2,range(10000000))) 6.57 s ± 214 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) 或者查看具体时间在哪里损耗的%time %time sum(map(lambda x:x**2,range(10000000))) CPU times: user 6.15 s, sys: 61.9 ms, total: 6.21 s Wall time: 6.41 s 333333283333335000000 %%prun/%prun命令调用profile模块，对单元中的代码进行宏观上的性能剖析 %prun将会产生一个有序表格来展示在该语句中所调用的每个内部函数调用的次数，每次调用的时间与该函数累计运行的时间。 %%prun def fib(n): if n 使用line_profiler,对代码做逐行性能分析 在ipython中使用line_profiler可以使用他们的ipython魔法命令%lprun,要使用这个魔法命令需要先加载 %lprun可以带上参数 -f 指定需要检查的方法 %load_ext line_profiler %lprun -s -f fib fib(20) 使用memory_profiler,对代码做内存分析 与line_profiler类似,memory_profiler也有对ipython的支持,使用方式也类似,他的魔法命令是%menit和%mprun 粗粒度内存检查 关于内存的使用,在数据量小的时候看不出来但一旦数据量大了就会很棘手,ipython中查看内存使用的魔法命令是%menit %load_ext memory_profiler %memit sum(map(lambda x:x**2,range(10000000))) peak memory: 41.92 MiB, increment: 0.10 MiB 细粒度内存检查 %mprun只能检查引用进来的模块的内存性能,因此需要先将代码写到文件重作为模块引入 %mprun可以带上参数 -f 指定需要检查的方法 import myfib %mprun -f myfib.fib myfib.fib(20) *使用C语言扩展做代码优化 对于提高python运行速度,我们常用C语言来加速,对于用C语言构建核心运算模块,Cython是numpy,scipy的发展方向.一般用Cython我们都是拿他写模块,写好后要编译安装,而ipython notebook对Cython有相当好的支持 我们可以用%load_ext Cython来直接编译运行Cython写出来的程序 %load_ext Cython 我们以斐波那契数列来举例,看看用在ipython中python的速度可以有多快 用Cython优化性能 原版python def fib(n): if n fib(20) 6765 %timeit fib(20) 5.04 ms ± 94.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) 直接用cython加速 %%cython def fib_cython(n): if n fib_cython(20) 6765 %timeit fib_cython(20) 1.66 ms ± 164 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) 时间上和原版俩差了3倍的速度 使用静态编译 %%cython cpdef long fib_cython_type(long n): if n fib_cython_type(20) 6765 %timeit fib_cython_type(20) 56.7 µs ± 1.8 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each) 速度直线上升,快了100倍不止! 使用缓存计算(递归改迭代) from functools import lru_cache as cache @cache(maxsize=None) def fib_cache(n): if n %timeit fib_cache(20) 181 ns ± 5.27 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) 或者简单的使用变量 def fib_seq(n): if n fib_seq(20) 6765 %timeit fib_seq(20) 2.4 µs ± 116 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) 原版的Python对迭代的优化还是相当可以的利用两个变量存储过程量,可以大大减少运算量 使用缓存并且使用Cython加速 %%cython from functools import lru_cache as cache @cache(maxsize=None) def fib_cache_cython(n): if n %timeit fib_cache_cython(20) 218 ns ± 13 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) %%cython def fib_seq_cython(n): if n fib_seq_cython(20) 6765 %timeit fib_seq_cython(20) 1.07 µs ± 25.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 惊了...只有1微秒左右! 再静态化 %%cython cpdef long fib_seq_cython_type(long n): if n fib_seq_cython_type(20) 6765 %timeit fib_seq_cython_type(20) 113 ns ± 1.31 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) 又快了4倍 使用numba加速 from numba import jit @jit def fib_seq_numba(n): if n fib_seq_numba(20) 6765 %timeit fib_seq_numba(20) 293 ns ± 5.73 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 略不如Cython的最终版本 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 15:27:49 "},"工具链篇/交互环境jupyter/多进程并行计算.html":{"url":"工具链篇/交互环境jupyter/多进程并行计算.html","title":"多进程并行计算","keywords":"","body":"*多进程并行计算 ipyparallel是ipython项目下的一个子模块,主要是解决并行计算和分布式计算的问题 https://github.com/ipython/ipyparallel 这个模块是独立于ipython的独立子项目,需要额外安装 $ pip install ipyparallel 单机并行计算 最简单的并行计算方法就是打开一个terminal,输入 $ ipcluster start 然后在python,ipython中就都可使用并行计算了 为并行环境制作一个专用profile ipython profile create --parallel --profile=myprofile 命令可以简单的创建一个通用的并行环境profile,之后我们就可以通过编辑~/.ipython/这个文件夹下的配置文件来配置这个profile了 一个例子:做一次wordcount 数据来源是 $wget http://www.gutenberg.org/files/27287/27287-0.txt 不并行的版本 import re import io non_word = re.compile(r'[\\W\\d]+', re.UNICODE) common_words = { 'the','of','and','in','to','a','is','it','that','which','as','on','by', 'be','this','with','are','from','will','at','you','not','for','no','have', 'i','or','if','his','its','they','but','their','one','all','he','when', 'than','so','these','them','may','see','other','was','has','an','there', 'more','we','footnote', 'who', 'had', 'been', 'she', 'do', 'what', 'her', 'him', 'my', 'me', 'would', 'could', 'said', 'am', 'were', 'very', 'your', 'did', 'not', } filename = 'source/README.md' def yield_words(filename): import io with io.open(filename, encoding='utf-8') as f: for line in f: for word in line.split(): word = non_word.sub('', word.lower()) if word and word not in common_words: yield word def word_count(filename): word_iterator = yield_words(filename) counts = {} counts = defaultdict(int) while True: try: word = next(word_iterator) except StopIteration: break else: counts[word] += 1 return counts from collections import defaultdict %time counts = word_count(filename) CPU times: user 3.32 ms, sys: 1.4 ms, total: 4.72 ms Wall time: 10.9 ms 并行版本 def split_text(filename): text = open(filename).read() lines = text.splitlines() nlines = len(lines) n = 10 block = nlines//n for i in range(n): chunk = lines[i*block:(i+1)*(block)] with open('count_file%i.txt' % i, 'w') as f: f.write('\\n'.join(chunk)) cwd = os.path.abspath(os.getcwd()) fnames = [ os.path.join(cwd, 'count_file%i.txt' % i) for i in range(n)] # 不用glob是为了精准 return fnames from ipyparallel import Client rc = Client() view = rc.load_balanced_view() v = rc[:] v.push(dict( non_word=non_word, yield_words=yield_words, common_words=common_words )) with rc[:].sync_imports(): import os from collections import defaultdict importing os on engine(s) importing defaultdict from collections on engine(s) fnames = split_text(filename) def count_parallel(): from collections import defaultdict pcounts = view.map(word_count, fnames) counts = defaultdict(int) for pcount in pcounts.get(): for k, v in pcount.iteritems(): counts[k] += v return counts, pcounts %time counts, pcounts = count_parallel() CPU times: user 50.6 ms, sys: 8.82 ms, total: 59.4 ms Wall time: 99.6 ms 可以看出cpu时间上确实减少了,几乎一半,但真实时间上却反而增加到了164ms,用%timeit查看,发现实际使用时间反而多出了20ms 这是因为cpu计算完后还要聚合结果,这个过程也得耗时,也就是说,并行是有额外开销的 最简单的应用--将函数提交到引擎中 并行就是多个核心同时执行任务了,最简单的就是执行重复任务了 c = Client() a = lambda :\"hi~\" %time c[:].apply_sync(a) CPU times: user 22.6 ms, sys: 5.05 ms, total: 27.7 ms Wall time: 35.4 ms ['hi~', 'hi~', 'hi~', 'hi~'] %time [a() for i in range(2)] CPU times: user 10 µs, sys: 6 µs, total: 16 µs Wall time: 17.9 µs ['hi~', 'hi~'] 看得出,cpython还是相当给力的,在这种小规模计算上并行反而比用列表生成器慢很多 直接调用ipyparallel 我们可以通过DirectView直接在ipython中通过Client对象直接的操作多个engine from ipyparallel import Client rc = Client() rc.ids#查看有多少个engine [0, 1, 2, 3] dview = rc[:]#使用全部engine %time map(lambda x:x**2,range(32)) CPU times: user 21 µs, sys: 5 µs, total: 26 µs Wall time: 26.9 µs [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961] %time dview.map_sync(lambda x:x**2,range(32))# 并行的map工具 CPU times: user 31.3 ms, sys: 5.12 ms, total: 36.4 ms Wall time: 41.4 ms [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961] 看来还是单进程给力哇 负载均衡view 并行的一大难题便是负载均衡,直接使用DirectView并没有这方面优化,可以使用LoadBalancedView来使用负载均衡的view lview = rc.load_balanced_view() %time lview.map_sync(lambda x:x**2,range(32)) CPU times: user 230 ms, sys: 47.3 ms, total: 277 ms Wall time: 305 ms [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961] Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 15:28:08 "},"工具链篇/交互环境jupyter/公开的jupyter_notebook服务.html":{"url":"工具链篇/交互环境jupyter/公开的jupyter_notebook服务.html","title":"公开的jupyter_notebook服务","keywords":"","body":"*jupyter notebook作为服务器 jupyter notebook本来就是一个基于浏览器的服务,它默认在localhost:8888启动.我们可以通过修改一些启动参数来将它对外.这种方式并不推荐,因为每次都得手动输入参数很繁琐. jupyter 提供了一个命令为我们生成一份配置文件放在~/.jupyter目录下. jupyter notebook --generate-config 我们可以修改其中的 c.NotebookApp.ip = '*'#或者'0.0.0.0' c.NotebookApp.open_browser = False# 服务启动不打开浏览器 c.NotebookApp.port = 就可以使用了 安全措施 jupyter notebook直接暴露在外显然是不安全的,解决安全问题有两个思路: 加密 使用私有通道 加密 访问密码 jupyter notebook可以使用jupyter notebook password命令创建密码,创建完成后他会保存在~/.jupyter目录下.形如: { \"NotebookApp\": { \"password\": \"sha1:xxxxxxxxx\" } } 将其中的password内容复制到上面的配置文件中的c.NotebookApp.password = u'xxxx'中,那么访问的时候如果浏览器没有cookie保存着这个信息就会要求输入密码了 ssl密文通信 启动的时候加上参数jupyter notebook --certfile=mycert.pem --keyfile mykey.key就可以使用ssl加密通信了(https).当然更好的方式是修改配置文件 c.NotebookApp.certfile = u'/absolute/path/to/your/certificate/mycert.pem' c.NotebookApp.keyfile = u'/absolute/path/to/your/certificate/mykey.key' 使用ssh私有通道 ssh隧道技术简单说就是将一个远端端口映射到本地一个端口,这样信息就都是通过ssh来传递了.在linux或者mac中这样启动: ssh -N -f -L [remote port]:localhost:[local port] -p [ssh port] -l [username] [公网IP] 在windows中ssh工具使用很作孽,我们可以使用xshell来代替: 我们架设要将7777端口映射到本地7777端口,那么在yu远端启动的时候配置文件中这样写 c.NotebookApp.ip = 'localhost' c.NotebookApp.open_browser = False# 服务启动不打开浏览器 c.NotebookApp.port = 7777 然后使用jupyter notebook启动服务即可.我们就可以使用本地的浏览器访问本地的7777端口来访问远端的notebook了 后台启动可以使用nohup 或者使用supervisor统一管理都可以. 使用jupyterhub解决多用户访问问题 使用ssh私有通道的方式可能更加安全些,但这没有改变一个问题: 多用户下的文件修改冲突问题. 官方的解决方案是使用jupyterhub jupyterhub是notebook的衍生,专门用来管理多用户.它默认使用服务器机器上的用户作为用户,并且启动时需要sudo权限. JupyterHub需要python3.4+和node.js的configurable-http-proxy库 安装使用以下步骤: python3 -m pip install jupyterhub npm install -g configurable-http-proxy 安装完毕后,类似jupyter notebook,jupyterhub也可以创建一个配置文件模板 jupyterhub --generate-config 这样就会在运行命令的当前目录下创建一个配置文件jupyterhub_config.py.要使用这个配置文件只需要使用-f指定即可 sudo jupyterhub -f jupyterhub_config.py 要正常的运行需要修改配置文件如下: c.JupyterHub.admin_access = True # 让admin账号可以控制或者进入非admin账户 c.Authenticator.whitelist = {} #将当前的系统账号设为白名单 c.Authenticator.admin_users={}#将当前的系统账号设为admin账号 c.JupyterHub.ip = '0.0.0.0'#设置外网可以访问 c.JupyterHub.port = 5888#设置端口 c.Spawner.cmd = ['/path/to/jupyterhub-singleuser']#将`jupyterhub-singleuser`写死 c.JupyterHub.ssl_cert = ''#设置ssl的证书文件地址,不用https可以不设置 c.JupyterHub.ssl_key = ''#设置ssl的证书的key文件地址,不用https可以不设置 之后运行即可.登录账号即为你当前的系统账号,密码为当前系统的登录密码 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 15:27:11 "},"工具链篇/交互环境jupyter/notebook格式转换工具.html":{"url":"工具链篇/交互环境jupyter/notebook格式转换工具.html","title":"notebook格式转换工具","keywords":"","body":"*notebook格式转换工具(nbconvert) nbconvert是jupyter notebook的格式转换工具,它支持把notebook转化为markdown,pdf,html等格式的文件 它依赖pandoc,所以先要安装pandoc,另外如果要转成pdf格式,还要安装latex和一些依赖 sudo tlmgr install ucs sudo tlmgr install collectbox sudo tlmgr install adjustbox sudo tlmgr install cyrillic sudo tlmgr install collection-langcyrillic 之后要使用nbconvert只需要: jupyter nbconvert --to input notebook 可以使用通配符来指定复数的.ipynb文件 常用的格式有: html 通用的网页格式 markdown markdown文本格式 reStructuredText .rst后缀的文本,sphinx的通用格式 script 提取文件中的代码并保存为对应格式 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 15:26:55 "},"工具链篇/交互环境jupyter/结语.html":{"url":"工具链篇/交互环境jupyter/结语.html","title":"结语","keywords":"","body":"结语 技术驱动还是业务驱动 这个话题可能有点大,jupyter项目是典型的业务驱动项目,它无疑非常成功,包括ananconda也是一个典型的业务驱动型项目,无疑它也很成功.你要说他们有什么技术洞见(这个词来自How Google Works这本书),难! 这似乎不符合我们的直觉,照理说技术驱动才可以拉开与对手的差距从而赢得市场,但为什么这两个项目不是这样呢? 其实个人认为技术洞见不光可以是技术上的领先,另一个维度是对于需求的透彻理解.这两个项目的开发者也都是目标客户,我们自己为自己写脚手架什么的也往往可以写的非常好用,这就是对于需求透彻理解的作用. 那技术驱动不如业务驱动么? 也不能这么说,这两个的难点不同: 技术驱动的难点在于技术.通常新技术不能带来10%以上的效率提升是难以让人放弃现有习惯的.因此技术驱动代表着必须和对手在技术上拉开一代差距.可以想象下这对于一般项目而言有多难 业务驱动的难点在对需求的理解.这个看起来似乎比上面的简单其实不然,目前我知道的人中能做到对需求理解及其透彻的只有已经过世的乔布斯.这也是为啥苹果这么一家技术上相对保守的公司可以和谷歌微软这样的技术大牛公司有来有回的原因. 技术驱动可以通过密集的资金砸出来,但业务驱动要做好必须有一个对需求有透彻理解的天才来设计产品. 当然了业务驱动的门槛低,多数企业项目也都是使用这种思路,作出微妙的产品后投入市场或者吹一波骗了投资收购走人.这种也是创始人发家致富的途径,与产品本身已经无关了,这边也就不多讨论. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/代码风格.html":{"url":"工具链篇/代码风格.html","title":"代码风格","keywords":"","body":"代码风格 python社区有一套成文的代码规范,就是有名的pep 8规范.而google也有一套成文的风格规范,他们都很不错,但更加推荐使用pep8标准,并且在一些细节上使用google的规范.当然了,python的代码风格并不是强制性的,只是使用这套规则会更加便于团队合作.是否使用还是看使用者个人 代码编排 缩进。4个空格的缩进（编辑器都可以完成此功能），不使用Tap，更不能混合使用Tap和空格。 每行最大长度79，换行可以使用反斜杠，最好使用圆括号。换行点要在操作符的后边敲回车。 类和top-level函数定义之间空两行；类中的方法定义之间空一行；函数内逻辑无关段落之间空一行；其他地方尽量不要再空行。 文档编排 模块内容的顺序：模块说明和docstring—import—globals&constants—其他定义。其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。 不要在一句import中多个库，比如import os, sys不推荐。 如果采用from XX import XX引用库，可以省略‘module.’，都是可能出现命名冲突，这时就要采用import XX。 空格的使用 总体原则，避免不必要的空格。 各种右括号前不要加空格。 逗号、冒号、分号前不要加空格。 函数的左括号前不要加空格。如Func(1)。 序列的左括号前不要加空格。如list[2]。 操作符左右各加一个空格，不要为了对齐增加空格。 函数默认参数使用的赋值符左右省略空格。 不要将多句语句写在同一行，尽管使用‘；’允许。 if/for/while语句中，即使执行语句只有一句，也必须另起一行。 注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释！ 注释必须使用英文，最好是完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符。 块注释，在一段代码前增加的注释。在‘#’后加一空格。段落之间以只有‘#’的行间隔。比如： # Description : Module config. # # Input : None # # Output : None 行注释，在一句代码后加注释。比如：x = x + 1 # Increment x 但是这种方式尽量少使用。 避免无谓的注释。 文档描述 为所有的共有模块、函数、类、方法写docstrings；非共有的没有必要，但是可以写注释（在def的下一行）。 如果docstring要换行，参考如下例子,详见PEP 257 \"\"\"Return a foobang Optional plotz says to frobnicate the bizbaz first. \"\"\" Shebang 大部分.py文件不必以#!作为文件的开始. 根据 PEP-394 , 程序的main文件应该以#!/usr/bin/python2或者 #!/usr/bin/python3开始.但其实更好的方式是使用#! /usr/bin/env/python2或者 #!/usr/bin/env python3 在计算机科学中, Shebang (也称为Hashbang)是一个由井号和叹号构成的字符串行(#!), 其出现在文本文件的第一行的前两个字符. 在文件中存在Shebang的情况下, 类Unix操作系统的程序载入器会分析Shebang后的内容, 将这些内容作为解释器指令, 并调用该指令, 并将载有Shebang的文件路径作为该解释器的参数. 例如, 以指令#!/bin/sh开头的文件在执行时会实际调用/bin/sh程序. #!先用于帮助内核找到Python解释器, 但是在导入模块时, 将会被忽略. 因此只有被直接执行的文件中才有必要加入#!. TODO注释 为临时代码使用TODO注释, 它是一种短期解决方案. 不算完美, 但够好了. TODO注释应该在所有开头处包含TODO字符串, 紧跟着是用括号括起来的你的名字, email地址或其它标识符. 然后是一个可选的冒号. 接着必须有一行注释, 解释要做什么. 主要目的是为了有一个统一的TODO格式, 这样添加注释的人就可以搜索到(并可以按需提供更多细节). 写了TODO注释并不保证写的人会亲自解决问题. 当你写了一个TODO, 请注上你的名字. # TODO(kl@gmail.com): Use a \"*\" here for string repetition. # TODO(Zeke) Change this to use relations. 如果你的TODO是”将来做某事”的形式, 那么请确保你包含了一个指定的日期(“2009年11月解决”)或者一个特定的事件(“等到所有的客户都可以处理XML请求就移除这些代码”). 命名规范 总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。 尽量单独使用小写字母l，大写字母O等容易混淆的字母。 模块命名尽量短小，使用全部小写的方式，可以使用下划线。 包命名尽量短小，使用全部小写的方式，不可以使用下划线。 类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。 异常命名使用CapWords+Error后缀的方式。 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是__all__机制;二是前缀一个下划线。 函数命名使用全部小写的方式，可以使用下划线。 常量命名使用全部大写的方式，可以使用下划线。 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。 类的属性有3种作用域public、non-public和subclass API，可以理解成C++中的public、private、protected，subclass API属性前缀一条下划线,这样使用import * from时不会包含,non-public属性前缀两条下划线,这样不使用__dir__无法被查看到. 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类Foo中声明__a,访问时，只能通过Foo._Foo__a，避免歧义。如果子类也叫Foo，那就无能为力了。 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls。 编码建议 编码中考虑到其他python实现的效率等问题，比如运算符‘+’在CPython（Python）中效率很高，但是Jython中却非常低，所以应该采用.join()的方式。 尽可能使用is,is not取代==，比如if x is not None 要优于if x。 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。 异常中不要使用裸露的except，except后跟具体的exceptions。 异常中try的代码尽可能少。比如： try: value = collection[key] except KeyError: return key_not_found(key) else: return handle_value(value) 要优于 try: # Too broad! return handle_value(collection[key]) except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key) 使用startswith() and endswith()代替切片进行序列前缀或后缀的检查。比如： if foo.startswith('bar'): 优于 if foo[:3] == 'bar': 使用isinstance()比较对象的类型。比如 if isinstance(obj, int): 优于 if type(obj) is type(1): 判断序列空或不空，有如下规则 if not seq: pass if seq: pass 优于 if len(seq): pass if not len(seq): pass 字符串不要以空格收尾。 二进制数据判断使用if boolvalue的方式。 导入格式 每个导入应该独占一行 Yes: import os import sys No: import os, sys 导入总应该放在文件顶部, 位于模块注释和文档字符串之后, 模块全局变量和常量之前. 导入应该按照从最通用到最不通用的顺序分组: 标准库导入 第三方库导入 应用程序指定导入 每种分组中, 应该根据每个模块的完整包路径按字典序排序, 忽略大小写. import foo from foo import bar from foo.bar import baz from foo.bar import Quux from Foob import ar Main 即使是一个打算被用作脚本的文件, 也应该是可导入的. 并且简单的导入不应该导致这个脚本的主功能(main functionality)被执行, 这是一种副作用. 主功能应该放在一个main()函数中. 在Python中, pydoc以及单元测试要求模块必须是可导入的. 你的代码应该在执行主程序前总是检查 if__name__ == '__main__' , 这样当模块被导入时主程序就不会被执行. def main(): pass if __name__ == '__main__': main() 所有的顶级代码在模块导入时都会被执行. 要小心不要去调用函数, 创建对象, 或者执行那些不应该在使用pydoc时执行的操作. 代码美化 要完全符合规范是很作孽繁琐的一件事,我们同样可以使用工具简化这个工作,这就是autopep8. 安装: pip install --upgrade autopep8 如果使用atom的话则可以安装Atom Beautify插件,它的python代码美化也是基于autopep8的. 如果使用的svcode的话可以安装官方插件python,然后插件会自动提醒安装需要的美化工具. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/docstring工具.html":{"url":"工具链篇/docstring工具.html","title":"docstring工具","keywords":"","body":"docstring工具 python是一门高度自省的编程语言,每个对象都有一个__doc__字段用于保存一段自我描述的文本.这个文本可以 被help()内置函数截获; 被标准库pydoc读出生成注释文档; 如果其中包含doctest语法的话也可以被doctest解析用于做测试 在每个模块/类/函数的定义过程中,定义体内的第一行最开头开始如果使用3个引号(\"\"\"或者''')的形式来构建一个字符串段,那么它就会被赋值给这个对象的__doc__字段,也就是这段字符串就是这个对象的docstring. docstrings注释风格 我们的docstrings注释要简洁明了,并且最好符合大多数人的阅读习惯,这样才便于维护,这边推荐谷歌风格的注释规范. 如果使用vscode的话,有一个插件autoDocstring可以非常简单的创建符合各种风格的docstring模板,只需要在config中设置下\"autoDocstring.docstringFormat\": \"google\",即可. 模块docstrings Python中有模块概念,可以简单的理解为每个文件都是一个模块,而每个文件夹也都是模块.只是文件夹模块的导入文件为其中的__init__.py文件. 通常模块也是要有docstring注释,用于在多人协作时记录一些元信息. 这些元信息包括: 模块简单说明 Version 模块的版本 Author 模块的作者 Email 模块作者的邮箱 Copyright 模块的版权,包括日期和作者 License 模块的许可证样板 History 模块的跟新历史 我们来看一个例子: \"\"\"定义一些标准错误和一些方法. + File: error.py + Version: 0.5 + Author: hsz + Email: hsz1273327@gmail.com + Copyright: 2018-02-08 hsz + License: MIT + History + 2018-01-23 created by hsz + 2018-01-23 version-0.5 by hsz \"\"\" 每个文件应该包含一个许可证样板. 根据项目使用的许可, 选择合适的样板. 函数docstrings 一个函数必须要有文档字符串, 除非它满足以下条件: 外部不可见 非常短小 命名简单明了 文档字符串应该包含函数做什么, 以及输入和输出的详细描述. 通常, 不应该描述”怎么做”, 除非是一些复杂的算法. 文档字符串应该提供足够的信息, 当别人编写代码调用该函数时, 他不需要看一行代码, 只要看文档字符串就可以了. 对于复杂的代码, 在代码旁边加注释会比使用文档字符串更有意义. 关于函数的几个方面应该在特定的小节中进行描述记录， 这几个方面如下文所述. 每节应该以一个标题行开始. 标题行以冒号结尾. 除标题行外, 节的其他内容应被缩进2个空格. Args: 列出每个参数的名字, 并在名字后使用一个冒号和一个空格, 分隔对该参数的描述.如果描述太长超过了单行80字符,使用2或者4个空格的悬挂缩进(与文件其他部分保持一致). 描述应该包括所需的类型和含义. 如果一个函数接受*foo(可变长度参数列表)或者**bar (任意关键字参数), 应该详细列出*foo和**bar. Returns: (或者 Yields: 用于生成器) 描述返回值的类型和语义. 如果函数返回None, 这一部分可以省略. Raises: 列出与接口有关的所有异常. 我们看一个例子: def flatten(items): \"\"\"压扁序列,将多层结构的序列压为一列. Args: items (Iterable): 复杂的多层序列 Returns: Iterable: 压扁后的单层序列 \"\"\" for item in items: is_iterable = isinstance(item, Iterable) is_string_or_bytes = isinstance(item, (str, bytes, bytearray)) if is_iterable and not is_string_or_bytes: for i in flatten(item): yield i else: yield item 类docstrings 类应该在其定义下有一个用于描述该类的文档字符串. 如果你的类有公共属性(Attributes), 那么文档中应该有一个属性(Attributes)段. 并且应该遵守和函数参数相同的格式. Attributes: 成员属性 我们看一个例子: class SampleClass(object): \"\"\"一个简单的类例子 Attributes: likes_spam: 布尔型参数 eggs: int型参数 \"\"\" def __init__(self, likes_spam=False): \"\"\"Inits SampleClass with blah.\"\"\" self.likes_spam = likes_spam self.eggs = 0 def public_method(self): \"\"\"Performs operation blah.\"\"\" 使用doctest利用docstring进行简单测试 Python提供了解析docstring中特定语法内容作为测试代码和待验证结果的工具. 其语法就是: 以>>>开头的就是要执行的代码 以...开头的行表示python中的代码段, 要执行代码下面一行就是要验证的内容. 比如a.py: \"\"\" >>> def add(x,y): ... return x+y >>> add(1,2) 3 \"\"\" 而要进行测试有两种方式: 直接使用命令行工具python -m doctest a.py -v 在这个模块的最后加上 if __name__ == '__main__': import doctest doctest.testmod() 然后直接执行这个文件即可 可以看到doctest写起来一点也不方便,会有除了代码外的很多额外内容需要添加,但它的优点就是代码和结果都可见,因此它的适用场景更多的是作为例子而非真正的测试.通常真正的单元测试会很细致,测试用例甚至比代码本身都多,如果使用doctest那注释的文本量就爆炸了,这样反而更加不利于代码维护,因此还是使用unittest模块单独做单元测试比较好. 文档生成 无论代码写的如何,如果没有一个详细清晰的文档会让使用和维护变得非常困难,负责任的开发者应该尽量为自己的代码维护一份文档.python可以使用自带的文档生成器pydoc,它可以读取代码中的docstring,自动的生成文档. 它的使用方式非常简单 !python -m pydoc -k 查找关键字 -p 用localhost打开网页版,后面填端口号 -g GUI版 -w 生成html文件 *sphinx-autodoc pydoc虽然方便,但实话说样式比较老旧,而且可定制性不强,现在的python包一般都用sphinx做文档,sphinx其实也是利用autodoc,结合docstring和规范化的文档格式,可以实现非常美观的项目文档.具体可以看我的这篇博文 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:51:36 "},"工具链篇/静态类型检测.html":{"url":"工具链篇/静态类型检测.html","title":"静态类型检测","keywords":"","body":"*类型注释和检验 python3.5起就支持函数的类型注释(pep 484),它的结构如下: def func(arg:int)->int: pass ps:类型注释只是注释,python解释器并不会处理它,要让它有类型检验的功能还要有其他工具配合. 函数的参数类型保存在它的__annotations__属性上 func.__annotations__ {'arg': int, 'return': int} *自定义泛型注解 类型注释可以直接使用系统自带的类和自己定义的类,但对于泛型注解就力不从心了,对于这种需求,python内置了typing模块来帮助泛型注释 协程注释 async def spam(ignored: int) -> str: return 'spam' async def foo() -> None: bar = await spam(42) # type: str 类型别名 Url = str def retry(url: Url, retry_count: int) -> None: pass 可调用类型 from typing import Callable def feeder(get_next_item: Callable[[], str]) -> None: pass def async_query(on_success: Callable[[int], None], on_error: Callable[[int, Exception], None]) -> None: pass 生成器类型 from typing import Generator def echo_round() -> Generator[int, float, str]: res = yield while res: res = yield round(res) return 'OK' from typing import Mapping, Set def notify_by_email(employees: Set[int], overrides: Mapping[str, str]) -> None: pass 泛型 from typing import Sequence, TypeVar T = TypeVar('T') # Declare type variable def first(l: Sequence[T]) -> T: # Generic function return l[0] 受限泛型 from typing import TypeVar AnyStr = TypeVar('AnyStr', str, bytes)#必须是str或者bytes def concat(x: AnyStr, y: AnyStr) -> AnyStr: return x + y Union类型 Union类型常用于可选类型 from typing import Union def handle_employees(e: Union[int, Sequence[int]]) -> None: if isinstance(e, Employee): e = [e] Optional类型 Optional类型通常表示这个被注释的参数是可以为None的. from typing import Optional def option_demo(x:int,y: Optional[int]=None) -> int: if y: return x+y else: return x 用户自定义泛型 from typing import TypeVar, Generic from typing import Iterable class Logger: pass T = TypeVar('T') class LoggedVar(Generic[T]): def __init__(self, value: T, name: str, logger: Logger) -> None: self.name = name self.logger = logger self.value = value def set(self, new: T) -> None: self.log('Set ' + repr(self.value)) self.value = new def get(self) -> T: self.log('Get ' + repr(self.value)) return self.value def log(self, message: str) -> None: self.logger.info('{}: {}'.format(self.name,message)) def zero_all_vars(vars: Iterable[LoggedVar[int]]) -> None: for var in vars: var.set(0) any类型 any类型和ts中一样,代表任意类型都可以 方法重载 from typing import overload class bytes: @overload def __getitem__(self, i: int) -> int: ... @overload def __getitem__(self, s: slice) -> bytes: ... 变量注解[3.6] 3.6版本起变量类型也可以注释了(pep 526),这看起来就像c语言一样,然而它依然还是注释 from typing import Optional,List foo: Optional[int] bar: List[str] = [] from typing import ClassVar class C: x: int # instance variable y: ClassVar[int] # class variable z = None # type: ClassVar[int] def foo(self) -> None: self.x = 0 # OK self.y = 0 # Error: Cannot assign to class variable \"y\" via instance C.y = 0 # This is OK 模块,类中的的变量注解同样保存在__annotations__中 C.__annotations__ {'x': int, 'y': typing.ClassVar[int]} c = C() c.__annotations__ {'x': int, 'y': typing.ClassVar[int]} __annotations__ {'bar': typing.List[str], 'foo': typing.Union[int, NoneType]} 静态类型检验 python解释器并不会做静态类型检验,我们可以利用mypy来实现 %%writefile src/C2/mypytest.py from typing import Callable def twice(i: int, next: Callable[[int], int]) -> int: return next(next(i)) def add(i: int) -> str:#写成返回str,这样就会报错! return i + 1 print(twice(3, add)) # 5 Overwriting src/C2/mypytest.py !mypy src/C2/mypytest.py src/C2/mypytest.py:8: error: Incompatible return value type (got \"int\", expected \"str\") src/C2/mypytest.py:10: error: Argument 2 to \"twice\" has incompatible type \"Callable[[int], str]\"; expected \"Callable[[int], int]\" *运行时类型检测 标准库自带的typing只能用于静态检测,当我们需要运行时检测时可以借助enforce来实现.enforce使用装饰器语法, 它提供了装饰器 @runtime_validation 用于运行时进行类型检测.同时提供了工具is_type_of_type来对类型和申明类型进行比较. 需要注意的是is_type_of_type对通过cloudpickle的对象无效 !pip install enforce Looking in indexes: http://pypi.douban.com/simple Requirement already satisfied: enforce in /Users/huangsizhe/anaconda3/lib/python3.6/site-packages (0.3.4) Requirement already satisfied: wrapt in /Users/huangsizhe/anaconda3/lib/python3.6/site-packages (from enforce) (1.10.11) \u001b[31mccxt 1.13.123 has requirement certifi>=2018.1.18, but you'll have certifi 2016.2.28 which is incompatible.\u001b[0m \u001b[31mccxt 1.13.123 has requirement requests>=2.18.4, but you'll have requests 2.14.2 which is incompatible.\u001b[0m import enforce @enforce.runtime_validation class A: test:str def __init__(self,text:str)->None: self.text = text @enforce.runtime_validation def foo(text: str) -> A: return A(text) a = foo(\"asd\") b = foo(123) --------------------------------------------------------------------------- RuntimeTypeError Traceback (most recent call last) in () ----> 1 b = foo(123) ~/anaconda3/lib/python3.6/site-packages/enforce/decorators.py in universal(wrapped, instance, args, kwargs) 102 103 # First, check argument types (every key not labelled 'return') --> 104 _args, _kwargs, _ = enforcer.validate_inputs(parameters) 105 106 if instance_method: ~/anaconda3/lib/python3.6/site-packages/enforce/enforcers.py in validate_inputs(self, input_data) 84 85 exception_text = parse_errors(self.validator.errors, self.hints) ---> 86 raise RuntimeTypeError(exception_text) 87 88 def validate_outputs(self, output_data: T) -> T: RuntimeTypeError: The following runtime type errors were encountered: Argument 'text' was not of type . Actual type was int. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:52:04 "},"工具链篇/日志工具.html":{"url":"工具链篇/日志工具.html","title":"日志工具","keywords":"","body":"日志工具 代码检查,debug,调优都只能让代码确保当时是可靠的,一些复杂的关联错误,也可能让这些测试呀debug呀失准,,而只有日志才能长期的帮助我们监控项目的健壮性.这种时候就可以使用标准库logging为程序的运行做记录,在试运行之后通过分析logging记录的方式来debug. 在logging框架下首先我们需要初始化一个logger来处理log,之后通过添加handler,Formatter和config子属性来自定义我们的logger. 一个简单的例子 import logging import sys #日志的名字,会在每行的一开始写 logger = logging.getLogger(\"endlesscode\") #格式化 formatter = logging.Formatter('%(name)-12s %(asctime)s %(levelname)-8s %(message)s', '%a, %d %b %Y %H:%M:%S',) #设定输出文件 file_handler = logging.FileHandler(\"src/test.log\") #为handler设置输出格式 file_handler.setFormatter(formatter) #流控制,将信息输出到标准流输出 stream_handler = logging.StreamHandler(sys.stderr) #为logger设置handler logger.addHandler(file_handler) #发送信息到流 logger.addHandler(stream_handler) #设置报错等级 #logger.setLevel(logging.ERROR) #报错 logger.error(\"w\") #移除handler logger.removeHandler(stream_handler) #报错 logger.error(\"f\") w 其中 level: 设置日志级别，默认为logging.WARNING stream: 指定将日志的输出流，可以指定输出到sys.stderr,sys.stdout或者文件，默认输出到sys.stderr，当stream和filename同时指定时，stream被忽略 输出文本的格式化 元素 格式化字符串 描述 args 不用格式化 参数会是一个元组 asctime %(asctime)s 可读的时间 created %(created)f 记录的创建时间 filename %(filename)s 文件名 funcName %(funcName)s 函数名 levelname %(levelname)s 错误,警报等的名字 levelno %(levelno)s 错误,警报等,是预警等级 lineno %(lineno)d 报错行数 module %(module)s 报错模块 msecs %(msecs)d 毫秒级的出错时间 message %(message)s 错误信息 name %(name)s log的名字 pathname %(pathname)s 报错文件所在path process %(process)d 进程id processName %(processName)s 进程名 relativeCreated %(relativeCreated)d 微秒级的报错时间 thread %(thread)d 线程id threadName %(threadName)s 线程名 日志回滚 日志也不是一直记录就好,也要考录时效性和存储空间的限制,回滚机制便是解决这个问题的 from logging.handlers import RotatingFileHandler #定义一个RotatingFileHandler，最多备份5个日志文件，每个日志文件最大10M Rthandler = RotatingFileHandler('src/myapp.log', maxBytes=10*1024*1024,backupCount=5) Rthandler.setLevel(logging.INFO) formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s') Rthandler.setFormatter(formatter) logging.getLogger('').addHandler(Rthandler) 几种handler StreamHandler(stream=None) 流输出 FileHandler(filename, mode='a', encoding=None, delay=False) 写入文件 WatchedFileHandler(filename[, mode[, encoding[, delay]]]) 监控log文件 RotatingFileHandler(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=0) 轮替日志,根据日志文件的大小来循环 TimedRotatingFileHandler(filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None) 轮替日志,根据时间来循环,interval参数可选的值有: \"S\"-Seconds 'M'-Minutes 'H'-Hours 'D'-Days 'W0'~'W6'-Weekday (0=Monday) 'midnight'-半夜循环 SocketHandler(host, port) 把log送到网上的socket DatagramHandler(host, port) 把log送到网上的UDP sockets SysLogHandler(address=('localhost', SYSLOG_UDP_PORT), facility=LOG_USER, socktype=socket.SOCK_DGRAM) log送到unix系统log SMTPHandler(mailhost, fromaddr, toaddrs, subject, credentials=None, secure=None, timeout=1.0) log送到电子邮箱 MemoryHandler(capacity, flushLevel=ERROR, target=None) log存入内存 HTTPHandler(host, url, method='GET', secure=False, credentials=None, context=None) log通过http网络送到服务器 使用.conf设置文件设置logging行为 当然可以在程序中设置log了,但为了改起来方便也可以写在别的文件中然后用config.fileConfig(path)来设置,配置文件的形式是这样: [loggers] keys=root,simpleExample [handlers] keys=consoleHandler [formatters] keys=simpleFormatter [logger_root] level=DEBUG handlers=consoleHandler [logger_simpleExample] level=DEBUG handlers=consoleHandler qualname=simpleExample propagate=0 [handler_consoleHandler] class=StreamHandler level=DEBUG formatter=simpleFormatter args=(sys.stdout,) [formatter_simpleFormatter] format=%(asctime)s - %(name)s - %(levelname)s - %(message)s datefmt=%a, %d %b %Y %H:%M:%S 要注意的是如果用这种方式那么,使用rotation file handler时，不要同时声明file handler，否则rotation发生时，doRollover 函数的os.rename 会报错(「另一个程序正在使用此文件，进程无法访问).当然,可以写另一个py文件专门用来初始化,要用的时候import进来就好了. 使用字典配置logging行为 上面一种看起来比较晦涩难懂难以维护,更加pythonic的做法是使用字典进行配置 import sys import logging import logging.config LOGGING_CONFIG = dict( version=1, loggers={ \"\":{ \"level\": \"INFO\", \"handlers\": [\"model_console\"] }, \"\": { \"level\": \"INFO\", \"handlers\": [\"server_console\"] } }, handlers={ \"model_console\": { \"class\": \"logging.StreamHandler\", \"formatter\": \"model\", \"stream\": sys.stdout }, \"server_console\": { \"class\": \"logging.StreamHandler\", \"formatter\": \"server\", \"stream\": sys.stdout } }, formatters={ \"model\": { \"format\": \"%(asctime)s :: %(name)s :: %(levelname)s :: %(process)d :: \"+ \"%(module)s - line %(lineno)d - funcname: %(funcName)s - params: %(params)s :: %(message)s\", \"datefmt\": \"[%Y-%m-%d %H:%M:%S %z]\", \"class\": \"logging.Formatter\" }, \"server\": { \"format\": \"%(asctime)s :: %(name)s :: %(levelname)s :: %(host)s :: \" + \"%(request)s :: %(message)s\", \"datefmt\": \"[%Y-%m-%d %H:%M:%S %z]\", \"class\": \"logging.Formatter\" } } ) logging.config.dictConfig(LOGGING_CONFIG) model_logger = logging.getLogger('') server_logger = logging.getLogger('') def a(): model_logger.info(\"qwer\",extra= dict(params = [\"123\",12])) a() [2018-06-06 17:35:01 +0800] :: :: INFO :: 27392 :: - line 6 - funcname: a - params: ['123', 12] :: qwer 由此延伸的就是使用json格式的文件进行配置了,毕竟字典和json在python中几乎可以完全等价的互换.本文不再延伸,读者可以自己去试试 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/调试工具.html":{"url":"工具链篇/调试工具.html","title":"调试工具","keywords":"","body":"代码调试 代码调试主要是debug,也就是确保程序不出错误.基本可以分为如下几个方面: 单步调试,一步一步的查看代码的运行状态 调用追踪,查看函数报错在堆栈中的状况 段错误追踪,一般用于C写扩展的模块追踪内存泄漏等错误 单步调试模块 pdb是python自带的调试模块,它可以在交互环境中使用,也可以在terminal中作为python的一个模式使用 要调试的脚本: #!/usr/bin/env python3 class Counter(object): \"\"\"一个计数器 用法: >>> counter1 = Counter() >>> counter1() 1 >>> counter1() 2 >>> counter2 = Counter(lambda : 2,-3) >>> counter2() -1 >>> counter2() 1 \"\"\" def __str__(self): return \"state:\"+str(self.value) def __repr__(self): return self.__str__ def __call__(self): def count(): self.value += self.func() return self.value return count() def __init__(self,func=lambda : 1,start=0): self.value = start self.func = func test = Counter() test() test() print(test) if __name__==\"__main__\": counter1 = Counter() counter2 = Counter() for i in range(10): counter1() for i in range(8): counter2() if counter1.value == counter2.value: print(\"not success\") else: print(\"don't known\") import doctest doctest.testmod(verbose=True) 命令行调试 python -m pdb counter.py 在交互shell中调试 import pdb import counter pdb.run('counter.test()') 常用的调试命令可以在调试模式下用help命令来查看 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/调用追踪与异常栈追踪.html":{"url":"工具链篇/调用追踪与异常栈追踪.html","title":"调用追踪与异常栈追踪","keywords":"","body":"调用追踪 我们的函数都是执行在栈中的,调用追踪就是追踪函数执行的栈信息.调试的时候我们除了想知道哪条代码错了,也会想知道是谁调用了这条错误的代码. 又或者希望知道运行时的堆栈信息.这个时候调用追踪模块就有用了 本节需要的预备知识有: 异常与警告 一个简单的例子 import traceback def func(): s = traceback.extract_stack() print('%s Invoked me!'%s[-2][2]) def a(): func() b = lambda :func() a() a Invoked me! b() Invoked me! traceback的api是这些，我将它翻译出来，英文不好的同学也可以对照着使用: traceback.print_tb(tb, limit=None, file=None) 如果limit参数是正数,则打印limit条数的(从调用者这一帧开始的)traceback对象的堆栈跟踪条目,否则打印最后的abs(limit)条目,如果limit被省略或为None，则打印所有条目 如果省略file或者None，则输出到sys.stderr,否则它应该是一个打开的文件或类似文件的对象来接收输出。 打印，以限制堆栈跟踪条目从traceback对象(从调用者这帧开始)，如果限制是积极的。否则，打印最后的ABS（限制）条目。如果限制被省略或没有，所有条目打印。如果文件被省略或没有，输出到`sys.stderr`；否则应打开的文件或类似文件的对象来接收输出。 traceback.print_exception(etype, value, tb, limit=None, file=None, chain=True) 将异常信息和堆栈跟踪条目从traceback对象tb打印到文件。这与print_tb()有以下不同: 如果tb不是None，它会打印一个 header Traceback（通常是最近一次调用）： 它在堆栈跟踪之后打印异常etype和值 如果etype是SyntaxError，并且value具有相应的格式，则会打印出语法错误发生的行，并带有指示错误大致位置的插入符号。 可选的limit参数与`print_tb()`的含义相同.如果chain为true（默认值），那么也会打印异常链（`__cause__`或`__context__`异常的属性），就像解释器本身在打印未处理的异常时一样。 traceback.print_exc(limit=None, file=None, chain=True) print_exception(*sys.exc_info(), limit, file, chain)的缩写 traceback.print_last(limit=None, file=None, chain=True) 这是print_exception(sys.last_type，sys.last_value，sys.last_traceback，limit，file，chain)的缩写。一般来说，只有在异常已经达到交互式提示之后才会有效 traceback.print_stack(f=None, limit=None, file=None) 如果limit为正值则以limit参数为条数打印堆栈跟踪条目(从调用点开始)否则，打印最后一个abs(limit)条目。如果省略limit或None，则打印所有条目。可选的f参数可用于指定要启动的备用堆栈帧。可选file参数与print_tb()具有相同的含义。 traceback.extract_tb(tb, limit=None) 返回从traceback对象tb提取的“预处理”堆栈跟踪条目列表。它对于堆栈跟踪的替代格式很有用。可选的limit参数与print_tb()的含义相同。 “预处理”堆栈跟踪条目是表示通常为堆栈跟踪打印的信息的4元组(文件名，行号，函数名称，文本)。文本是带有前导和尾随空格的字符串;如果源不可用，则为None。 traceback.extract_stack(f=None, limit=None) 从当前堆栈帧中提取原始的追溯。返回值的格式与extract_tb()的格式相同。可选的f和limit参数与print_stack()具有相同的含义。 traceback.format_list(extracted_list) 给定一个由extract_tb()或extract_stack()返回的元组列表，返回一个准备打印的字符串列表。结果列表中的每个字符串对应于参数列表中具有相同索引的项。每个字符串以换行符结尾.对于源文本行不为None的项目，字符串也可能包含内部换行符。 traceback.format_exception_only(etype, value) 格式化traceback的异常部分。参数是异常类型和值，例如由sys.last_type和sys.last_value给出的。返回值是一个字符串列表，每个都以换行符结尾。通常，列表包含单个字符串;但是，对于SyntaxError异常，它包含几行(打印时)显示有关发生语法错误的详细信息。指示发生哪个异常的消息是列表中始终最后一个字符串。 traceback.format_exception(etype, value, tb, limit=None, chain=True) 格式化堆栈跟踪和异常信息。参数与print_exception()的相应参数具有相同的含义。返回值是字符串列表，每个都以换行符结尾，一些包含内部换行符。当这些行连接并打印时，打印与print_exception()完全相同的文本。 traceback.format_exc(limit=None, chain=True) 类似print_exc(limit)，但是返回一个字符串而不是打印到一个文件 traceback.format_tb(tb, limit=None) format_list(extract_tb(tb，limit))的缩写 traceback.format_stack(f=None, limit=None) format_list(extract_stack(f, limit))的缩写 traceback.clear_frames(tb) 通过调用每个帧对象的clear()方法来清除traceback对象tb中所有堆栈帧的局部变量。 traceback.walk_stack(f) 从给定帧中的f.f_back后面移动一个堆栈，产生每个帧的帧和行号。如果f为None，则使用当前堆栈。它常用于和StackSummary.extract()一起使用。 traceback.walk_tb(tb) 在tb_next之后走一个回溯，产生每个帧的帧和行号。此帮助程序与StackSummary.extract()一起使用。 class traceback.StackSummary StackSummary对象表示可以进行格式化的调用堆栈,它的静态方法extract 常与traceback.walk_stack或者traceback.walk_tb配合使用 classmethod extract(frame_gen, *, limit=None, lookup_lines=True, capture_locals=False) 从帧生成器构造一个StackSummary对象(例如由walk_stack()或walk_tb()的返回).如果有limit参数，则只有这么多帧是从frame_gen中获取的。如果lookup_lines为False，则返回的FrameSummary对象将不会读取它们的行，从而使得创建StackSummary的成本更低(如果实际上可能没有格式化，则可能是有价值的).如果capture_locals为True，则每个FrameSummary中的局部变量被捕获为对象表示。 *段错误追踪 所谓的段错误就是指访问的内存超出了系统所给这个程序的内存空间，通常这个值是由gd tr来保存的，他是一个48位的寄存器，其中的32位是保存由它指向的 gdt表，后13位保存 相应于gdt的下标，最后3位包括了程序是否在内存中以及程序的在cpu中的运行级别，指向 的gdt是由以64位为一个单位的表，在这张表中就保存着程序运行的代码段以及数据段的起 始地址以及与此相应的段限和页面交换还有程序运行级别还有内存粒度等等的信息。 在编程中以下几类做法容易导致段错误,基本上是错误地使用指针引起的。 访问系统数据区，尤其是往系统保护的内存地址写数据最常见就是给一个指针以0地址。 内存越界(数组越界，变量类型不一致等)： 访问到不属于你的内存区域。 python由于与C有着千丝万缕的联系,所以使用ctypes这类模块的时候也很容易出段错误这种问题.python3.5+提供了faulthandler工具来做段错误追踪. %%writefile src/C3/faulthandler_test.py import ctypes ctypes.string_at(0) Overwriting src/C3/faulthandler_test.py !python3 src/C3/faulthandler_test.py !python3 -q -X faulthandler src/C3/faulthandler_test.py Fatal Python error: Segmentation fault Current thread 0x00007fff9462e380 (most recent call first): File \"/Users/huangsizhe/anaconda3/lib/python3.6/ctypes/__init__.py\", line 492 in string_at File \"src/C3/faulthandler_test.py\", line 3 in 另一中用法是在文件内写入faulthandler.enable() %%writefile src/C3/faulthandler_test2.py import ctypes import faulthandler faulthandler.enable() ctypes.string_at(0) Overwriting src/C3/faulthandler_test2.py !python3 src/C3/faulthandler_test2.py Fatal Python error: Segmentation fault Current thread 0x00007fff9462e380 (most recent call first): File \"/Users/huangsizhe/anaconda3/lib/python3.6/ctypes/__init__.py\", line 492 in string_at File \"src/C3/faulthandler_test2.py\", line 5 in Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:51:48 "},"工具链篇/单元测试.html":{"url":"工具链篇/单元测试.html","title":"单元测试","keywords":"","body":"单元测试 项目写完后应该写测试以确保代码稳定可靠.经过测试稳定可靠的代码才能经得住时间的考验.但即便有测试,如果代码覆盖不够,测试用例不能覆盖全部情况,这样也并不能保准项目就一定稳健.因此条件允许的话也最好将类型注释写好,利用mypy做好静态类型检验. 将代码分解为独立不耦合的小部件,针对这些小部件的测试就是单元测试.测试单元应该集中于小部分的功能，并且证明在各种情况下它的行为正确(包括错误行为). 常常将测试代码和运行代码一起写是一种非常好的习惯。聪明地使用这种方法将会帮助你更加精确地定义代码的含义，并且代码的耦合性更低。 一般来说,更加推崇的方法是先写测试用例确定代码行为,再写代码,也就是所谓的测试驱动编程. 测试的通用规则： 测试单元应该集中于小部分的功能，并且证明它是对的。 每个测试单元应该完全独立。每个都能够单独运行，除了调用的命令，都需在测试套件中。要想实现这个规则，测试单元应该加载最新的数据集，之后再做一些清理。 尽量使测试单元快速运行。如果一个单独的测试单元需要较长的时间去运行，开发进度将会延迟，测试单元将不能如期常态性运行。有时候，因为测试单元需要复杂的数据结构，并且当它运行时每次都要加载，所以其运行时间较长。把运行吃力的测试单元放在单独的测试组件中，并且按照需要运行其它测试单元。 学习使用工具，学习如何运行一个单独的测试用例。然后，当在一个模块中开发了一个功能时，经常运行这个功能的测试用例，理想情况下，一切都将自动。 在编码会话前后，要常常运行完整的测试组件。只有这样，你才会坚信剩余的代码不会中断。 实现钩子（hook）是一个非常好的主意。因为一旦把代码放入分享仓库中，这个钩子可以运行所有的测试单元。 如果你在开发期间不得不打断自己的工作，写一个被打断的单元测试，它关于下一步要开发的东西。当回到工作时，你将更快地回到原先被打断的地方，并且步入正轨。 当你调试代码的时候，首先需要写一个精确定位bug的测试单元。尽管这样做很难，但是捕捉bug的单元测试在项目中很重要。 测试函数使用长且描述性的名字。这边的样式指导与运行代码有点不一样，运行代码更倾向于使用短的名字，而测试函数不会直接被调用。在运行代码中，square()或者甚至sqr()这样的命名都是可以的，但是在测试代码中，你应该这样取名test_square_of_number_2()，test_square_negative_number()。当测试单元失败时，函数名应该显示，而且尽可能具有描述性。 当发生了一些问题，或者不得不改变时，如果代码中有一套不错的测试单元，维护将很大一部分依靠测试组件解决问题，或者修改确定的行为。因此测试代码应该尽可能多读，甚至多于运行代码。目的不明确的测试单元在这种情况下没有多少用处。 测试代码的另外一个用处是作为新开发人员的入门。当工作基于代码，运行并且阅读相关的测试代码是一个非常好的做法。开发人员将会或者应该发现热点，而这将引起困难和其它情况，如果他们一定要加一些功能，第一步应该是要增加一个测试单元，通过这种方法，确保新功能不再是一个没有被嵌入到接口中的工作路径。 unittest模块 python标准库中自带了unittest框架以用来做单元测试.unittest已经可以满足一般的测试需求了.它包含了所有测试框架需要的部件.相比较使用第三方测试框架,unittest相对来说更加稳定可靠,而且作为标准库,也避免了额外的依赖安装. 使用 unittest 的标准流程为： 从 unittest.TestCase 派生一个子类 在类中定义各种以 \"test_\" 打头的方法 通过 unittest.main() 函数来启动测试 unittest可以指定测试模块使用 unittest test.py或者unittest test或者unittest test.test 它可以带上以下参数 -v 测试的详细信息 -f 出错就停 -c 可以用ctrol+c停止,并出结果 -b 运行时结果存到stderr和stdout里 unittest 支持自动搜索,这需要在后面加上子选项discover, discover可以有这些参数: -s 指定文件夹 -t 指定模块 -p 模式匹配要测试的文件 unittest 的一个很有用的特性是 TestCase 的 setUp() 和 tearDown() 方法，这种方法统称\"钩子\"它们提供了为测试进行准备和扫尾工作的功能，听起来就像上下文管理器一样。这种功能很适合用在测试对象需要复杂执行环境的情况下。 基本用法 我们将测试如下这个模块: %%writefile src/C3/func_oper_unitest.py #!/usr/bin/env python \"\"\"\\ 这里可以写用到多个函数的 \"\"\" from functools import reduce from operator import mul,add def multiply(*args): \"\"\"\\ 这里可以写单元测试 >>> multiply(2,3) 6 >>> multiply('baka~',3) 'baka~baka~baka~' \"\"\" return reduce(mul,args) def summing(*args): \"\"\"\\ 这里可以写单元测试 >>> summing(2,3) 5 >>> summing(2,3,4) 9 \"\"\" return reduce(add,args) Overwriting src/C3/func_oper_unitest.py 测试用例 测试用例是指一系列相关测试的实例.如何界定这个相关程度根据实际情况而定,比如粗略的测试可以以模块为单位,一个模块的测试都放在一个测试用例中,细致的则可以是针对一个函数或者一个接口的测试都放在一个测试用例中. unittest.TestCase是测试用例的超类,编写测试用例只要继承它即可. %%writefile src/C3/test_my.py import unittest from func_oper_unitest import multiply,summing class Test_mul(unittest.TestCase): def setUp(self): pass def test_number_3_4(self): self.assertEqual(multiply(3,4),12) def test_string_a_3(self): self.assertEqual(multiply('a',3),'aaa') class Test_sum(unittest.TestCase): def setUp(self): pass def test_number_3_4(self): self.assertEqual(summing(3,4),7) def test_number_3_4_5(self): self.assertEqual(summing(3,4,5),12) class TestCase1(unittest.TestCase): def setUp(self): pass def test_sum_mul_2_3_mul_2_3(self): self.assertEqual(summing(multiply(2,3),multiply(2,3)),12) if __name__ == '__main__': unittest.main() Overwriting src/C3/test_my.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.003s FAILED (failures=8, skipped=2, expected failures=2) 钩子 如果要对一个模块中的每一个测试函数都做同样的初始化操作和结尾清除等操作，那么创建n个测试用例就得写n遍一样的代码，为了减少重复的代码， 测试用例的实例可以使用下面两个函数定义其中每个测试样例的初始化和清除工作： setUp(self): 每次执行测试用例之前调用。无参数，无返回值。该方法抛出的异常都视为error，而不是测试不通过。没有默认的实现。 tearDown(self): 每次执行测试用例之后调用。无参数，无返回值。测试方法抛出异常，该方法也正常调用，该方法抛出的异常都视为error，而不是测试不通过。只用setUp()调用成功，该方法才会被调用。没有默认的实现。通过setup 和 tesrDown组装一个module成为一个固定的测试装置。注意：如果setup运行抛出错误，则测试用例代码则不会执行。但是，如果setpu执行成功，不管测试用例是否执行成功都会执行teardown。 测试用例也有一个类级别的钩子,它可以在测试用例类实例化之前和类全部测试实例运行完后进行操作 @classmethod def setUpClass(cls): cls._connection = createExpensiveConnectionObject() @classmethod def tearDownClass(cls): cls._connection.destroy() 测试钩子也可以定义模块级别的钩子,它会在模块被引用和模块运行结束后进行工作 def setUpModule(): createConnection() def tearDownModule(): closeConnection() %%writefile src/C3/test_hook.py import unittest from func_oper_unitest import multiply,summing def setUpModule(): print(\"setUpModule\") def tearDownModule(): print(\"tearUpModule\") class Test_mul(unittest.TestCase): @classmethod def setUpClass(cls): print(\"setUpClass\") @classmethod def tearDownClass(cls): print(\"tearDownClass\") def setUp(self): print(\"instance setUp\") def tearDown(self): print(\"instance tearDown\") def test_number_3_4(self): print(\"t1\") self.assertEqual(multiply(3,4),12) def test_string_a_3(self): print(\"t2\") self.assertEqual(multiply('a',3),'aaa') if __name__ == '__main__': unittest.main() Overwriting src/C3/test_hook.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.003s FAILED (failures=8, skipped=2, expected failures=2) 上面的结果可以很清洗的看到测试钩子的上下文范围. 断言 断言是用来声明结果状态的工具,如果结果符合预期,那么断言就该通过,否则断言就该报断言错误 python自带断言关键字assert assert 1==1 assert 1==0 --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) in () ----> 1 assert 1==0 AssertionError: 自带的断言关键字功能单一,往往不能完全满足测试需要,比如要测报错的错误类型就很麻烦了,因此除assert关键字外,彪悍尊哭unittest模块还有其他几个断言工具实现更加复杂的断言. 基本断言方法 基本的断言方法提供了测试结果是True还是False。所有的断言方法都有一个msg参数，如果指定msg参数的值，则将该信息作为失败的错误信息返回。 断言方法 断言描述 assertEqual(arg1, arg2, msg=None) 验证arg1=arg2，不等则fail assertNotEqual(arg1, arg2, msg=None) 验证arg1 != arg2, 相等则fail assertTrue(expr, msg=None) 验证expr是true，如果为false，则fail assertFalse(expr,msg=None) 验证expr是false，如果为true，则fail assertIs(arg1, arg2, msg=None) 验证arg1、arg2是同一个对象，不是则fail assertIsNot(arg1, arg2, msg=None) 验证arg1、arg2不是同一个对象，是则fail assertIsNone(expr, msg=None) 验证expr是None，不是则fail assertIsNotNone(expr, msg=None) 验证expr不是None，是则fail assertIn(arg1, arg2, msg=None) 验证arg1是arg2的子串，不是则fail assertNotIn(arg1, arg2, msg=None) 验证arg1不是arg2的子串，是则fail assertIsInstance(obj, cls, msg=None) 验证obj是cls的实例，不是则fail assertNotIsInstance(obj, cls, msg=None) 验证obj不是cls的实例，是则fail 容器断言 判断两个容器中内容是否一样 断言方法 针对容器 断言描述 assertMultiLineEqual(a, b) strings 比较两个字符串是否一样 assertSequenceEqual(a, b) sequences 比较两个序列是否一样 assertListEqual(a, b) lists 比较两个list是否一样 assertTupleEqual(a, b) tuples 比较两个元组是否一样 assertSetEqual(a, b) sets 或者 frozensets 比较两个集合是否一样 assertDictEqual(a, b) dicts 比较两个字典是否一样 模糊比较断言 unittest框架提供的第二种断言类型就是比较断言。 下面我们看下各种比较断言： 断言方法 断言描述 参数说明 assertAlmostEqual (first, second, places = 7, msg = None, delta = None) 验证first约等于second. palces: 指定精确到小数点后多少位，默认为7 assertNotAlmostEqual (first, second, places, msg, delta) 验证first不约等于second。 palces: 指定精确到小数点后多少位，默认为7,注： 在上述的两个函数中，如果delta指定了值，则first和second之间的差值必须≤delta== assertGreater (first, second, msg = None) 验证first > second，否则fail --- assertGreaterEqual (first, second, msg = None) 验证first ≥ second，否则fail --- assertLess (first, second, msg = None) 验证first --- assertLessEqual (first, second, msg = None) 验证first ≤ second，否则fail --- assertRegexpMatches (text, regexp, msg = None) 验证正则表达式regexp搜索==匹配==的文本text regexp：通常使用re.search() assertNotRegexpMatches (text, regexp, msg = None) 验证正则表达式regexp搜索==不匹配==的文本text regexp：通常使用re.search() 异常断言 断言方法 断言描述 assertRaises(exc, fun, *args, **kwds) 验证异常测试，第一个参数是预期的异常,第二个则是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的异常，否则测试失败. assertRaisesRegex(exc, r, fun, *args, **kwds) 验证异常测试，第一个参数是预期的异常,第二个参数则是一个用来匹配错误信息的正则表达式,第三个则是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的异常,且错误信息也匹配，否则测试失败. assertWarns(warn, fun, *args, **kwds) 验证警告测试，第一个参数是预期的警告,第二个参数是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的警告否则测试失败. assertWarnsRegex(warn, r, fun, *args, **kwds) 验证警告测试，第一个参数是预期的警告,第二个参数则是一个用来匹配警告信息的正则表达式,第三个则是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的警告，且警告信息也匹配否则测试失败. assertLogs(logger, level) 断言log信息 异常断言与其他不太一样,往往结合上下文使用 %%writefile src/C3/test_assert_base.py import unittest class demoTest(unittest.TestCase): def test_eq(self): self.assertEqual(4 + 5,9) def test_not_eq(self): self.assertNotEqual(5 * 2,10) def test_seq(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) def test_not_seq(self): a = [\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\",\"4\") self.assertSequenceEqual(a, b) def test_almost_eq(self): self.assertAlmostEqual(1.003, 1.004, places = 2) def test_not_almost_eq(self): self.assertAlmostEqual(1.003, 1.004, places = 4) def test_exc(self): def fun(): assert 0 self.assertRaises(AssertionError, fun) def test_with_exc(self): def fun(): assert 0 with self.assertRaises(AssertionError) as a: fun() Overwriting src/C3/test_assert_base.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.004s FAILED (failures=8, skipped=2, expected failures=2) 跳过测试和预期测试出错 unittest提供了4个装饰器来控制测试的行为 @unittest.skip(reason) 跳过测试用例的某条测试项目 @unittest.skipIf(condition, reason) 如果条件condition条件成立,那就跳过测试用例的某条测试项目 @unittest.skipUnless(condition, reason) 如果条件condition条件不成立,那就跳过测试用例的某条测试项目 @unittest.expectedFailure 断定测试项目会失败 %%writefile src/C3/test_assert_skip.py import unittest class demoTest(unittest.TestCase): @unittest.skip(\"跳过\") def test_eq(self): self.assertEqual(4 + 5,9) @unittest.expectedFailure def test_not_eq(self): self.assertNotEqual(5 * 2,10) @unittest.skipIf(1==0, \"if 1 ==0\") def test_seq(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) @unittest.skipUnless(1==0, \"unless 1 ==0\") def test_seq_2(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) @unittest.expectedFailure def test_not_seq(self): a = [\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\",\"4\") self.assertSequenceEqual(a, b) Overwriting src/C3/test_assert_skip.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.005s FAILED (failures=8, skipped=2, expected failures=2) 使用子测验进行迭代测试 有时候我们希望对一个迭代器中的内容分别进行测试,这种时候就可以使用测试样例的subTest上下文 %%writefile src/C3/test_subtest.py import unittest class demoTest(unittest.TestCase): def test_subtest(self): for i in range(0, 6): with self.subTest(i=i): self.assertEqual(i % 2, 0) Overwriting src/C3/test_subtest.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.007s FAILED (failures=8, skipped=2, expected failures=2) 分组测试 很多时候我们希望将测试用例组织起来一部分一部分的测试而不是一次全测了,这种时候就可以使用unittest.TestSuite组织需要的测试,细化的运行测试. 注意细分的测试不能用命令行工具来运行了,而是应该独立运行脚本 %%writefile src/C3/test_suite.py import unittest class ArithTest(unittest.TestCase): def test_eq(self): self.assertEqual(4 + 5,9) def test_not_eq(self): self.assertNotEqual(5 * 2,10) def test_seq(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) def test_not_seq(self): a = [\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\",\"4\") self.assertSequenceEqual(a, b) def suite(): suite = unittest.TestSuite() suite.addTest(ArithTest(\"test_eq\")) suite.addTest(ArithTest('test_seq')) return suite if __name__ == '__main__': runner = unittest.TextTestRunner(verbosity=2) test_suite = suite() runner.run(test_suite) Overwriting src/C3/test_suite.py !python3 src/C3/test_suite.py test_eq (__main__.ArithTest) ... ok test_seq (__main__.ArithTest) ... ok ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK 测试模块最佳实践 测试驱动的开发模式中,我们需要全局测试以便了解被测试到的代码覆盖情况,也需要对每个单独的文件执行测试,用来了解针对某一接口或者功能的测试是否可以通过,因此我们需要测试模块可以全局测试也可以单测试文件测试.假设我们的测试模块文件结构如下: test| |---__init__.py |---test_model1| | |--__init__.py | |--test_interface1.py | |--test_interface2.py | |---test_model2| | |--__init__.py | |--test_interface3.py | |---main.py mock测试 mock测试就是在测试过程中，对于某些不容易构造或者不容易获取的对象，用一个虚拟的对象来创建以便测试的测试方法。 mock测试通常有几个使用场景: 调用外部接口 通常我的软件都会调用一些已有的服务,与这些服务进行交互我们才能顺利执行软件.这就引入了副作用——我们测试的时候不希望真的为了测试而这些外部服务,但不调用往往我们的业务逻辑又进展不下去.直观一点,我们希望测试一项扫码付款功能,它需要调用支付宝的付款接口,我们测试的时候当然并不希望真的调用支付宝付款,毕竟会真的产生交易,这种时候就是mock测试的用武之地了. 模拟耗时步骤 比如我们要写一个代码,它会进行一步耗时1小时的计算(可以假设是使用tensorflow训练一个深度学习模型).而我们的测试代码只是希望测试出去训练模型外的业务逻辑有没有出错,这样的话就可以使用mock模拟一下这一步耗时的计算,这样就可以先调通其他逻辑,确保无误后再构建完整的代码了 不修改环境的测试 比如我们的测试要删除数据库中的一条数据,而我们并不是真的要删掉,而是测试功能是否可以实现,这种时候就可以使用mock测试了 一个真实的例子 unittest模块提供了一个mock子模块, 我们以一个测试文件删除的例子来看看mock怎么工作的 待测脚本: 待测脚本可以判断path是不是文件,如果是就删除 %%writefile rm.py import os import os.path def rm(filename): if os.path.isfile(filename): os.remove(filename) Overwriting rm.py 测试用例: %%writefile test/rm_test_1.py from rm import rm from unittest import mock from unittest import TestCase class RmTestCase(TestCase): @mock.patch('rm.os.path') @mock.patch('rm.os') def test_rm(self, mock_os, mock_path): # mock_path就是patch过后的`os.path`,mock_os就是patch过后的`os` #需要注意顺序 #指定`mock_path.isfile`的返回值False mock_path.isfile.return_value = False rm(\"any path\") #测试mock_os.remove有没有被调用 self.assertFalse(mock_os.remove.called, \"Failed to not remove the file if not present.\") # 指定`mock_path.isfile`的返回值为True mock_path.isfile.return_value = True rm(\"any path\") mock_os.remove.assert_called_with(\"any path\") Overwriting test/rm_test_1.py !python3 -m unittest -v test.rm_test_1 test_rm (test.rm_test_1.RmTestCase) ... ok ---------------------------------------------------------------------- Ran 1 test in 0.001s OK mock.patch装饰器将指定的对象替换为mock,其实质就是猴子补丁. 利用patch装饰器将原始对象替换为mock对象,并将替换后的对象作为参数传入测试用例的测试项中 指定mock行为 mock对象是假的,但他可以模拟真实行为,以下是它的接口: from unittest.mock import Mock mock = Mock() 断言行为 assert_called 断言方法被调用过至少一次 mock.method.assert_called() --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) in () ----> 1 mock.method.assert_called() ~/anaconda3/lib/python3.6/unittest/mock.py in assert_called(_mock_self) 784 msg = (\"Expected '%s' to have been called.\" % 785 self._mock_name or 'mock') --> 786 raise AssertionError(msg) 787 788 def assert_called_once(_mock_self): AssertionError: Expected 'method' to have been called. mock.method() mock.method.assert_called() assert_called_once 断言方法只被调用过一次(3.6) mock.method.assert_called_once() mock.method() mock.method.assert_called_once() --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) in () ----> 1 mock.method.assert_called_once() ~/anaconda3/lib/python3.6/unittest/mock.py in assert_called_once(_mock_self) 793 msg = (\"Expected '%s' to have been called once. Called %s times.\" % 794 (self._mock_name or 'mock', self.call_count)) --> 795 raise AssertionError(msg) 796 797 def assert_called_with(_mock_self, *args, **kwargs): AssertionError: Expected 'method' to have been called once. Called 2 times. assert_called_with(*args, **kwargs) 断言方法被调用过且调用时的参数为填入的参数 mock.method(1,2,k=4) mock.method.assert_called_with(1, 2,k=4) assert_called_once_with(*args, **kwargs) 断言方法只被调用过一次且调用时的参数为填入的参数 assert_any_call(*args, **kwargs) 断言对象有方法被用参数调用过调用过 assert_has_calls(calls, any_order=False) 断言某些结果是被mock对象产出的 mock = Mock(return_value=None) call1 = mock(1) call2 = mock(2) call3 = mock(3) call4 = mock(4) mock.mock_calls# 查看mock对象的call对象 [call(1), call(2), call(3), call(4)] call1 = mock.mock_calls[0] call1 call(1) mock.assert_has_calls(mock.mock_calls[:2]) mock.assert_has_calls(mock.mock_calls, any_order=True) assert_not_called() 断言mock对象没被调用过 设置行为 reset_mock(*, return_value=False, side_effect=False) 重置mock对象,side_effect翻译为副作用,可以设置一个异常 mock_add_spec(spec, spec_set=False) 为mock设置规范,来定义mock对象内部的属性(attribute) attach_mock(mock, attribute) 为mock设置一个mock对象在它上面 configure_mock(**kwargs) 设置mock attrs = {'method.return_value': 3, 'other.side_effect': KeyError} mock.configure_mock(**attrs) mock.method() 3 mock.other() --------------------------------------------------------------------------- KeyError Traceback (most recent call last) in () ----> 1 mock.other() ~/anaconda3/lib/python3.6/unittest/mock.py in __call__(_mock_self, *args, **kwargs) 937 # in the signature 938 _mock_self._mock_check_sig(*args, **kwargs) --> 939 return _mock_self._mock_call(*args, **kwargs) 940 941 ~/anaconda3/lib/python3.6/unittest/mock.py in _mock_call(_mock_self, *args, **kwargs) 993 if effect is not None: 994 if _is_exception(effect): --> 995 raise effect 996 997 if not _callable(effect): KeyError: return_value 设置mock的返回值 mock = Mock() mock.return_value = 'fish' mock() 'fish' side_effect 设置一个副作用,也就是异常 mock = Mock() mock.side_effect = Exception('Boom!') mock() --------------------------------------------------------------------------- Exception Traceback (most recent call last) in () 3 4 ----> 5 mock() ~/anaconda3/lib/python3.6/unittest/mock.py in __call__(_mock_self, *args, **kwargs) 937 # in the signature 938 _mock_self._mock_check_sig(*args, **kwargs) --> 939 return _mock_self._mock_call(*args, **kwargs) 940 941 ~/anaconda3/lib/python3.6/unittest/mock.py in _mock_call(_mock_self, *args, **kwargs) 993 if effect is not None: 994 if _is_exception(effect): --> 995 raise effect 996 997 if not _callable(effect): Exception: Boom! mock状态监控 called 是否被调用过 call_count 被调用计数 call_args mock的最近的call对象 mock = Mock(return_value=None) print(mock.call_args) None mock() mock.call_args call() mock.call_args == () True mock(3, 4) mock.call_args call(3, 4) mock.call_args == ((3, 4),) True mock(3, 4, 5, key='fish', next='w00t!') mock.call_args call(3, 4, 5, key='fish', next='w00t!') call_args_list mock的call对象列表 mock.call_args_list [call(), call(3, 4), call(3, 4, 5, key='fish', next='w00t!')] method_calls mock对象中的方法调用情况 mock.method_calls [] mock.method1() mock.method_calls [call.method1()] mock_calls mock自身调用和其方法调用情况 mock.mock_calls [call(), call(3, 4), call(3, 4, 5, key='fish', next='w00t!'), call.method1()] 测试覆盖率 测试通过往往也并不能保证程序一定稳健可靠,因为测试很有可能没有覆盖全面.这时候测试覆盖率就成了评价一个项目可靠程度的标准之一了. python标准库没有提供覆盖率统计工具,但coverage.py已经是实质上的覆盖率标准工具了. coverage的使用有两步: 使用coverage脚本的run命令执行脚本 !python3 -m coverage run src/C3/test_suite.py test_eq (__main__.ArithTest) ... ok test_seq (__main__.ArithTest) ... ok ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK 使用report/html命令输出覆盖率结果 !coverage report Name Stmts Miss Cover ------------------------------------------ src/C3/test_suite.py 23 4 83% 如果是针对全局的测试覆盖率,那么这样用: !python3 -m coverage run --source=src/C3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/工具链篇/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.004s FAILED (failures=8, skipped=2, expected failures=2) 其中--source=用于指定要测试覆盖率的文件夹 !python3 -m coverage report Name Stmts Miss Cover --------------------------------------------------- src/C3/Obj_test.py 7 7 0% src/C3/__init__.py 0 0 100% src/C3/faulthandler_test.py 2 2 0% src/C3/faulthandler_test2.py 4 4 0% src/C3/func_oper_unitest.py 7 0 100% src/C3/line_profile_test.py 7 7 0% src/C3/memory_test.py 15 15 0% src/C3/memory_test_round.py 8 8 0% src/C3/profile_test.py 11 11 0% src/C3/profile_test_foo.py 7 7 0% src/C3/profile_test_pstats.py 14 14 0% src/C3/rm.py 3 3 0% src/C3/test_assert_base.py 27 0 100% src/C3/test_assert_skip.py 18 4 78% src/C3/test_hook.py 23 1 96% src/C3/test_my.py 23 1 96% src/C3/test_subtest.py 6 0 100% src/C3/test_suite.py 23 7 70% --------------------------------------------------- TOTAL 205 91 56% 当然了还有其他的知名测试框架比如nose,green等,都很值得尝试.但个人觉得标准库的测试框架已经相当够用,结合coverage.py,也很简单直接.少即是多,我们的项目应该尽量减少第三方依赖 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/部署服务.html":{"url":"工具链篇/部署服务.html","title":"部署服务","keywords":"","body":"部署服务 python有一套完善的项目部署方案,从打包到环境隔离,再到监控,一应俱全.如果没有特殊需求,完全可以跳过容器直接使用.当然了如果运维希望使用docker这类容器部署以限制各个项目的资源使用量时,得益于zipapp和pip,python也同样简单易于部署. 打包与分发 python3.5提供了一种打包分发的方式--zipapp(PEP 441).它可以将写好的项目打包成.pyz文件,这样就可以简单的将项目四处分发了.注意,这种方式最好是打包纯python代码,这样不容易因为平台不同而出现无法使用的情况.如果有c扩展,那么最好单独抽出来写成模块利用pip单独安装. .pyz文件并不能独立运行,依然依赖python环境.因此如果不用docker打包的话最好使用虚拟环境让项目在虚拟环境中运行. zipapp的用法如下: python -m zipapp myapp -m \"myapp:main\" myapp是一个项目文件夹,并非模块,我们使用-m指定使用其中的哪个模块的哪个方法作为入口 同时也可以使用-p指定一个字符串作为Shebang python -m zipapp myapp -m \"myapp:main\" -p \"/user/bin/env python3\" zipapp本质是一个用zip打包项目的工具,它的定位其实是简化版jar.一个打包好的二进制文件远比文件夹好分发使用.这也是go语言的核心竞争力之一.现在python有了这样一个工具,虽然使用起来还是要配合虚拟机和pip包管理工具,但已经很够用了. 使用虚拟环境部署 项目部署运行时不可能通过常规手段激活虚拟环境.而事实上也不需要,其实要使用虚拟环境只要指定好用虚拟环境的python解释器运行项目了.比如有个虚拟环境建在~/VENV文件夹.那么就可以直接使用这个文件夹下的python解释器直接使用. ~/VENV/bin/python myapp.pyz 批量部署 python的运维神器fabric,用它可以实现对远程服务器的批量部署操作 一些使用方法和心得可以看我的博客 服务监控 python的另一运维神器supervisor,配合cesi可以很好的监控管理项目进程.具体的可以看我的这篇博文 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/性能调优工具.html":{"url":"工具链篇/性能调优工具.html","title":"性能调优工具","keywords":"","body":"性能调优 在代码可以实现功能且健壮不出错的前提下,我们往往会有优化性能的需求 性能调优大约可以在运行时间和运行内存占用两方面来考量,下面介绍的工具定位精度由粗到细,也分为这两个方面 测试整体运行时间 Python中的timeit是测试代码执行效率的工具.可以用命令行直接测试脚本,也可以测试代码字符串的效率,当然最简单的还是直接用ipython的内置timeit魔法命令测某段代码的效率 import timeit t = timeit.Timer('map(lambda x: x**2,range(1000))') t.timeit() 0.404256040987093 !python -m timeit -s \"map(lambda x: x**2,range(1000))\" 100000000 loops, best of 3: 0.00833 usec per loop 函数级性能瓶颈定位 python的标准库中有一个可以实现性能瓶颈定位的模块叫cprofile,他是一个开销极小的C扩展.用它可以实现函数级的性能分析,配合pstats模块还可以输出分析报告 使用单独模块分析 %%writefile src/C3/profile_test.py def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C3/profile_test.py %%writefile src/C3/profile_test.py def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": try : import profile except: import cProfile as profile profile.run(\"foo()\") Overwriting src/C3/profile_test.py !python src/C3/profile_test.py 5 function calls in 0.002 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.001 0.001 :0(exec) 1 0.001 0.001 0.001 0.001 :0(setprofile) 1 0.000 0.000 0.001 0.001 :1() 1 0.000 0.000 0.002 0.002 profile:0(foo()) 0 0.000 0.000 profile:0(profiler) 1 0.001 0.001 0.001 0.001 profile_test.py:1(foo) 使用命令行分析 %%writefile src/C3/profile_test_foo.py #coding:utf-8 def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C3/profile_test_foo.py !python -m cProfile src/C3/profile_test_foo.py 4 function calls in 0.001 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.001 0.001 profile_test_foo.py:2() 1 0.001 0.001 0.001 0.001 profile_test_foo.py:2(foo) 1 0.000 0.000 0.001 0.001 {built-in method builtins.exec} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} 统计项说明 统计项 说明 ncalls 函数被调用次数 tottime 函数总计运行时间,不含调用函数运行时间 cumtime 函数总计运行时间,含调用的函数运行时间 percall 函数运行一次平均时间,等于tottime(cumtime)/ncalls filename:lineno 函数所在文件名,函数的行号,函数名 与pstats结合提供多种形式的报表 %%writefile src/C3/profile_test_pstats.py def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": try : import profile except: import cProfile as profile profile.run(\"foo()\",\"foo.txt\") import pstats p = pstats.Stats(\"foo.txt\") p.sort_stats(\"time\").print_stats() Overwriting src/C3/profile_test_pstats.py !python src/C3/profile_test_pstats.py Wed Jun 6 22:26:56 2018 foo.txt 5 function calls in 0.001 seconds Ordered by: internal time ncalls tottime percall cumtime percall filename:lineno(function) 1 0.001 0.001 0.001 0.001 src/C3/profile_test_pstats.py:1(foo) 1 0.000 0.000 0.000 0.000 :0(setprofile) 1 0.000 0.000 0.001 0.001 :0(exec) 1 0.000 0.000 0.001 0.001 profile:0(foo()) 1 0.000 0.000 0.001 0.001 :1() 0 0.000 0.000 profile:0(profiler) stats有许多函数,可以提供不同的报表 stats函数说明 函数 说明 strip_dirs() 除去文件名前名的路径信息 add(filename,[...]) 把profile输出的文件加入stats实例中统计 dump_stats(filename) 把stats统计结果保存到文件 sort_stats(key,[...]) 最重要的,可以给profile统计结果排序 reverse_order() 数据反排序 print_stats([restriction,...]) 把报表输出到stdout print_callers([restriction,...]) 输出调用指定函数的相关信息 print_callees([restriction,...]) 输出指定函数调用过的函数的相关信息 sort_stats可接受的参数 参数 说明 ncalls 被调次数 cumulative 函数运行总时间 file 文件名 module 模块名 pcalls 简单统计 line 行号 name 函数名 nfl name,file,line stdname 标准函数名 time 函数内部运行时间 语句级性能瓶颈定位 cprofiler只能追踪到哪个函数是性能瓶颈,而函数中哪条语句是性能瓶颈就追踪不到了,对于语句级性能瓶颈定位,python并没有官方工具,但github上有位大神制作了line_profiler,这个工具可以实现这一功能,它也几乎可以说是python的半标准工具之一了. 因为不是标准库中的内容,所以需要pip安装. 使用方法十分简单,在需要分析的函数上面加上装饰器@profile即可(注意不用import任何东西,这条装饰器在定位好后应该删除以保证代码可以运行) %%writefile src/C3/line_profile_test.py @profile def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C3/line_profile_test.py !python3 -m kernprof -l -v src/C3/line_profile_test.py Wrote profile results to line_profile_test.py.lprof Timer unit: 1e-06 s Total time: 0.00559 s File: src/C3/line_profile_test.py Function: foo at line 2 Line # Hits Time Per Hit % Time Line Contents ============================================================== 2 @profile 3 def foo(): 4 1 6.0 6.0 0.1 sum = 0 5 10001 2658.0 0.3 47.5 for i in range(10000): 6 10000 2926.0 0.3 52.3 sum += i 7 1 0.0 0.0 0.0 return sum 内存分析 memory_profiler是用来分析内存使用情况和追踪内存泄露的工具.它用法比较接近line_profiler 由于不是标准库中的模块,它需要pip安装. 需要注意的是windows下需要在script文件夹下将mprof文件改名为mprof.py并在同一目录下创建一个mprof.bat文件编辑为如下内容 @echo off python \"%~dpn0.py\" %* 它的使用及其简单: %%writefile src/C3/memory_test.py from memory_profiler import profile @profile def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": try : import profile as cProfile except: import cProfile cProfile.run(\"foo()\",\"foo.txt\") import pstats p = pstats.Stats(\"foo.txt\") p.sort_stats(\"time\").print_stats() Overwriting src/C3/memory_test.py 之后使用 python src/C3/memory_test.py 就可以看到详细结果了 指定精度可以在profile装饰器后面加上参数 如: @profile(precision=4) mprof工具类似kernprof,用它可以输出更加友好的统计分析页面 %%writefile src/C3/memory_test_round.py from memory_profiler import profile @profile def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C3/memory_test_round.py !mprof run src/C3/memory_test_round.py mprof: Sampling memory every 0.1s running as a Python program... Filename: src/C3/memory_test_round.py Line # Mem usage Increment Line Contents ================================================ 2 48.9 MiB 48.9 MiB @profile 3 def foo(): 4 48.9 MiB 0.0 MiB sum = 0 5 48.9 MiB 0.0 MiB for i in range(10000): 6 48.9 MiB 0.0 MiB sum += i 7 48.9 MiB 0.0 MiB return sum !mprof plot Using last profile data. Figure(1260x540) 对象分析及追踪(windows下不能用) Objgraph可以实现对象分析和追踪,它也是用pip安装,不过它依赖xdot(pip 安装) 和graphviz(brew安装) 它可以实现的功能有: 统计 定义过滤对象 遍历和显示对象图 %%writefile src/C3/Obj_test.py #encoding=utf-8 import objgraph if __name__ == '__main__': x = [] y = [x, [x], dict(x=x)] objgraph.show_refs([y], filename='sample-graph.png') #把[y]里面所有对象的引用画出来 objgraph.show_backrefs([x], filename='sample-backref-graph.png') #把对x对象的引用全部画出来 #objgraph.show_most_common_types() #所有常用类型对象的统计，数据量太大，意义不大 objgraph.show_growth(limit=4) #打印从程序开始或者上次show_growth到现在增加的对象（按照增加量的大小排序） Overwriting src/C3/Obj_test.py !python src/C3/Obj_test.py Graph written to /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/objgraph-jcx95ebu.dot (4 nodes) Image renderer (dot) not found, not doing anything else Graph written to /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/objgraph-ncj576f1.dot (7 nodes) Image renderer (dot) not found, not doing anything else function 2116 +2116 dict 1181 +1181 wrapper_descriptor 1002 +1002 tuple 945 +945 于是你可以看到图了 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"工具链篇/结语.html":{"url":"工具链篇/结语.html","title":"结语","keywords":"","body":"结语 编程语言的历史遗产与历史包袱 通常我们讲一门历史悠久的语言总归或多或少的有所谓的历史遗产和历史包袱.但很奇怪的是通常讲C++讲的都是包袱,讲python就是讲的遗产. 个人认为这和编程语言的发展过程和一些决策是有关系的. C++最早的目标就是做更好的C,因此在语言设计的时候充分考虑了向下兼容性,这当然有好处,可以在短期内利用现有的生态快速得到推广,相同思路的是编程语言julia,它可以几乎无缝的嵌入python和R的模块.但坏处也同样不可以无视--所兼容的语言及其开发者共性的的缺点也会被沿袭下来,造成与自身语言概念设计(这个词来源于人月传说)的冲突.而妥协是一种习惯,一旦有了一次就会有第二次,像C++为了向各种兼容就会做出各种妥协,慢慢慢慢这门语言就会失去一些核心的东西,而变得难以理解,历史包袱就这样诞生了. python发展过程中最大得益于3点: 它在适当的范围内被应用,这个范围不大也不小 python之父是一个意志坚定的人.这样它可以在实践的检验下维持自己的概念设计,不断的迭代优化. 开源 即便如今python3和python2都不兼容,python核心的概念设计完全没有改变过.因而他的包在多数时候都是可以修改到符合最新的版本.如果包作者不愿意更新,那很快也会有新的替代品,这样这门语言本身就是这个社区的核心,自然就可以淘汰掉包袱只留遗产了. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/":{"url":"语法篇/","title":"语法篇","keywords":"","body":"总章 就像九阴真经秘籍一样,总章部分讲的是python这门语言的\"内功\",也就是其设计哲学.python虽然现在很潮,但看现在的版本号和第三方包生态也知道其实这门语言挺古老的.回顾历史上种种编程语言,大多都是昙花一现,但最终还是被埋没在历史的长河中,能长期发展并逐渐构建出一个庞大而有活力的社区的屈指可数.一门语言能经久不衰一定会有其内在原因,而这往往与其设计哲学有相当大的关系.就像搞革命,胜利往往是思想的胜利. 设计哲学 每次给人安利python我都会搬出来python的设计主旨,不废话看下面 import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! python强调实用性,一致性和中庸,奉行少即是多的哲学思想.在这门编程语言的任何地方都可以看到这种设计哲学. 代码可读性 高质量代码有三要素：可读性、可维护性、可变更性.python设计思想非常强调可读性,很多人把它当做能运行的伪代码用.这也是为啥很多非计算机专业的人学习使用python的原因,没有难以阅读的符号,一切看起来就和英语差不多,加上缩进,天然的条理清晰容易理解. 胶水语言 很多人觉得python慢,但他们忽略了python是除lua外最易使用C语言扩展的胶水语言.在多数情况下python的性能足够使用,而在性能遇到瓶颈时可以找到短板将其用C重写以获得性能提升. 在计算密集型应用中python借助其良好的扩展性用哟很大的作为. python是当今最流行的开源科学计算语言之一,开源语言中唯一能在科学计算方面与之匹敌的是r语言;tensorflow,theano等深度学习使用的高性能GPU符号计算工具都是以python作为语言平台的.与之竞争的只有C++的caffe和lua的torch. 在i/o密集型应用中python同样优秀.借助协程和uvloop,单进程下python服务器可以达到惊人的吞吐量和极短的响应时间.而uvloop是利用cython和libuv实现的事件循环.本质上是一个优秀的C扩展. 安全性 Python自然也是有局限性的,总的来说它的局限性体现在安全性上,而根源来自'用户是守规矩的'这一假设上: 基于协议的语言设计让动态重载成为了可能,一旦被滥用除了影响可维护性外更加容易引起安全隐患 类没有语言级别的可见度设定功能,只是人为的以成员命名规范来划分可见度,这种防君子不防小人的做法同样有安全隐患,因此可以说python的类不存在真正意义上的封装 Python字节码的反编译相当简单,借助一些反编译工具可以相当简单的查看到源码,甚至可以查看到运行中程序的特定变量. 因此可以说Python\"不安全\".但讨论一个编程语言安不安全似乎又有些傻,任何语言都不是安全的,即便是汇编写出来的程序也是可以破解反编译的.而安全更多的应该在架构层面上进行保证.当你的服务可以直接让未认证过的用户访问时你就已经败了,任何语言都是如此. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/Python的数据模型/":{"url":"语法篇/Python的数据模型/","title":"Python的数据模型","keywords":"","body":"Python的数据模型 Python一直以来以实用性和一致性著称,而简单优雅的对象模型正是其实用性和一致性的来源. 本部分将包括以下几个部分: 数据模型 变量引用与垃圾回收 本部分是python的基本内容,主要是讲的解释器的调用对象方式和对象生命周期控制. python的解释器有一套简单实用的内在逻辑来处理运行时的对象生命周期. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/Python的数据模型/数据模型.html":{"url":"语法篇/Python的数据模型/数据模型.html","title":"数据模型","keywords":"","body":"数据模型 python最好的品质之一是一致性,当你熟悉了python之后遇到一个新的模块你总是可以快速的理解它,这便是得益于其一致性,任何对象都平等一致没有\"魔法\". 如果你用惯了典型的面向对象语言如java这种,初看python的代码会很不习惯.比如希望知道一个列表的长度,符合面向对象语言的查看方式是collection.len()而在python中很奇怪确是len(collection).更奇怪的是无论是列表,字典,集合还是什么,取长度都是len(object) 这是一种设计思想上的差别,python中万物都是对象,但python却不是纯粹的面向对象语言.所谓的pythonic的关键也在于此.这种设计思想完全体现在python的数据模型上,而python数据模型的通用API也为用户自己构建符合python语言特性的对象提供了工具. python的数据模型与其说是模型不如说是语言框架描述,它规范了一套语言自身的交互接口,只要符合这些接口,对象就可以与语言框架与其他符合接口的对象相互交互.正是因为python的一致性,使用python语言不会让你觉得自由,但会让你觉得轻松.因此常有人将python编程比喻为搭乐高积木,衔接用的接口已经都设计好了,玩家要做的只是发挥想象力专注于实现自己的创意. \"魔术方法\" 那么这些用于实现语言框架接口又是什么样呢? 这些接口被戏称为\"魔术方法\",他们的特征是方法名前后都有如__的两个下划线,这些方法能让你自己的对象实现如下的语言框架: 迭代 集合类 属性访问 运算符重载 函数和方法的调用 对象的创建和销毁 字符串表示形式和格式化 上下文管理 协程 实际感受下魔术方法 下面是一个例子用来展示如何使用__getitme__和__len__这两个魔术方法,帮助我们构建一个有序的扑克牌类的过程(例子来自第一章示例1.1) PS:为了便于理解这个例子所有变量用中文.实际编程的时候用中文并不是好习惯,尤其是参与开源项目的时候 from collections import namedtuple Card = namedtuple('扑克牌', ['大小', '花色']) class 牌堆: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = '梅花 方片 红桃 黑桃'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] 首先，我们用collections.namedtuple构建了一个简单的类来表示一张纸牌.namedtuple常用于构建只有少数属性但是没有方法的对象,比如数据库条目.利用namedtuple,我们可以很轻松地得到一个纸牌对象: beer_card = Card(\"7\",\"方片\") beer_card 扑克牌(大小='7', 花色='方片') 当然我们这个例子主要还是关注FrenchDeck这个类,它既短小又精悍.首先,它跟任何标准Python集合类型一样,可以用len()函数来查看一叠牌有多少张: deck = 牌堆() len(deck) 52 deck[0] 扑克牌(大小='2', 花色='梅花') 要随机抽取一张牌,只要使用python标准库的random.choice即可 from random import choice choice(deck) 扑克牌(大小='7', 花色='红桃') 现在已经可以体会到通过实现魔术方法来利用Python数据模型的两个好处 作为你的类的用户,他们不必去记住标准操作的各式名称（\"怎么得到元素的总数？是.size()还是.length()还是别的什么？\"） 由于接口统一,可以更加方便地利用Python的标准库,比如random.choice函数，从而不用重新发明轮子,即便是使用第三方库,只要大家都统一使用相同的接口也可以相互调用. 因为__getitem__方法把[]操作交给了self._cards列表,所以我们的deck类自动支持切片slicing操作 deck[:3] [扑克牌(大小='2', 花色='梅花'), 扑克牌(大小='3', 花色='梅花'), 扑克牌(大小='4', 花色='梅花')] deck[12::13] [扑克牌(大小='A', 花色='梅花'), 扑克牌(大小='A', 花色='方片'), 扑克牌(大小='A', 花色='红桃'), 扑克牌(大小='A', 花色='黑桃')] 同时因为实现了__getitem__方法，这一摞牌就变成可迭代的了 for card in deck: if card.花色 == \"红桃\": print(card) 扑克牌(大小='2', 花色='红桃') 扑克牌(大小='3', 花色='红桃') 扑克牌(大小='4', 花色='红桃') 扑克牌(大小='5', 花色='红桃') 扑克牌(大小='6', 花色='红桃') 扑克牌(大小='7', 花色='红桃') 扑克牌(大小='8', 花色='红桃') 扑克牌(大小='9', 花色='红桃') 扑克牌(大小='10', 花色='红桃') 扑克牌(大小='J', 花色='红桃') 扑克牌(大小='Q', 花色='红桃') 扑克牌(大小='K', 花色='红桃') 扑克牌(大小='A', 花色='红桃') 迭代通常是隐式的，譬如说一个集合类型没有实现__contains__方法,那么in运算符就会按顺序做一次迭代搜索.于是,in 运算符可以用在我们的FrenchDeck类上,因为它是可迭代的 排序 我们按照常规,用点数来判定扑克牌的大小,2 最小、A 最大;同时还要加上对花色的判定,黑桃最大、红桃次之、方块再次.梅花最小.下面就是按照这个规则来给扑克牌排序的函数,梅花2的大小是0，黑桃A 是51: def spades_high(card): 花色取值 = dict(梅花=3, 红桃=2, 方片=1, 黑桃=0) rank_value = 牌堆.ranks.index(card.大小) return rank_value * len(花色取值) + 花色取值[card.花色] for card in sorted(deck, key=spades_high): print(card) 扑克牌(大小='2', 花色='黑桃') 扑克牌(大小='2', 花色='方片') 扑克牌(大小='2', 花色='红桃') 扑克牌(大小='2', 花色='梅花') 扑克牌(大小='3', 花色='黑桃') 扑克牌(大小='3', 花色='方片') 扑克牌(大小='3', 花色='红桃') 扑克牌(大小='3', 花色='梅花') 扑克牌(大小='4', 花色='黑桃') 扑克牌(大小='4', 花色='方片') 扑克牌(大小='4', 花色='红桃') 扑克牌(大小='4', 花色='梅花') 扑克牌(大小='5', 花色='黑桃') 扑克牌(大小='5', 花色='方片') 扑克牌(大小='5', 花色='红桃') 扑克牌(大小='5', 花色='梅花') 扑克牌(大小='6', 花色='黑桃') 扑克牌(大小='6', 花色='方片') 扑克牌(大小='6', 花色='红桃') 扑克牌(大小='6', 花色='梅花') 扑克牌(大小='7', 花色='黑桃') 扑克牌(大小='7', 花色='方片') 扑克牌(大小='7', 花色='红桃') 扑克牌(大小='7', 花色='梅花') 扑克牌(大小='8', 花色='黑桃') 扑克牌(大小='8', 花色='方片') 扑克牌(大小='8', 花色='红桃') 扑克牌(大小='8', 花色='梅花') 扑克牌(大小='9', 花色='黑桃') 扑克牌(大小='9', 花色='方片') 扑克牌(大小='9', 花色='红桃') 扑克牌(大小='9', 花色='梅花') 扑克牌(大小='10', 花色='黑桃') 扑克牌(大小='10', 花色='方片') 扑克牌(大小='10', 花色='红桃') 扑克牌(大小='10', 花色='梅花') 扑克牌(大小='J', 花色='黑桃') 扑克牌(大小='J', 花色='方片') 扑克牌(大小='J', 花色='红桃') 扑克牌(大小='J', 花色='梅花') 扑克牌(大小='Q', 花色='黑桃') 扑克牌(大小='Q', 花色='方片') 扑克牌(大小='Q', 花色='红桃') 扑克牌(大小='Q', 花色='梅花') 扑克牌(大小='K', 花色='黑桃') 扑克牌(大小='K', 花色='方片') 扑克牌(大小='K', 花色='红桃') 扑克牌(大小='K', 花色='梅花') 扑克牌(大小='A', 花色='黑桃') 扑克牌(大小='A', 花色='方片') 扑克牌(大小='A', 花色='红桃') 扑克牌(大小='A', 花色='梅花') 为牌堆添加洗牌功能 目前的牌堆无法洗牌,这是因为我们虽然用__getitem__方法将获取牌的位置行为委托给了self._cards,但这实际上只是实现了不可变序列协议,关于这些协议的问题,会在后面讲到.要让牌堆支持洗牌,还需要给它定义一个__setitem__方法. class 牌堆: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = '梅花 方片 红桃 黑桃'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] def __setitem__(self,position,card): self._cards[position] = card deck = 牌堆() from random import shuffle shuffle(deck) for i in deck: print(i) 扑克牌(大小='2', 花色='红桃') 扑克牌(大小='10', 花色='黑桃') 扑克牌(大小='2', 花色='方片') 扑克牌(大小='A', 花色='梅花') 扑克牌(大小='K', 花色='方片') 扑克牌(大小='A', 花色='黑桃') 扑克牌(大小='K', 花色='黑桃') 扑克牌(大小='7', 花色='黑桃') 扑克牌(大小='K', 花色='梅花') 扑克牌(大小='3', 花色='黑桃') 扑克牌(大小='9', 花色='方片') 扑克牌(大小='5', 花色='方片') 扑克牌(大小='6', 花色='梅花') 扑克牌(大小='J', 花色='梅花') 扑克牌(大小='6', 花色='黑桃') 扑克牌(大小='8', 花色='梅花') 扑克牌(大小='9', 花色='红桃') 扑克牌(大小='4', 花色='红桃') 扑克牌(大小='9', 花色='梅花') 扑克牌(大小='Q', 花色='梅花') 扑克牌(大小='3', 花色='梅花') 扑克牌(大小='4', 花色='黑桃') 扑克牌(大小='5', 花色='红桃') 扑克牌(大小='A', 花色='红桃') 扑克牌(大小='10', 花色='方片') 扑克牌(大小='2', 花色='黑桃') 扑克牌(大小='K', 花色='红桃') 扑克牌(大小='4', 花色='方片') 扑克牌(大小='2', 花色='梅花') 扑克牌(大小='3', 花色='红桃') 扑克牌(大小='J', 花色='黑桃') 扑克牌(大小='9', 花色='黑桃') 扑克牌(大小='5', 花色='梅花') 扑克牌(大小='Q', 花色='黑桃') 扑克牌(大小='3', 花色='方片') 扑克牌(大小='6', 花色='红桃') 扑克牌(大小='Q', 花色='红桃') 扑克牌(大小='6', 花色='方片') 扑克牌(大小='7', 花色='梅花') 扑克牌(大小='Q', 花色='方片') 扑克牌(大小='8', 花色='红桃') 扑克牌(大小='4', 花色='梅花') 扑克牌(大小='J', 花色='方片') 扑克牌(大小='A', 花色='方片') 扑克牌(大小='8', 花色='黑桃') 扑克牌(大小='7', 花色='红桃') 扑克牌(大小='10', 花色='梅花') 扑克牌(大小='5', 花色='黑桃') 扑克牌(大小='8', 花色='方片') 扑克牌(大小='J', 花色='红桃') 扑克牌(大小='10', 花色='红桃') 扑克牌(大小='7', 花色='方片') 如何使用魔术方法 首先明确一点,魔术方法的存在是为了被Python解释器调用的,你自己并不需要调用它们.也就是说没有my_object.__len__()这种写法(虽然其实这样写也会正常运行),而应该使用len(my_object).在执行len(my_object)的时候,如果my_object是一个自定义类的对象,那么Python会自己去调用其中由你实现的__len__方法. 然而如果是Python内置的类型,比如列表(list)、字符串(str)、字节序列(bytearray)等,那么CPython会抄个近路,__len__ 实际上会直接返回PyVarObject里的ob_size属性.PyVarObject是表示内存中长度可变的内置对象的C语言结构体.直接读取这个值比调用一个方法要快很多. 很多时候,魔术方法的调用是隐式的,比如for i in x:这个语句,背后其实用的是iter(x),而这个函数的背后则是x.__iter__()方法.当然前提是这个方法在x中被实现了. 通常你的代码无需直接使用魔术方法.除非有大量的元编程存在,直接调用魔术方法的频率应该远远低于你去实现它们的次数.唯一的例外可能是__init__ 方法,你的代码里可能经常会用到它,目的是在你自己的子类的__init__ 方法中调用超类的构造器. 通过内置的函数(例如len、iter、str等等)来使用魔术方法是最好的选择.这些内置函数不仅会调用魔术方法,通常还提供额外的好处,而且对于内置的类来说,它们的速度更快. PS:不要自己想当然地随意添加魔术方法,比如__foo__之类的,因为虽然现在这个名字没有被Python内部使用,以后就不一定了 目前的魔术方法都可以在官网的第3节中找到详细说明.这边不一一复述. 为什么len不是普通方法? 回到最初的问题,为什么不是collection.len()而是len(collection)? len之所以不是一个普通方法,是为了让Python自带的数据结构可以\"走后门\",让解释器可以针对内置数据类型提供更好的优化.同时多亏了它是魔术方法，我们也可以把len 用于自定义数据类型.纯粹未必是最好的,python的数据模型实现兼顾通用性,效率和一致性.也印证了\"Python之禅\"中的一句话:\"不能让特例特殊到开始破坏既定规则.\" Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/Python的数据模型/变量引用与垃圾回收.html":{"url":"语法篇/Python的数据模型/变量引用与垃圾回收.html","title":"变量引用与垃圾回收","keywords":"","body":"*变量引用与垃圾回收 中文中太阳叫\"太阳\",英语中太阳叫\"sun\",法语中太阳叫\"soleil\",日语中太阳叫\"たいよう\",不同的叫法其实指的是同一个东西. python中的变量就有点像各种语言中的名词,它只是代表一个对象而已. 通常我们将变量与对象的关系称作打标签,变量就是我们的标签,而对象就是要被打标签的东西. python中的变量与对象的关系比较类似java中的引用,或者说是C中的指针变量. 标识,相等性和别名 我们还是用之前的扑克牌来做例子 from collections import namedtuple Card = namedtuple('扑克牌', ['大小', '花色']) 红桃A = Card(\"A\",\"红桃\") 红桃A 扑克牌(大小='A', 花色='红桃') 红桃Ace = 红桃A 红桃A is 红桃Ace True 可以看到,红桃A和红桃Ace其实是同一个东西.这边又有了一个新的问题,怎么看出来这两个变量其实是一个对象呢? id(红桃A),id(红桃Ace) (4470352992, 4470352992) 内置方法id()可以检查对象identity,每个对象在生成的时候就会产生一个identity,同一个进程中同一时间不会存在不同的identity在虚拟机中,cpython中对象的identity是其内存中的空间. is运算符专门用来判别变量指向的对象的identity是否一样.也就是是不是指向同一个对象. is和== python中也常会有要判别两个对象是否相等的情况 import copy def one(): return [1,2,3] a = one() b = copy.copy(a) a == b True a is b False a和b不是同一个对象,但内容一样.那为啥可以用==判断呢?==实际上是调用对象的魔术方法__eq__而的运算来的,只要在对象中改写这个方法其实也可以让a不等于b,不过__eq__是无法在外部改写的,这也相对增加了安全性 a.__eq__(b) True a.__eq__ = lambda x:False --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 a.__eq__ = lambda x:False AttributeError: 'list' object attribute '__eq__' is read-only 可变对象与不可变对象 一般来说python中的对象分为两类 不可变对象 可变对象 不可变对象包括str,bytes和数字类型,他们特点就是存在内存中,对象的内容是不可变的. 可变对象包括list,dict,set,以及自定义类型的实例等. 对象复制 python标准库提供了一个用于复制可变对象的工具copy import copy a = [1,2,3,4,5] id(a) 4468230152 aa = copy.copy(a) id(aa) 4468229960 a == aa True a is aa False 像python内置的容器,直接使用自身作为参数实例化一个新对象可以简单的复制 ab = list(a) id(ab) 4468181832 list有一个语法糖,可以简单的复制原有列表 aaa = a[:] id(aaa) 4468179848 浅复制和深复制 浅复制是指复制了最外层容器,副本中的元素是源容器中元素的引用.而深复制则是完全复制.python默认使用浅复制. 对于浅复制,如果所有元素都是不可变的,那么这样没有问题,还能节省内存。但是,如果有可变的元素,可能就会导致意想不到的问题. python中浅复制和深复制可以分别使用copy.copy(object)和copy.deepcopy(object)来实现,而对象复制操作对应的接口为__copy__() 和 __deepcopy__() 下面一个例子(来自流畅的python例8-8)可以用来对比浅复制和深复制的差别 class Bus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) import copy bus1 = Bus(['Alice', 'Bill', 'Claire', 'David']) bus2 = copy.copy(bus1) bus3 = copy.deepcopy(bus1) id(bus1), id(bus2), id(bus3) (4471042848, 4471042792, 4471043128) bus1.drop('Bill') bus1.passengers ['Alice', 'Claire', 'David'] bus2.passengers ['Alice', 'Claire', 'David'] id(bus1.passengers), id(bus2.passengers), id(bus3.passengers) (4468181640, 4468181640, 4468181320) bus3.passengers ['Alice', 'Bill', 'Claire', 'David'] bus1 和 bus2 共享同一个列表对象,因为 bus2 是 bus1 的浅复制副本。 函数参数作为引用时 Python唯一支持的参数传递模式是共享传参(call by sharing).多数面向对象语言都采用这一模式,包括 Ruby、Smalltalk 和 Java(Java 的引用类型是这样,基本类型按值传参).共享传参指函数的各个形式参数获得实参中各个引用的副本.也就是说,函数内部的形参是实参的别名. 这种方案的结果是,函数可能会修改作为参数传入的可变对象,但是无法修改那些对象的标识(即不能把一个对象替换成另一个对象).下例中有个简单的函数,它在参数上调用+=运算符.分别把数字、列表和元组传给那个函数,实际传入的实参会以不同的方式受到影响. def f(a, b): a += b return a x = 1 y = 2 f(x, y) 3 a = [1, 2] b = [3, 4] f(a, b) [1, 2, 3, 4] a, b ([1, 2, 3, 4], [3, 4]) t = (10, 20) u = (30, 40) f(t, u) (10, 20, 30, 40) t, u ((10, 20), (30, 40)) 不要使用可变类型作为参数的默认值 可选参数可以有默认值,这是Python函数定义的一个很棒的特性,这样我们的API在进化的同时能保证向后兼容。然而,我们应该避免使用可变的对象作为参数的默认值. 下面的例子中我们用之前的Bus类为基础定义一个新类,HauntedBus,然后修改 __init__ 方法。这一次,passengers的默认值不是None,而是[], 这样就不用像之前那样使用if判断了.这个'聪明的举动'会让我们陷入麻烦. class HauntedBus: \"\"\"备受幽灵乘客折磨的校车\"\"\" def __init__(self, passengers=[]): self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 然后就会出现下面的诡异行为 bus1 = HauntedBus(['Alice', 'Bill']) bus1.passengers ['Alice', 'Bill'] bus1.pick('Charlie') bus1.drop('Alice') bus1.passengers ['Bill', 'Charlie'] bus2 = HauntedBus() bus2.pick('Carrie') bus2.passengers ['Carrie'] bus3 = HauntedBus() bus3.passengers ['Carrie'] bus3.pick('Dave') bus2.passengers ['Carrie', 'Dave'] bus2.passengers is bus3.passengers True bus1.passengers ['Bill', 'Charlie'] 问题就在于,没有指定初始乘客的HauntedBus实例会共享同一个乘客列表. 这种问题很难发现.如示上例所示,实例化HauntedBus时,如果传入乘客,会按预期运作.但是不为HauntedBus指定乘客的话,奇怪的事就发生了,这是因为self. passengers变成了passengers参数默认值的别名. 出现这个问题的根源是,默认值在定义函数时计算(通常在加载模块时),因此默认值变成了函数对象的属性.因此,如果默认值是可变对象,而且修改了它的值,那么后续的函数调用都会受到影响. HauntedBus.__init__.__defaults__ (['Carrie', 'Dave'],) 我们可以验证bus2.passengers是一个别名,它绑定到HauntedBus.__init__.__ defaults__ 属性的第一个元素上 可变默认值导致的这个问题说明了为什么通常使用None作为接收可变值的参数的默认值 防御可变参数 如果定义的函数接收可变参数,应该谨慎考虑调用方是否期望修改传入的参数. 例如,如果函数接收一个字典,而且在处理的过程中要修改它,那么这个副作用要不要体现到函数外部? 具体情况具体分析。这其实需要函数的编写者和调用方达成共识. 最后一个校车示例中,TwilightBus实例与客户共享乘客列表,这会产生意料之外的结果.在分析实现之前,我们先从客户的角度看看TwilightBus类是如何工作的. class TwilightBus: \"\"\"让乘客销声匿迹的校车\"\"\" def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] bus = TwilightBus(basketball_team) bus.drop('Tina') bus.drop('Pat') basketball_team ['Sue', 'Maya', 'Diana'] TwilightBus 违反了设计接口的最佳实践,即'最少惊讶原则'.学生从校车中下车后,她的名字就从篮球队的名单中消失了,这确实让人惊讶. 除非本来就有这种需求,否则我们应该让校车自己维护乘客列表 class Bus: \"\"\"行为正常的校车\"\"\" def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers[:] def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] bus = Bus(basketball_team) bus.drop('Tina') bus.drop('Pat') basketball_team ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] bus.passengers ['Sue', 'Maya', 'Diana'] 内置方法del和垃圾回收 对象绝不会自行销毁;然而,无法得到对象时,可能会被当作垃圾回收. del语句 del语句删除名称,而不是对象.del命令可能会导致对象被当作垃圾回收,但是那仅是当删除的变量保存的是对象的最后一个引用,或者无法得到对象时的情况.重新绑定名字到其他对象如None也可能会导致对象的引用数量归零,导致对象被销毁. 有个__del__特殊方法,但是它不会销毁实例而是在即将销毁实例之前触发,它不应该在代码中调用. 即将销毁实例时,Python解释器会调用__del__方法,给实例最后的机会,释放外部资源.自己编写的代码很少需要实现 __del__代码,有些python 新手会花时间实现,但却吃力不讨好,因为__del__很难用对.具体的可以看Python 语言参 考手册中'Data Model'一章中__del__特殊方法的文档 垃圾回收 在 CPython 中,垃圾回收使用的主要算法是引用计数.实际上,每个对象都会统计有多少引用指向自己.当引用计数归零时,对象立即就被销毁: CPython 会在对象上调用__del__方法(如果定义了), 然后释放分配给对象的内存 CPython 2.0 增加了分代垃圾回收算法, 用于检测引用循环中涉及的对象组——如果一组对象之间全是相互引用,即使再出色的引用方式也会导致组中的对象不可获取. Python的其他实现有更复杂的垃圾回收程序,而且不依赖引用计数,这意味着,对象的引用数量为零时可能不会立即调用__del__方法. 为了演示对象生命结束时的情形,下例使用weakref.finalize注册一个回调函数,在销毁对象时调用. import weakref s1 = {1, 2, 3} s2 = s1 bye = lambda :print('对象随风而逝~') ender = weakref.finalize(s1, bye) ender.alive True del s1 ender.alive True s2 = 'spam' 对象随风而逝~ ender.alive False 你可能觉得奇怪,为什么上例中的{1, 2, 3}对象被销毁了?毕竟,我们把s1引用传给finalize函数了,而为了监控对象和调用回调,必须要有引用。这是因为,finalize持有{1, 2, 3}的弱引用 弱引用 正是因为有引用,对象才会在内存中存在.当对象的引用数量归零后,垃圾回收程序会把对象销毁.但是,有时需要引用对象,而不让对象存在的时间超过所需时间.这经常用在缓存中. 弱引用不会增加对象的引用数量.引用的目标对象称为所指对象(referent).因此我们说,弱引用不会妨碍所指对象被当作垃圾回收. 弱引用在缓存应用中很有用,因为我们不想仅因为被缓存引用着而始终保存缓存对象. 下例展示了如何使用weakref.ref实例获取所指对象.如果对象存在,调用弱引用可以获取对象;否则返回None. weakref.getweakrefcount(object) 可以获取对象object关联的弱引用对象数 weakref.getweakrefs(object)可以获取object关联的弱引用对象列表 import weakref def callback(reference): \"\"\"Invoked when referenced object is deleted\"\"\" print('callback(', reference, ')') obj = {2, 3} r = weakref.ref(obj, callback) print('obj:', obj) print('ref:', r) print('r():', r()) print('deleting obj') del obj print('r():', r()) obj: {2, 3} ref: r(): {2, 3} deleting obj callback( ) r(): None 代理Proxy 使用weakref.proxy和使用普通weakref的区别就是不需要(),可以像原对象一样地使用proxy访问原对象的属性. import weakref def test_func(reference): print('Hello from Callback function!') a = {1,2,3} #建立一个对a的代理(弱引用) x = weakref.proxy(a, test_func) print(a) print(x) del a {1, 2, 3} {1, 2, 3} Hello from Callback function! weakref模块的文档指出,weakref.ref类其实是低层接口,供高级用途使用,多数程序最好使用weakref集合和finalize.也就是说,应该使用WeakKeyDictionary、WeakValueDictionary、WeakSet 和 finalize(在内部使用弱引用),不要自己动手创建并处理weakref.ref实例. 下面以WeakValueDictionary为例子看看weakref的高级接口如何使用. WeakValueDictionary类实现的是一种可变映射,里面的值是对象的弱引用.被引用的对象在程序中的其他地方被当作垃圾回收后,对应的键会自动从WeakValueDictionary中删除.因此,WeakValueDictionary经常用于缓存. 我们对WeakValueDictionary的演示是奶酪店,客户问了40多种奶酪,包括切达干酪和马苏里拉奶酪,但是都没有货. class Cheese: def __init__(self, kind): self.kind = kind def __repr__(self): return 'Cheese({self.kind})'.format(self=self) 我们把catalog中的各种奶酪载入WeakValueDictionary实现的stock中.然而,删除catalog后,stock 中只剩下一种奶酪了. import weakref stock = weakref.WeakValueDictionary() catalog = [Cheese('Red Leicester'), Cheese('Tilsit'),Cheese('Brie'), Cheese('Parmesan')] for cheese in catalog: stock[cheese.kind] = cheese sorted(stock.keys()) ['Brie', 'Parmesan', 'Red Leicester', 'Tilsit'] del catalog sorted(stock.keys()) ['Parmesan'] del cheese sorted(stock.keys()) [] 删除catalog之后,stock中的大多数奶酪都不见了,这是WeakValueDictionary的预期行为.为什么不是全部呢? 临时变量引用了对象,这可能会导致该变量的存在时间比预期长.通常,这对 局部变量来说不是问题,因为它们在函数返回时会被销毁.但是在上例中,for循环中的变量cheese是全局变量,除非显式删除,否则不会消失 与WeakValueDictionary对应的是 WeakKeyDictionary,后者的键是弱引用. WeakKeyDictionary实例可以为应用中其他部分拥有的对象附加数据,这样就无需为对象添加属性.这对覆盖属性访问权限的对象尤其有用. weakref模块还提供了WeakSet类,按照文档的说明,这个类的作用很简单--'保存元素弱 引用的集合类.元素没有强引用时,集合会把它删除' 如果一个类需要知道所有实例,一种好的方案是创建一个WeakSet类型的类属性,保存实例的引用.如果使用常规的set,实例永远不会被垃圾回收,因为类中有实例的强引用,而类存在的时间与Python进程一样 长,除非显式删除类. 这些集合,以及一般的弱引用,能处理的对象类型有限.不是每个Python对象都可以作为弱引用的目标(或称所指对象).基本的 list和dict实例不能作为所指对象,但是它们的子类可以轻松地解决这个问题 class MyList(list): \"\"\"list的子类,实例可以作为弱引用的目标\"\"\" pass a_list = MyList(range(10)) # a_list可以作为弱引用的目标 wref_to_a_list = weakref.ref(a_list) set实例可以作为所指对象,因此上例才使用set实例.用户定义的类型也没问题,但是int和tuple实例不能作为弱引用的目标,甚至它们的子类也不行。 这些局限基本上是CPython的实现细节,在其他Python解释器中情况可能不一样.这些局限是内部优化导致的结果. Python对不可变类型施加的把戏 python的内部有一种优化措施较驻留(interning).他的结果之一就是共享字符串字面量,以及在小的整数防止重复创建'热门'数字,如 0、—1 和 42。注意,CPython不会驻留所有字符串和整数,驻留的条件是实现细节,而且没有文档说明.这一优化措施可以节省内存,提升解释器的速度.但只有不可变类型会受到影响.这也是为什么弱引用在int,tuple这类不可变类型中无法使用的原因 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:29:28 "},"语法篇/Python的数据模型/结语.html":{"url":"语法篇/Python的数据模型/结语.html","title":"结语","keywords":"","body":"结语 '数据模型'一词的由来 数据模型(Data model)来自于官网的第3节, 全文中出现了400次object,个人认为叫\"对象模型\"似乎更合适,可能叫数据模型的意图是不想被认为python是一门纯粹的面向对象语言吧. '魔术方法' 在 Ruby 中也有类似“特殊方法”的概念,但是 Ruby 社区称之为“魔术方法”,而实际上 Python 社区里也有不少人用的是后者。Python 和 Ruby 都利用了这个概念来提供丰富的元对象协议,这既不是魔术也不特殊,而是让语言的用户和核心开发者拥有并使用同样的工具。 考虑一下 JavaScript,情况就正好反过来了.JavaScript 中的对象有不透明的魔术般的特性,而你无法在自定义的对象中模拟这些行为。比如在 JavaScript 1.8.5 中,用户的自定义对象不能有只读属性,然而不少 JavaScript 的内置对象却可以有。因此在 JavaScript 中,只读属性是“魔术”般的存在,对于普通的 JavaScript 用户而言,它 就像超能力一样。2009 年推出的 ECMAScript 5.1 才让用户可以定义只读属性。 JavaScript 中跟元对象协议有关的部分一直在进化,但由于历史原因,这方面它还是赶不上 Python 和 Ruby。 python中人人平等 Python 采取了直观的方式来比较对象. ==运算符比较对象的值,而 is 比较引用. 你可以在自己的类中定义 __eq__ 方法,决定 == 如何比较实例。如果不覆盖 __eq__ 方法,那么从 object 继承的方法比较对象的ID,因此这种后备机制认为用户定义的类的各个实例是不同的。 此外,Python 支持重载运算符,== 能正确处理标准库中的所有对象,包括None——这是一个正常的对象.说来python中语言层面来讲所有对象都是正常对象,有相似的行为 可变性 如果所有 Python 对象都是不可变的,那么本章就没有存在的必要了。处理不可变的对象时,变量保存的是真正的对象还是共享对象的引用无关紧要。如果a == b成立,而且两个对象都不会变,那么它们就可能是相同的对象。这就是为什么字符串可以安全 使用驻留。仅当对象可变时,对象标识才重要. 在“纯”函数式编程中,所有数据都是不可变的,如果为集合追加元素,那么其实会创建新的集合。然而,Python不是函数式语言,更别提纯不纯了。在 Python 中,用户定义的类,其实例默认可变(多数面向对象语言都是如此)。自己创建对象时,如果需要不可变的对象,一定要格外小心。此时,对象的每个属性都必须是不可变的,否则会出现类似元组那种行为:元组本身不可变,但是如果里面保存着可变对象,那么元组的值可能会变. 可变对象还是导致多线程编程难以处理的主要原因,因为某个线程改动对象后,如果不正确地同步,那就会损坏数据。但是过度同步又会导致死锁. 对象析构和垃圾回收 Python 没有直接销毁对象的机制,这一疏漏其实是一个好的特性:如果随时可以销毁对象,那么指向对象的强引用怎么办? CPython 中的垃圾回收主要依靠引用计数,这容易实现,但是遇到引用循环容易泄露内存,因此 CPython 2.0实现了分代垃圾回收程序,它能把引用循环中不可获取的对象销毁。 但是引用计数仍然作为一种基准存在,一旦引用数量归零,就立即销毁对象。这意味着,在CPython中,这样写是安全的(至少目前如此): open('test.txt', 'w', encoding='utf-8').write('1, 2, 3') 这行代码是安全的,因为文件对象的引用数量会在 write 方法返回后归零,Python 在销毁内存中表示文件的对象之前,会立即关闭文件。然而,这行代码在 Jython 或 IronPython 中却不安全,因为它们使用的是宿主运行时(Java VM 和 .NET CLR)中的垃圾回收程序,那些回收程序更复杂,但是不依靠引用计数,而且销毁对象和关闭文件的时间可能更长。在任何情况下,包括 CPython,最好显式关闭文件;而关闭文件的最可靠方式是使用 with 语句,它能保证文件一定会被关闭,即使打开文件时抛出了 异常也无妨。使用 with,上述代码片段变成了: with open('test.txt', 'w', encoding='utf-8') as fp: fp.write('1, 2, 3') 参数传递:共享传参 解释 Python 中参数传递的方式时,人们经常这样说:\"参数按值传递,但是这里的值是引用.\" 这么说没错,但是会引起误解,因为在旧式语言中,最常用的参数传递模式有按值传递(如C语言,函数得到参数的副本)和 按引用传递(函数得到参数的指针).在 Python 中,函数得到参数的副本,但是参数始终是引用.因此,如果参数引用的是可变对象, 那么对象可能会被修改,但是对象的标识不变.此外,因为函数得到的是参数引用的副本,所以重新绑定对函数外部没有影响. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/模块/":{"url":"语法篇/模块/","title":"模块","keywords":"","body":"模块 python中有两个时点,一个是运行时,一个是模块导入时.由此可见模块在python中的重要程度. python的模块就是单独的.py文件或者内含__init__.py的文件夹. 模块(module)是一个可以迭代的概念,A中包含B模块,那么B就是A中的子模块.但这俩都是模块.这个概念和包(package)既有联系又有区别. package通常指的是一个最顶层的非入口模块,代码分发的最小单元也是package,而模块通常只是python可以调用的最小单元的意思.不过这两个词在社区中基本上是混着用的,大家也没有对其做严格区分. 本章会介绍模块相关的知识,包括: 导入时和运行时 模块的预设字段 模块的加载流程 加载特殊数据模块 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 15:33:45 "},"语法篇/模块/导入时与运行时.html":{"url":"语法篇/模块/导入时与运行时.html","title":"导入时与运行时","keywords":"","body":"导入时与运行时 我们得知道Python解释器什么时候计算各个代码块.Python程序员会区分\"导入时\"和\"运行时\",不过这两个术语没有严格的定义,而且二者之间存在着灰色地带. 毕竟导入动作是可以在运行时执行的. 在导入时,解释器会从上到下一次性解析完.py模块的源码,然后生成用于执行的字节码,需要注意的是导入模块是从来是最小化导入,如果父模块的__init__.py中没有导入其下的子模块,那么直接导入父模块的话子模块是不会被导入的(也不会生成子模块的.pyc).如果导入时句法有错误,就在此时报告. 导入也有一个缓存机制,其判别方式是依靠比对文件的更新时间戳,如果本地的__pycache__文件夹中有最新的.pyc 文件，解释器会跳过上述导入步骤,因为已经有运行所需的字节码了. 编译肯定是导入时的活动,不过那个时期还会做些其他事,因为Python中的语句几乎都是可执行的,也就是说语句可能会运行用户代码,修改用户程序的状态.尤其是import语句,它不只是声明,在进程中首次导入模块时,还会运行所导入模块中的全部顶层代码——以后导入相同的模块则使用缓存,只做名称绑定.那些顶层代码可以做任何事，包括通常在\"运行时\"做的事，例如连接数据库. 因此，“导入时”与“运行时”之间的界线是模糊的： import语句可以触发任何\"运行时\"行为. 模块导入主要做的是讲函数和类的定义体加入模块的全局命名空间. 函数 导入模块时,解释器会执行顶层的def语句,可是这么做有什么作用呢？解释器会编译函数的定义体(首次导入模块时),把函数对象绑定到对应的全局名称上,但是显然解释器不会执行函数的定义体通常这意味着解释器在导入时定义顶层函数,但是仅当在运行时调用函数时才会执行函数的定义体. 类 在导入时,解释器会执行每个类的定义体,甚至会执行嵌套类的定义体.执行类定义体的结果是,定义了类的属性和方法,并构建了类对象.从这个意义上理解,类的定义体属于“顶层代码”，因为它在导入时运行. 上述说明模糊又抽象，下面通过练习理解各个时期所做的事情。 %%writefile evalsupport.py print(' evalsupport module start') def deco_alpha(cls): print(' deco_alpha') def inner_1(self): print(' deco_alpha:inner_1') cls.method_y = inner_1 return cls class MetaAleph(type): print(' MetaAleph body') def __init__(cls, name, bases, dic): print(' MetaAleph.__init__') def inner_2(self): print(' MetaAleph.__init__:inner_2') cls.method_z = inner_2 print(' evalsupport module end') Overwriting evalsupport.py %%writefile evaltime.py from evalsupport import deco_alpha print(' evaltime module start') class ClassOne(): print(' ClassOne body') def __init__(self): print(' ClassOne.__init__') def __del__(self): print(' ClassOne.__del__') def method_x(self): print(' ClassOne.method_x') class ClassTwo(object): print(' ClassTwo body') @deco_alpha class ClassThree(): print(' ClassThree body') def method_y(self): print(' ClassThree.method_y') class ClassFour(ClassThree): print(' ClassFour body') def method_y(self): print(' ClassFour.method_y') if __name__ == '__main__': print(' ClassOne tests', 30 * '.') one = ClassOne() one.method_x() print(' ClassThree tests', 30 * '.') three = ClassThree() three.method_y() print(' ClassFour tests', 30 * '.') four = ClassFour() four.method_y() print(' evaltime module end') Overwriting evaltime.py 场景1: 导入模块 解释器会执行所导入模块及其依赖（evalsupport）中的每个类定义体。 解释器先计算类的定义体，然后调用依附在类上的装饰器函数，这是合理的行为，因为必须先构建类对象，装饰器才有类对象可处理。 在这个场景中，只运行了一个用户定义的函数或方法——deco_alpha装饰器。 import evaltime evalsupport module start MetaAleph body evalsupport module end evaltime module start ClassOne body ClassTwo body ClassThree body deco_alpha ClassFour body evaltime module end 场景2:执行evaltime.py 场景2 主要想说明的是，类装饰器可能对子类没有影响.在示例中， 我们把ClassFour定义为ClassThree的子类.ClassThree类上依附的@deco_alpha装饰器把method_y方法替换掉了，但是这对ClassFour类根本没有影响. 当然，如果ClassFour.method_y方法使用super(...)调用ClassThree.method_y方法，我们便会看到装饰器起作用，执行inner_1函数. !python evaltime.py evalsupport module start MetaAleph body evalsupport module end evaltime module start ClassOne body ClassTwo body ClassThree body deco_alpha ClassFour body ClassOne tests .............................. ClassOne.__init__ ClassOne.method_x ClassThree tests .............................. deco_alpha:inner_1 ClassFour tests .............................. ClassFour.method_y evaltime module end ClassOne.__del__ Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 15:28:32 "},"语法篇/模块/模块的预设字段.html":{"url":"语法篇/模块/模块的预设字段.html","title":"模块的预设字段","keywords":"","body":"模块的预设字段 python中所有东西都是对象,模块也不例外,在一个模块被导入后它就是作为一个对象而存在的,但这个对象有点特殊 无论加载多少次,它都是唯一对象. 每个模块都有一些特殊的字段,和python中类的魔术命令差不多,他们可以用来对模块自省 本文主要介绍这些特殊字段 我们以一个模块作为例子来观察.其结构如下: module_test| |-__init__.py |-a| |-__init__.py |-b.py 其中module_test.__init__.py为: \"\"\"这就是一个测试.\"\"\" from pathlib import Path path=Path(__file__) if path.exists(): dir_path = path.absolute().parent __path__.append(str(dir_path.joinpath(\"a\"))) b.py为 def func(): return 1 __all__ = [\"func\"] import module_test from module_test import a __name__字段用于自省模块的名字 一旦某个模块被导入后,他的__name__字段就会保存从其所在包的起点位置到自身的引用关系以组成自身的名字.这个规则有点类似java中的模块概念. 特别的是所有的入口模块其名都为__main__ print(__name__) print(module_test.__name__) print(a.__name__) __main__ module_test module_test.a __doc__字段用于自省模块的docstring 模块的__doc__字段用于自省模块的docstring, print(module_test.__doc__) 这就是一个测试. __all__字段用于设置模块的导入范围 __all__是用于限制模块使用from xxxx import *这样形式的模块导入语法的导入对象范围的字段.在要进行限制的模块下设置 __all__:List[str] = [\"asfd\"] 使用与对象同名的字符串指代可以进行导入的对象.这样这种语法下就可以对导入进行限制,一定程度上防止命名空间被污染 __path__字段用于自省模块的所在绝对地址 这个关键字只对package有意义,入口模块是没有这个字段的,访问也会报错,需要注意. __path__字段是在加载时被创建的,可以记录其所在的绝对地址.,注意它是一个List[str]数据. __path__字段会影响导入时对包中包含的模块和子包的搜索.比如在moduletest中为`_path`添加一个子模块的路径,他就会同时导入这个子模块 module_test.__path__ ['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/module_test', '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/module_test/a'] __file__用于自省被引用模块文件的路径 如果当前文件包含在sys.path里面，那么，__file__返回一个相对路径; 如果当前文件不包含在sys.path里面，那么__file__返回一个绝对路径. module_test.__file__ '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/module_test/__init__.py' __package__用于自省所在的包位置 __package__只有package中才会有,入口模块中__package__为空.__package__主要是为了相对引用而设置的一个属性, 如果所在的文件是一个package的话, 它和__name__的值是一样的, 如果是子模块的话, 它的值就跟父模块一致 print(module_test.__package__) print(a.__package__) module_test module_test.a __spec__模块规范对象 module_test.__spec__ ModuleSpec(name='module_test', loader=, origin='/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/module_test/__init__.py', submodule_search_locations=['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/module_test', '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/module_test/a']) __loader__模块加载器 模块使用模块加载器加载进python的虚拟机,而__loader__则是自省导入时使用加载器的字段.此处不多扩展,在下一篇中我们会详细介绍模块的加载流程以及如何利用这一流程做一些特殊的事情. module_test.__loader__ __cached__ 模块是否已经缓存 如果已经缓存的话,则会保存模块对应.pyc的绝对地址 module_test.__cached__ '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/module_test/__pycache__/__init__.cpython-36.pyc' __dict__用于自省模块中所有字段 和python的其他对象一样,__dict__用于自省模块对象中所有的字段. 本文只是先将这些字段罗列出来便于查找后面的小节中我们会详细介绍模块的加载流程. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:27:43 "},"语法篇/模块/模块的加载流程.html":{"url":"语法篇/模块/模块的加载流程.html","title":"模块的加载流程","keywords":"","body":"模块的加载流程 python程序说到底是执行的是模块,模块要被执行都有两个步骤: 导入到虚拟机的内存中 执行其中的代码 本节主要就是讲的这个模块导入的流程 入口模块 入口模块是一个特殊的模块.它是用户使用python xxxx所指定的执行模块.你的程序由这个入口进入,他是一个程序第一个被导入到虚拟机中的模块.python解释器会给他的__name__定义为__main__,并且其他一些预设字段会设上None. 可以作为入口模块的模块有两种: 单独的.py文件形成的模块 文件夹形式的包中第一层的__main__.py文件 模块导入 python中模块和包是一个意思.一个.py文件就是一个模块,如果模块复杂,那么带有__init__.py的文件夹也是一个模块.模块中可以嵌套模块以构建为一个更为复杂的模块. python的模块引入使用的是import语句.具体有3种形式: import package from package import object from package import object as name 而引入机制可以分为两种: 相对引入 完全引入 相对引入 相对引入中一个点号来标识引入类库的精确位置.与linux的相对路径表示相似,一个点表示当前目录,每多一个点号则代表向上一层目录. from .string import a from ..string import a from ...string import a 相对引入使用被引入文件的__name__ 属性来决定该文件在整个包结构的位置.那么如果文件的__name__没有包含任何包的信息,例如__name__被设置为了__main__,则认为其为入口模块(top level script),而不管该文件的位置，这个时候相对引入就没有引入的参考物. 完全引入 完全引入，非常类似于Java的引入进制, 完全引用是Python的默认的引入机制.它的使用方法如下: from pkg import foo from pkg.moduleA import foo 要注意的是,需要从包目录最顶层目录依次写下而不能从中间开始. 两种引用方式各有利弊.绝对引用代码更加清晰明了,可以清楚的看到引入的包名和层次,但当包名修改的时候,我们需要手动修改所有的引用代码.相对引用则比较精简,不会被包名修改所影响,但是可读性较差,不如完全引用清晰. 前文有介绍过,python的加载通常使用import语句.import语句实际上只是一种加载方式,还可以使用内置函数__import__(name:str, globals=None, locals=None, fromlist=(), level=0)或者使用标准库importlib.import_module(name:str, package=None) import importlib module_test = importlib.import_module(\"module_test\") # 相当于 import module_test module_test = __import__('module_test') # 相当于 import module_test a = __import__('module_test.a',fromlist=[\"b\"]) # 相当于 from module_test import a,但是其下会将其子模块放入a的字段中 a.b.func() 1 加载机制 模块的加载分为两种情况: 对未被加载过的模块进行加载 对已经加载过的模块进行加载 当Python的解释器遇到import语句或者其他上述导入语句时,它会先去查看sys.modules中是否已经有同名模块被导入了,如果有就直接取来用;没有就去查阅sys.path里面所有已经储存的目录.这个列表初始化的时候,通常包含一些来自外部的库(external libraries)或者是来自操作系统的一些库,当然也会有一些类似于dist-package的标准库在里面.这些目录通常是被按照顺序或者是直接去搜索想要的--如果说他们当中的一个包含有期望的package或者是module,这个package或者是module将会在整个过程结束的时候被直接提取出来保存在sys.modules中(sys.modules是一个模块名:模块对象的字典结构). 当在这些个地址中实在是找不着时,它就会抛出一个ModuleNotFoundError错误. import ujson 这一机制常常被我们用来按环境加载相同功能的不同模块,以保证系统的鲁棒性 try: import ujson except ModuleNotFoundError: import json as ujson 导入顺序,sys.path和环境变量PYTHONPATH 我们来实际看看sys.path的内容 import sys sys.path ['', '/Users/huangsizhe/anaconda3/lib/python36.zip', '/Users/huangsizhe/anaconda3/lib/python3.6', '/Users/huangsizhe/anaconda3/lib/python3.6/lib-dynload', '/Users/huangsizhe/anaconda3/lib/python3.6/site-packages', '/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/aeosa', '/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/IPython/extensions', '/Users/huangsizhe/.ipython'] 可以看到第一位是个空字符串,代表的是相对路径下的当前目录. 由于在导入模块的时候,解释器会按照列表的顺序搜索,直到找到第一个模块,所以优先导入的模块为同一目录下的模块. 导入模块时搜索路径的顺序也可以改变.这里分两种情况: 通过sys.path.append(),sys.path.insert()等方法来改变,这种方法当重新启动解释器的时候,原来的设置会失效. 改变环境变量PYTHONPATH,这种设置方法随着环境变量的有效范围变化,只要启动python时先指定即可. 我们写个脚本pythonpath_test.py测试下PYTHONPATH的效用 import sys import pprint pprint.pprint(sys.path) !python pythonpath_test.py ['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块', '/Users/huangsizhe/anaconda3/lib/python36.zip', '/Users/huangsizhe/anaconda3/lib/python3.6', '/Users/huangsizhe/anaconda3/lib/python3.6/lib-dynload', '/Users/huangsizhe/anaconda3/lib/python3.6/site-packages', '/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/aeosa'] !PYTHONPATH=extension python pythonpath_test.py ['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块', '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/extension', '/Users/huangsizhe/anaconda3/lib/python36.zip', '/Users/huangsizhe/anaconda3/lib/python3.6', '/Users/huangsizhe/anaconda3/lib/python3.6/lib-dynload', '/Users/huangsizhe/anaconda3/lib/python3.6/site-packages', '/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/aeosa'] 可以看到,PYTHONPATH在第二位上将其值添加到了查找范围中. 关于__path__的更多细节 上面提到的Python的import流在大多数情况下默认等行为就已经可以满足需求,但是事实上细节远不止这些.他省略了一些我们可以根据需要调节的地方. 首先，__path__这个属性是我们可以在__init__.py里面去定义的.你可以认为他像一个sys.path的本地扩展并且只服务于我们导入的的子模块.换句话说,它包含地址时时应该寻找一个的子模块被导入.默认的情况下只有__init__.py的目录,但是他可以扩展到包含任何其他任何的路径. 这个说的很绕,实际看段例子就可以看出来. 通常__path__的扩展借助于标准库pkgutil,后文还会有对其使用的介绍,我们的例子也要借助这个工具.pkgutil.extend_path(path, name)的作用是在sys.path范围内查找与同名的模块,将其地址也添加到本语句所在的模块的__path__中. 我们的测试模块叫demopkg1其结构如下: demopkg1-| |-__init__.py |-shared.py 测试模块的扩展叫extension,其结构如下: extension=| |-__init__.py |-demopkg1-| |-__init__.py |-shared.py demopkg1的__init__.py内容如下 import pkgutil import pprint print('demopkg1.__path__ before:') pprint.pprint(__path__) print() __path__ = pkgutil.extend_path(__path__, __name__) print('demopkg1.__path__ after:') pprint.pprint(__path__) print() 这段代码作用是打印出模块加载后的__path__变化情况. 我们的测试入口代码是pkgutil_extend_path.py,其内容如下: import demopkg1 print('demopkg1 :', demopkg1.__file__) try: import demopkg1.shared except Exception as err: print('demopkg1.shared : Not found ({})'.format(err)) else: print('demopkg1.shared :', demopkg1.shared.__file__) try: import demopkg1.not_shared except Exception as err: print('demopkg1.not_shared: Not found ({})'.format(err)) else: print('demopkg1.not_shared:', demopkg1.not_shared.__file__) 这段代码是用于检测模块下则子模块都导入了哪些的. 先来看直接执行 !python pkgutil_extend_path.py demopkg1.__path__ before: ['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1'] demopkg1.__path__ after: ['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1'] demopkg1 : /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1/__init__.py demopkg1.shared : /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1/shared.py demopkg1.not_shared: Not found (No module named 'demopkg1.not_shared') 可以看到模块只是按默认的情况在执行,但如果先定义环境变量PYTHONPATH=extension再执行 !PYTHONPATH=extension python3 pkgutil_extend_path.py demopkg1.__path__ before: ['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1'] demopkg1.__path__ after: ['/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1', '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/extension/demopkg1'] demopkg1 : /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1/__init__.py demopkg1.shared : /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/demopkg1/shared.py demopkg1.not_shared: /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/模块/extension/demopkg1/not_shared.py 可以看到extension中的not_shared也可以被导入了.由此可见__path__的一个很大的作用就是扩展其子模块的查找范围 *模块对象的生成 无论使用哪种导入方法,最终我们获得的都是一个模块对象,那它是怎么生成的呢?实际上这有两个步骤: 使用模块查找器finder找到模块 使用模块加载器loader将模块载入内存. 这两个的基类都可以在importlib.abc中找到 而他们之间使用模块规范对象(importlib.machinery.ModuleSpec)来封装结果. 模块查找流程 我们来完善下模块的查找流程: 当一个模块被用import语句调用时, import 某个模块 | | 遍历sys.meta_path | |---有执行.find_spec()后返回非None的---------| | |- 使用.find_spec()返回的spec对象生成模块 执行.find_spec()后返回的都为None | | 遍历sys.path | | 检查sys.path_importer_cache上有没有各个path对应的finder缓存--有finder缓存---| | |-使用.find_spec()返回的spec对象生成模块 | 没有缓存 | 遍历sys.path_hooks | 执行其中的可执行对象,直到获得返回值为finder的终止 --------------------| | |-将这个finder设为这个path的缓存finder | | | |-使用.find_spec()返回的spec对象生成模块 没有一个找到finder-----抛出ModuleNotFoundError finder finder(importlib.abc.MetaPathFinder或importlib.abc.PathEntryFinder子类的实例)是一个模块查找器,我们总结它可以完成以下三件事中的任意一件: 抛出一个异常,然后完全取消所有的导入流程 返回一个None,意思是被导入的这个模块不能够被这个查找器所找到。但是他仍然可以被导入流的下一个阶段所找到,比如说一些自定义的查找器或者是Python的标准导入机制。 返回一个模块规范对象(importlib.machinery.ModuleSpec)用来加载实际的模块 sys.meta_path中保存着当前可用的finder,在加载时,虚拟机会遍历sys.meta_path,调用其中所有元素的find_spec()方法,以查看其中是否有一个对象是否可以找到要导入的模块. 调用find_spec()方法时至少需要导入的模块的绝对名称.如果要导入的模块包含在包中,那么父包的__path__属性作为第二个参数传入. 需要注意importlib.abc.MetaPathFinder通常用于子类化sys.meta_path中的finder类,而importlib.abc.PathEntryFinder通常用于子类化sys.path_hooks中工厂函数返回的finder类 我们可以看看默认的finder有哪些 sys.meta_path [_frozen_importlib.BuiltinImporter, _frozen_importlib.FrozenImporter, _frozen_importlib_external.PathFinder, , , ] loader 模块加载器(Loader子类的实例)其实就是一个用来加载制定模块规范对象的对象,它会将finder中创建的模块规范对象加载到内存成为真正的模块. loader通常在finder中使用,finder正确执行返回的模块规范对象中就包含一个字段用于存放loader,而导入流程的后半段就是执行这个模块规范对象的中loader,有两条路线: 如果loader定义了exec_module(module)方法: 执行器就会执行loader的exec_module(module)方法,这个方法本身还会检测和调用create_module(spec).而create_module(spec)会将spec对象转换成model对象 如果loader没有定义exec_module(module)方法: 执行器会执行load_module(name).这种情况其实已经被弃用了,现在还保留只是为了向后兼容. 无论执行的哪步,最终执行的结果就是 为模块对象设置上了其自省字段 在本地模块的命名空间上设置好了要导入的名字 在sys.modules中注册上模块对象 *模块重加载 通常模块一旦被导入就不应该重载,但有时候确实会有这样的需求.importlib.reload(module)->new_module提供了重新加载先前导入的模块的功能. 如果您已使用外部编辑器编辑了模块源文件,并希望在不离开Python解释器的情况下试用新版本,这将非常有用. 当执行reload时,Python模块的代码被重新编译,模块级代码被重新执行,通过重用最初加载模块的loader来定义一组新的对象. 缺陷 重新导入会导致将不同的对象放置在sys.modules中 旧对象只有在引用计数下降到零后才被回收,不会因为重载而被回收 对旧对象的其他引用(例如模块外部的名称)不会被重新引用以引用新对象因此直接作用于使用from ... import ...语法导入的模块,因为难以追踪命名空间中哪些是模块中的 当模块被重新加载时,它的字典(包含模块的全局变量)被保留.名称的重定义将覆盖旧的定义,因此这通常不是问题.如果模块的新版本没有定义由旧版本定义的名称,则旧定义将保留.这个特性可以用于模块的优势,如果它维护一个全局表或缓存的对象可以用try语句,它可以测试表是否存在. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:27:36 "},"语法篇/模块/模块加载特殊内容.html":{"url":"语法篇/模块/模块加载特殊内容.html","title":"模块加载特殊内容","keywords":"","body":"*模块加载特殊内容 从加载机制上看其实python解释器可以加载任何内容,只要定义好相应的finder和loader即可.这种扩展方式叫做import hook,官方其实也提供了几个import hook来实现一些特殊需求.本文将介绍这个 模块加载数据 就和C/C++中一些常量数据甚至文件内容直接写在头文件中可以加快运行时的速度一样,在python的导入时直接将需要的数据导入其实也是一种提高运行时效率的方法. python中有标准库pkgutil.get_data(package,path),可以帮我们实现这个需求. 我们有一个html文件叫\"base.html\"这边我们使用pkgutil来加载它 将其放入一个模块内 我们将其放入一个叫data_demo的模块中 data_demo-| |-__init__.py |-base.html 使用pkgutil.get_data加载数据 import pkgutil template = pkgutil.get_data('data_demo', 'base.html') print(template.decode('utf-8')) PyMOTW Template Example Template This is a sample data file. 加载zip包中的数据模块 python默认就可以加载zip包中的模块.这也就为大文件的导入提供了方便. 我们将data_demo文件中的文件打包到zip归档中 zipdata_demo.zip--| |-data_demo-| |-__init__.py |-base.html 然后还是使用pkgutil来读取数据,注意需要先将zipdata_demo.zip加入模块可以访问的位置 import pkgutil import sys sys.path.insert(0, 'zipdata_demo.zip') import data_demo emplate = pkgutil.get_data('data_demo', 'base.html') print(emplate.decode('utf-8')) PyMOTW Template Example Template This is a sample data file. 模块加载zip包中的python模块 上面的例子我们可以看到python自带加载zip中模块的能力,但每次加载都要显式的写上代码这样相当的不优雅 import sys sys.path.insert(0, 'xxxx.zip') python提供了标准库zipimport来解决这个问题 import zipimport importer = zipimport.zipimporter('zipdata_demo.zip') module = importer.load_module('data_demo') module.__path__ ['zipdata_demo.zip/data_demo'] import pkgutil emplate = pkgutil.get_data('data_demo', 'base.html') print(emplate.decode('utf-8')) PyMOTW Template Example Template This is a sample data file. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:27:30 "},"语法篇/模块/结语.html":{"url":"语法篇/模块/结语.html","title":"结语","keywords":"","body":"结语 语言设计的一致性 python是真正面向对象的编程语言,它的内部什么都是对象,这点在模块上提现非常深刻,因为即便是非常特使的模块也是对象.模块的导入过程也都是利用的接口一致性. 这让语言的扩展更加简单. 模块导入的最佳实践 这边只是分享个人习惯,一家之言而已. 我个人认为: 直接使用import xxxxx 这种方式是最安全也最具扩展性的,但它有一个缺点太过明显让我放弃了这种方式--当模块层级很深时每次调用其中方法都需要写一串非常长的名字.这非常影响可读性 使用from xxxx import * 这种方式最不可取,他会污染当前模块的命名空间,但它有其应用场景,就是在多层的包中,如果__init__.py只是为了将下层子模块中的内容导入上层,那么只要下层子模块定义好了__all__,就可以使用 这种方式做模块/框架开发的可以使用,不建议大型多人合作的项目这样用. 我的个人风格是这样写的: from xxx import ( A, B, C ) 个人认为这种写法最为清晰直接,可以很清楚的知道命名空间中哪些是来自外部模块的,而且如果不需要某个依赖了也可以先通过注释的方式进行检测. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 15:47:20 "},"语法篇/文本与字节序/":{"url":"语法篇/文本与字节序/","title":"文本与字节序","keywords":"","body":"文本,内存与字节序列 人类使用文本,计算机使用字节序列. 说到底计算机语言就是将人类使用的文本转化为机器使用字节序列的工具,而内存则是存放要处理内容的空间. 本节讲文本与字节序列的,并且讲解python中的内存工具和流工具 文本和编码 字节序列与内存视图 正则表达式 文件与IO流 序列化 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/文本与字节序/文本和编码.html":{"url":"语法篇/文本与字节序/文本和编码.html","title":"文本和编码","keywords":"","body":"文本和编码 字符串是个相当简单的概念:一个字符串是一个字符序列.问题出在\"字符\"的定义上. 在2015 年,\"字符\"的最佳定义是Unicode字符.因此从Python 3的str对象中获取的元素是Unicode字符 Unicode标准把字符的标识和具体的字节表述进行了如下的明确区分. 字符的标识,即码位是0~1 114 111的数字(十进制).在Unicode标准中以4~6个十六进制数字表示,而且加前缀U+.例如字母A的码位是U+0041,欧元符号的码位是U+20AC,高音谱号的码位是U+1D11E. 在Unicode 6.3标准中约10%的有效码位有对应的字符. 字符的具体表述取决于所用的编码.编码是在码位和字节序列之间转换时使用的算法.在UTF-8编码中,A(U+0041)的码位编码成单个字节\\x41,而在UTF-16LE编码中编码成两个字节\\x41\\x00.再举个例子:欧元符号(U+20AC)在UTF-8编码中是三个字节--\\xe2\\x82\\xac,而在UTF-16LE中编码成两个字节--\\xac\\x20. 把码位转换成字节序列的过程是编码,使用encode;把字节序列转换成码位的过程是解码,使用decode. 非英语用户常常会搞反所谓的编码解码,可以这样理解--把Unicode字符串想成\"人类可读\"的文本.那么 把字节序列变成人类可读的文本字符串就是解码 而把字符串变成用于存储或传输的字节序列就是编码 s = \"中文文本\" len(s) 4 b = s.encode(\"utf-8\")#编码 b b'\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe6\\x96\\x87\\xe6\\x9c\\xac' len(b) 12 b.decode(\"utf-8\") '中文文本' 混乱的编码问题 现今使用UTF-8编码是最通用的,但编码存在很多\"历史遗留问题\",比如中文编码混乱的问题(非英语都有这个问题) chardet是一个用于推断编码类型的工具,可以使用pip安装,使用它可以大致判断出文本使用的是什么编码,并给出该编码的可能性大小.具体用法可以看它的文档,下面是最简单的用法 import chardet chardet.detect(b) {'confidence': 0.938125, 'encoding': 'utf-8', 'language': ''} from requests import get rawdata = get('http://yahoo.co.jp/').content chardet.detect(rawdata) {'confidence': 0.99, 'encoding': 'utf-8', 'language': ''} 基本的编解码器 Python自带了超过100 种编解码器(codec, encoder/decoder),用于在文本和字节之间相互转换.每个编解码器都有一个名称，如utf_8,而且经常有几个别名,如utf8、utf-8 和U8.这些名称可以传给open()、str.encode()、bytes.decode() 等函数的encoding参数. 如下是几种最常见的编码: latin1(即iso8859_1) 一种重要的编码,是其他编码的基础,例如cp1252和Unicode(注意latin1与cp1252的字节值是一样的甚至连码位也相同) cp1252 微软制定的latin1超集,也是windows下各种编码问题的万恶之源,相对于latin1添加了有用的符号,例如弯引号和€(欧元);有些Windows 应用把它称为ANSI,但它并不是ANSI标准. cp437 IBM PC 最初的字符集,包含框图符号.与后来出现的latin1不兼容. gb2312 用于编码简体中文的陈旧标准,这是亚洲语言中使用较广泛的多字节编码之一.网络上中文乱码的万恶之源之一 utf-8 目前Web中最常见的8位编码;与ASCII兼容(纯ASCII文本是有效的UTF-8文本) utf-16le UTF-16的16位编码方案的一种形式;所有UTF-16支持通过转义序列(称为\"代理对\"，surrogate pair)表示超过U+FFFF的码位. UTF-16取代了1996年发布的Unicode 1.0编码(UCS-2).这个编码在很多系统中仍在使用,但是支持的最大码位是U+FFFF.从Unicode 6.3起，分配的码位中有超过50%在U+10000以上,包括逐渐流行的表情符号(emoji pictograph). for codec in ['latin_1', 'utf_8', 'utf_16']: print(codec, 'El Niño'.encode(codec), sep='\\t') latin_1 b'El Ni\\xf1o' utf_8 b'El Ni\\xc3\\xb1o' utf_16 b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' 大字节序还是小字节序 你可能注意到了,UTF-16编码的序列开头有几个额外的字节\\xff\\xfe这是BOM,即字节序标记(byte-order mark),指明编码时使用Intel CPU的小字节序. 在小字节序设备中,各个码位的最低有效字节在前面:字母'E'的码位是U+0045(十进制数69),在字节偏移的第2位和第3位编码为69和0. 在大字节序CPU中,编码顺序是相反的;'E'编码为0和69. 为了避免混淆,UTF-16编码在要编码的文本前面加上特殊的不可见字符ZERO WIDTH NOBREAK SPACE(U+FEFF).在小字节序系统中,这个字符编码为b'\\xff\\xfe'(十进制数 255, 254).因为按照设计,U+FFFE字符不存在,在小字节序编码中,字节序列b'\\xff\\xfe'必定是ZERO WIDTH NO-BREAK SPACE,所以编解码器知道该用哪个字节序. UTF-16有两个变种： UTF-16LE,显式指明使用小字节序; UTF-16BE,显式指明使用大字节序. 如果使用这两个变种,不会生成BOM. 与字节序有关的问题只对一个字(word)占多个字节的编码(如UTF-16和UTF-32)有影响.UTF-8的一大优势是,不管设备使用哪种字节序,生成的字节序列始终一致,因此不需要BOM.尽管如此,某些Windows应用(尤其是Notepad)依然会在UTF-8编码的文件中添加BOM;而且Excel会根据有没有BOM确定文件是不是UTF-8编码,否则它假设内容使用Windows代码页(codepage)编码.UTF-8编码的U+FEFF字符是一个三字节序列:b'\\xef\\xbb\\xbf'.因此,如果文件以这三个字节开头,有可能是带有BOM的UTF-8文件.然而,Python不会因为文件以b'\\xef\\xbb\\xbf' 开头就自动假定它是UTF-8编码的. ascii码支持 binascii是处理ascii编码的工具,binascii模块包含很多在二进制和ASCII编码的二进制表示转换的方法.通常情况不会直接使用这些功能,而是使用像UU,base64编码,或BinHex封装模块. binascii模块包含更高级别的模块使用的,用C语言编写的低级高效功能. 接口如下: binascii.a2b_uu(string) 将一行uuencoded数据转换回二进制并返回二进制数据.线通常包含45(二进制)字节,除了最后一行.行数据后面可以是空格. binascii.b2a_uu(data) 将二进制数据转换成一行ASCII字符,返回值是转换行,包括换行符.数据长度最多为45. binascii.a2b_base64(string) 将一个base64数据块转换回二进制数据并返回二进制数据.一次可能会传递多条线. binascii.b2a_base64(data, *, newline=True) 将二进制数据转换为base64编码中的ASCII字符行.返回值是转换行,如果换行符为true则包含换行符.此功能的输出符合RFC 3548. binascii.a2b_qp(data, header=False) 将可打印数据块转换回二进制数据并返回二进制数据.一次可能会传递多条线.如果可选参数头存在且为真,下划线将被解码为空格. binascii.b2a_qp(data, quotetabs=False, istext=True, header=False) 将二进制数据转换成可引用可打印编码的ASCII字符行.返回值是转换行.如果可选参数quotetabs存在且为真,则将对所有选项卡和空格进行编码.如果可选参数istext存在且为真,那么换行不会被编码,而尾随空白将被编码.如果可选参数头存在且为真,则空格将按照RFC1522编码为下划线.如果可选参数头存在且为false,则换行符也将被编码;否则换行转换可能会损坏二进制数据流. binascii.a2b_hqx(string) 将binhex4格式的ASCII数据转换为二进制,无需进行RLE解压缩.字符串应包含完整数量的二进制字节,或(在binhex4数据的最后一部分的情况下)剩余的位为零. binascii.rledecode_hqx(data) 根据binhex4标准对数据执行RLE解压缩.该算法在一个字节后使用0x90作为重复指示符,后跟计数.计数为0指定字节值0x90.例程返回解压缩的数据,除非数据输入数据在孤立的重复指示符中结束,在这种情况下会引发Incomplete异常. binascii.rlecode_hqx(data) 对数据执行binhex4风格的RLE压缩并返回结果 binascii.b2a_hqx(data) 执行hexbin4二进制到ASCII转换并返回生成的字符串.该参数应该已经是RLE编码,并且可以将长度除以3(除了可能的最后一个片段) binascii.crc_hqx(data, value) 计算数据的16位CRC值,以值作为初始CRC开始,并返回结果.这使用CRC-CCITT多项式x16 x12 x5 1,通常表示为0x1021.该CRC用于binhex4格式. binascii.crc32(data[, value]) 计算CRC-32,数据的32位校验和,以值的初始CRC开始.默认的初始CRC为零.该算法与ZIP文件校验和一致.由于该算法被设计为用作校验和算法,因此不适合用作通用散列算法.使用如下: import binascii print(binascii.crc32(b\"hello world\")) # Or, in two pieces: crc = binascii.crc32(b\"hello\") crc = binascii.crc32(b\" world\", crc) print('crc32 = {:#010x}'.format(crc)) 222957957 crc32 = 0x0d4a1185 binascii.b2a_hex(data) binascii.hexlify(data) 返回二进制数据的十六进制表示.数据的每个字节被转换成相应的2位十六进制表示.因此返回的字节对象是数据长度的两倍 binascii.a2b_hex(hexstr) binascii.unhexlify(hexstr) 返回由十六进制字符串hexstr表示的二进制数据,这个函数是b2a_hex()的倒数.hexstr必须包含偶数个十六进制数字(可以是大写或小写),否则会出现错误异常. python3支持Unicode python3从头到脚都支持Unicode,这也意味着像java一样,你可以将类名,函数名,变量名都设为中文(或者其他语言).不少人认为这样做不好,但考虑到代码的传播范围,其实使用更加便于交流的文字是更好的方法.比如,这个代码是一个日本企业内部使用的,而且他们并不打算让外国人用也不打算向前兼容python2,那么他们完全可以使用全日语来写文档,定义变量,函数,类. 为了正确比较而规范化Unicode字符串 因为Unicode有组合字符(变音符号和附加到前一个字符上的记号,打印时作为一个整体),所以拉丁语系文字比如法语,意大利语字符串比较起来很复杂,我们拿café这个词来作为例子.这个词可以使用两种方式构成,分别有4个和5个码位,但是结果完全一样. s1 = 'café' s2 = 'cafe\\u0301' s1, s2 ('café', 'café') len(s1), len(s2) (4, 5) s1 == s2 False U+0301是COMBINING ACUTE ACCENT,加在e后面得到é.在Unicode标准中,é 和e\\u0301 这样的序列叫\"标准等价物\"(canonical equivalent),应用程序应该把它们视作相同的字符.但是,Python看到的是不同的码位序列,因此判定二者不相等. 这个问题的解决方案是使用标准库的unicodedata.normalize函数提供的Unicode规范化.这个函数的第一个参数是这4个字符串中的一个：'NFC'、'NFD'、'NFKC' 和'NFKD' NFC（Normalization Form C）和NFD (Normalization Form D) 使用最少的码位构成等价的字符串，而NFD 把组合字符分解成基字符和单独的组合字符。这两种规范化方式都能让比较行为符合预期： from unicodedata import normalize s1 = 'café' s2 = 'cafe\\u0301' len(normalize('NFC', s1)), len(normalize('NFC', s2)) (4, 4) len(normalize('NFD', s1)), len(normalize('NFD', s2)) (5, 5) 西方键盘通常能输出组合字符,因此用户输入的文本默认是NFC形式.不过,安全起见,保存文本之前,最好使用normalize('NFC', user_text)清洗字符串.NFC也是W3C的Character Model for the World Wide Web: String Matching and Searching规范推荐的规范化形式。 NFKC和NFKD 在另外两个规范化形式(NFKC 和NFKD)的首字母缩略词中,字母K表示\"compatibility\"(兼容性).这两种是较严格的规范化形式,对\"兼容字符\"有影响.虽然Unicode的目标是为各个字符提供\"规范的\"码位,但是为了兼容现有的标准,有些字符会出现多次.例如虽然希腊字母表中有\"μ\"这个字母(码位是U+03BC，GREEK SMALL LETTER MU),但是Unicode还是加入了微符号μ(U+00B5)以便与latin1相互转换.因此,微符号是一个\"兼容字符\". 在NFKC和NFKD形式中,各个兼容字符会被替换成一个或多个\"兼容分解\"字符,即便这样有些格式损失,但仍是\"首选\"表述--理想情况下格式化是外部标记的职责,不应该由Unicode处理.下面举个例子: 二分之一½(U+00BD)经过兼容分解后得到的是三个字符序列'1/2'；微符号μ(U+00B5)经过兼容分解后得到的是小写字母μ(U+03BC) from unicodedata import normalize, name half = '½' normalize('NFKC', half) '1⁄2' four_squared = '4²' normalize('NFKC', four_squared) '42' micro = 'μ' micro_kc = normalize('NFKC', micro) micro, micro_kc ('μ', 'μ') ord(micro), ord(micro_kc) (956, 956) name(micro), name(micro_kc) ('GREEK SMALL LETTER MU', 'GREEK SMALL LETTER MU') 使用1/2 替代½可以接受,微符号也确实是小写的希腊字母μ,但是把4²转换成42就改变原意了.某些应用程序可以把4²保存为42,但是normalize函数对格式一无所知.因此NFKC 或NFKD可能会损失或曲解信息,但是可以为搜索和索引提供便利的中间表述--用户搜索1 ⁄ 2 inch时如果还能找到包含½ inch的文档那么用户会感到满意. 使用NFKC和NFKD规范化形式时要小心,而且只能在特殊情况中使用,例如搜索和索引,而不能用于持久存储,因为这两种转换会导致数据损失. 大小写折叠 大小写折叠其实就是把所有文本变成小写,再做些其他转换.这个功能由str.casefold()实现. 对于只包含latin1字符的字符串s,s.casefold()得到的结果与s.lower()一样,唯有两个例外: 微符号μ 会变成小写的希腊字母μ（在多数字体中二者看起来一样）； 德语Eszett(\"sharp s\"，ß)会变成ss 自Python 3.4 起,str.casefold()和str.lower()得到不同结果的有116个码位。Unicode6.3命名了110122个字符，这只占0.11% 极端\"规范化\":去掉变音符号 去掉变音符号不是正确的规范化方式,因为这往往会改变词的意思,而且可能误判搜索结果.但是对现实生活却有所帮助--人们有时很懒或者不知道怎么正确使用变音符号,而且拼写规则会随时间变化.因此实际语言中的重音经常变来变去. 比如café,对于中国人来说é很难打出来,所以用户往往就打cafe了,我们需要一个去掉组合记号的函数用来实现这种极端的规范化 import unicodedata import string def shave_marks(txt): \"\"\"去掉全部变音符号\"\"\" norm_txt = unicodedata.normalize('NFD', txt) shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c)) return unicodedata.normalize('NFC', shaved) order = '“Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.”' shave_marks(order) '“Herr Voß: • ½ cup of OEtker™ caffe latte • bowl of acai.”' Greek = 'Zέφupoς, Zéfiro' shave_marks(Greek) 'Zεφupoς, Zefiro' 总结unicode规范化: NFC和NFD可以放心使用,而且能合理比较Unicode字符串 对大多数应用来说，NFC是最好的规范化形式 不区分大小写的比较应该使用str.casefold() 在必要的时候,我们可以删除一些变音符号来做规范化 文本排序 Python比较任何类型的序列时,会一一比较序列里的各个元素.对字符串来说,比较的是码位.可是在比较非ASCII字符时,得到的结果不尽如人意. l = [\"前\",\"后\",\"左\",\"右\"] sorted(l) ['前', '右', '后', '左'] 按照中文传统,我们应该希望按拼音首字母顺序排序即后前右左,但明显不是. 实际上在Python中,非ASCII文本的标准排序方式是使用locale.strxfrm函数,根据locale模块的文档,这个函数会\"把字符串转换成适合所在区域进行比较的形式\".使用locale.strxfrm函数之前,必须先为应用设定合适的区域设置,还要祈祷操作系统支持这项设置.在区域设为pt_BR的GNU/Linux(Ubuntu 14.04)中.而在windows中还没这个功能. 在Linux操作系统中中国大陆的读者可以使用zh_CN.UTF-8,简体中文会按照汉语拼音顺序进行排序. unicode排序工具PyUCA James Tauber，一位高产的Django贡献者，他一定是感受到了这一痛点，因此开发了 PyUCA 库,这是Unicode排序算法包. PyUCA 没有考虑区域设置。如果想定制排序方式，可以把自定义的排序表路径传给Collator()构造方法。PyUCA 默认使用项目自带的allkeys.txt，这就是Unicode 6.3.0的\"Default Unicode Collation Element Table\"的副本 import pyuca coll = pyuca.Collator() fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola'] sorted_fruits = sorted(fruits, key=coll.sort_key) sorted_fruits ['açaí', 'acerola', 'atemoia', 'cajá', 'caju'] 以指定列宽格式化字符串 文本标注 python定义字符串使用成对的',\",\"\"\",'''构建而成,而文本可以标注为r,u,b,f等 s = \"这是一句话\\n\" s '这是一句话\\n' 原始文本标注r 用r标注的文本表示不会理会转义字符\\ s = r\"这是一句话\\n\" s '这是一句话\\\\n' unicode文本标注u 用u标注的文本表示字符串为unicode,python3中str就是Unicode,所以其实这个没什么意义,主要是为了给python3向前兼容的 btypes文本标注b 用b标注的文本标识文本为bytes,使用这个标注说明文本是字节序列 格式化文本标注f 用f标注的文本表示其中有用{}占位的内容由前面定义的变量填充,需要注意一旦标注为f则文本实际上已经不是文本了,而是一个函数,如果占位符没有找到对应的变量,则会报错,将f标注的文本放入函数中指定参数为其中的占位符也没有用 a = 1 b = 2 f\"asdf{a}{b}\" 'asdf12' 格式化字符串 python可以使用str.format()方法来格式化字符串这种方式更加直观 \"{}是{}\".format(\"一\",1) '一是1' \"{a}是{b}\".format(a=\"一\",b=1) '一是1' 文本模板 python提供了一个模块from string import Template,可以用于定义文本模板.它通常用来作为文件的内容模板. Template用起来和字符串的format方法类似,使用$标识要替换的占位字符,然后使用方法substitute来替换.以下是一个dockerfile的文本模板 from string import Template file = Template(\"\"\" FROM python:$v1:$v2 ADD requirements/requirements.txt /code/requirements.txt ADD $project_name.$suffix /code/$project_name.$suffix WORKDIR /code RUN pip install -r requirements.txt \"\"\") content = file.substitute(v1=3,v2=6,project_name=\"my project\",suffix=\"pyz\") print(content) FROM python:3:6 ADD requirements/requirements.txt /code/requirements.txt ADD my project.pyz /code/my project.pyz WORKDIR /code RUN pip install -r requirements.txt Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/文本与字节序/字节序列与内存视图.html":{"url":"语法篇/文本与字节序/字节序列与内存视图.html","title":"字节序列与内存视图","keywords":"","body":"字节序列与内存视图 字节与内存往往联系在一起,内存中存的永远是字节,要是其有意义必须通过编码,本节介绍python的字节和内存操作. 本节的先验知识有: 序列对象 字节与字节序列 Python内置了两种基本的二进制序列类型: Python 3 引入的不可变bytes类型 Python 2.6 添加的可变bytearray类型 bytes 或bytearray对象的各个元素是介于0~255(含)之间的整数.然而二进制序列的切片始终是同一类型的二进制序列,包括长度为1的切片 cafe = bytes('café', encoding='utf_8') cafe cafe[0] # 单个元素为0~255之间的整数 99 cafe[:1] # 使用切片则返回同类型序列 b'c' bytearray是可变序列 不同于bytes,bytearray是可变序列.它是可以修改的,行为类似list. cafe_arr = bytearray(cafe) cafe_arr.append(2) cafe_arr 虽然二进制序列其实是整数序列,但是它们的字面量表示法表明其中有ASCII文本.因此各个字节的值可能会使用下列三种不同的方式显示: 可打印的ASCII范围内的字节(从空格到~)使用ASCII字符本身 制表符、换行符、回车符和\\对应的字节,使用转义序列\\t、\\n、\\r 和\\\\ 其他字节的值,使用十六进制转义序列(例如\\x00是空字节) 格式化二进制序列 除了格式化方法(format 和format_map) 和几个处理Unicode数据的方法(包括casefold、isdecimal、isidentifier、isnumeric、isprintable 和encode) 之外,str类型的其他方法都支持bytes和bytearray类型.这意味着我们可以使用熟悉的字符串方法处理二进制序列,如endswith、replace、strip、translate、upper等,只有少数几个其他方法的参数是bytes对象而不是str对象. 此外如果正则表达式编译自二进制序列而不是字符串re模块中的正则表达式函数也能处理二进制序列. Python不能使用foramte方法处理二进制序列,只能使用%运算符处理二进制序列. print(b\"sadfg%d\" % (12)) b'sadfg12' print(b\"sadfg{}\".format(12)) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 print(b\"sadfg{}\".format(12)) AttributeError: 'bytes' object has no attribute 'format' 二进制序列创建 二进制序列有个类方法是str没有的,名为fromhex,它的作用是解析十六进制数字对(数字对之间的空格是可选的),构建二进制序列: bytes.fromhex('31 4B CE A9') b'1K\\xce\\xa9' 通过str编码而来 \"流星雨\".encode(\"utf-8\") b'\\xe6\\xb5\\x81\\xe6\\x98\\x9f\\xe9\\x9b\\xa8' 构建bytes 或 bytearray 实例还可以调用各自的构造方法,传入下述参数。 一个 str 对象和一个 encoding 关键字参数。 bytes('sphinx',encoding=\"utf-8\") b'sphinx' 一个可迭代对象,提供 0~255 之间的数值。 bytes([12,34,32,212]) b'\\x0c\" \\xd4' 一个实现了缓冲协议的对象(如 bytes、bytearray、memoryview、array.array);此时,把源对象中的字节序列复制到新建的二进制序列中 import array numbers = array.array('h', [-2, -1, 0, 1, 2]) octets = bytes(numbers) octets b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00' python与内存 Cpython本质上是建筑在C语言上的,python也有工具直接如同C语言一样处理内存. 内存与位 所谓内存是一段连续的物理内存片段,一般内存都是按bytes分段使用的,一位(bit)就是一个二进制位(存储二进制数据),而一个byte就是8位二进制位.因此每一位看作一个10进制数的话,其范围为 $0\\to(2^8-1)$ 也就是0~255这就与我们python的bytes对象对应起来了. 无论是什么对象什么类型,数据存在内存中的永远是0,1构成的编码,因此总可以使用bytes来处理.而类型本质上来说只是指示编码的工具. 位运算 python的数字但一般来说默认的表现形式是10进制的,也有2进制,8进制16进制的表现形式,但实际上是转化为str. num1 = 1 num2 = 0 bnum1 = bin(num1) bnum1 '0b1' hnum1 = hex(num1) hnum1 '0x1' onum1 = oct(num1) onum1 '0o1' bnum2 = bin(num2) bnum2 '0b0' hnum2 = hex(num2) hnum2 '0x0' onum2 = oct(num2) onum2 '0o0' python也有位运算.但只有int类型才可以使用 bin(num1&num2)#按位与 & '0b0' bin(num1&num1)#按位与 & '0b1' bin(num2&num2)#按位与 & '0b0' bin(num1|num2)#按位或 '0b1' bin(num1|num1)#按位或 '0b1' bin(num2|num2)#按位或 '0b0' bin(num1^num2)#按位异或 ^ '0b1' bin(num1^num1)#按位异或 ^ '0b0' bin(num2^num2)#按位异或 ^ '0b0' bin(~num2)#按位翻转~ '-0b1' ~num2 -1 bin(~num1)#按位翻转~ '-0b10' ~num1 -2 bin(num1 '0b10' bin(num1>>1)#左移运算符 >> '0b0' array对象 python有一个很特殊的序列类型array.array,它是同构可变序列,需要指定类型,事实上str,bytes,btyearray,memoryview都是同构序列,他们实际上是一段连续的内存,因此更加紧凑也更加高效. array.array,它是同构可变序列,需要指定类型.这些类型必须是与C语言中对应的.可以指定的类型有: Type code C Type Minimum size in bytes 'c' character 1 'b' signed integer 1 'B' unsigned integer 1 'u' Unicode character 2 'h' signed integer 2 'H' unsigned integer 2 'i' signed integer 2 'I' unsigned integer 2 'l' signed integer 4 'L' unsigned integer 4 'f' floating point 4 'd' floating point 8　　 from array import array from random import random floats = array('d', (random() for i in range(10**7))) floats[-1] 0.13967783903892583 with open('output/floats.bin', 'wb') as fp: floats.tofile(fp) floats2 = array('d') with open('output/floats.bin', 'rb') as fp: floats2.fromfile(fp,10**7)#把1000 万个浮点数从二进制文件里读取出来 floats2[-1] 0.13967783903892583 floats2 == floats True array.tofile和array.fromfile用起来很简单.把这段代码跑一跑你还会发现它的速度也很快.一个小试验告诉我用array.fromfile从一个二 进制文件里读出1000万个双精度浮点数只需要0.1 秒,这比从文本文件里读取的速度要快60倍,因为后者会使用内置的float方法把每一行文字转换成浮点数.另外使用array.tofile写入到二进制文件比以每行一个浮点数的方式把所有数字写入到文本文件要快7倍.同时1000万个这样的数在二进制文件里只占用80,000,000个字节(每个浮点数占用8 个字节,不需要任何额外空间),如果是文本文件的话我们需要181,515,739 个字节. 内存缓冲对象与二进制序列 使用缓冲类对象创建 bytes 或 bytearray 对象时,始终复制源对象中的字节序列.与之相反memoryview 对象允许在二进制数据结构之间共享内存.如果想从二进制序列中提取结构化信息,struct模块是重要的工具。 memoryview memoryview是一个内置类,它能让用户在不复制内容的情况下操作同一个数组的不同切片.memoryview的概念受到了NumPy的启发,它其实是泛化和去数学化的NumPy数组.它让你在不需要复制内容的前提下,在数据结构之间共享内存.其中数据结构可以是任何形式,比如PIL图片、SQLite数据库和 NumPy的数组等等.这个功能在处理大型数据集合的时候非常重要. memoryview.cast的概念跟数组模块类似,能用不同的方式读写同一块内存数据,而且内容字节不会随意移动.这听上去又跟C 语言中类型转换的概念差不多.memoryview.cast 会把同一块内存里的内容打包成一个全新的 memoryview 对象给你. 我们利用 memoryview 精准地修改了一个数组的某个字节,这个数组的元素是 16 位二进制整数 numbers = array.array('h', [-2, -1, 0, 1, 2]) #有符号整数(2个字节) memv = memoryview(numbers) len(memv) 5 memv[0] -2 memv_oct = memv.cast('B') # 转化为无符号(单字节) memv_oct.tolist() [254, 255, 255, 255, 0, 0, 1, 0, 2, 0] memv_oct[5] = 4 memv_oct.tolist() [254, 255, 255, 255, 0, 4, 1, 0, 2, 0] numbers array('h', [-2, -1, 1024, 1, 2]) struct struct就是结构体,C中的结构体就是一段连续的内存空间,顺序地存储指定类型的内容. struct解包需要知道字节顺序,打包的后的字节顺序默认上是由操作系统的决定的,当然struct模块也提供了自定义字节顺序的功能,可以指定大端存储、小端存储等特定的字节顺序,对于底层通信的字节顺序是十分重要的,不同的字节顺序和存储方式也会导致字节大小的不同.在format字符串前面加上特定的符号即可以表示不同的字节顺序存储方式,例如采用小端存储 s = struct.Struct(‘就可以了. 字节顺序字符串定义规则如下: Character Byte order Size Alignment @ native native native = native standard none little-endian standard none > big-endian standard none ! network (= big-endian) standard none python中也是类似功能.与array类似,也需要为每段指定数据类型: Format C Type Python type Standard size Notes x pad byte no value --- --- c char bytes of length 1 1 --- b signed char integer 1 --- B unsigned char integer 1 --- ? _Bool bool 1 --- h short integer 2 --- H unsigned short integer 2 --- i int integer 4 --- I unsigned int integer 4 --- l long integer 4 --- L unsigned long integer 4 --- q long long integer 8 --- Q unsigned long long integer 8 --- n ssize_t integer --- --- N size_t integer --- --- e --- float 2 半精度浮点数 f float float 4 --- d double float 8 --- s char[] bytes --- --- p char[] bytes --- --- P void * integer --- --- 利用buffer，使用pack_into和unpack_from方法 使用二进制打包数据的场景大部分都是对性能要求比较高的使用环境.而在上面提到的pack方法都是对输入数据进行操作后重新创建了一个内存空间用于返回,也就是说我们每次pack都会在内存中分配出相应的内存资源,这有时是一种很大的性能浪费.struct模块还提供了pack_into()和unpack_from()的方法用来解决这样的问题,也就是对一个已经提前分配好的buffer进行字节的填充,而不会每次都产生一个新对象对字节进行存储. import struct import binascii import ctypes values = (1, b'abc', 2.7) s = struct.Struct('I3sf')# 指定类型 prebuffer = ctypes.create_string_buffer(s.size)#ctypes模块创建一个缓冲 print('Before :',binascii.hexlify(prebuffer)) Before : b'000000000000000000000000' s.pack_into(prebuffer,0,*values) print('After pack:',binascii.hexlify(prebuffer)) After pack: b'0100000061626300cdcc2c40' unpacked = s.unpack_from(prebuffer,0) print('After unpack:',unpacked) After unpack: (1, b'abc', 2.700000047683716) 我们可以把多个对象pack到一个buffer里面，然后通过指定不同的offset进行unpack import struct import binascii import ctypes values1 = (1, b'abc', 2.7) values2 = (b'defg',101) s1 = struct.Struct('I3sf') s2 = struct.Struct('4sI') prebuffer = ctypes.create_string_buffer(s1.size+s2.size) print('Before :',binascii.hexlify(prebuffer)) s1.pack_into(prebuffer,0,*values1) s2.pack_into(prebuffer,s1.size,*values2) print('After pack:',binascii.hexlify(prebuffer)) print(s1.unpack_from(prebuffer,0)) print(s2.unpack_from(prebuffer,s1.size)) Before : b'0000000000000000000000000000000000000000' After pack: b'0100000061626300cdcc2c406465666765000000' (1, b'abc', 2.700000047683716) (b'defg', 101) memoryview 和 struct struct 模块提供了一些函数,把打包的字节序列转换成不同类型字段组成的元组,还有一些函数用于执行反向转换,把元组转换成打包的字节序列。struct 模块能处理bytes、bytearray和memoryview对象. memoryview 类不是用于创建或存储字节序列的,而是共享内存,让你访问其他二进制序列、打包的数组和缓冲中的数据切片,而无需复制字节序列,例如PIL 就是这样处理图像的. 下例使用memoryview 和struct 提取一个 GIF 图像的宽度和高度 import struct # 结构体的格式: b'GIF89a,\\x01,\\x01' # 拆包 memoryview 对象,得到一个元组,包含类型、版本、宽度和高度 struct.unpack(fmt, header) (b'GIF', b'89a', 300, 300) #删除引用,释放 memoryview 实例所占的内存 del header del img mmap做文件映射 python提供一个mmap模块用于将文件映射至内存,即将一个文件或者其它对象映射到进程的地址空间,实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系.mmap对象可以作为进程间通过文件进行IPC的一种替换手段. 创建 mmap 对象 windows mmap(filedesc, length, tagname='') Unix mmap(filedesc, length, flag=MAP_SHARED, prot=PROT_READ|PROT_WRITE) 创建并返回一个 mmap 对象,参数 filedesc 通常是由 f.fileno()获得的. mmap 创建对象的含义是:将指定 fd 的前 length 字节映射到内存. Windows中可以通过参数tagname为一段内存映射指定名称,这样一个文件上面可以同时具有多个mmap. windows中的内存映射都是可读可写的,同时在进程之间共享. Unix平台上参数flags的可选值包括: mmap.MAP_PRIVATE:这段内存映射只有本进程可用 mmap.MAP_SHARED:将内存映射和其他进程共享,所有映射了同一文件的进程,都能够看到其中一个所做的更改 参数prot对应的取值包括:mmap.PROT_READ, mmap.PROT_WRITE 和 mmap.PROT_WRITE | mmap.PROT_READ。最后一个的含义是同时可读可写。 mmap 对象的方法: m.close()关闭 m 对应的文件; m.find(str, start=0)从 start 下标开始,在 m 中从左往右寻找子串 str 最早出现的下标; m.flush([offset, n])把 m 中从offset开始的n个字节刷到对应的文件中,参数 offset 要么同时指定，要么同时不指定; m.move(dstoff, srcoff, n) 等于m[dstoff:dstoff+n] = m[srcoff:srcoff+n],把从 srcoff 开始的 n 个字节复制到从 dstoff 开始的n个字节,可能会覆盖重叠的部分. m.read(n) 返回一个字符串,从 m 对应的文件中最多读取 n 个字节,将会把 m 对应文件的位置指针向后移动; m.read_byte() 返回一个1字节长的字符串,从 m 对应的文件中读1个字节,要是已经到了EOF还调用read_byte(),则抛出异常 ValueError; m.readline() 返回一个字符串,从 m 对应文件的当前位置到下一个'\\n',当调用readline()时文件位于 EOF,则返回空字符串; m.resize(n) 把 m 的长度改为 n,m 的长度和 m 对应文件的长度是独立的; m.seek(pos, how=0) 同 file 对象的 seek 操作,改变 m 对应的文件的当前位置; m.size()　返回 m 对应文件的长度(不是 m 对象的长度len(m)); m.tell() 返回 m 对应文件的当前位置; m.write(bytes)把二进制字节序列写到 m 对应文件的当前位置,如果从 m 对应文件的当前位置到 m 结尾剩余的空间不足len(str)，则抛出ValueError; m.write_byte(byte)把1个字节(对应一个字符)写到 m 对应文件的当前位置,实际上m.write_byte(ch) 等于 m.write(ch).如果 m 对应文件的当前位置在 m 的结尾,也就是 m 对应文件的当前位置到 m 结尾剩余的空间不足1个字节,write()抛出异常ValueError,而write_byte() 什么都不做. 对于EOF的处理,write() 和 read_byte() 抛出异常ValueError,而 write_byte()和 read() 什么都不做. 使用mmap模块了其大致特点如下: 普通文件被映射到虚拟地址空间后,程序可以向访问普通内存一样对文件进行访问,在有些情况下可以提高IO效率. 它占用物理内存空间少,可以解决内存空间不足的问题,适合处理超大文件. 不同于通常的字符串对象,它是可变的,可以通过切片的方式更改,也可以定位当前文件位置m.tell()或m.seek()定位到文件的指定位置,再进行m.write(str)固定长度的修改操作. mmap常用于处理大数据 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 11:48:15 "},"语法篇/文本与字节序/正则表达式.html":{"url":"语法篇/文本与字节序/正则表达式.html","title":"正则表达式","keywords":"","body":"正则表达式 正则表达式,又称规则表达式,它是用于匹配字符串,unicode,bytes的通用方法.使用特定的格式对特定的文本做模式匹配,以此来定位要处理的字符. 这种模式匹配的特定格式是各个语言通用的,可以看https://deerchao.net/tutorials/regex/regex.htm这个网站学习,本文不做多余阐述. python中使用re模块来使用正则表达式,它的接口有: re.compile(pattern) 产生正则匹配对象 import re prog = re.compile(r\"\\W+\") prog.match(\"Words, words, words.\") re.match('com','comwww.runcomoob') re.search(pattern, string, flags=0) 扫描通过字符串查找正则表达式模式产生匹配的第一个位置,并返回相应的匹配对象.如果字符串中没有位置匹配模式则返回None;请注意这不同于在字符串中的某一点找到零长度匹配. re.match(pattern, string, flags=0) 如果字符串开头的零个或多个字符与正则表达式模式匹配,则返回相应的匹配对象.如果字符串与模式不匹配,返回None;请注意这与零长度匹配不同.请注意即使在MULTILINE模式下,re.match()只会在字符串的开头匹配,而不是在每一行的开头.如果要在字符串中的任意位置找到匹配项,请改用search() re.fullmatch(pattern, string, flags=0) 如果整个字符串与正则表达式模式匹配,则返回一个相应的匹配对象.如果字符串与模式不匹配,返回None;请注意,这与零长度匹配不同 上面的接口都会返回一个匹配对象用于展示匹配的结果 re.split(pattern, string, maxsplit=0, flags=0) 按pattern的出现拆分字符串.如果在模式中使用捕获括号,则模式中所有组的文本也作为生成列表的一部分返回.如果maxsplit不为零,则最多会出现maxsplit拆分,并将该字符串的其余部分作为列表的最后一个元素返回 import re re.split(r'\\W+', 'Words, words, words.') ['Words', 'words', 'words', ''] re.split(r'(\\W+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '.', ''] re.split(r'\\W+', 'Words, words, words.', 1) ['Words', 'words, words.'] re.split(r'[a-f]+', '0a3B9', flags=re.IGNORECASE) ['0', '3', '9'] re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] re.split(r'x*', 'axbc') /Users/huangsizhe/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match. return _compile(pattern, flags).split(string, maxsplit) ['a', 'bc'] re.split(\"^$\", \"foo\\n\\nbar\\n\", flags=re.M) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 re.split(\"^$\", \"foo\\n\\nbar\\n\", flags=re.M) ~/anaconda3/lib/python3.6/re.py in split(pattern, string, maxsplit, flags) 210 and the remainder of the string is returned as the final element 211 of the list.\"\"\" --> 212 return _compile(pattern, flags).split(string, maxsplit) 213 214 def findall(pattern, string, flags=0): ValueError: split() requires a non-empty pattern match. re.findall(pattern, string, flags=0) 返回字符串中模式的所有非重叠匹配,作为字符串列表.字符串从左到右扫描,并按照找到的顺序返回匹配项.如果模式中存在一个或多个组,则返回组的列表;如果模式有多个组,这将是一个元组的列表.结果中包含空模式匹配,除非他们触及另一个模式匹配的开始. re.finditer(pattern, string, flags=0) 返回一个迭代器,在字符串中的RE模式的所有非重叠匹配上产生匹配对象.字符串从左到右扫描,并按照找到的顺序返回匹配项.结果中包含空匹配,除非他们触及另一个匹配的开始. re.sub(pattern, repl, string, count=0, flags=0) 返回通过替换repl替换字符串中最左侧不重叠的pattern的字符串获取的字符串.如果没有找到模式,则字符串不会更改.repl可以是一个字符串或一个函数;如果是字符串,则会处理其中的任何反斜杠转义. 这个接口将在3.7中弃用 re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):', r'static PyObject*\\npy_\\1(void)\\n{', 'def myfunc():') 'static PyObject*\\npy_myfunc(void)\\n{' def dashrepl(matchobj): if matchobj.group(0) == '-': return ' ' else: return '-' re.sub('-{1,2}', dashrepl, 'pro----gram-files') 'pro--gram files' re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE) 'Baked Beans & Spam' re.subn(pattern, repl, string, count=0, flags=0) 执行与sub()相同的操作,但返回一个元组(new_string，number_of_subs_made). re.escape(pattern) 脱离除ASCII字母,数字和'_'以外的所有字符.如果要匹配任意的可能具有正则表达式元字符的字符串,这将非常有用. print(re.escape('python.exe')) python\\.exe import string legal_chars = string.ascii_lowercase + string.digits + \"!#$%&'*+-.^_`|~:\" print('[%s]+' % re.escape(legal_chars)) [abcdefghijklmnopqrstuvwxyz0123456789\\!\\#\\$\\%\\&\\'\\*\\+\\-\\.\\^_\\`\\|\\~\\:]+ operators = ['+', '-', '*', '/', '**'] print('|'.join(map(re.escape, sorted(operators, reverse=True)))) \\/|\\-|\\+|\\*\\*|\\* re.purge() 清除正则表达式缓存. 正则表达式与unicode python的re模块可以匹配unicode se = re.search(r\"收\",\"一定要收复台湾\") se.start() 3 \"一定要收复台湾\"[3] '收' Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/文本与字节序/文件与IO流.html":{"url":"语法篇/文本与字节序/文件与IO流.html","title":"文件与IO流","keywords":"","body":"文件与IO流 计算机离不开文件与IO流,文件是多数操作系统的基本构成单位,而IO流则是将数据用于运算和输出结果的工具.无论是文件还是IO流,都是由bytes构成的,表现形式也只有两种: str 经过编码的bytes bytes 一般图片音频等使用bytes 标准输入输出 python提供了标准输入输出函数 input(prompt:str='')->str prompt是提示文本 input(\"输入吧\") 输入吧 '' print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) file: 默认为标准输出,但可以指定一个文件对象用于输出 sep: 字符串插入值之间，默认为空格。 end: 字符串附加在最后一个值之后，默认换行符。 flush: 是否强制冲洗替换流。 print(\"1234\") 1234 流对象 python的流对象都定义在io模块中,包括如下种类: TextIOWrapper,继承自TextIOBase,IOBase BufferedReader/BufferedWriter,继承自BufferedIOBase,IOBase StringIO继承自TextIOBase, IOBase BytesIO继承自BufferedIOBase,IOBase FileIO继承自RawIOBase, IOBase 文件对象 python从硬盘中读入的文件会被封装为文件对象(TextIOWrapper). 文件对象实质上是一个流对象. 从文件中提取文件对象的方式是使用 open(filepath, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None) buffering 指定缓冲策略,0为关闭缓冲(必须带b),大于0的整数为缓冲区大小,-1表示不固定 encoding 指定编码方式 errors 解码报错时报什么错 newline 定义使用何种方式换行可以是None, '', '\\n', '\\r', and '\\r\\n' closefd,如果closefd为False，底层文件描述符将保持打开状态,文件关闭时。当给出文件名时，这不起作用在这种情况下必须为True。 opener,传递一个可打开的作为opener可以使用自定义的开启者。默认通过os.open作为opener mode, 指定文件的读写模式 模式 描述 r 以只读方式打开文件.文件的指针将会放在文件的开头.这是默认模式. rb 以二进制格式打开一个文件用于只读.文件指针将会放在文件的开头.这是默认模式. r+ 打开一个文件用于读写.文件指针将会放在文件的开头. rb+ 以二进制格式打开一个文件用于读写.文件指针将会放在文件的开头. w 打开一个文件只用于写入.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件. wb 以二进制格式打开一个文件只用于写入.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件. w+ 打开一个文件用于读写.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件. wb+ 以二进制格式打开一个文件用于读写.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件. a 打开一个文件用于追加.如果该文件已存在,文件指针将会放在文件的结尾.也就是说新的内容将会被写入到已有内容之后.如果该文件不存在,创建新文件进行写入. ab 以二进制格式打开一个文件用于追加.如果该文件已存在,文件指针将会放在文件的结尾.也就是说新的内容将会被写入到已有内容之后.如果该文件不存在,创建新文件进行写入. a+ 打开一个文件用于读写.如果该文件已存在,文件指针将会放在文件的结尾.文件打开时会是追加模式.如果该文件不存在,创建新文件用于读写. ab+ 以二进制格式打开一个文件用于追加.如果该文件已存在,文件指针将会放在文件的结尾.如果该文件不存在,创建新文件用于读写. mode中带有b的返回的对象是BufferedReader对象,不带的是TextIOWrapper而读写的不同也会带来方法的不同.open的使用方式最好结合上下文工具with语句使用 with open(\"src/hello.txt\",\"wb\") as f: print(type(f).mro()) [, , , ] 针对不同的打开模式,文件对象的的方法会有些不同,但有些基本方法是共用的,就是继承自IOBase的方法 IOBase的基本方法 close() 关闭文件对象 fileno() 返回流的底层文件描述符(一个整数)(如果存在).如果IO对象不使用文件描述符,则会引发OSError. flush() 清空流的写入缓冲区(如果适用).这对于只读和非阻塞流不起作用. isatty() 如果流是交互式的(连接到终端/tty设备),返回True. seek(offset[, whence]) 将流位置更改为给定的字节偏移.偏移量相对于由whence指示的位置进行解释.offset的默认值为SEEK_SET.可选的值为: SEEK_SET or 0 – 流的开始(默认);偏移量应为零或正数 SEEK_CUR or 1 – 当前流位置;偏移可能为负 SEEK_END or 2 – 流的结尾,偏移量通常为负数 返回新的绝对位置。 seekable() 如果流支持随机访问,则返回True. tell() 返回当前流的位置。 truncate(size=None) 将流调整为给定大小(以字节为单位)(如果未指定大小,则调整当前位置).当前流位置不变.这种调整大小可以扩展或减少当前的文件大小.在扩展的情况下,新文件区域的内容取决于平台(在大多数系统上,其他字节为零填充).将返回新的文件大小. 与读写相关的方法有: readable() 如果流可以读取,返回True.如果为False,则read()将引发OSError. readline(size=-1) 从流中读取并返回一行.如果指定了大小,则读取最多大小的字节.对于二进制文件,行终止符始终为b'\\ n';对于文本文件,open()的newline参数可用于选择识别的行终止符. readlines(hint=-1) 读取并返回流中的行列表.可以指定提示来控制读取的行数:如果所有行的总大小(以字节/字符为单位)超过提示,则不会读取更多行.请注意,现在更加推荐的方式是使用 for line in file: func(line) 而不调用file.readlines(). writable() 如果流支持写入,则返回True.如果为False，write()和truncate()将引发OSError。 writelines(lines) 将行写入流 TextIOBase的基本方法 detach() 将底层二进制缓冲区与TextIOBase分开并返回.底层缓冲区分离后TextIOBase处于不可用状态.一些TextIOBase实现(如StringIO)可能不具有底层缓冲区的概念,调用此方法将引发UnsupportedOperation. read(size) 读入 +　write(s) 写字符串到对象 BufferedIOBase的基本方法 detach() 将底层原始流与缓冲区分开并返回.原始流已分离后,缓冲区处于不可用状态.一些缓冲区如BytesIO没有从该方法返回的单个原始流的概念,它们引发UnsupportedOperation read(size=-1) 读取并返回到大小字节,如果省略参数,则None或者否定数据被读取并返回,直到达到EOF.如果流已经处于EOF则返回空字节对象.如果参数为正,并且底层原始流不具有交互性,则可能会发出多个原始读取以满足字节计数(除非首先达到EOF).但是对于交互式原始流,最多只会发出一次原始读取,结果并不意味着EOF即将到来.如果底层原始流处于非阻塞模式并且目前没有可用的数据,则会引发BlockingIOError read1(size=-1) 读取并返回到大小字节,最多只能调用底层原始流的read()或readinto()方法.如果要在BufferedIOBase对象之上实现自定义的缓冲区,这将非常有用. readinto(b) 将字节读入预先分配的可写入字节的对象b并返回读取的字节数.像read()一样,可能会向底层的原始流发出多次读取,除非后者是交互式的.如果底层原始流处于非阻塞模式并且目前没有可用的数据,则会引发BlockingIOError。 readinto1(b) 将字节读入预先分配的可写入字节的对象b,最多使用一个对底层原始流的read()或readinto方法的调用.返回读取的字节数.如果底层原始流处于非阻塞模式并且目前没有可用的数据,则会引发BlockingIOError write(b) 编写给定的类似字节的对象b,并返回写入的字节数(总是等于b的长度,以字节为单位),因为如果写入失败(OSError将被引发).根据实际的实现,这些字节可以容易地写入底层流,或者由于性能和延迟原因而被保存在缓冲器中.当处于非阻塞模式时,如果数据需要写入原始流但无法接受所有数据而不阻塞,则会引发BlockingIOError.该方法返回后,调用者可能会释放或变异b.因此在方法调用期间实现只能访问b. 另一种读写文件的方式 FileIO类是读写文件的另一种方式,与open不同之处在于它继承自RawIOBase,也就是说它是没有缓冲区也没有解码过的的单纯文件io from io import FileIO with FileIO(\"src/hello.txt\", mode='r', closefd=True, opener=None) as f: print(f.read()) b'' RawIOBase的基本方法 read(size=-1) 读出bytes readall() 从流中读取并返回所有字节,直到EOF,如果需要,可以使用多个流调用. readinto(b) 将字节读入预分配的可写入字节的对象b,并返回读取的字节数.如果对象处于非阻塞模式,并且没有字节可用,则返回None. write(b) 写入bytes 内存中生成文件对象 io模块可以用于生成文件对象其中有StringIO和BytesIO两种,头一种文件对象保存字符串,后一种则保存字节流 使用io模块生成的文件对象更多的是作为流使用,因此有一些特别的方法 getvalue() 返回一个包含缓冲区的全部内容的str或者bytes read1() BytesIO对象可以使用,读取并返回到大小字节,最多只能调用底层原始流的read()(或readinto())方法.如果您在BufferedIOBase对象之上实现自己的缓冲区,这将非常有用. readinto1() BytesIO对象可以使用,将字节读入预先分配的可写入字节的对象b,最多使用一个对底层原始流的read()(或readinto())方法的调用.返回读取的字节数.如果底层原始流处于非阻塞模式,并且目前没有可用的数据,则会引发BlockingIOError. getbuffer() BytesIO对象可以使用,在缓冲区的内容上返回可读写的视图(memoryview),而不复制它们.另外,视图的突变将会透明地更新缓冲区的内容 from io import StringIO ,BytesIO steam = BytesIO(b\"asdfg\") steam.read() b'asdfg' steam.write(b\"1234\") 4 steam.getvalue() b'asdfg1234' view = steam.getbuffer() view[2:4] = b\"56\" steam.getvalue() b'as56g1234' Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/文本与字节序/序列化.html":{"url":"语法篇/文本与字节序/序列化.html","title":"序列化","keywords":"","body":"序列化 序列化是最常见的字节应用.所谓序列化就是将特定对象转化为一串字节序列,用以存储,作为配置文件或者传输.它的反向操作被称为反序列化. python有丰富的序列化工具如标准库中的base64,json,pickle,又如一些开源的第三方序列化工具如dill,msgpack等. 这些工具虽然都是序列化工具,但设计目的并不相同,本文将会对他们中有代表性的进行介绍 通常作为配置文件,常见的配置文件格式有这么几种: xml 常见于那些历史比较久的,尤其是java写的软件,像hadoop就是拿xml作为配置 json 恐怕是js社区最喜欢的配置形式,每个js项目的package.json都是其配置 ini/conf 也是比较历史悠久的配置形式,常见于C写的项目,python项目中最常见的配置形式 yaml 几乎可以和json划等号的配置形式,似乎是ruby常用的配置形式.很多静态网站项目喜欢使用,github page默认的渲染器jekyll就是用的yaml来做配置的 python中,json在序列化部分已经讲过,xml可以使用标准库xml进行解析.而标准库的ConfigParser模块可以解析.conf或者.ini配置文件..yml则需要使用第三方包pyyaml 而作为传输信息点载体,常见的有: xml Java体系下普遍使用 json 当前最常见的交互载体 messagepack 一种新兴的交互载体,更快更小 base64 通常用于传输字节流 base64用于序列化文件 Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一,常用于传输小文件,网址等.下面是使用base64序列化网址的例子(注意base64编码的参数只能是bytes) import base64 url = b\"http://blog.hszofficial.site\" url_b64 = base64.b64encode(url)#编码base64 url_b64 b'aHR0cDovL2Jsb2cuaHN6b2ZmaWNpYWwuc2l0ZQ==' base64.b64decode(url_b64)#解码base64 b'http://blog.hszofficial.site' 很多时候base64被作为加密算法做简单的加密,当然这有点自欺欺人的意思,所谓的加密也只是让人无法直接读出而已 Base64更常见的使用场景之一就是在http协议中传输小图片.它的效果是将整个图片的信息都序列化到一串字节序中 with open(\"source/mysite.gif\",\"rb\") as f: pic = f.read() pic_64 = base64.b64encode(pic) pic_64[:5] b'R0lGO' isinstance(pic_64,bytes) True len(pic_64) 31092 pic_64.decode()[:5] 'R0lGO' 同学们可以扫描下面的二维码来访问我的主站 from IPython.display import HTML HTML(''.format(value=pic_64.decode())) 显然这种方式传输大文件很不靠谱,但小图片还是可以的 pickle用于持续化python的内置简单对象 有的时候我们想序列化的不光是数据和数据结构,还有对象,这种时候就需要将对象以一定的协议序列化为二进制数据. python的pickle模块是标准库中最常用的序列化模块,它实现了基本的数据序列和反序列化.通过pickle模块的序列化操作我们能够将程序中运行的对象信息保存到文件中去,永久存储;通过pickle模块的反序列化操作,我们能够从文件中创建上一次程序保存的对象. 需要注意,pickel的文件并不是默认跨版本支持的,可以对照这张表设定需要的参数 pickel到目前为止有5种序列化格式: 版本 说明 支持python版本 0 人类可读的文本,用于最早期 全部版本 1 老的二进制版本文本同样用于早期 全部版本 2 出现于2.3版本,用以支持新类 2.3+ 3 出现于3.0版本,用以支持bytes类型 3.0+ 4 出现于Python 3.4.用于扩充pickel的支持类型和大对象 3.4+ python3.5+默认使用的是版本4的pickle格式 要指定使用某一种pickle格式,可以在方法中使用protocol:int=n来指定 pickle的局限性 pickle的兼容性问题一直让人诟病,除了python没有别的语言使用pickle,而如上表所示,pickle在各个版本的python中也不是默认通用的 pickle实际上并不能传递函数或者类,而是只能记录下它的状态信息而已,因此不能跨模块传递,除此之外,一些对象类型也是不可pickle的.例如Python不能 pickle文件对象(或者任何带有对文件对象引用的对象),因为 Python 在 unpickle 时不能保证它可以重建该文件的状态. pickle的接口 pickle的接口与json类似带s为序列化或反序列化为字符串,不带的则是处理文件对象 import pickle exa_l=[1,2,3,4,5] exa_b = pickle.dumps(exa_l) exa_b b'\\x80\\x03]q\\x00(K\\x01K\\x02K\\x03K\\x04K\\x05e.' pickle.loads(exa_b) [1, 2, 3, 4, 5] with open(\"source/pickle_test.txt\",\"wb\") as f: pickle.dump(exa_l,f) with open(\"source/pickle_test.txt\",\"rb\") as f: view_exam = pickle.load(f) view_exam [1, 2, 3, 4, 5] 命令行工具 pickletools 在python3中提供了一个命令行工具来管理pickle文件 !python -m pickle source/pickle_test.txt [1, 2, 3, 4, 5] !python -m pickletools source/pickle_test.txt 0: \\x80 PROTO 3 2: ] EMPTY_LIST 3: q BINPUT 0 5: ( MARK 6: K BININT1 1 8: K BININT1 2 10: K BININT1 3 12: K BININT1 4 14: K BININT1 5 16: e APPENDS (MARK at 5) 17: . STOP highest protocol among opcodes = 2 可用的参数: -a, –annotate 用简短的操作码描述来标注每一行。 -o, –output= 写入输出的文件的名称。 -l, –indentlevel= 用于缩进新的MARK级别的空白数。 -m, –memo 拆卸多个物体时，请在拆卸之间保留备注。 -p, –preamble= 当指定多于一个pickle文件时，在每次分解之前打印给定的前导码 dill用于序列化python对象 dill支持几乎所有的python数据,按github上的说法,它支持: none, type, bool, int, long, float, complex, str, unicode, tuple, list, dict, file, buffer, builtin, both old and new style classes, instances of old and new style classes, set, frozenset, array, functions, exceptions functions with yields, nested functions, lambdas cell, method, unboundmethod, module, code, methodwrapper, dictproxy, methoddescriptor, getsetdescriptor, memberdescriptor, wrapperdescriptor, xrange, slice, notimplemented, ellipsis, quit 还不支持的有: frame(帧),generator(生成器对象,因为包含帧状态),traceback(依然是因为无法保存帧状态) 与pickle不同,dill的序列化可以跨模块传递,事实上dill也是为了分布式计算传递python对象而设计的. dill对python3.5+支持不错,它支持协程,也支持numpy数组,只是序列化的过程中typehint会被消除. dill的设计目标是为分布式系统传输对象提供支持.因此支持的类型最多,但实际使用它的时候由于它序列化后的字节长度往往过大所以可能反而并不适合用于传输,而它的全面细致让它在用于保存时其实更有优势. dill在windows上似乎并不是完全支持.因此跨平台使用时需要谨慎. dill可以直接使用pip安装,使用也相当简单,只要替代pickle就行了,他们接口相同 import dill from asyncio import sleep import asyncio async def asyng(n:int): print(\"n:\"+str(n)+\" wait\") await sleep(1) print(\"n:\"+str(n)+\"done\") with open(\"source/dill_cor.txt\",\"wb\") as f: dill.dump(asyng,f) with open(\"source/dill_cor.txt\",\"rb\") as f: s1 = dill.load(f) loop = asyncio.new_event_loop() loop.run_until_complete(asyncio.wait([s1(1),s1(2),s1(3)])) n:2 wait n:3 wait n:1 wait n:2done n:3done n:1done ({:3> result=None>, :3> result=None>, :3> result=None>}, set()) cloudpickle另一个pickle序列化工具 cloudpickle的开发目的也是一样而且现在已经在pyspark和dask中实用(dask中之前使用的是dill),它相较于dill,cloudpickle更加健壮,从目前来看应该是更加适合用于传输的工具.实际上它只是实现了序列化,而反序列化是交给自带的pickle的,这种设计可以在反序列化一端减少依赖,也让反序列化更加快速. 从指标上来说: cloudpickle 序列化更加快速,比dill快大约10% cloudpickle 反序列化更加快速,比dill块大约85% cloudpickle 序列化出的bytes长度大约比dill长20%(带typehints的情况) cloudpickle 支持typehits 序列化 class A: test:str def __init__(self,text:str)->None: self.text = text import cloudpickle AP = cloudpickle.dumps(A) 反序列化 import pickle AO = pickle.loads(AP) AO.__annotations__ {'test': str} .ini/.conf文件解析 .ini文件形如下面 [DEFAULT] serveraliveinterval = 45 compression = yes compressionlevel = 9 forwardx11 = yes [bitbucket.org] user = hg [topsecret.server.com] port = 50022 forwardx11 = no 可以分为几个部分: Sections 节,每个节代表一项配置系列 Case insensitivity 参数字段,具体要配置的字段对应的值 可以理解成一个两层的字典 写 ConfigParser()用于初始化一个解析器,这个解析器可以像字典一样使用 import configparser config = configparser.ConfigParser() config['DEFAULT'] = {'ServerAliveInterval': '45', 'Compression': 'yes', 'CompressionLevel': '9'} config['bitbucket.org'] = {} config['bitbucket.org']['User'] = 'hg' config['topsecret.server.com'] = {} topsecret = config['topsecret.server.com'] topsecret['Port'] = '50022' # mutates the parser topsecret['ForwardX11'] = 'no' # same here config['DEFAULT']['ForwardX11'] = 'yes' with open('example.ini', 'w') as configfile: config.write(configfile) 读 初始化一个空的解析器后可以通过.read方法来读入一个已有的配置. config = configparser.ConfigParser() config.sections() [] config.read('example.ini') ['example.ini'] 可以通过sections方法获取所有节 config.sections() ['bitbucket.org', 'topsecret.server.com'] 'bitbucket.org' in config True 'bytebong.com' in config False 获取到节后,就可以像操作字典一样操作这个节内的内容了 for k,v in config['bitbucket.org'].items(): print(k,v) user hg serveraliveinterval 45 compression yes compressionlevel 9 forwardx11 yes config['bitbucket.org']['User'] 'hg' config['DEFAULT']['Compression'] 'yes' topsecret = config['topsecret.server.com'] topsecret['ForwardX11'] 'no' topsecret['Port'] '50022' for key in config['bitbucket.org']: print(key) user serveraliveinterval compression compressionlevel forwardx11 xml文件解析 xml即可扩展标记语言,它可以用来标记数据、定义数据类型,是一种允许用户对自己的标记语言进行定义的源语言,简单说它是html的爹.大约长这个样子: 4 Python 测试 Zope 它有如下特征: 它是有标签对组成, 标签可以有属性: 标签对可以嵌入数据: abc 标签可以嵌入子标签(具有层级关系): 和html特点上是差不多的. 对于xml的支持,python提供4种解析方式:DOM,SAX和ElementTree,具体特点归纳如下: 方法 对应模块 实现方式 特点 DOM xml.dom W3C DOM API的实现.将XML数据在内存中解析成一个树,通过对树的操作来操作XML. 高内存占用,但解析成树便于分析 SAX xml.sax SAX API的实现.用事件驱动模型,通过在解析XML的过程中触发一个个的事件并调用用户定义的回调函数来处理XML文件. 低内存占用,局部加载,API不友好 ElementTree xml.etree.ElementTree 一个轻量级的DOM,具有方便友好的API.代码可用性好速度快,消耗内存少 比DOM快,API友好,性能和SAX差不多,也支持文档局部加载 import requests content = requests.get(\"http://www.w3school.com.cn/example/xmle/plant_catalog.xml\").text content[:100] '\\r\\nDOM方法: 在xml.dom模块中我们一般用xml.dom.minidom子模块来解析xml,其中parse用于解析文件,parseString用于解析字符串 from xml.dom.minidom import parse,parseString dom = parseString(content)#解析xml文件,返回一个dom对象 root=dom.documentElement#返回xml生成树的根 root.nodeName#节点名 'CATALOG' root.nodeValue#节点值 root.nodeType#节点类型 1 其中节点类型对应的意义 NodeType Named Constant 1 ELEMENT_NODE 2 ATTRIBUTE_NODE 3 TEXT_NODE 4 CDATA_SECTION_NODE 5 ENTITY_REFERENCE_NODE 6 ENTITY_NODE 7 PROCESSING_INSTRUCTION_NODE 8 COMMENT_NODE 9 DOCUMENT_NODE 10 DOCUMENT_TYPE_NODE 11 DOCUMENT_FRAGMENT_NODE 12 NOTATION_NODE root.hasAttributes() # 判断标签是否有属性 False commoneles=root.getElementsByTagName('COMMON')#获取已知标签名的元素(按顺序返回元素) #item = commoneles[0].getAttribute(\"id\") #获得标签属性值 commonele0 = commoneles[0] commonele0.firstChild.data#获取到第一个子节点的值 'Bloodroot' 再看一个更加简单的例子,我们有一个配置文件plant_catalog.xml用于配置所有植物对应的价格: Bloodroot Sanguinaria canadensis 4 Mostly Shady $2.44 031599 Columbine Aquilegia canadensis 3 Mostly Shady $9.37 030699 Marsh Marigold Caltha palustris 4 Mostly Sunny $6.81 051799 Cowslip Caltha palustris 4 Mostly Shady $9.90 030699 Dutchman's-Breeches Dicentra cucullaria 3 Mostly Shady $6.44 012099 Ginger, Wild Asarum canadense 3 Mostly Shady $9.03 041899 Hepatica Hepatica americana 4 Mostly Shady $4.45 012699 Liverleaf Hepatica americana 4 Mostly Shady $3.99 010299 Jack-In-The-Pulpit Arisaema triphyllum 4 Mostly Shady $3.23 020199 Mayapple Podophyllum peltatum 3 Mostly Shady $2.98 060599 Phlox, Woodland Phlox divaricata 3 Sun or Shade $2.80 012299 Phlox, Blue Phlox divaricata 3 Sun or Shade $5.59 021699 Spring-Beauty Claytonia Virginica 7 Mostly Shady $6.59 020199 Trillium Trillium grandiflorum 5 Sun or Shade $3.90 042999 Wake Robin Trillium grandiflorum 5 Sun or Shade $3.20 022199 Violet, Dog-Tooth Erythronium americanum 4 Shade $9.04 020199 Trout Lily Erythronium americanum 4 Shade $6.94 032499 Adder's-Tongue Erythronium americanum 4 Shade $9.58 041399 Anemone Anemone blanda 6 Mostly Shady $8.86 122698 Grecian Windflower Anemone blanda 6 Mostly Shady $9.16 071099 Bee Balm Monarda didyma 4 Shade $4.59 050399 Bergamot Monarda didyma 4 Shade $7.16 042799 Black-Eyed Susan Rudbeckia hirta Annual Sunny $9.80 061899 Buttercup Ranunculus 4 Shade $2.57 061099 Crowfoot Ranunculus 4 Shade $9.34 040399 Butterfly Weed Asclepias tuberosa Annual Sunny $2.78 063099 Cinquefoil Potentilla Annual Shade $7.06 052599 Primrose Oenothera 3 - 5 Sunny $6.56 013099 Gentian Gentiana 4 Sun or Shade $7.81 051899 Blue Gentian Gentiana 4 Sun or Shade $8.56 050299 Jacob's Ladder Polemonium caeruleum Annual Shade $9.26 022199 Greek Valerian Polemonium caeruleum Annual Shade $4.36 071499 California Poppy Eschscholzia californica Annual Sun $7.89 032799 Shooting Star Dodecatheon Annual Mostly Shady $8.60 051399 Snakeroot Cimicifuga Annual Shade $5.63 071199 Cardinal Flower Lobelia cardinalis 2 Shade $3.02 022299 让我们来解析它 dom = parse(\"plant_catalog.xml\")#解析xml文件,返回一个dom对象 root=dom.documentElement#返回xml生成树的根 plantes = root.getElementsByTagName('PLANT') result = map(lambda x:(x.getElementsByTagName('COMMON')[0].firstChild.data, x.getElementsByTagName('PRICE')[0].firstChild.data),plantes) for i in result: print(i[0],\":\",i[1]) Bloodroot : $2.44 Columbine : $9.37 Marsh Marigold : $6.81 Cowslip : $9.90 Dutchman's-Breeches : $6.44 Ginger, Wild : $9.03 Hepatica : $4.45 Liverleaf : $3.99 Jack-In-The-Pulpit : $3.23 Mayapple : $2.98 Phlox, Woodland : $2.80 Phlox, Blue : $5.59 Spring-Beauty : $6.59 Trillium : $3.90 Wake Robin : $3.20 Violet, Dog-Tooth : $9.04 Trout Lily : $6.94 Adder's-Tongue : $9.58 Anemone : $8.86 Grecian Windflower : $9.16 Bee Balm : $4.59 Bergamot : $7.16 Black-Eyed Susan : $9.80 Buttercup : $2.57 Crowfoot : $9.34 Butterfly Weed : $2.78 Cinquefoil : $7.06 Primrose : $6.56 Gentian : $7.81 Blue Gentian : $8.56 Jacob's Ladder : $9.26 Greek Valerian : $4.36 California Poppy : $7.89 Shooting Star : $8.60 Snakeroot : $5.63 Cardinal Flower : $3.02 SAX方法 SAX方法是事件驱动的,所以第一个就是继承回调类并重载回调函数,这和html.parser类似 ContentHandler类常用方法介绍: characters(content)方法 调用时机: 从行开始,遇到标签之前,存在字符,content的值为这些字符串. 从一个标签,遇到下一个标签之前,存在字符,content的值为这些字符串. 从一个标签,遇到行结束符之前,存在字符,content的值为这些字符串. 标签可以是开始标签,也可以是结束标签. startDocument()方法 文档启动的时候调用. endDocument()方法 解析器到达文档结尾时调用. startElement(name, attrs)方法 遇到XML开始标签时调用,name是标签的名字,attrs是标签的属性值字典. endElement(name)方法 遇到XML结束标签时调用. startElementNS(name, qname, attrs)方法 遇到XML命名空间开始时调用 endElementNS(name, qname)方法 遇到XML命名空间结束时调用 之后只要创建解析器对象就可以像解析html一样解析xml了,我们依然用上面的例子 import xml.sax.handler class PlanteHandler(xml.sax.handler.ContentHandler): def __init__(self): self.CurrentData = \"\" self.type = \"\" self.format = \"\" self.year = \"\" self.rating = \"\" self.stars = \"\" self.description = \"\" # 元素开始事件处理 def startElement(self, tag, attributes): self.CurrentData = tag chidren = { \"PlANTE\":lambda :print(\"*****PlANTE*****\"), \"COMMON\":lambda :print(\"name:\",end=''), \"PRICE\":lambda :print(\"price:\",end='') } chidren.get(self.CurrentData,lambda : None)() # 元素结束事件处理 def endElement(self, tag): self.CurrentData = \"\" # 内容事件处理 def characters(self, content): chidren = { \"COMMON\":lambda:print(content), \"PRICE\":lambda:print(content) } chidren.get(self.CurrentData,lambda :None)() parser = xml.sax.make_parser()#创建解析器对象 Handler = PlanteHandler()#创建回调对象 parser.setContentHandler(Handler)#设置回调对象到解析器对象 parser.parse(\"plant_catalog.xml\") name:Bloodroot price:$2.44 name:Columbine price:$9.37 name:Marsh Marigold price:$6.81 name:Cowslip price:$9.90 name:Dutchman's-Breeches price:$6.44 name:Ginger, Wild price:$9.03 name:Hepatica price:$4.45 name:Liverleaf price:$3.99 name:Jack-In-The-Pulpit price:$3.23 name:Mayapple price:$2.98 name:Phlox, Woodland price:$2.80 name:Phlox, Blue price:$5.59 name:Spring-Beauty price:$6.59 name:Trillium price:$3.90 name:Wake Robin price:$3.20 name:Violet, Dog-Tooth price:$9.04 name:Trout Lily price:$6.94 name:Adder's-Tongue price:$9.58 name:Anemone price:$8.86 name:Grecian Windflower price:$9.16 name:Bee Balm price:$4.59 name:Bergamot price:$7.16 name:Black-Eyed Susan price:$9.80 name:Buttercup price:$2.57 name:Crowfoot price:$9.34 name:Butterfly Weed price:$2.78 name:Cinquefoil price:$7.06 name:Primrose price:$6.56 name:Gentian price:$7.81 name:Blue Gentian price:$8.56 name:Jacob's Ladder price:$9.26 name:Greek Valerian price:$4.36 name:California Poppy price:$7.89 name:Shooting Star price:$8.60 name:Snakeroot price:$5.63 name:Cardinal Flower price:$3.02 ElementTree方法 从总结上来看可以说ElementTree方法是最好的方法,Dom处理大文本的时候会相当吃内存,而SAX无法全面解析文档结构.ElementTree怎两者兼而有之,加上友好的api.这也是我最推荐的方法. 将 XML 解析为树的形式: XML 是一种分级的数据形式,所以最自然的表示方法是将它表示为一棵树.ET有两个对象来实现这个目的 ElementTree 将整个 XML 解析为一棵树 Element 将单个结点解析为树 如果是整个文档级别的操作(比如说读,写,找到一些有趣的元素)通常用ElementTree.单个 XML 元素和它的子元素通常用 Element. xml.etree.ElementTree提供接口parse对文件进行解析,也可以使用类xml.etree.ElementTree.ElementTree通过指定file关键字指定文件进行解析 如果想要解析文本,则可以使用接口fromstring来进行解析 import xml.etree.ElementTree as ET tree = ET.ElementTree(file='plant_catalog.xml') root = tree.getroot() root.tag, root.attrib#标签和属性 ('CATALOG', {}) #查看子节点 for child in root: print(child.tag, child.attrib) PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} PLANT {} root[0].tag, root[0].attrib#进入一个子节点查看 ('PLANT', {}) # 找元素 #以一个节点为根深度优先遍历 for elem in tree.iter(): print(elem.tag, elem.attrib,elem.text) CATALOG {} PLANT {} COMMON {} Bloodroot BOTANICAL {} Sanguinaria canadensis ZONE {} 4 LIGHT {} Mostly Shady PRICE {} $2.44 AVAILABILITY {} 031599 PLANT {} COMMON {} Columbine BOTANICAL {} Aquilegia canadensis ZONE {} 3 LIGHT {} Mostly Shady PRICE {} $9.37 AVAILABILITY {} 030699 PLANT {} COMMON {} Marsh Marigold BOTANICAL {} Caltha palustris ZONE {} 4 LIGHT {} Mostly Sunny PRICE {} $6.81 AVAILABILITY {} 051799 PLANT {} COMMON {} Cowslip BOTANICAL {} Caltha palustris ZONE {} 4 LIGHT {} Mostly Shady PRICE {} $9.90 AVAILABILITY {} 030699 PLANT {} COMMON {} Dutchman's-Breeches BOTANICAL {} Dicentra cucullaria ZONE {} 3 LIGHT {} Mostly Shady PRICE {} $6.44 AVAILABILITY {} 012099 PLANT {} COMMON {} Ginger, Wild BOTANICAL {} Asarum canadense ZONE {} 3 LIGHT {} Mostly Shady PRICE {} $9.03 AVAILABILITY {} 041899 PLANT {} COMMON {} Hepatica BOTANICAL {} Hepatica americana ZONE {} 4 LIGHT {} Mostly Shady PRICE {} $4.45 AVAILABILITY {} 012699 PLANT {} COMMON {} Liverleaf BOTANICAL {} Hepatica americana ZONE {} 4 LIGHT {} Mostly Shady PRICE {} $3.99 AVAILABILITY {} 010299 PLANT {} COMMON {} Jack-In-The-Pulpit BOTANICAL {} Arisaema triphyllum ZONE {} 4 LIGHT {} Mostly Shady PRICE {} $3.23 AVAILABILITY {} 020199 PLANT {} COMMON {} Mayapple BOTANICAL {} Podophyllum peltatum ZONE {} 3 LIGHT {} Mostly Shady PRICE {} $2.98 AVAILABILITY {} 060599 PLANT {} COMMON {} Phlox, Woodland BOTANICAL {} Phlox divaricata ZONE {} 3 LIGHT {} Sun or Shade PRICE {} $2.80 AVAILABILITY {} 012299 PLANT {} COMMON {} Phlox, Blue BOTANICAL {} Phlox divaricata ZONE {} 3 LIGHT {} Sun or Shade PRICE {} $5.59 AVAILABILITY {} 021699 PLANT {} COMMON {} Spring-Beauty BOTANICAL {} Claytonia Virginica ZONE {} 7 LIGHT {} Mostly Shady PRICE {} $6.59 AVAILABILITY {} 020199 PLANT {} COMMON {} Trillium BOTANICAL {} Trillium grandiflorum ZONE {} 5 LIGHT {} Sun or Shade PRICE {} $3.90 AVAILABILITY {} 042999 PLANT {} COMMON {} Wake Robin BOTANICAL {} Trillium grandiflorum ZONE {} 5 LIGHT {} Sun or Shade PRICE {} $3.20 AVAILABILITY {} 022199 PLANT {} COMMON {} Violet, Dog-Tooth BOTANICAL {} Erythronium americanum ZONE {} 4 LIGHT {} Shade PRICE {} $9.04 AVAILABILITY {} 020199 PLANT {} COMMON {} Trout Lily BOTANICAL {} Erythronium americanum ZONE {} 4 LIGHT {} Shade PRICE {} $6.94 AVAILABILITY {} 032499 PLANT {} COMMON {} Adder's-Tongue BOTANICAL {} Erythronium americanum ZONE {} 4 LIGHT {} Shade PRICE {} $9.58 AVAILABILITY {} 041399 PLANT {} COMMON {} Anemone BOTANICAL {} Anemone blanda ZONE {} 6 LIGHT {} Mostly Shady PRICE {} $8.86 AVAILABILITY {} 122698 PLANT {} COMMON {} Grecian Windflower BOTANICAL {} Anemone blanda ZONE {} 6 LIGHT {} Mostly Shady PRICE {} $9.16 AVAILABILITY {} 071099 PLANT {} COMMON {} Bee Balm BOTANICAL {} Monarda didyma ZONE {} 4 LIGHT {} Shade PRICE {} $4.59 AVAILABILITY {} 050399 PLANT {} COMMON {} Bergamot BOTANICAL {} Monarda didyma ZONE {} 4 LIGHT {} Shade PRICE {} $7.16 AVAILABILITY {} 042799 PLANT {} COMMON {} Black-Eyed Susan BOTANICAL {} Rudbeckia hirta ZONE {} Annual LIGHT {} Sunny PRICE {} $9.80 AVAILABILITY {} 061899 PLANT {} COMMON {} Buttercup BOTANICAL {} Ranunculus ZONE {} 4 LIGHT {} Shade PRICE {} $2.57 AVAILABILITY {} 061099 PLANT {} COMMON {} Crowfoot BOTANICAL {} Ranunculus ZONE {} 4 LIGHT {} Shade PRICE {} $9.34 AVAILABILITY {} 040399 PLANT {} COMMON {} Butterfly Weed BOTANICAL {} Asclepias tuberosa ZONE {} Annual LIGHT {} Sunny PRICE {} $2.78 AVAILABILITY {} 063099 PLANT {} COMMON {} Cinquefoil BOTANICAL {} Potentilla ZONE {} Annual LIGHT {} Shade PRICE {} $7.06 AVAILABILITY {} 052599 PLANT {} COMMON {} Primrose BOTANICAL {} Oenothera ZONE {} 3 - 5 LIGHT {} Sunny PRICE {} $6.56 AVAILABILITY {} 013099 PLANT {} COMMON {} Gentian BOTANICAL {} Gentiana ZONE {} 4 LIGHT {} Sun or Shade PRICE {} $7.81 AVAILABILITY {} 051899 PLANT {} COMMON {} Blue Gentian BOTANICAL {} Gentiana ZONE {} 4 LIGHT {} Sun or Shade PRICE {} $8.56 AVAILABILITY {} 050299 PLANT {} COMMON {} Jacob's Ladder BOTANICAL {} Polemonium caeruleum ZONE {} Annual LIGHT {} Shade PRICE {} $9.26 AVAILABILITY {} 022199 PLANT {} COMMON {} Greek Valerian BOTANICAL {} Polemonium caeruleum ZONE {} Annual LIGHT {} Shade PRICE {} $4.36 AVAILABILITY {} 071499 PLANT {} COMMON {} California Poppy BOTANICAL {} Eschscholzia californica ZONE {} Annual LIGHT {} Sun PRICE {} $7.89 AVAILABILITY {} 032799 PLANT {} COMMON {} Shooting Star BOTANICAL {} Dodecatheon ZONE {} Annual LIGHT {} Mostly Shady PRICE {} $8.60 AVAILABILITY {} 051399 PLANT {} COMMON {} Snakeroot BOTANICAL {} Cimicifuga ZONE {} Annual LIGHT {} Shade PRICE {} $5.63 AVAILABILITY {} 071199 PLANT {} COMMON {} Cardinal Flower BOTANICAL {} Lobelia cardinalis ZONE {} 2 LIGHT {} Shade PRICE {} $3.02 AVAILABILITY {} 022299 #以一个节点为根深度优先遍历,查找有没有符合要求的元素 for elem in tree.iter(tag=\"COMMON\"): print(elem.tag, elem.attrib,elem.text) COMMON {} Bloodroot COMMON {} Columbine COMMON {} Marsh Marigold COMMON {} Cowslip COMMON {} Dutchman's-Breeches COMMON {} Ginger, Wild COMMON {} Hepatica COMMON {} Liverleaf COMMON {} Jack-In-The-Pulpit COMMON {} Mayapple COMMON {} Phlox, Woodland COMMON {} Phlox, Blue COMMON {} Spring-Beauty COMMON {} Trillium COMMON {} Wake Robin COMMON {} Violet, Dog-Tooth COMMON {} Trout Lily COMMON {} Adder's-Tongue COMMON {} Anemone COMMON {} Grecian Windflower COMMON {} Bee Balm COMMON {} Bergamot COMMON {} Black-Eyed Susan COMMON {} Buttercup COMMON {} Crowfoot COMMON {} Butterfly Weed COMMON {} Cinquefoil COMMON {} Primrose COMMON {} Gentian COMMON {} Blue Gentian COMMON {} Jacob's Ladder COMMON {} Greek Valerian COMMON {} California Poppy COMMON {} Shooting Star COMMON {} Snakeroot COMMON {} Cardinal Flower 用XPath查找元素 XPath是一门在 XML 文档中查找信息的语言.XPath 可用来在 XML 文档中对元素和属性进行遍历. XPath 是 W3C XSLT 标准的主要元素,对XPath 的理解是很多高级 XML 应用的基础.ElementTree支持XPath语法查找元素. 什么是 XPath? XPath可以说是使用路径表达式在 XML 文档中进行导航的一个标准 支持的路径表达式有: 表达式 描述 tag 选取此节点的所有子节点。 / 从根节点选取。(绝对路径) // 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。(相对路径) . 选取当前节点。 .. 选取当前节点的父节点。 @ 选取属性。 @ xxx=aaa 选取属性值为aaa的属性 * 匹配任意元素节点 @* 匹配任意元素 node() 匹配任意类型节点 [] 筛选 竖条 和 iterfind()方法可以使用XPath来查找需要的元素. 我们来试着打印出所有植物和他的对应价格并为大于5美元的计数 countmony = 0 for elem in zip(tree.iterfind(\"*/COMMON\"),tree.iterfind(\"*/PRICE\")): print(elem[0].tag, elem[0].text) print(elem[1].tag, elem[1].text) if float(elem[1].text[1:]) > 5: countmony += 1 print(countmony) COMMON Bloodroot PRICE $2.44 COMMON Columbine PRICE $9.37 COMMON Marsh Marigold PRICE $6.81 COMMON Cowslip PRICE $9.90 COMMON Dutchman's-Breeches PRICE $6.44 COMMON Ginger, Wild PRICE $9.03 COMMON Hepatica PRICE $4.45 COMMON Liverleaf PRICE $3.99 COMMON Jack-In-The-Pulpit PRICE $3.23 COMMON Mayapple PRICE $2.98 COMMON Phlox, Woodland PRICE $2.80 COMMON Phlox, Blue PRICE $5.59 COMMON Spring-Beauty PRICE $6.59 COMMON Trillium PRICE $3.90 COMMON Wake Robin PRICE $3.20 COMMON Violet, Dog-Tooth PRICE $9.04 COMMON Trout Lily PRICE $6.94 COMMON Adder's-Tongue PRICE $9.58 COMMON Anemone PRICE $8.86 COMMON Grecian Windflower PRICE $9.16 COMMON Bee Balm PRICE $4.59 COMMON Bergamot PRICE $7.16 COMMON Black-Eyed Susan PRICE $9.80 COMMON Buttercup PRICE $2.57 COMMON Crowfoot PRICE $9.34 COMMON Butterfly Weed PRICE $2.78 COMMON Cinquefoil PRICE $7.06 COMMON Primrose PRICE $6.56 COMMON Gentian PRICE $7.81 COMMON Blue Gentian PRICE $8.56 COMMON Jacob's Ladder PRICE $9.26 COMMON Greek Valerian PRICE $4.36 COMMON California Poppy PRICE $7.89 COMMON Shooting Star PRICE $8.60 COMMON Snakeroot PRICE $5.63 COMMON Cardinal Flower PRICE $3.02 23 iterparse(source, events=None, parser=None)处理XML流 我们刚讲过如何使用 ET 来将 XML 读入内存并且处理.但它就不会碰到和 DOM 一样的内存问题么？当然会.这也是为什么这个包提供一个特殊的工具,用来处理大型文档,并且解决了内存问题,这个工具叫 iterparse. 他有4个关键字: start---元素开始 end---元素结束 start-ns---命名空间开始 end-ns---命名空间结束 iterparse每次返回一个(event, elem)对,可以用这些返回和关键字做匹配,调用回调函数达到解析的目的,还是上面的例子 countf = 0 def counter(): def count(): global countf if float(elem.text[1:]) >5: countf += 1 return countf return count mycounter = counter() for event,elem in ET.iterparse('plant_catalog.xml'): keywords={ \"PRICE\":mycounter } events={ \"start\":lambda :False, \"end\":lambda :(keywords.get(elem.tag,lambda :False)()), \"start-ns\":lambda :False, \"end-ns\":lambda :False } events.get(event,lambda :False)() print(countf) 23 建立XML文档 ElementTree 对象提供了 write 方法可以用来建立xml文档,另外俩虽然也可以,但没这个方便. 我们要建立一个xml,需要从元素入手 a = ET.Element(\"elema\")# 创建一个元素 b = ET.Element(\"elemb\") sub1 = ET.Element(\"sub1\") sub2 = ET.Element(\"sub2\") root = ET.Element('root') a.text = \"text\"#为元素创建数据 a.attrib = {\"class\":\"a\"}#创建属性 sub1sub1 = ET.SubElement(sub1,\"sub1sub1\")#创建一个节点的子节点 root.extend((a,b))#扩展节点 b.extend((sub1,sub2)) tree = ET.ElementTree(root) tree.write(\"output.xml\") !cat output.xml text 顺道一提,因为html是xml的子集所以理论上也可以当xml一样解析. xml是一种比较老的格式化文本协议,至今流行于java项目中,常作为配置文件的格式,像hadoop,spark都还是使用的xml来做配置文件的格式. 在早期,xml也作为网络通信或者对象描述序列化时常常使用的文本协议,但是因为过重现在已经基本被json取代.因此我将它放在这里顺带一提.个人认为xml即便是作为配置文件也过于重了,很难想象除了java社区因为思维惯性还用它以为其他人还用它. json用于消息传输 json是当今网络数据传递的标准格式之一,相比较于xml,它更轻量,因此更加便于传输,而且其本身就可以被javascript识别为js对象,更加便于前端处理. python的标准变量类型与js十分相像因此有天然的Json支持,也就是他的json模块了. python标准库中有json模块专门用于序列化和反序列化json 与其他序列化不太一样的地方在于,python中json序列化出来并不是bytes而是字符串.其实json作为一种标准格式其实应该和html,xml这些放在一起类比才对,但这里作为序列化工具主要是因为它可以直接对应python中的list和dict import json d = dict(name='Bob', age=20, score=88) json_str = json.dumps(d) json_str '{\"name\": \"Bob\", \"age\": 20, \"score\": 88}' json.loads(json_str) {'age': 20, 'name': 'Bob', 'score': 88} json模块可以直接处理json格式的文件,使用的接口与处理json格式字符串类似,只是方法名后面没有s with open('source/new.json', 'w') as f: cont = json.dump(d,f) with open('source/new.json', 'r') as f: cont = json.load(f) print(cont) {'name': 'Bob', 'age': 20, 'score': 88} ujson 虽然Python自带这个json序列化工具,但因为它的代码是纯净的python代码,因此比较慢,如果想有更快的序列化和反序列化速度的话,可以使用ujson,这个快很多因为是C写的底层. 他们接口完全相同 import ujson %timeit json.loads(json_str) 2.59 µs ± 52 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit ujson.loads(json_str) 543 ns ± 4.43 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) %timeit json.dumps(d) 2.83 µs ± 13.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit ujson.dumps(d) 530 ns ± 2.89 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 可以看到ujson无论是序列化还是反序列化都比自带的json模块快上一个数量级 .yml文件解析 .yml文件需要使用第三方包pyyaml来解析,据说效率很高. .yml文件形如: name: Silenthand Olleander race: Human traits: [ONE_HAND, ONE_EYE] yml是一种与json等价的格式,很多现代项目的标准配置格式.比如gitpage默认的静态页面生成框架jekyll就是使用这种格式配置项目 写 pyyml可以像json一样直接将字典写成配置文件,甚至可以将pyhton对象写成配置文件 import yaml so = {'name': 'Silenthand Olleander', 'race': 'Human', 'traits': ['ONE_HAND', 'ONE_EYE'] } so {'name': 'Silenthand Olleander', 'race': 'Human', 'traits': ['ONE_HAND', 'ONE_EYE']} print(yaml.dump(so)) name: Silenthand Olleander race: Human traits: [ONE_HAND, ONE_EYE] with open(\"exsample.yml\",'w') as f: f.write(yaml.dump(so)) class Hero: def __init__(self, name, hp, sp): self.name = name self.hp = hp self.sp = sp def __repr__(self): return \"%s(name=%r, hp=%r, sp=%r)\" % (self.__class__.__name__, self.name, self.hp, self.sp) h= Hero(\"Galain Ysseleg\", hp=-3, sp=2) print(yaml.dump(h)) !!python/object:__main__.Hero {hp: -3, name: Galain Ysseleg, sp: 2} 读 with open(\"exsample.yml\") as f: result = yaml.load(f) result {'name': 'Silenthand Olleander', 'race': 'Human', 'traits': ['ONE_HAND', 'ONE_EYE']} msgpack用于更好的传递消息 msgpack是现在最快最小的通用序列化协议,官方的说法是It's like JSON.but fast and small.有测试确实效率非常高. 但其实msgpack和json适用范围并不完全重叠,json作为通用传输协议活跃于web应用,它传递的是字符串,而mspack传递的更多的是bytes,用途也更加底层,常用于分布式服务的消息传递,rpc等 import msgpack 序列化为bytes msgpack可以序列化list和dict pack = msgpack.packb([1, 2, 3]) pack b'\\x93\\x01\\x02\\x03' msgpack.unpackb(pack) [1, 2, 3] msgpack.unpackb(pack,use_list=False)# 指定use_list为False则会返回tuple (1, 2, 3) pack = msgpack.packb(dict(a=1,b=2,c=3)) pack b'\\x83\\xa1a\\x01\\xa1b\\x02\\xa1c\\x03' msgpack.unpackb(pack) {b'a': 1, b'b': 2, b'c': 3} 反序列化为字符串 pack = msgpack.packb([\"你\", \"我\", \"他\"]) pack b'\\x93\\xa3\\xe4\\xbd\\xa0\\xa3\\xe6\\x88\\x91\\xa3\\xe4\\xbb\\x96' msgpack.unpackb(pack) [b'\\xe4\\xbd\\xa0', b'\\xe6\\x88\\x91', b'\\xe4\\xbb\\x96'] msgpack.unpackb(pack,encoding='utf-8') ['你', '我', '他'] 序列化流 unpacker可以反序列化流,它可以从一个流(或从通过其feed方法提供的字节)中分离多个对象. import msgpack from io import BytesIO buf = BytesIO() for i in range(10): buf.write(msgpack.packb(list(range(i)))) buf.seek(0) unpacker = msgpack.Unpacker(buf) for unpacked in unpacker: print(unpacked) [] [0] [0, 1] [0, 1, 2] [0, 1, 2, 3] [0, 1, 2, 3, 4] [0, 1, 2, 3, 4, 5] [0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6, 7] [0, 1, 2, 3, 4, 5, 6, 7, 8] 自定义对象序列化 也可以序列化自定义数据类型.以下是datetime.datetime的示例. 我们可以用default来指定自定义序列化和反序列化的方法. 需要注意的是序列化后的对象字段和值都会被变成bytes,因此需要适当的decode import datetime import msgpack useful_dict = { \"id\": 1, \"created\": datetime.datetime.now(), } def decode_datetime(obj): if b'__datetime__' in obj: obj = datetime.datetime.strptime(obj[b\"as_str\"].decode(), \"%Y%m%dT%H:%M:%S.%f\") return obj def encode_datetime(obj): if isinstance(obj, datetime.datetime): return {b'__datetime__': True, b'as_str': obj.strftime(\"%Y%m%dT%H:%M:%S.%f\")} return obj packed_dict = msgpack.packb(useful_dict, default=encode_datetime) packed_dict b'\\x82\\xa2id\\x01\\xa7created\\x82\\xac__datetime__\\xc3\\xa6as_str\\xb820180607T18:13:21.312504' this_dict_again = msgpack.unpackb(packed_dict, object_hook=decode_datetime) this_dict_again {b'created': datetime.datetime(2018, 6, 7, 18, 13, 21, 312504), b'id': 1} 如上面的自定义方法,序列化是将容器中的对象找出来,一个一个执行自定义的序列化方法,因此需要用isinstance方法来判别出类型来再做特殊处理. 而反序列化则是需要通过指定的字段找出序列化的内容,再执行反序列化 结合dill传递对象 import dill class Vector2D: def __repr__(self): return \"Vector2D\".format(self=self) def __dill__(self): return dill.dumps(self) def __init__(self,a:int,b:int): self.a = a self.b = b def __add__(self,c): a = self.a+c.a b = self.b+c.b return Vector2D(a,b) def encode_v2d(obj): if isinstance(obj, Vector2D): return {b'__Vector2D__': True, b'as_bytes': obj.__dill__()} return obj def decode_v2d(obj): if b'__Vector2D__' in obj: obj = dill.loads(obj[b\"as_bytes\"]) return obj useful_dict = { \"id\": 1, \"created\": Vector2D(1,2), } packed_dict = msgpack.packb(useful_dict, default=encode_v2d) packed_dict b'\\x82\\xa2id\\x01\\xa7created\\x82\\xac__Vector2D__\\xc3\\xa8as_bytes\\xda\\x03\\x87\\x80\\x03cdill.dill\\n_create_type\\nq\\x00(cdill.dill\\n_load_type\\nq\\x01X\\x04\\x00\\x00\\x00typeq\\x02\\x85q\\x03Rq\\x04X\\x08\\x00\\x00\\x00Vector2Dq\\x05h\\x01X\\x06\\x00\\x00\\x00objectq\\x06\\x85q\\x07Rq\\x08\\x85q\\t}q\\n(X\\n\\x00\\x00\\x00__module__q\\x0bX\\x08\\x00\\x00\\x00__main__q\\x0cX\\x08\\x00\\x00\\x00__repr__q\\rcdill.dill\\n_create_function\\nq\\x0e(h\\x01X\\x08\\x00\\x00\\x00CodeTypeq\\x0f\\x85q\\x10Rq\\x11(K\\x01K\\x00K\\x01K\\x03KCC\\x0cd\\x01j\\x00|\\x00d\\x02\\x8d\\x01S\\x00q\\x12NX\\x1b\\x00\\x00\\x00Vector2Dq\\x13X\\x04\\x00\\x00\\x00selfq\\x14\\x85q\\x15\\x87q\\x16X\\x06\\x00\\x00\\x00formatq\\x17\\x85q\\x18h\\x14\\x85q\\x19X \\x00\\x00\\x00q\\x1ah\\rK\\x03C\\x02\\x00\\x01q\\x1b))tq\\x1cRq\\x1dc__builtin__\\n__main__\\nh\\rNN}q\\x1etq\\x1fRq X\\x08\\x00\\x00\\x00__dill__q!h\\x0e(h\\x11(K\\x01K\\x00K\\x01K\\x02KCC\\nt\\x00j\\x01|\\x00\\x83\\x01S\\x00q\"N\\x85q#X\\x04\\x00\\x00\\x00dillq$X\\x05\\x00\\x00\\x00dumpsq%\\x86q&h\\x14\\x85q\\'h\\x1ah!K\\x05C\\x02\\x00\\x01q())tq)Rq*c__builtin__\\n__main__\\nh!NN}q+tq,Rq-X\\x08\\x00\\x00\\x00__init__q.h\\x0e(h\\x11(K\\x03K\\x00K\\x03K\\x02KCC\\x10|\\x01|\\x00_\\x00|\\x02|\\x00_\\x01d\\x00S\\x00q/N\\x85q0X\\x01\\x00\\x00\\x00aq1X\\x01\\x00\\x00\\x00bq2\\x86q3h\\x14h1h2\\x87q4h\\x1ah.K\\x07C\\x04\\x00\\x01\\x06\\x01q5))tq6Rq7c__builtin__\\n__main__\\nh.NN}q8tq9Rq:X\\x07\\x00\\x00\\x00__add__q;h\\x0e(h\\x11(K\\x02K\\x00K\\x04K\\x03KCC\"|\\x00j\\x00|\\x01j\\x00\\x17\\x00}\\x02|\\x00j\\x01|\\x01j\\x01\\x17\\x00}\\x03t\\x02|\\x02|\\x03\\x83\\x02S\\x00q(h\\x14X\\x01\\x00\\x00\\x00cq?h1h2tq@h\\x1ah;K\\nC\\x06\\x00\\x01\\x0c\\x01\\x0c\\x01qA))tqBRqCc__builtin__\\n__main__\\nh;NN}qDtqERqFX\\x07\\x00\\x00\\x00__doc__qGNX\\r\\x00\\x00\\x00__slotnames__qH]qIutqJRqK)\\x81qL}qM(h1K\\x01h2K\\x02ub.' this_dict_again = msgpack.unpackb(packed_dict, object_hook=decode_v2d) this_dict_again {b'created': Vector2D, b'id': 1} v1 = this_dict_again[b\"created\"] v2 = Vector2D(2,2) v1+v2 Vector2D Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/文本与字节序/结语.html":{"url":"语法篇/文本与字节序/结语.html","title":"结语","keywords":"","body":"结语 编码 关于编码实际上除了文本文件,几乎所有数据都要有格式有编码.MP3,jpg都是编码方式, 也就是按照统一蓝本描绘内容的数据.正因为有了编码我们才能区别数据的类型.数据才能被人类所使用. python 在内存中如何表示字符串 Python 官方文档对字符串的码位在内存中如何存储避而不谈.毕竟,这是实现细节.理论上,怎么存储都没关系：不 管内部表述如何,输出时每个字符串都要编码成字节序列. 在内存中,Python3使用固定数量的字节存储字符串的各个码位,以便高效访问各个字符或切片. 在Python 3.3 之前,编译CPython 时可以配置在内存中使用16 位或32 位存储各个码位. 16 位是\"窄构建\"（narrow build） 32 位是\"宽构建\"（wide build）. 如果想知道用的是哪个,要查看sys.maxunicode 的值--65535 表示\"窄构建\",不能透明地处理U+FFFF以上的码位. \"宽构建\"没有这个限制,但是消耗的内存更多：每个字符占4个字节,就算是中文象形文字的码位大多数也只占2 个字节. 这两种构建没有高下之分,应该根据自己的需求选择. 从Python 3.3 起,创建str对象时,解释器会检查里面的字符,然后为该字符串选择最经济的内存布局： 如果字符都在latin1 字符集中,那就使用1 个字节存储每个码位 否则,根据字符串中的具体字符,选择2 个或4 个字节存储每个码位. 这是简述,完整细节参阅\"PEP 393—Flexible String Representation\". 灵活的字符串表述类似于Python 3 对int 类型的处理方式：如果一个整数在一个机器 字中放得下,那就存储在一个机器字中；否则解释器切换成变长表述,类似于Python 2 中的long 类型.这种聪明的做法得到推广,真是让人欢喜! 流 流是一种抽象概念,它代表了数据的无结构化传递.按照流的方式进行输入输出,数据被当成无结构的字节序或字符序列. 从流中取得数据的操作称为提取操作,而向流中添加数据的操作称为插入操作.用来进行输入输出操作的流就称为IO流. 换句话说,IO流就是以流的方式进行输入输出. 现如今很多工具都是基于流的,比如我们在网络上看的视频听的歌,都是使用流技术实现的.而基于流的计算工具也非常中要,比如strom,比如spark 序列化 本文介绍的序列化工具除了pickle基本都是类似json这种可以自我表示的类型.而工业上在分布式系统中使用更多的可能还是类似pickle这样需要 有文件标识结构化数据的序列化方案(pickle可以看作是使用python代码标识结构化数据).当然了pickle无法跨语言不具备通用性. 这类工具的代表是Protobuf和Thrift.他们都有python接口. 本文之所以不做介绍主要是因为其无法自治,并不符合python的特点,这种方式强调转换后字节数要短,以便更快的传输.但因为其无法自治,调试会很不方便, 也会为版本管理带来额外的复杂度. 相关扩展和模块 xpinyin 一个将中文转换为拼音的工具. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/流程控制/":{"url":"语法篇/流程控制/","title":"流程控制","keywords":"","body":"流程控制 现今的神经科学表明人类的思维是跳跃的,分布式的,并行的,而计算机只能按步一步一步的顺序执行. 如何让计算机理解我们人类设计的计算流程就是本部分探讨的课题.python提供了许多工具可以描述我们想要的计算工具. 但他们各自有各自的特性,有各自的适用场景. 单线程同步流程控制 阻塞异步与协程 多线程与GIL 多进程 并行编程的惯用法 并发模型 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/流程控制/单线程同步流程控制.html":{"url":"语法篇/流程控制/单线程同步流程控制.html","title":"单线程同步流程控制","keywords":"","body":"单线程同步流程控制 python与多数其他语言一样默认是单线程同步的顺序执行语句.这也是所有语言的基础. python中语句会一行一行地被解释执行,而流控制语句则是用于控制当前解释执行哪条语句的工具 流程分支 python只有if语句没有switch,这也带来了语义上的歧义: if/else代表判断逻辑,一般用于根据一条语句的结果正误来确定下一步的执行内容 if/elif/else代表分支,一般用于根据一个变量的取值不同来确定下一步执行的内容. 虽然这种方式看似减少了关键字数量,但实际上增加了错误语义的使用可能.个人认为是python设计的一大败笔. 使用字典结合匿名函数更加优雅的实现简单流程分支 if/elif来实现switch并取优雅,需要为一个变量写多次判断语句,因此如果分支逻辑简单,完全可以使用字典+lambda函数 def which_type(x): return { int:lambda x:print(x,\"is int\"), float:lambda x:print(x,\"is float\"), list:lambda x:print(x,\"is list\") }.get(type(x),lambda x:print(\"i dont know\"))(x) which_type(2) 2 is int 循环语句 循环语句主要目的就是让一段代码反复顺序执行,python有两种循环语句: for循环 主要用于根据先验循环次数执行循环内代码的情况.他会遍历一个迭代器,先验的次数就是这个迭代器的长度,每取出一个对象都会执行for块中的语句 while循环 主要用于没有先验循环次数,而是根据判断条件执行循环内代码的情况 for i in range(10): print(i) 0 1 2 3 4 5 6 7 8 9 i = 0 while i 0 1 2 3 4 5 6 7 8 9 打断语句break和continue 循环中可以使用break跳出循环或者使用continue跳出当次循环 i = 0 while True: i += 1 if i > 10 : break if i % 2 == 0 : continue print(i) 1 3 5 7 9 try/except 不仅用于处理错误，还常用于控制流程 在Python中,try/except不仅用于处理错误,还常用于控制流程.为此，Python 官方词汇表还定义了一个缩略词(口号): EAFP 取得原谅比获得许可容易(easier to ask for forgiveness than permission).这是一种常见的Python编程风格,先假定存在有效的键或属性,如果假定不成立,那么捕获异常.这种风格简单明快,特点是代码中有很多try和except语句.与其他很多语言一样(如C 语言),这种风格的对立面是LBYL风格. LBYL 三思而后行(look before you leap).这种编程风格在调用函数或查找属性或键之前显式测试前提条件.与EAFP风格相反,这种风格的特点是代码中有很多if 语句.在多线程环境中,LBYL 风格可能会在\"检查\"和\"行事\"的空当引入条件竞争.例如对if key in mapping: return mapping[key]这段代码来说,如果在测试之后,但在查找之前,另一个线程从映射中删除了那个键,那么这段代码就会失败.这个问题可以使用锁或者EAFP风格解决. 如果选择使用EAFP风格,那就要更深入地了解else子句,并在try/except语句中合理使用 特殊的else语句 else子句不仅能在if语句中使用,还能在for、while和try语句中使用.for/else、while/else和try/else的语义关系紧密,不过与if/else差别很大. 此处的else语句理解为then可能更加合适,它代表的是\"没有遇到特殊情况就执行以下代码\"这样的语义.具体到不同的语句,语义如下: for 仅当for循环运行完毕时)即for循环没有被break语句终止)才运行else块 while 仅当while循环因为条件为假值而退出时(即while循环没有被break语句中止)才运行else块 循环语句中使用else语句可以省去大量的状态变量,最典型的就是为避免网络异常而多次访问某个地址的场景 import requests conn = requests.get(\"http://www.baidu.com\") def get_html(url): for i in range(3): try: conn = requests.get(url) except: print(f\"第{i+1}次连不上服务器\") else: return conn.text else: raise ConnectionError(\"连不上服务器\") get_html(\"http://www.baidu.com\") '\\r\\n ç\\x99¾åº¦ä¸\\x80ä¸\\x8bï¼\\x8cä½\\xa0å°±ç\\x9f¥é\\x81\\x93 æ\\x96°é\\x97» hao123 å\\x9c°å\\x9b¾ è§\\x86é¢\\x91 è´´å\\x90§ ç\\x99»å½\\x95 document.write(\\'ç\\x99»å½\\x95\\'); æ\\x9b´å¤\\x9aäº§å\\x93\\x81 å\\x85³äº\\x8eç\\x99¾åº¦ About Baidu &copy;2017&nbsp;Baidu&nbsp;ä½¿ç\\x94¨ç\\x99¾åº¦å\\x89\\x8då¿\\x85è¯»&nbsp; æ\\x84\\x8fè§\\x81å\\x8f\\x8dé¦\\x88&nbsp;äº¬ICPè¯\\x81030173å\\x8f·&nbsp; \\r\\n' get_html(\"http://www.bidss.ecom\") 第1次连不上服务器 第2次连不上服务器 第3次连不上服务器 --------------------------------------------------------------------------- ConnectionError Traceback (most recent call last) in () ----> 1 get_html(\"http://www.bidss.ecom\") in get_html(url) 8 return conn.text 9 else: ---> 10 raise ConnectionError(\"连不上服务器\") 11 ConnectionError: 连不上服务器 try 仅当try块中没有异常抛出时才运行else块。官方文档还指出--else子句抛出的异常不会由前面的except子句处理. 在所有情况下，如果异常或者return,break或continue语句导致控制权跳到了复合语句的主块之外,else子句也会被跳过 EAFP风格的python代码 上面说道EAFP风格,需要注意的是这种风格下try/else语句应当被大量有针对性地使用,它应当细粒度的防守单条语句而不是像多数人那样防守一段代码.这会让代码看起来很啰嗦,但相对来说更加安全 上下文管理器和with块 上下文管理器对象存在的目的是管理with语句,就像迭代器的存在是为了管理for语句一样. with语句的目的是简化try/finally模式.这种模式用于保证一段代码运行完毕后执行某项操作,即便那段代码由于异常、return语句或sys.exit()调用而中止,也会执行指定的操作.finally子句中的代码通常用于释放重要的资源,或者还原临时变更的状态. 上下文管理器协议包含__enter__和__exit__两个方法.with语句开始运行时,会在上下文管理器对象上调用__enter__方法.with语句运行结束后,会在上下文管理器对象上调用__exit__ 方法,以此扮演finally子句的角色. 最常见的例子是确保关闭文件对象.这在前文已经有所描述.注意,与函数和模块不同，with块没有定义新的作用域. __enter__() 方法 __enter__()方法要求最好返回一个对象(如果不返回一个对象,as语句会捕获一个None),一般是self,但不一定.除了返回上下文管理器之外,还可能返回其他对象. __exit__(exc_type, exc_value, traceback)方法 exc_type 异常类(例如ZeroDivisionError) exc_value 异常实例.有时会有参数传给异常构造方法,例如错误消息,这些参数可以使用exc_value.args获取 traceback traceback对象 不管控制流程以哪种方式退出with块,都会在上下文管理器对象上调用__exit__方法,而不是在__enter__方法返回的对象上调用.with语句的as子句是可选的.对open函数来说,必须加上as子句,以便获取文件的引用.不过,有些上下文管理器会返回None,因为没什么有用的对象能提供给用户. 下面看一个上下文管理器修改上下文环境中print函数行为的例子: import sys class LookingGlass: def __enter__(self): self.original_write = sys.stdout.write sys.stdout.write = self.reverse_write return 'JABBERWOCKY' def reverse_write(self, text): self.original_write(text[::-1]) def __exit__(self, exc_type, exc_value, traceback): sys.stdout.write = self.original_write if exc_type is ZeroDivisionError: print('Please DO NOT divide by zero!') return True with LookingGlass() as what: print('Alice, Kitty and Snowdrop') print(what) pordwonS dna yttiK ,ecilA YKCOWREBBAJ what 'JABBERWOCKY' print('Back to normal.') Back to normal. 抛开了with语句,上下文管理器也可以这样使用 manager = LookingGlass() monster = manager.__enter__() print(monster == 'JABBERWOCKY') print(monster) manager.__exit__(None, None, None) print(monster) eurT YKCOWREBBAJ JABBERWOCKY 使用try/finally可以这样写 manager = LookingGlass() try: monster = manager.__enter__() print(monster == 'JABBERWOCKY') print(monster) except: pass finally: manager.__exit__(None, None, None) print(monster) eurT YKCOWREBBAJ JABBERWOCKY contextlib模块 contextlib模块中提供了一些类和其他函数,用于快速的构建上下文管理器 closing 如果对象提供了close()方法,但没有实现__enter__/__exit__协议,那么可以使用这个函数构建上下文管理器 suppress 构建临时忽略指定异常的上下文管理器 @contextmanager 这个装饰器把简单的生成器函数变成上下文管理器,这样就不用创建类去实现管理器协议了 ContextDecorator 这是个基类,用于定义基于类的上下文管理器.这种上下文管理器也能用于装饰函数,在受管理的上下文中运行整个函数. ExitStack 这个上下文管理器能进入多个上下文管理器.with块结束时,ExitStack按照后进先出的顺序调用栈中各个上下文管理器的__exit__方法.如果事先不知道with块要进入多少个上下文管理器,可以使用这个类.例如同时打开任意一个文件列表中的所有文件. 使用@contextmanager @contextmanager装饰器能减少创建上下文管理器的样板代码量,因为不用编写一个完整的类,定义__enter__和__exit__方法,而只需实现有一个yield语句的生成器,生成想让__enter__方法返回的值. 在使用@contextmanager装饰的生成器中,yield语句的作用是把函数的定义体分成三部分: yield 语句前面的所有代码在with块开始时(即解释器调用__enter__方法时)执行 yield 语句,用于抛出__enter__要返回的对象,并可以接收异常 yield 语句后面的代码在with块结束时(即调用__exit__方法时)执行 import contextlib @contextlib.contextmanager def looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write yield 'JABBERWOCKY' sys.stdout.write = original_write with looking_glass() as what: print(what) print(\"12345\") print(what) print(\"12345\") YKCOWREBBAJ 54321 JABBERWOCKY 12345 其实,contextlib.contextmanager装饰器会把函数包装成实现__enter__和__exit__方法的类. 这个类的__enter__方法有如下作用: 调用生成器函数,保存生成器对象(这里把它称为gen) 调用next(gen),执行到yield关键字所在的位置. 返回next(gen)产出的值,以便把产出的值绑定到with/as语句中的目标变量上 with块终止时,__exit__方法会做以下几件事 检查有没有把异常传给exc_type;如果有,调用gen.throw(exception),在生成器函数定义体中包含yield关键字的那一行抛出异常. 否则调用next(gen),继续执行生成器函数定义体中yield语句之后的代码 如果在with块中抛出了异常,Python解释器会将其捕获,然后在looking_glass函数的yield表达式里再次抛出.但是那里没有处理错误的代码,因此looking_glass函数会中止,永远无法恢复成原来的sys.stdout.write方法,导致系统处于无效状态.因此上面的例子并不完整,下面给出完整的例子 @contextlib.contextmanager def looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write try: yield 'JABBERWOCKY' except Exception as e: msg = 'a error!' finally: sys.stdout.write = original_write if msg: print(msg) with looking_glass() as what: print(what) print(\"12345\") raise AssertionError(\"123\") print(what) print(\"12345\") YKCOWREBBAJ 54321 a error! JABBERWOCKY 12345 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/流程控制/阻塞异步与协程.html":{"url":"语法篇/流程控制/阻塞异步与协程.html","title":"阻塞异步与协程","keywords":"","body":"从顺序执行到并行执行 前几天去外地参加朋友婚礼,作为一个外地人我是不认路的,但我被安排了去接其他客人,于是我不得不依赖导航.我需要打开导航,听着它的指挥开车. 这就是一个典型的并行执行的过程,我要同时开车,并且同时监听着手机上的导航的指挥. 人们往往是同时做几件,比如边看电视边吃饭,边听音乐边工作,边打电话边开车(千万不要这么做).并且很多时候我们不得不同时做几件事,而一件事是另一件事的依赖. 人可以并行的执行任务(事实上人脑就是并行处理事件的)但电脑'不行',单核电脑比较耿直只会按固定好的顺序执行任务.前文也已经介绍过了如何组织单线程过程. 但好在电脑的运转速度远比人的反应速度快,因此我们可以耍点小花招让多个任务看起来是一起执行的. 拿之前看导航开车的例子来说,实际上我开车这个事件可以看作一个循环,每个循环中我有两个动作 我的耳朵在监听着手机(使用声音的音色语调等特征识别),当它有指示的时候我会按照指示执行 没有指示就根据路况开一段 当然了这个事件看起来作为并发的例子更加合适,但道理是一样的. 阻塞与非阻塞 阻塞和非阻塞关注的是程序在等待调用结果(消息,返回值)时的状态. 阻塞调用是指调用结果返回之前，当前线程会被挂起.调用线程只有在得到结果之后才会返回. 非阻塞调用指在不能立刻得到结果之前,该调用不会阻塞当前线程. 如果开车的时候我监听导航是阻塞的,那就意味着我的关注点转移到了导航上,必须要有它的指导我才会有动作,这么开车早就出事故了. 推广到我们的程序,也就是说我们的流程需要可以被保存状态,将线程的控制权转移到其他流程中.同时也要可以下次再被转移回来接着上次的继续运行. 同步与异步 同步与异步同步和异步关注的是消息通信机制(synchronous communication/ asynchronous communication). 所谓同步，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由*调用者*主动等待这个*调用*的结果。 而异步则是相反，*调用*在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。 开车的时候导航就是异步的,当打开导航后就会有个反馈--地图上我们的位置会被标记出来.而实际的导航信息都是由导航自己语音通知我们的. 有了上面的概念,我们就可以来看看python中官方的单线程并行解决方案了 协程及其语法 协程是一种单线程通过调度器或者事件循环从而实现的并行的解决方案.它是由用户控制的\"并行\",因此只要代码一样(没有使用random)协程的运行顺序就是一样的.实际上完全可以等价的用回调函数实现. 协程是实现高并发的方案中开销最小的方案.在io密集型任务中往往是最高效的方案.python3.5以后协程语法已经基本定型. python的协程模型可以分为如下几个部分: coroutine 协程对象:协程对象,指一个使用async关键字定义的函数,它的调用不会立即执行函数,而是会返回一个协程对象.协程对象需要注册到事件循环,由事件循环调用. 调度器/事件循环(event_loop):用于调度协程运行的顺序,调度器用于调度协程而事件循环则是一种特殊的调度器--程序开启一个无限的循环,程序员会把一些函数注册到事件循环上.当满足事件发生的时候,调用相应的协程函数. 协程语法可以说是函数的一个超集,它的特征是使用async def来定义,并且可以在其内部使用await关键字等待另一个协程完成.协程对象的抽象基类为collections.abc.Coroutine,实现send(value),throw(type, exc, tb),close()和__await__()接口. 可以看出协程与生成器接口相似,就是多了个__await__()少了迭代器相关的__next__()和__iter__()事实上,在3.7版本之前,协程都是使用生成器来实现的. 协程对象内部需要实现Awaitable协议,也就是要实现__await__接口,这个接口必须返回一个迭代器,带有这一接口的对象我们称之为Future-like对象,有它的就可以被程序用await关键字挂起等待,Future-like类的抽象基类为collections.abc.Awaitable await语法 await就是用来挂起等待任务结束的关键字它只能在协程中使用. 有效用法: 表达式 被解析为 if await fut: pass if (await fut): pass if await fut + 1: pass if (await fut) + 1: pass pair = await fut, 'spam' pair = (await fut), 'spam' with await fut, open(): pass with (await fut), open(): pass await foo()['spam'].baz()() await ( foo()['spam'].baz()() ) return await coro() return ( await coro() ) res = await coro() ** 2 res = (await coro()) ** 2 func(a1=await coro(), a2=0) func(a1=(await coro()), a2=0) await foo() + await bar() (await foo()) + (await bar()) -await foo() -(await foo()) 无效用法： 表达式 应该写为 await await coro() await (await coro()) await -coro() await (-coro()) 一般来说await会挂起直到它下面的一串Future-like对象都运行结束才会继续向下. 异步迭代器和async for 异步迭代器可以在它的iter实现里挂起、调用异步代码,也可以在它的__next__方法里挂起、调用异步代码.要支持异步迭代,需要: 对象必须实现一个__aiter__接口,返回一个异步迭代器对象,这个异步迭代器对象在每次迭代时会返回一个Future-like对象 一个异步迭代器必须实现一个__anext__方法,在每次迭代时返回一个Future-like对象 要停止迭代，__anext__必须抛出一个StopAsyncIteration异常。 python的buildin方法中有aiter()和anext()可以直接调用异步迭代器的对应接口实现. 例子: import asyncio class Ticker: \"\"\"Yield numbers from 0 to `to` every `delay` seconds.\"\"\" def __init__(self, delay, to): self.delay = delay self.i = 0 self.to = to def __aiter__(self): return self async def __anext__(self): i = self.i if i >= self.to: raise StopAsyncIteration self.i += 1 if i: await asyncio.sleep(self.delay) return i async def main(): async for i in Ticker(1,5): print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) 0 1 2 3 4 异步列表解析(3.6) 列表解析中可以使用await来等待Future-like对象的结果,如: result = [await fun() for fun in funcs if await condition()] 在列表中允许使用async for来做迭代,它的形式如下: [i async for i in Ticker(1,5) if i % 2] import asyncio class Ticker: \"\"\"Yield numbers from 0 to `to` every `delay` seconds.\"\"\" def __init__(self, delay, to): self.delay = delay self.i = 0 self.to = to def __aiter__(self): return self async def __anext__(self): i = self.i if i >= self.to: raise StopAsyncIteration self.i += 1 if i: await asyncio.sleep(self.delay) return i async def main(): result = [i async for i in Ticker(1,5) if i % 2] print(result) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) [1, 3] 异步迭代器工具 github上有一个异步迭代器工具aitertools,它的主要作用就是转换同步迭代器和对一步迭代器进行组合,主要的接口有: aiter(iter) 将一个同步的可迭代对象转化为异步可迭代对象 alist(aiter) 将一个异步可迭代对象转化为list atuple(aiter) 将一个异步可迭代对象转化为tuple count(start=0, step=1) 生成一个从start开始每次步进step的异步计数器 cycle(aiter) 将一个异步可迭代对象转化为一个以他为基础的循环 (obj, times=None) 将一个对象转化为一个以他为基础的重复异步可迭代对象 accumulate(iterable, func=operator.add) 对一个异步可迭代对象进行卷积 chain(*iterables) 将几个可迭代对象串联 compress(data, selectors)并行处理两个可迭代的对象;如果selectors中的元素是真值,产出data中对应的元素 dropwhile(predicate, iterable)处理iterable,跳过predicate的计算结果为真值的元素,然后产出剩下的各个元素(不再进一步检查) filterfalse(predicate, iterable)与filter函数的作用类似,不过predicate的逻辑是相反的--predicate返回假值时产出对应的元素 groupby(iterable, key=None)产出由两个元素组成的元素,形式为(key,group)其中key是分组标准,group是生成器,用于产出分组里的元素 islice(iterable, *args)产出it的切片,作用类似于s[:stop]或s[start:stop:step],不过it可以是任何可迭代的对象,而且这个函数实现的是惰性操作 starmap(func, iterable)把it中的各个元素传给func,产出结果;输入的可迭代对象应该产出可迭代的元素iit,然后以func(*iit)这种形式调用func takewhile(predicate, iterable)predicate返回真值时产出对应的元素,然后立即停止,不再继续检查 tee(iterable, n=2)产出一个由n个生成器组成的元组,每个生成器用于单独产出输入的可迭代对象中的元素 zip_longest(*iterables, fillvalue=None)并行从输入的各个可迭代对象中获取元素,产出由N个元素组成的元组,等到最长的可迭代对象到头后才停止,空缺的值使用fillvalue填充 product(*iterables, repeat=1)把前两个元素传给func,然后把计算结果和第三个元素传给func,以此类推,返回最后的结果;如果提供了initial,把它当作第一个元素传入 异步上下文管理器和async with 异步上下文管理器类似普通的上下文管理器,可以让程序在进入上下文和离开上下文之间挂起状态,调用异步代码. 异步上下文管理器需要实现两个接口 __aenter__处理进入上下文时的操作,如果有返回值,则可以使用as标定上下文中的变量名 __aexit__处理离开上下文时的操作,和__exit__的参数一样,它的参数必须是self,exc_type, exc, tb,分别代表对象自身对象,exception_type , exception_value , 和 traceback,如果正常退出,exc_type, exc, tb将会是 None. __aenter__和__aexit__,它们必须返回一个Future-like对象 和普通的with语句一样,可以在单个async with语句里指定多个上下文管理器. 异步上下文管理器的一个示例: import asyncio class Ticker: \"\"\"Yield numbers from 0 to `to` every `delay` seconds.\"\"\" def __init__(self, delay, to): self.delay = delay self.i = 0 self.to = to def __aiter__(self): return self async def __anext__(self): i = self.i if i >= self.to: raise StopAsyncIteration self.i += 1 if i: await asyncio.sleep(self.delay) return i class AsyncContextTicker: def __init__(self,delay, to): self.data = Ticker(delay, to) async def __aenter__(self): print('entering context') await asyncio.sleep(1) return self.data async def __aexit__(self, exc_type, exc, tb): await asyncio.sleep(1) print('exit context') async def main(): async with AsyncContextTicker(1,5) as ticker: async for i in ticker: print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) entering context 0 1 2 3 4 exit context 异步生成器[3.6] 带yield关键字的函数是生成器,带yield关键字的协程就是异步生成器,从效果上看异步生成器效果和异步迭代器效果差不多,它需要实现协议: PyAsyncGenASend : __anext__和asend()接口 ,对应一般生成器中的__next__和send(),用于在异步生成器间交互信息 PyAsyncGenAThrow : athrow() and aclose()接口,对应一般生成器的throw()和close(),用于关闭异步生成器或者抛出错误 StopAsyncIteration用于标注结束 import asyncio async def ticker(delay, to): \"\"\"Yield numbers from 0 to *to* every *delay* seconds.\"\"\" for i in range(0,to): yield i await asyncio.sleep(delay) async def main(): async for i in ticker(1,5): print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) 0 1 2 3 4 关于yield from 因为异步步生成器本质上是异步迭代器的子类,我们可以利用这一点使用async for语句代替yield from的语义. import asyncio async def g1(x): for i in range(x): yield i async def g2(): async for v in g1(5): yield v async def main(): async for i in g2(): print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) 0 1 2 3 4 协程的状态 协程可以有4种状态,可以是用python的反射模块inspect.getcoroutinestate(coroutine)来查看 CORO_CREATED: 等待被使用 CORO_RUNNING: 目前执行中 CORO_SUSPENDED: 目前在await处暂停等待信号中 CORO_CLOSED: 执行结束 实用例子 协程有三种不同的代码编写风格: 拉取式 典型的异步生成器和异步迭代器使用场景 推送式 通过将数据推送给协程让协程一步一步的计算返回数据 任务式 根据状态来排定运行顺序 推送式 我们用一个计算移动平均值的异步生成器来看看协程是如何工作的. async def averager(): total = 0.0 count = 0 average = None while True: term = yield average total += term count += 1 average = total/count async def grouper(): aver = averager() await aver.__anext__() for i in range(11): j = await aver.asend(i) print(j) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(grouper()) 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 任务式 一个简单的离散事件仿真类--出租车队运营仿真 import random from collections import namedtuple import queue import argparse import time Event = namedtuple('Event',[ 'time', 'proc', 'action'])#定义事件 DEFAULT_NUMBER_OF_TAXIS = 3#出租车数量 DEFAULT_END_TIME = 180#运行时间默认180 SEARCH_DURATION = 5 #找乘客时间默认为5 TRIP_DURATION = 20 #载客时间默认为20 DEPARTURE_INTERVAL = 5#出库间隔默认5 async def taxi_process(ident, trips, start_time=0): \"\"\"每次改变状态时创建事件，把控制权让给仿真器\"\"\" # 定义一个异步生成器,用于描述process time = yield Event(start_time, ident, 'leave garage') for i in range(trips): time = yield Event(time, ident, 'pick up passenger') time = yield Event(time, ident, 'drop off passenger') yield Event(time, ident, 'going home') def compute_duration(previous_action): \"\"\"Compute action duration using exponential distribution\"\"\" if previous_action in ['leave garage', 'drop off passenger']: # new state is prowling interval = SEARCH_DURATION elif previous_action == 'pick up passenger': # new state is trip interval = TRIP_DURATION elif previous_action == 'going home': interval = 1 else: raise ValueError('Unknown previous_action: %s' % previous_action) return int(random.expovariate(1/interval)) + 1 class Simulator: def __init__(self, procs_map): self.events = queue.PriorityQueue() self.procs = dict(procs_map) async def run(self, end_time): \"\"\"排定并显示事件，直到时间结束\"\"\" for _, proc in sorted(self.procs.items()): first_event = await proc.__anext__() self.events.put(first_event) sim_time = 0 while sim_time taxis = {i: taxi_process(i, (i + 1) * 2, i * DEPARTURE_INTERVAL) for i in range(DEFAULT_NUMBER_OF_TAXIS)} sim = Simulator(taxis) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(sim.run(DEFAULT_END_TIME)) taxi: 0 Event(time=0, proc=0, action='leave garage') taxi: 1 Event(time=5, proc=1, action='leave garage') taxi: 1 Event(time=6, proc=1, action='pick up passenger') taxi: 0 Event(time=8, proc=0, action='pick up passenger') taxi: 2 Event(time=10, proc=2, action='leave garage') taxi: 2 Event(time=15, proc=2, action='pick up passenger') taxi: 0 Event(time=17, proc=0, action='drop off passenger') taxi: 1 Event(time=17, proc=1, action='drop off passenger') taxi: 2 Event(time=17, proc=2, action='drop off passenger') taxi: 1 Event(time=18, proc=1, action='pick up passenger') taxi: 2 Event(time=18, proc=2, action='pick up passenger') taxi: 2 Event(time=20, proc=2, action='drop off passenger') taxi: 2 Event(time=21, proc=2, action='pick up passenger') taxi: 2 Event(time=25, proc=2, action='drop off passenger') taxi: 2 Event(time=26, proc=2, action='pick up passenger') taxi: 2 Event(time=27, proc=2, action='drop off passenger') taxi: 2 Event(time=28, proc=2, action='pick up passenger') taxi: 0 Event(time=31, proc=0, action='pick up passenger') taxi: 1 Event(time=38, proc=1, action='drop off passenger') taxi: 1 Event(time=41, proc=1, action='pick up passenger') taxi: 0 Event(time=59, proc=0, action='drop off passenger') taxi: 2 Event(time=60, proc=2, action='drop off passenger') taxi: 2 Event(time=63, proc=2, action='pick up passenger') taxi: 0 Event(time=67, proc=0, action='going home') taxi: 1 Event(time=92, proc=1, action='drop off passenger') taxi: 1 Event(time=98, proc=1, action='pick up passenger') taxi: 1 Event(time=99, proc=1, action='drop off passenger') taxi: 1 Event(time=101, proc=1, action='going home') taxi: 2 Event(time=105, proc=2, action='drop off passenger') taxi: 2 Event(time=107, proc=2, action='going home') *** end of events *** 事件循环 事件循环是一个无限的的循环,用来监控触发事件.一般我们用loop = asyncio.new_event_loop()来创建一个事件循环的实例,然后将其使用asyncio.set_event_loop(loop)来将循环实例定义为当前的事件循环.如果程序并不需要考虑使用多个循环的话我们也可以直接使用asyncio.get_event_loop()来获取当前事件循环的实例 事实上python原生的事件循环并不高效,uvloop是一个高效的事件循环,它使用cython编写,并使用libuv,就是node.js用的那个高性能事件驱动的程序库.我们在生产环境可以使用它来运行协程.(windows下无法使用) python的协程运转需要显式的指定循环.asyncio则提供了如'中央处理设备'一般的功能，它支持如下操作： 产生,设置和管理事件循环 异步时间管理 将回调函数注册到事件循环 管理协程的执行,包括取消,延迟,调用等 将耗时函数调用委托给一个线程池 协程错误处理 创建可用于多种类型的通信的服务端和客户端的Transports 启动进程以及相关的和外部通信程序的Transports 后两个操作在网络部分再讨论,本篇只讨论前面的功能 产生,设置和管理事件循环 上面已经介绍了如何产生事件循环,以下是关于设置管理事件循环的接口,这些接口的实例为loop: run_forever() 运行直到stop()被调用.如果在调用run_forever()之前调用stop()，则以超时为0轮询I/O选择器一次,运行所有响应I/O事件(以及已经安排的回调)的回调，然后退出。 如果在运行run_forever()时调用stop(),则会运行当前批次的回调,然后退出.请注意,在这种情况下,回调计划的回调将不会运行;他们会在下一次run_forever()被调用时运行. run_until_complete(future) 跑到期物完成.如果参数是一个coroutine对象，那么它被wrap_future()包装起来成为一个期物.返回期物的结果，或者抛出异常. is_running() 返回时间循环的状态 stop() 停止事件循环 is_closed() 如果事件循环被关闭，则返回True。 close() 关闭事件循环.循环不能再次运行,待处理的回调将丢失.这将清除队列并关闭执行程序且不等待执行程序完成.这一过程不可逆转,要再次使用必须重新创建一个时间循环并设置为当前事件循环 coroutine shutdown_asyncgens()[3.6] 安排所有当前打开的异步生成器对象,以aclose()调用.调用此方法后,事件循环将在每次迭代新的异步生成器时发出警告.应该用于可靠地完成所有调度的异步生成器. 异步时间管理 asyncio.sleep(nbr) 这是一个异步的延迟工具,必须在协程中使用await调用 loop.time() 根据事件循环的内部时钟，将当前时间作为浮点值返回,返回的是时间戳 from datetime import datetime import time from asyncio import sleep async def now(): print(datetime.now()) await sleep(1) print(datetime.now()) await sleep(1) print(asyncio.get_event_loop().time()) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(now()) print(loop.time()) loop.close() 2018-06-07 22:34:07.134776 2018-06-07 22:34:08.137805 243914.380729733 243914.380907182 将回调函数注册到事件循环 它的工作机制类似于先进先出队列,所以如果一些回调需要一段时间来处理任务,其它的回调就会相应的延迟,直到先前的回调结束 回调函数处理的接口同样是loop,他们有: call_soon(callback, *args) 基本的回调注册,行为如前面介绍类似先进先出队列 call_later(delay, callback, *args) 在一定延迟后执行回调 call_at(when, callback, *args) 使用int或者float代表时间戳,在该时间执行回调函数 import asyncio def hello_world(loop): print('Hello World') loop.stop() loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) # Schedule a call to hello_world() loop.call_soon(hello_world, loop) loop.call_soon(hello_world, loop) loop.call_soon(hello_world, loop) loop.call_soon(hello_world, loop) # Blocking call interrupted by loop.stop() loop.run_forever() loop.close() Hello World Hello World Hello World Hello World call_soon_threadsafe(callback, *args) call_soon(callback, *args)的线程安全版本 很多时候,我们的事件循环用于注册协程,而有的协程需要动态的添加到事件循环中.一个简单的方式就是使用多线程.当前线程创建一个事件循环,然后在新建一个线程,在新线程中启动事件循环.当前线程不会被block. from threading import Thread import time now = lambda: time.time() def start_loop(loop): asyncio.set_event_loop(loop) loop.run_forever() def more_work(x): print('More work {}'.format(x)) time.sleep(x) print('Finished more work {}'.format(x)) start = now() new_loop = asyncio.new_event_loop() t = Thread(target=start_loop, args=(new_loop,)) t.start() print('TIME: {}'.format(time.time() - start)) new_loop.call_soon_threadsafe(more_work, 6) new_loop.call_soon_threadsafe(more_work, 3) TIME: 0.0028290748596191406 More work 6 :8> 启动上述代码之后,当前线程不会被block,新线程中会按照顺序执行call_soon_threadsafe方法注册的more_work方法,后者因为time.sleep操作是同步阻塞的,因此运行完毕more_work需要大致6 + 3 期物 asyncio模块的将协程注册到时间需要先将其包装为期物,也就是Future或者Task. Task类用来管理协同程序运行的状态,是Future的子类,Future的接口如下: cancel() 取消期物对象并安排回调.如果期物对象已经完成或取消,返回False.否则,将期物对象的状态更改为取消,调度回调并返回True. cancelled() 如果期物对象被取消,返回True done() 如果期物对象完成,返回True.完成意味着结果/异常可用,或者期物对象被取消 result() 返回期物对象代表的结果.如果期物对象取消,则会引发CancelledError.如果期物对象的结果尚不可用,则会引发InvalidStateError.如果期物对象已经完成并且设置了异常,则会引发异常. exception() 返回在期物对象设置的异常.异常(如果没有设置异常,则为None)仅在期物对象完成时才会返回.如果期物对象取消,则会引发CancelledError.如果期物对象尚未完成,则会引发InvalidStateError. add_done_callback(fn) 添加一个回调,以便在期物对象完成时运行.使用单个参数(未来对象)调用回调.如果在调用此函数时已经完成了未来,则使用call_soon()调度回调. 通常需要结合functools.partial使用 fut.add_done_callback(functools.partial(print, \"Future:\", flush=True)) 会在回调时执行 print(\"Future:\", fut, flush=True) remove_done_callback(fn) 从'完成调用'列表中删除回调的所有实例.返回删除的回调数. set_result(result) 标记期物对象的状态为done并设定其结果.如果在调用此方法时期物对象已经完成,则引发InvalidStateError set_exception(exception) 标记期物对象的状态为done并设定一个异常.如果在调用此方法时期物对象已经完成,则引发InvalidStateError Task作为Future的子类,额外的方法有: classmethod all_tasks(loop=None) 返回一组事件循环的所有任务对象.默认情况下,返回当前事件循环的所有任务. classmethod current_task(loop=None) 返回事件循环正在执行的任务对象,默认为当前的事件循环.在任务的上下文中调用时返回None. cancel() 请求此任务自行取消.这将安排一个CancelledError通过事件循环在下一个循环中被引入到包装的协同程序中,然后,协调程序有机会使用try / except / finally清理甚至拒绝该请求.与Future.cancel()不同,这不保证任务将被取消. 异常可能会被捕获并被执行,延迟取消任务或者完全阻止取消.该任务也可能返回值或引发不同的异常.在调用此方法之后,cancelled()将不会返回True(除非该任务已被取消).当包装的协同程序以CancelledError异常终止(即使未调用cancel()时,任务将被标记为已取消. get_stack(*, limit=None) 返回此任务的协程的堆栈帧列表 print_stack(*, limit=None, file=None) 打印此任务的协程的堆栈或追溯.对于由get_stack()检索到的帧,它会产生与追溯模块类似的输出.limit参数传递给get_stack().文件参数是写入输出的I/O流;默认情况下,输出将写入sys.stderr. 创建期物 创建期物必须使用事件循环loop,接口为: create_future() 创建一个期物 create_task(coro) 使用一个协程创建一个任务 set_task_factory(factory) 设置一个由AbstractEventLoop.create_task()使用的工厂函数. 如果工厂为无，则将设置默认任务工厂 如果工厂是可调用的,它应该有一个签名匹配(loop,coro),其中循环将是对活动事件循环的引用,coro将是一个协程对象.工厂函数必须返回一个asyncio.Future兼容的对象。 get_task_factory() 尝试任务工厂,如果默认工作正在使用,则为\"无\" 管理协程的执行,包括取消,延迟,调用等 事件循环实际上上面只能注册期物,而asyncio的很多接口可以直接使用协程,其原因是这些接口会自动将协程包装为期物task. loop.run_until_complete()是最简单的将协程注册进事件循环中并运行的方法. import asyncio import datetime async def display_date(loop): end_time = loop.time() + 5.0 while True: print(datetime.datetime.now()) if (loop.time() + 1.0) >= end_time: break await asyncio.sleep(1) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) # Blocking call which returns when the display_date() coroutine is done loop.run_until_complete(display_date(loop)) loop.close() 2018-06-07 22:34:13.015772 2018-06-07 22:34:14.020046 2018-06-07 22:34:15.025442 2018-06-07 22:34:16.026280 Finished more work 6 More work 3 2018-06-07 22:34:17.027029 asyncio.run_coroutine_threadsafe(coro, loop) 线程安全的执行协程,可以看做是loop.run_until_complete()的线程安全版本. def start_loop(loop): asyncio.set_event_loop(loop) loop.run_forever() async def do_some_work(x): print('Waiting {}'.format(x)) await asyncio.sleep(x) print('Done after {}s'.format(x)) def more_work(x): print('More work {}'.format(x)) time.sleep(x) print('Finished more work {}'.format(x)) start = now() new_loop = asyncio.new_event_loop() t = Thread(target=start_loop, args=(new_loop,)) t.start() print('TIME: {}'.format(time.time() - start)) asyncio.run_coroutine_threadsafe(do_some_work(6), new_loop) asyncio.run_coroutine_threadsafe(do_some_work(4), new_loop) TIME: 0.0012660026550292969 Waiting 6 Waiting 4 Finished more work 3 上述的例子,主线程中创建一个new_loop,然后在另外的子线程中开启一个无限事件循环.主线程通过run_coroutine_threadsafe新注册协程对象.这样就能在子线程中进行事件循环的并发操作,同时主线程又不会被block.一共执行的时间大概在6s左右. ensure_future是asyncio封装好的创建Task的函数,它还支持一些参数,甚至指定loop. 可以使用asyncio.gather(*coros_or_futures, loop=None, return_exceptions=False)¶合并多个协程为一个期物 import asyncio async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) await asyncio.sleep(1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(asyncio.gather( factorial(\"A\", 2), factorial(\"B\", 3), factorial(\"C\", 4) )) loop.close() Task B: Compute factorial(2)... Task A: Compute factorial(2)... Task C: Compute factorial(2)... Task B: Compute factorial(3)... Task A: factorial(2) = 2 Task C: Compute factorial(3)... Task B: factorial(3) = 6 Task C: Compute factorial(4)... Task C: factorial(4) = 24 coroutine asyncio.wait(futures, *, loop=None, timeout=None, return_when=ALL_COMPLETED) wait和gather的返回值不一样,wait也可以在第一个future完全或者出错时就返回. import asyncio async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) await asyncio.sleep(1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(asyncio.wait([ factorial(\"A\", 2), factorial(\"B\", 3), factorial(\"C\", 4)] )) loop.close() Task B: Compute factorial(2)... Task C: Compute factorial(2)... Task A: Compute factorial(2)... Task B: Compute factorial(3)... Task C: Compute factorial(3)... Task A: factorial(2) = 2 Task B: factorial(3) = 6 Task C: Compute factorial(4)... Task C: factorial(4) = 24 asyncio.as_completed(fs, *, loop=None, timeout=None)用于返回一个迭代器，其值等待是Future实例. import asyncio import datetime async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) await asyncio.sleep(1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) return f async def main(): for f in asyncio.as_completed([factorial(\"A\", 2),factorial(\"B\", 3),factorial(\"C\", 4)]): result = await f loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) # Blocking call which returns when the display_date() coroutine is done loop.run_until_complete(main()) loop.close() Task A: Compute factorial(2)... Task B: Compute factorial(2)... Task C: Compute factorial(2)... Task A: factorial(2) = 2 Task B: Compute factorial(3)... Task C: Compute factorial(3)... Task B: factorial(3) = 6 Task C: Compute factorial(4)... Task C: factorial(4) = 24 将耗时函数调用委托给一个线程池/进程池执行器 coroutine run_in_executor(executor, func, *args) 安排在指定的执行器中调用func. 执行器参数应该是Executor实例.如果执行程序为无,则使用默认执行程序. 通常我们用functools.partial来处理要执行的函数 set_default_executor(executor) 设置run_in_executor()使用的默认执行程序。 所谓执行器executor是指concurrent.futures模块下的ThreadPoolExecutor或者ProcessPoolExecutor的实例,在目前python标准api几乎只支持同步方法的情况下,ThreadPoolExecutor可以作为临时方案使用解io密集型问题,而对于计算密集型任务,更加适合使用ProcessPoolExecutor. import asyncio import time async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) loop = asyncio.get_event_loop() await loop.run_in_executor(None,time.sleep,1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(asyncio.wait([ factorial(\"A\", 2), factorial(\"B\", 3), factorial(\"C\", 4)] )) loop.close() Task A: Compute factorial(2)... Task B: Compute factorial(2)... Task C: Compute factorial(2)... Task A: factorial(2) = 2 Task B: Compute factorial(3)... Task C: Compute factorial(3)... Task B: factorial(3) = 6 Task C: Compute factorial(4)... Task C: factorial(4) = 24 协程错误处理 set_exception_handler(handler) 将处理程序设置为新的事件循环异常处理程序.如果处理程序为None,则将设置默认的异常处理程序.如果处理程序是可调用对象,它应该具有匹配的签名(循环,上下文),其中循环将是对活动事件循环的引用,上下文将是一个dict对象(有关上下文的详细信息,请参阅call_exception_handler()文档) get_exception_handler() 返回异常处理程序,如果使用默认处理程序,则返回None. default_exception_handler(context) 默认异常处理程序.当异常发生时调用,并且没有设置异常处理程序,并且可以由想要推迟到默认行为的自定义异常处理程序调用.context参数与call_exception_handler()中的含义相同. call_exception_handler(context) 调用当前的事件循环异常处理程序.上下文是一个包含以下键的dict对象(新键可以稍后介绍): ‘message’: Error message; ‘exception’ (optional): Exception object; ‘future’ (optional): asyncio.Future instance; ‘handle’ (optional): asyncio.Handle instance; ‘protocol’ (optional): Protocol instance; ‘transport’ (optional): Transport instance; ‘socket’ (optional): socket.socket instance. 例子: 生产者消费者模型 以下是一个生产者消费者模式的例子 import asyncio import random async def produce(queue, n): for x in range(1, n + 1): # produce an item print('producing {}/{}'.format(x, n)) # simulate i/o operation using sleep await asyncio.sleep(random.random()) item = str(x) # put the item in the queue await queue.put(item) # indicate the producer is done await queue.put(None) async def consume(queue): while True: # wait for an item from the producer item = await queue.get() if item is None: # the producer emits None to indicate that it is done break # process the item print('consuming item {}...'.format(item)) # simulate i/o operation using sleep await asyncio.sleep(random.random()) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) queue = asyncio.Queue(loop=loop) producer_coro = produce(queue, 10) consumer_coro = consume(queue) loop.run_until_complete(asyncio.gather(producer_coro, consumer_coro)) loop.close() producing 1/10 producing 2/10 consuming item 1... producing 3/10 consuming item 2... producing 4/10 consuming item 3... producing 5/10 producing 6/10 consuming item 4... producing 7/10 consuming item 5... producing 8/10 consuming item 6... consuming item 7... producing 9/10 consuming item 8... producing 10/10 consuming item 9... consuming item 10... Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/流程控制/多线程与GIL.html":{"url":"语法篇/流程控制/多线程与GIL.html","title":"多线程与GIL","keywords":"","body":"多线程与GIL GIL CPython解释器本身就不是线程安全的,因此有全局解释器锁(GIL),一次只允许使用一个线程执行 Python 字节码.因此一个 Python 进程通常不能同时使用多个 CPU 核心。 编写 Python 代码时无法控制 GIL;不过,执行耗时的任务时,可以使用一个内置的函数或一个使用 C 语言编写的扩展释放GIL.其实有个使用 C 语言编写的 Python库能管理GIL,自行启动操作系统线程,利用全部可用的 CPU 核心.这样做会极大地增加库代码的复杂度,因此大多数库的作者都不这么做. 然而,标准库中所有执行阻塞型I/O操作的函数,在等待操作系统返回结果时都会释放GIL.这意味着在 Python 语言这个层次上可以使用多线程处理io阻塞问题,而 I/O 密集型 Python 程序能从中受益--一个 Python 线程等待网络响应时,阻塞型 I/O 函数会释放 GIL,再运行一个线程. 为什么需要GIL GIL是必须的,这是Python设计的问题--Python解释器是非线程安全的.这意味着当从线程内尝试安全的访问Python对象的时候将有一个全局的强制锁.在任何时候,仅仅一个单一的线程能够获取Python对象或者C API.每100个字节的Python指令解释器将重新获取锁,这(潜在的)阻塞了I/O操作.因此CPU密集型的代码使用线程库时,不会获得性能的提高. 使用concurrent.futures进行高层抽象的多线程操作 concurrent.futures提供两种编程模型: 并行任务模型 单独任务独立使用自己的过程和数据,多任务独立并行计算 MapReduce模型 为各个线程分发数据执行相同的过程 并行任务模型 这个模型使用submit提交任务到上下文管理器,之后使用返回对象的result()方法阻塞io等待任务完成 from concurrent.futures import ThreadPoolExecutor,as_completed from random import randrange from time import time def arcfour(key, in_bytes, loops=20): \"\"\"rc4算法\"\"\" kbox = bytearray(256) # create key box for i, car in enumerate(key): # copy key and vector kbox[i] = car j = len(key) for i in range(j, 256): # repeat until full kbox[i] = kbox[i-j] # [1] initialize sbox sbox = bytearray(range(256)) # repeat sbox mixing loop, as recommened in CipherSaber-2 # http://ciphersaber.gurus.com/faq.html#cs2 j = 0 for k in range(loops): for i in range(256): j = (j + sbox[i] + kbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # main loop i = 0 j = 0 out_bytes = bytearray() for car in in_bytes: i = (i + 1) % 256 # [2] shuffle sbox j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # [3] compute t t = (sbox[i] + sbox[j]) % 256 k = sbox[t] car = car ^ k out_bytes.append(car) return out_bytes clear = bytearray(b'1234567890' * 100000) t0 = time() cipher = arcfour(b'key', clear) print('elapsed time: %.2fs' % (time() - t0)) result = arcfour(b'key', cipher) assert result == clear, '%r != %r' % (result, clear) print('elapsed time: %.2fs' % (time() - t0)) print('OK') elapsed time: 0.47s elapsed time: 0.95s OK def crypto_process(size, key): in_text = bytearray(randrange(256) for i in range(size)) cypher_text = arcfour(key, in_text) out_text = arcfour(key, cypher_text) assert in_text == out_text, 'Failed arcfour_test' return size def main(workers=None): JOBS = 12 SIZE = 2**18 KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\" STATUS = '{} workers, elapsed time: {:.2f}s' if workers: workers = int(workers) t0 = time() with ThreadPoolExecutor(workers) as executor: actual_workers = executor._max_workers to_do = [] for i in range(JOBS, 0, -1): size = SIZE + int(SIZE / JOBS * (i - JOBS/2)) job = executor.submit(crypto_process, size, KEY) to_do.append(job) for future in as_completed(to_do): res = future.result() print('{:.1f} KB'.format(res/2**10)) print(STATUS.format(actual_workers, time() - t0)) main(1) 384.0 KB 362.7 KB 341.3 KB 320.0 KB 298.7 KB 277.3 KB 256.0 KB 234.7 KB 213.3 KB 192.0 KB 170.7 KB 149.3 KB 1 workers, elapsed time: 5.74s main(2) 362.7 KB 384.0 KB 320.0 KB 341.3 KB 298.7 KB 277.3 KB 234.7 KB 256.0 KB 192.0 KB 213.3 KB 170.7 KB 149.3 KB 2 workers, elapsed time: 5.90s main(4) 341.3 KB 320.0 KB 362.7 KB 384.0 KB 234.7 KB 277.3 KB 256.0 KB 298.7 KB 170.7 KB 149.3 KB 192.0 KB 213.3 KB 4 workers, elapsed time: 6.13s MapReduce模型 这种模式可能更加被大家熟悉,同一个流程,将容器中的数据一条一脚放入子进程运算,最终也结果也会被放入容器中.最后可以将收集来的数据在主进程中进行处理 import math PRIMES = [ 112272535095293, 112582705942171, 112272535095293, 115280095190773, 115797848077099, 1099726899285419] def is_prime(n): if n % 2 == 0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n + 1, 2): if n % i == 0: return False return True [is_prime(i) for i in PRIMES] [True, True, True, True, True, False] def ProcessPool_prime(PRIMES= PRIMES ,workers=4): with ThreadPoolExecutor(max_workers=workers) as executor: total = [] for prime in executor.map(is_prime, PRIMES): #print('%d is prime: %s' % (number, prime)) total.append(prime) return total ProcessPool_prime() [True, True, True, True, True, False] 使用线程池进行相对底层的多进程操作 线程池的方式很适合批量创建子线程.线程池模块藏在多进程模块multiprocessing.pool下,ThreadPool 对ThreadPool对象调用join()方法会等待所有子进程执行完毕,调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了. 请注意输出的结果,task 0,1,2,3是立刻执行的,而task 4要等待前面某个task完成后才执行,这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程.这是Pool有意设计的限制,并不是操作系统的限制.如果改成p = Pool(5)就可以同时跑5个进程. 由于Pool的默认大小是CPU的核数,如果你不幸拥有8核CPU,你要提交至少9个子进程才能看到上面的等待效果. 除了使用apply_async方法外,还有apply,map和map_async可以用于线程池的计算,编程模型也是如concurrent.futures一样分为两类 并行任务模型 apply 单一任务布置 apply_async 非阻塞单一任务布置 MapReduce模型 map 同系统的map方法 map_async 非阻塞的map apply_async from multiprocessing.pool import ThreadPool as Pool import os, time, random def long_time_task(name): print('运行任务 %s (%s)...' % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print('任务 %s 执行了 %0.2f 秒.' % (name, (end - start))) print('父线程 %s.' % os.getpid()) p = Pool(4) for i in range(5): p.apply_async(long_time_task, args=(i,))#创建非阻塞子线程用这个 print('等待所有子线程完成...') p.close() p.join() print('所有子线程完成了.') 父线程 36193. 等待所有子线程完成... 运行任务 0 (36193)...运行任务 1 (36193)...运行任务 2 (36193)...运行任务 3 (36193)... 任务 0 执行了 1.00 秒. 运行任务 4 (36193)... 任务 3 执行了 1.13 秒. 任务 2 执行了 2.02 秒. 任务 1 执行了 2.81 秒. 任务 4 执行了 1.93 秒. 所有子线程完成了. map_async from multiprocessing.pool import ThreadPool as Pool from time import sleep def f(x): return x*x # start 4 worker processes pool = Pool(processes=4) print(\"map: \",pool.map(f, range(10))) print(\"imap:\") for i in pool.imap_unordered(f, range(10)): print(i) # evaluate \"f(10)\" asynchronously res = pool.apply_async(f, [10]) print(\"apply:\",res.get(timeout=1)) # prints \"100\" # make worker sleep for 10 secs res = pool.apply_async(sleep, [10]) print(res.get(timeout=1)) # raises multiprocessing.TimeoutError map: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] imap: 0 1 4 9 16 25 36 49 64 81 apply: 100 --------------------------------------------------------------------------- TimeoutError Traceback (most recent call last) in () 18 # make worker sleep for 10 secs 19 res = pool.apply_async(sleep, [10]) ---> 20 print(res.get(timeout=1)) # raises multiprocessing.TimeoutError ~/anaconda3/lib/python3.6/multiprocessing/pool.py in get(self, timeout) 638 self.wait(timeout) 639 if not self.ready(): --> 640 raise TimeoutError 641 if self._success: 642 return self._value TimeoutError: 获取进程池中的运算结果 from multiprocessing.pool import ThreadPool as Pool import time def func(msg): print(\"msg:\", msg) time.sleep(1) print(\"end\") return \"done \" + msg pool = Pool(processes=4) result = [] for i in range(3): msg = \"hello %d\" %(i) result.append(pool.apply_async(func, (msg, ))) pool.close() pool.join() for res in result: print(\":::\", res.get()) print(\"Sub-process(es) done.\") msg: hello 0 msg: hello 1 msg: hello 2 end end end ::: done hello 0 ::: done hello 1 ::: done hello 2 Sub-process(es) done. 更底层的多线程编程 threading模块提供了一个高层的API来提供线程的并发性.这些线程并发运行并共享内存.多线程看着多么美好的,但因为数据安全的问题被加了锁.所以永远是单核运行,不细说了看个简单的用法吧 下面来看threading模块的具体用法: import threading import time def worker(i): print(i) time.sleep(1) print(\"AWAKE\") for i in range(5): t = threading.Thread(target=worker,args=(i,)) t.start() print(\"closed\") 01 2 3 4closed AWAKEAWAKE AWAKEAWAKEAWAKE 对比下不用多线程: def worker(i): print(i) import time time.sleep(1) print(\"AWAKE\") for i in range(5): worker(i) 0 AWAKE 1 AWAKE 2 AWAKE 3 AWAKE 4 AWAKE 一个相对复杂的例子 from threading import Thread import os #子线程要执行的代码 def run_proc(name): for i in range(3): print(u'子线程 %s (%s)...' % (name, os.getpid())) print(u'子线程结束.') print(u'父线程 {}.'.format(os.getpid())) p = Thread(target=run_proc, args=('test',)) print(u'子线程要开始啦.') p.start() for i in range(3): print(u'父线程{pid}进行中...'.format(pid = os.getpid())) p.join() print(u\"父线程结束啦\") 父线程 36193. 子线程要开始啦. 子线程 test (36193)... 子线程 test (36193)...父线程36193进行中... 父线程36193进行中... 父线程36193进行中... 子线程 test (36193)... 子线程结束. 父线程结束啦 使用Thread作为父类自定义子线程 Thread的子类需要重写run方法 from threading import Thread from queue import Queue class Processor(Thread): def __init__(self, queue, idx): super(Processor, self).__init__() self.queue = queue self.idx = idx def return_name(self): ## NOTE: self.name is an attribute of multiprocessing.Process return \"Thread idx=%s is called '%s'\" % (self.idx, self.name) def run(self): self.queue.put(self.return_name()) processes = list() q = Queue() for i in range(0,5): p=Processor(queue=q, idx=i) processes.append(p) p.start() for proc in processes: proc.join() ## NOTE: You cannot depend on the results to queue / dequeue in the ## same order print(\"RESULT: {}\".format(q.get())) RESULT: Thread idx=0 is called 'Thread-31' RESULT: Thread idx=1 is called 'Thread-32' RESULT: Thread idx=2 is called 'Thread-33' RESULT: Thread idx=3 is called 'Thread-34' RESULT: Thread idx=4 is called 'Thread-35' 创建子线程时,只需要传入一个执行函数和函数的参数,创建一个Thread实例,用start()方法启动,这样创建进程比fork()简单. join()方法可以等待子线程结束后再继续往下运行,通常用于线程间的同步. 可以看到我们的父线程进行完了子线程才进行.其实当执行start方法的时候我们就已经把线程创建好并给他任务了.虽然线程启动了,但我们并不能知道它啥时候运算完成.这时候用join方法来确认是否执行完了(通过阻塞主线程),也就是起个等待结果的作用. 使用队列管理线程 线程安全是多线程编程中最不容易的事儿,线程间同步,互斥数据共享一直是要考虑的问题,而最常见的就是用队列实现管理线程了. 生产者消费者模型 队列最常见的用处就是在生产者消费者模式中作为数据缓冲区.以下就是一个生产者消费者模式的例子 import queue as Queue import threading import random class Producer(threading.Thread): \"\"\"生产者\"\"\" def __init__(self,q,con,name): super(Producer,self).__init__() self.q = q self.name = name self.con = con print(\"生产者{self.name}产生了\".format(self=self)) def run(self): count = 3 #只生产满3轮,要不然就会无限循环出不去了 while count>0: #global writelock self.con.acquire() if self.q.full(): print(\"队列满了,生产者等待\") count-=1 self.con.wait() else: value = random.randint(0,10) print(\"{self.name}把值{self.name}:{value}放入了队列\".format(self=self,value=value)) self.q.put(\"{self.name}:{value}\".format(self=self,value=value)) self.con.notify() self.con.release() class Consumer(threading.Thread): \"\"\"消费者\"\"\" def __init__(self,q,con,name): super(Consumer,self).__init__() self.q = q self.name = name self.con = con print(\"消费者{self.name}产生了\".format(self=self)) def run(self): while True: #global writelock self.con.acquire() if self.q.empty(): print(\"队列空了,消费者等待\") self.con.wait() else: value = self.q.get() print(\"{self.name}从队列中获取了{self.name}:{value}\".format(self=self, value=value)) self.con.notify() self.con.release() q = Queue.Queue(10) con = threading.Condition() p1 = Producer(q,con,\"P1\") p1.start() p2 = Producer(q,con,\"P2\") p2.start() c1 = Consumer(q,con,\"C1\") c1.start() 生产者P1产生了 P1把值P1:10放入了队列生产者P2产生了 P1把值P1:10放入了队列 P1把值P1:2放入了队列 P1把值P1:10放入了队列 P1把值P1:1放入了队列 消费者C1产生了 P1把值P1:6放入了队列 P1把值P1:9放入了队列 P1把值P1:3放入了队列 P1把值P1:4放入了队列 P1把值P1:4放入了队列 队列满了,生产者等待 队列满了,生产者等待 C1从队列中获取了C1:P1:10 C1从队列中获取了C1:P1:10 C1从队列中获取了C1:P1:2 C1从队列中获取了C1:P1:10 C1从队列中获取了C1:P1:1 C1从队列中获取了C1:P1:6 C1从队列中获取了C1:P1:9 C1从队列中获取了C1:P1:3 C1从队列中获取了C1:P1:4 C1从队列中获取了C1:P1:4 队列空了,消费者等待 P1把值P1:7放入了队列 P1把值P1:8放入了队列 P1把值P1:9放入了队列 P1把值P1:10放入了队列 P1把值P1:1放入了队列 P1把值P1:7放入了队列 P1把值P1:9放入了队列 P1把值P1:10放入了队列 P1把值P1:4放入了队列 P1把值P1:1放入了队列 队列满了,生产者等待 队列满了,生产者等待 C1从队列中获取了C1:P1:7 C1从队列中获取了C1:P1:8 C1从队列中获取了C1:P1:9 C1从队列中获取了C1:P1:10 C1从队列中获取了C1:P1:1 P2把值P2:10放入了队列 P2把值P2:1放入了队列 P2把值P2:10放入了队列 P2把值P2:1放入了队列 P2把值P2:4放入了队列 队列满了,生产者等待 队列满了,生产者等待 C1从队列中获取了C1:P1:7 C1从队列中获取了C1:P1:9 C1从队列中获取了C1:P1:10 queue模块说明 队列类型 queue.Queue(maxsize)先进先出队列,maxsize是队列长度,其值为非正数时是无限循环队列 queue.LifoQueue(maxsize) 后进先出队列,也就是栈 queue.PriorityQueue(maxsize) 优先级队列 支持方法 qsize() 返回近似队列大小,,用近似二字因为当该值大于0时不能保证并发执行的时候get(),put()方法不被阻塞 empty() 判断是否为空,空返回True否则返回False full() 当设定了队列大小的时候,如果队列满了则返回True,否则False put(item[,block[,timeout]]) 向队列添加元素 当block设置为False时队列满则抛出异常 当block为True,timeout为None时则会等待直到有空位 当block为True,timeout不为None时则根据设定的时间判断是否等待,超时了就抛出错误 put_nowait(item) 相当于put(item,False) get([,block[,timeout]) 从队列中取出元素, 当block设置为False时队列空则抛出异常 当block为True,timeout为None时则会等待直到有+元素 当block为True,timeout不为None时则根据设定的时间判断是否等待,超时了就抛出错误 get_nowait() 等价于get(False) task_done() 发送信号表明入列任务已经完成,常在消费者线程里使用 join() 阻塞直到队列中所有元素处理完 Queue是线程安全的,而且支持in操作,因此用它的时候不用考虑锁的问题 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/流程控制/多进程.html":{"url":"语法篇/流程控制/多进程.html","title":"多进程","keywords":"","body":"python多进程编程 python受GIL限制,无法利用到多核,要使用多核提高cpu的利用率这种时候最简单的方式就是使用多进程实现突破GIL限制. 换言之python多进程的价值体现在CPU密集型作业上. 进程(Process)是计算机中的程序关于某数据集合上的一次运行活动,是系统进行资源分配和调度的基本单位,是操作系统结构的基础.在早期面向进程设计的计算机结构中,进程是程序的基本执行实体;在当代面向线程设计的计算机结构中,进程是线程的容器.程序是指令、数据及其组织形式的描述,进程是程序的实体. python调用系统fork Unix/Linux操作系统提供了一个fork()系统调用.普通的函数调用,调用一次,返回一次,但是fork()调用一次,返回两次,因为操作系统自动把当前进程(称为父进程)复制了一份(称为子进程),然后分别在父进程和子进程内返回. 子进程永远返回0,而父进程返回子进程的ID.这样做的理由是,一个父进程可以fork出很多子进程,所以父进程要记下每个子进程的ID,而子进程只需要调用getppid()就可以拿到父进程的ID. pythonos模块封装了fork()(unix-like系统).事实上在类unix系统下,python的多进程都是基于fork的,而windows下情况就不一样了. windows下的多进程局限性 在windows下,由于没有fork,python的多进程模块multiprocessing必须要有if __name__=='__main__':也就是说它无法在非入口模块下使用 import os print('Process ({}) 开始...'.format(os.getpid())) # Only works on Unix/Linux/Mac: pid = os.fork() if pid == 0: print('子进程: ({}) 它的父进程是: ({}).'.format(os.getpid(), os.getppid())) else: print('父进程 ({}) 产生了子进程: ({}).'.format(os.getpid(), pid)) Process (36236) 开始... 父进程 (36236) 产生了子进程: (36401). 子进程: (36401) 它的父进程是: (36236). 使用concurrent.futures进行高层抽象的多进程操作 在python3中,模块concurrent.futures提供了一些更加简单易用的多进程操作,它主要利用进程池. 这个库支持多线程和多进程,接口一样,只是使用的对象不同而已. concurrent.futures提供两种编程模型: 并行任务模型 单独任务独立使用自己的过程和数据,多任务独立并行计算 MapReduce模型 为各个进程分发数据执行相同的过程 并行任务模型 这个模型使用submit提交任务到上下文管理器,之后使用返回对象的result()方法阻塞io等待任务完成 from concurrent.futures import ProcessPoolExecutor,as_completed from random import randrange from time import time def arcfour(key, in_bytes, loops=20): \"\"\"rc4算法\"\"\" kbox = bytearray(256) # create key box for i, car in enumerate(key): # copy key and vector kbox[i] = car j = len(key) for i in range(j, 256): # repeat until full kbox[i] = kbox[i-j] # [1] initialize sbox sbox = bytearray(range(256)) # repeat sbox mixing loop, as recommened in CipherSaber-2 # http://ciphersaber.gurus.com/faq.html#cs2 j = 0 for k in range(loops): for i in range(256): j = (j + sbox[i] + kbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # main loop i = 0 j = 0 out_bytes = bytearray() for car in in_bytes: i = (i + 1) % 256 # [2] shuffle sbox j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # [3] compute t t = (sbox[i] + sbox[j]) % 256 k = sbox[t] car = car ^ k out_bytes.append(car) return out_bytes clear = bytearray(b'1234567890' * 100000) t0 = time() cipher = arcfour(b'key', clear) print('elapsed time: %.2fs' % (time() - t0)) result = arcfour(b'key', cipher) assert result == clear, '%r != %r' % (result, clear) print('elapsed time: %.2fs' % (time() - t0)) print('OK') elapsed time: 0.50s elapsed time: 1.02s OK def crypto_process(size, key): in_text = bytearray(randrange(256) for i in range(size)) cypher_text = arcfour(key, in_text) out_text = arcfour(key, cypher_text) assert in_text == out_text, 'Failed arcfour_test' return size def main(workers=None): JOBS = 12 SIZE = 2**18 KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\" STATUS = '{} workers, elapsed time: {:.2f}s' if workers: workers = int(workers) t0 = time() with ProcessPoolExecutor(workers) as executor: actual_workers = executor._max_workers to_do = [] for i in range(JOBS, 0, -1): size = SIZE + int(SIZE / JOBS * (i - JOBS/2)) job = executor.submit(crypto_process, size, KEY) to_do.append(job) for future in as_completed(to_do): res = future.result() print('{:.1f} KB'.format(res/2**10)) print(STATUS.format(actual_workers, time() - t0)) main(1) 384.0 KB 362.7 KB 341.3 KB 320.0 KB 298.7 KB 277.3 KB 256.0 KB 234.7 KB 213.3 KB 192.0 KB 170.7 KB 149.3 KB 1 workers, elapsed time: 6.50s main(2) 362.7 KB 384.0 KB 320.0 KB 341.3 KB 277.3 KB 298.7 KB 234.7 KB 256.0 KB 192.0 KB 213.3 KB 149.3 KB 170.7 KB 2 workers, elapsed time: 4.44s main(4) 320.0 KB 341.3 KB 362.7 KB 384.0 KB 256.0 KB 234.7 KB 298.7 KB 277.3 KB 149.3 KB 170.7 KB 192.0 KB 213.3 KB 4 workers, elapsed time: 3.92s MapReduce模型 这种模式可能更加被大家熟悉,同一个流程,将容器中的数据一条一脚放入子进程运算,最终也结果也会被放入容器中.最后可以将收集来的数据在主进程中进行处理 import math PRIMES = [ 112272535095293, 112582705942171, 112272535095293, 115280095190773, 115797848077099, 1099726899285419] def is_prime(n): if n % 2 == 0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n + 1, 2): if n % i == 0: return False return True [is_prime(i) for i in PRIMES] [True, True, True, True, True, False] %timeit [is_prime(i) for i in PRIMES] 2.98 s ± 164 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) def ProcessPool_prime(PRIMES= PRIMES ,workers=4): with ProcessPoolExecutor(max_workers=workers) as executor: total = [] for prime in executor.map(is_prime, PRIMES): #print('%d is prime: %s' % (number, prime)) total.append(prime) return total ProcessPool_prime() [True, True, True, True, True, False] %timeit ProcessPool_prime(workers=4) 2.07 s ± 52.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) 使用进程池进行相对底层的多进程操作 进程池的方式很适合批量创建子进程. 对Pool对象调用join()方法会等待所有子进程执行完毕,调用join()之前必须先调用close(),调用close()之后就不能继续添加新的Process了. 请注意输出的结果,task 0,1,2,3是立刻执行的,而task 4要等待前面某个task完成后才执行,这是因为Pool的默认大小在我的电脑上是4,因此最多同时执行4个进程.这是Pool有意设计的限制,并不是操作系统的限制.如果改成p = Pool(5)就可以同时跑5个进程. 由于Pool的默认大小是CPU的核数,如果你不幸拥有8核CPU,你要提交至少9个子进程才能看到上面的等待效果. 除了使用apply_async方法外,还有apply，map和map_async可以用于线程池的计算,编程模型也是如concurrent.futures一样分为两类 并行任务模型 apply 单一任务布置 apply_async 非阻塞单一任务布置 MapReduce模型 map 同系统的map方法 map_async 非阻塞的map apply_async from multiprocessing import Pool import os, time, random def long_time_task(name): print('运行任务 %s (%s)...' % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print('任务 %s 执行了 %0.2f 秒.' % (name, (end - start))) print('父进程 %s.' % os.getpid()) p = Pool(4) for i in range(5): p.apply_async(long_time_task, args=(i,))#创建非阻塞子进程用这个 print('等待所有子进程完成...') p.close() p.join() print('所有子进程完成了.') 父进程 36236. 运行任务 0 (36481)... 运行任务 1 (36482)... 运行任务 2 (36483)... 运行任务 3 (36484)... 等待所有子进程完成... 任务 0 执行了 0.65 秒. 运行任务 4 (36481)... 任务 3 执行了 2.09 秒. 任务 1 执行了 2.29 秒. 任务 4 执行了 2.03 秒. 任务 2 执行了 2.84 秒. 所有子进程完成了. map_async from multiprocessing import Pool from time import sleep def f(x): return x*x # start 4 worker processes pool = Pool(processes=4) print(\"map: \",pool.map(f, range(10))) print(\"imap:\") for i in pool.imap_unordered(f, range(10)): print(i) # evaluate \"f(10)\" asynchronously res = pool.apply_async(f, [10]) print(\"apply:\",res.get(timeout=1)) # prints \"100\" # make worker sleep for 10 secs res = pool.apply_async(sleep, [10]) print(res.get(timeout=1)) # raises multiprocessing.TimeoutError map: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] imap: 0 1 4 9 16 25 36 49 64 81 apply: 100 --------------------------------------------------------------------------- TimeoutError Traceback (most recent call last) in () 18 # make worker sleep for 10 secs 19 res = pool.apply_async(sleep, [10]) ---> 20 print(res.get(timeout=1)) # raises multiprocessing.TimeoutError ~/anaconda3/lib/python3.6/multiprocessing/pool.py in get(self, timeout) 638 self.wait(timeout) 639 if not self.ready(): --> 640 raise TimeoutError 641 if self._success: 642 return self._value TimeoutError: 获取进程池中的运算结果 import multiprocessing import time def func(msg): print(\"msg:\", msg) time.sleep(1) print(\"end\") return \"done \" + msg pool = multiprocessing.Pool(processes=4) result = [] for i in range(3): msg = \"hello %d\" %(i) result.append(pool.apply_async(func, (msg, ))) pool.close() pool.join() for res in result: print(\":::\", res.get()) print(\"Sub-process(es) done.\") msg: hello 1 msg: hello 0 msg: hello 2 end end end ::: done hello 0 ::: done hello 1 ::: done hello 2 Sub-process(es) done. 更底层的多进程编程 标准库中的multiprocessing模块就是跨平台版本的多进程模块. multiprocessing模块提供了一个Process类来代表一个进程对象,下面的例子演示了启动一个子进程并等待其结束: from multiprocessing import Process import os #子进程要执行的代码 def run_proc(name): for i in range(3): print(u'子进程 %s (%s)...' % (name, os.getpid())) print(u'子进程结束.') print(u'父进程 {}.'.format(os.getpid())) p = Process(target=run_proc, args=('test',)) print(u'子进程要开始啦.') p.start() for i in range(3): print(u'父进程{pid}进行中...'.format(pid = os.getpid())) p.join() print(u\"父进程结束啦\") 父进程 36236. 子进程要开始啦. 子进程 test (36495)... 子进程 test (36495)... 子进程 test (36495)... 子进程结束. 父进程36236进行中... 父进程36236进行中... 父进程36236进行中... 父进程结束啦 使用Process作为父类自定义子进程 Process的子类需要重写run方法 from multiprocessing import Process, Queue class Processor(Process): def __init__(self, queue, idx): super(Processor, self).__init__() self.queue = queue self.idx = idx def return_name(self): ## NOTE: self.name is an attribute of multiprocessing.Process return \"Process idx=%s is called '%s'\" % (self.idx, self.name) def run(self): self.queue.put(self.return_name()) processes = list() q = Queue() for i in range(0,5): p=Processor(queue=q, idx=i) processes.append(p) p.start() for proc in processes: proc.join() ## NOTE: You cannot depend on the results to queue / dequeue in the ## same order print(\"RESULT: {}\".format(q.get())) RESULT: Process idx=0 is called 'Processor-57' RESULT: Process idx=1 is called 'Processor-58' RESULT: Process idx=2 is called 'Processor-59' RESULT: Process idx=3 is called 'Processor-60' RESULT: Process idx=4 is called 'Processor-61' 创建子进程时,只需要传入一个执行函数和函数的参数,创建一个Process实例,用start()方法启动,这样创建进程比fork()简单. join()方法可以等待子进程结束后再继续往下运行,通常用于进程间的同步. 可以看到我们的父进程进行完了子进程才进行.其实当执行start方法的时候我们就已经把进程创建好并给他任务了.虽然进程启动了,但我们并不能知道它啥时候运算完成.这时候用join方法来确认是否执行完了(通过阻塞主进程),也就是起个等待结果的作用. 进程间通信 如何让进程间通信呢,其实原理上来讲就是构造一个独立的数据结构来存放结果来参与通信 有两种方式,最常用的一种是用队列 先进先出队列Queue from multiprocessing import Process, Queue def f(q): q.put([42, None, 'hello']) q = Queue() p = Process(target=f, args=(q,)) p.start() print(q.get()) # prints \"[42, None, 'hello']\" p.join() [42, None, 'hello'] 个稍微复杂一点的例子: from multiprocessing import Process, Queue import os, time, random # 写数据进程执行的代码: def write(q): for value in ['A', 'B', 'C']: print('Put %s to queue...' % value) q.put(value) time.sleep(random.random()) # 读数据进程执行的代码: def read(q): # pr进程里是死循环，无法等待其结束，只能强行终止: while True: if not q.empty(): value = q.get(True) print('Get %s from queue.' % value) time.sleep(random.random()) else: q.put(\"Done!\") break # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 等待pw结束: pw.join() # 启动子进程pr，读取: pr.start() pr.join() print(q.get()) print('\\n所有数据都写入并且读完') Put A to queue... Put B to queue... Put C to queue... Get A from queue. Get B from queue. Get C from queue. Done! 所有数据都写入并且读完 两个进程间,父进程创建一个队列给各个子进程,子进程接收父进程的队列作为参数运行.运行过程中将结果存入队列最后运行完后将”done!”存入队列,由父进程接收. 生产者消费者模型 队列最常见的用处就是在生产者消费者模式中作为数据缓冲区.以下就是一个生产者消费者模式的例子 import random from multiprocessing import Process, Queue,Condition class Producer(Process): \"\"\"生产者\"\"\" def __init__(self,q,con,name): super(Producer,self).__init__() self.q = q self.name = name self.con = con print(\"生产者{self.name}产生了\".format(self=self)) def run(self): count = 3 #只生产满3轮,要不然就会无限循环出不去了 while count>0: #global writelock self.con.acquire() if self.q.full(): print(\"队列满了,生产者等待\") count-=1 self.con.wait() else: value = random.randint(0,10) print(\"{self.name}把值{self.name}:{value}放入了队列\".format(self=self,value=value)) self.q.put(\"{self.name}:{value}\".format(self=self,value=value)) self.con.notify() self.con.release() class Consumer(Process): \"\"\"消费者\"\"\" def __init__(self,q,con,name): super(Consumer,self).__init__() self.q = q self.name = name self.con = con print(\"消费者{self.name}产生了\".format(self=self)) def run(self): while True: #global writelock self.con.acquire() if self.q.empty(): print(\"队列空了,消费者等待\") self.con.wait() else: value = self.q.get() print(\"{self.name}从队列中获取了{self.name}:{value}\".format(self=self, value=value)) self.con.notify() self.con.release() q = Queue(10) con = Condition() p1 = Producer(q,con,\"P1\") p1.start() p2 = Producer(q,con,\"P2\") p2.start() c1 = Consumer(q,con,\"C1\") c1.start() 生产者P1产生了 生产者P2产生了 消费者C1产生了 P1把值P1:4放入了队列 P1把值P1:2放入了队列 P1把值P1:0放入了队列 P1把值P1:3放入了队列 P1把值P1:5放入了队列 P1把值P1:0放入了队列 P1把值P1:7放入了队列 P1把值P1:4放入了队列 P1把值P1:5放入了队列 P1把值P1:5放入了队列 队列满了,生产者等待 队列满了,生产者等待 C1从队列中获取了C1:P1:4 P1把值P1:6放入了队列 队列满了,生产者等待 C1从队列中获取了C1:P1:2 P2把值P2:1放入了队列 队列满了,生产者等待 队列满了,生产者等待 C1从队列中获取了C1:P1:0 P2把值P2:8放入了队列 队列满了,生产者等待 管道Pipes 既然是管道,那就肯定有两端,有方向,分成单向管道和双向管道了. 看一个最简单的双向管道 from multiprocessing import Process, Pipe def f(conn): conn.send([42, None, 'hello']) conn.close() parent_conn, child_conn = Pipe() p = Process(target=f, args=(child_conn,)) p.start() print(parent_conn.recv()) # prints \"[42, None, 'hello']\" p.join() [42, None, 'hello'] 稍微复杂的例子: from multiprocessing import Process, Pipe import os, time, random # 写数据进程执行的代码: def write(conn): value = [\"h1 reader~\"] print('Put %s to pip...' % value) conn.send(value) time.sleep(1) # 读数据进程执行的代码: def read(conn): # pr进程里是死循环，无法等待其结束，只能强行终止: value = conn.recv() print('Get %s from pip.' % value) conn.send(\"hi writer~~\") # 父进程创建Pipe，并传给各个子进程： parent_conn, child_conn = Pipe() pw = Process(target=write, args=(parent_conn,))#起点 pr = Process(target=read, args=(child_conn,))#终点 # 启动子进程pw，写入: pw.start() # 等待pw结束: pw.join() # 启动子进程pr，读取: pr.start() pr.join() print(parent_conn.recv()) print('\\n所有数据都写入并且读完') Put ['h1 reader~'] to pip... Get ['h1 reader~'] from pip. hi writer~~ 所有数据都写入并且读完 可以看出管道的限制相对多些,必须要建立连接才能交换数据,一出一进这样子,这也是为啥队列用的比较多. 静态数据共享 python里面的全局变量也只管到他自己的进程,如果要让一个静态的数据在每个子进程中都可以调用.那么需要用到模块中的几个方法: Value, Array 静态数据位共享,静态数组共享,本质就是在内存中开辟一块用于共享的空间,Value和Array都必须使用C类型保存数据 from multiprocessing import Process, Value, Array def f(n, a): n.value = 3.1415927 for i in range(len(a)): a[i] = -a[i] num = Value('d', 0.0) arr = Array('i', range(10)) p = Process(target=f, args=(num, arr)) p.start() p.join() print(num.value) print(arr[:]) 3.1415927 [0, -1, -2, -3, -4, -5, -6, -7, -8, -9] 高级共享multiprocessing.Manager 之前介绍了queue,pipe,array和value,这些都太具体底层,有没有什么方法可以像处理python容器一样简单地处理数据共享的问题呢?multiprocess提供一个manager模块. Manager()返回的manager对象控制了一个server进程,此进程包含的python对象可以被其他的进程通过proxies来访问.从而达到多进程间数据通信且安全。 Manager支持的类型有 list dict Namespace Lock RLock Semaphore BoundedSemaphore Condition Event Queue Value Array。 import multiprocessing import time def worker(d, key, value): d[key] = value mgr = multiprocessing.Manager() d = mgr.dict() jobs = [ multiprocessing.Process(target=worker, args=(d, i, i*2)) for i in range(10) ] for j in jobs: j.start() for j in jobs: j.join() print ('Results:' ) for key, value in enumerate(dict(d)): print(\"%s=%s\" % (key, value)) Results: 0=0 1=7 2=2 3=1 4=4 5=3 6=5 7=6 8=8 9=9 namespace对象没有公共的方法,但是有可写的属性 import multiprocessing manager = multiprocessing.Manager() Global = manager.Namespace() Global.x = 10 Global.y = 'hello' print(Global) Namespace(x=10, y='hello') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/流程控制/并行编程的惯用法.html":{"url":"语法篇/流程控制/并行编程的惯用法.html","title":"并行编程的惯用法","keywords":"","body":"并行编程的惯用法 人们通常认为并行等同于多核,但现代计算机在不同层次上都使用了并行技术.比如说,单核的运行速度现今仍能每年不断提升的原因是--单核包含的晶体管数量,如同摩尔定律预测的那样变得越来越多,而单核在位级和指令级两个层次上都能够并行地使用这些晶体管资源. 位级(bit-level)并行 为什么32位计算机的运行速度比8位计算机更快？因为并行.对于两个32位数的加法,8位计算机必须进行多次8位计算,而32位计算机可以一步完成,即并行地处理32位数的4字节. 计算机的发展经历了8位、16位、32位,现在正处于64位时代.然而由位升级带来的性能改善是存在瓶颈的,这也正是短期内我们无法步入128位时代的原因. 指令级(instruction-level)并行 现代CPU的并行度很高,其中使用的技术包括流水线、乱序执行和猜测执行等. 程序员通常可以不关心处理器内部并行的细节,因为尽管处理器内部的并行度很高,但是经过精心设计,从外部看上去所有处理都像是串行的. 而这种\"看上去像串行\"的设计逐渐变得不适用.处理器的设计者们为单核提升速度变得越来越困难.进入多核时代,我们必须面对的情况是--无论是表面上还是实质上,指令都不再串行执行了. 数据级(data)并行 数据级并行(也称为\"单指令多数据\",SIMD)架构,可以并行地在大量数据上施加同一操作.这并不适合解决所有问题,但在适合的场景却可以大展身手. 图像处理就是一种适合进行数据级并行的场景.比如为了增加图片亮度就需要增加每一个像素的亮度.现代GPU(图形处理器)也因图像处理的特点而演化成了极其强大的数据并行处理器. 任务级(task-level)并行 终于来到了大家所认为的并行形式——多处理器.从程序员的角度来看,多处理器架构最明显的分类特征是其内存模型(共享内存模型或分布式内存模型). 对于共享内存的多处理器系统,每个处理器都能访问整个内存,处理器之间的通信主要通过内存进行. 对于分布式内存的多处理器系统,每个处理器都有自己的内存,处理器之间的通信主要通过网络进行. 通过内存通信比通过网络通信更简单更快速,所以用共享内存编程往往更容易.然而当处理器个数逐渐增多,共享内存就会遭遇性能瓶颈——此时不得不转向分布式内存.如果要开发一个容错系统,就要使用多台计算机以规避硬件故障对系统的影响,此时也必须借助于分布式内存. 并行方式如何选择 首先python的多线程和协程都是共享内存式的,而多进程虽然是在同一机器上,但各个进程间并不共享内存,因此是分布式的. 看起来多进程,多线程,协程都是以并行的方式运行的,那么我们该如何选择使用什么技术呢? 首先我们可以简单的通过分析目标功能来选择,如果我们的项目主要是计算密集型的,比如是并行计算多个数据是否是质数这类,那么没得选,只有多进程才可以做到最大化利用cpu资源,另外两个都只能跑满一个cpu核心. 接着就是主要是io操作的任务了,io密集型任务首选当然是协程,也只有协程可以搞定10k问题,但python的默认I/O多是同步I/O,因此在所需依赖无法满足的情况下只能使用多线程方式替代. 协程和多线程都最多跑满一个核心,但其机制是完全不一样的,协程是用户组织代码,因此是写成顺序执行的异步执行,说白了还是在顺序执行,只是线程运行哪段代码会在协程间跳转执行,打个比方有点像拉链,只要有一个齿坏了,整个过程就会卡住. 但多线程则完全不同,一个线程卡死了并不会影响其他线程. 并行编程的常用同步机制(原语) python包含多种同步机制,这些工具使用思路上是一致的,因此无论是协程,线程还是进程都可以使用,只是使用的模块会有些许不同,用途也会有写不同 信号量 Semaphore 在并行编程中,为了防止不同的过程(线程/进程/协程)同时对一个公用的资源进行修改,需要进行同时访问的数量(通常是1).信号量同步基于内部计数器,每调用一次acquire(),计数器减1;每调用一次release(),计数器加1.计数器的值永远不会小于0.当计数器为0时.acquire()调用被阻塞,直到其他线程来调用release().Semaphore支持上下文管理协议 Semaphore的接口有两个: acquire() 获取一个信号量,协程中这个方法是一个协程 release() 释放一个信号量 locked() 协程中独有,用来判断是否被锁定 信号量有两种: Semaphore 标准信号量 BoundedSemaphore 有界信号量,它会检查内部计数器的值,并保证它不会大于初始值,如果超了,就引发一个ValueError 多数情况下,semaphore用于守护限制访问(但不限于1)的资源,如果semaphore被release()过多次,这意味着存在bug. 信号量在线程,进程,协程中的使用的模块并不一样: 协程--asynico.Semaphore(value=1, *, loop=None) 线程--threading.Semaphore(value=1) 进程--multiprocessing.Semaphore([value]) 协程版本 import aiohttp import asyncio NUMBERS = range(12) URL = 'http://httpbin.org/get?a={}' sema = asyncio.Semaphore(3) async def fetch_async(a): async with aiohttp.request('GET', URL.format(a)) as r: data = await r.json() return data['args']['a'] async def print_result(a): async with sema: r = await fetch_async(a) print('fetch({}) = {}'.format(a, r)) #loop = asyncio.new_event_loop() #asyncio.set_event_loop(loop) loop = asyncio.get_event_loop() f = asyncio.wait([print_result(num) for num in NUMBERS]) loop.run_until_complete(f) fetch(3) = 3 fetch(4) = 4 fetch(9) = 9 fetch(10) = 10 fetch(1) = 1 fetch(6) = 6 fetch(5) = 5 fetch(11) = 11 fetch(0) = 0 fetch(2) = 2 fetch(7) = 7 fetch(8) = 8 ({:11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>}, set()) 多线程版本 import time from random import random from threading import Thread, Semaphore sema = Semaphore(3) def foo(tid): with sema: print('{} acquire sema'.format(tid)) wt = random() * 2 time.sleep(wt) print('{} release sema'.format(tid)) threads = [] for i in range(5): t = Thread(target=foo, args=(i,)) threads.append(t) t.start() for t in threads: t.join() 0 acquire sema 1 acquire sema 2 acquire sema 2 release sema3 acquire sema 0 release sema 4 acquire sema 3 release sema 4 release sema 1 release sema 多进程 %%writefile src/semaphore.py from multiprocessing import Process, Semaphore def foo(tid,sema): import time from random import random with sema: print('{} acquire sema'.format(tid)) wt = random() * 2 time.sleep(wt) print('{} release sema'.format(tid)) if __name__ == \"__main__\": sema = Semaphore(3) processes = [] for i in range(5): t = Process(target=foo, args=(i,sema)) processes.append(t) for t in processes: t.start() for t in processes: t.join() Overwriting src/semaphore.py !python src/semaphore.py 0 acquire sema 1 acquire sema 2 acquire sema 2 release sema 3 acquire sema 0 release sema 4 acquire sema 1 release sema 3 release sema 4 release sema 锁Lock Lock也可以叫做互斥锁,其实相当于信号量为1. 在多线程中锁的作用是用于锁定读写,以确认同一个资源同一时间只能被一个操作访问. python中锁有两种 Lock 标准锁 RLock 可重入锁,可以由同一个过程多次获取.在内部,除了原始锁使用的锁定/解锁状态之外,它还使用\"拥有过程\"和\"递归级别\"的概念.在锁定状态下,某些过程拥有锁;在解锁状态下,没有线程拥有它. 我们先看一个不加锁的例子: import time from threading import Thread value = 0 def getlock(): global value new = value + 1 time.sleep(0.001) # 使用sleep让线程有机会切换 value = new threads = [] for i in range(100): t = Thread(target=getlock) t.start() threads.append(t) for t in threads: t.join() print(value) 10 不加锁的情况下,结果会远远的小于100.那我们加上互斥锁看看 import time from threading import Thread, Lock value = 0 lock = Lock() def getlock(): global value with lock: new = value + 1 time.sleep(0.001) value = new threads = [] for i in range(100): t = Thread(target=getlock) t.start() threads.append(t) for t in threads: t.join() print(value) 100 锁作为一种特殊信号量,它的接口与Semaphore一致.在线程,进程,协程中的使用的模块分别为: 协程--asynico.Lock(*,loop=None) 线程--threading.Lock(value=1) 进程--multiprocessing.Lock([value]) 在协程中,实际上协程并没有抢占资源的情况,因此此处的锁更多的是用来作为一个全局的变量锁定一些流程用 import asyncio import functools def unlock(lock): print('callback releasing lock') lock.release() async def test(locker, lock): print('{} waiting for the lock'.format(locker)) with await lock: print('{} acquired lock'.format(locker)) print('{} released lock'.format(locker)) async def main(loop): lock = asyncio.Lock() await lock.acquire() loop.call_later(0.1, functools.partial(unlock, lock)) await asyncio.wait([test('l1', lock), test('l2', lock)]) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main(loop)) loop.close() l2 waiting for the lock l1 waiting for the lock callback releasing lock l2 acquired lock l2 released lock l1 acquired lock l1 released lock 而针对于多进程,锁同样起到一个全局信号的作用,比如多个进程处理同一个文件,就需要加锁来限制 %%writefile src/lock.py import multiprocessing import sys def worker_with(lock, f): with lock: with open(f,\"a+\") as fs: fs.write('Lock acquired via with\\n') if __name__ == '__main__': f = \"source/file.txt\" lock = multiprocessing.Lock() w = multiprocessing.Process(target=worker_with, args=(lock, f)) w.start() w.join() Overwriting src/lock.py !python src/lock.py 事件 一个过程发送/传递事件,所谓事件是指的一个保存标记状态的对象,如果内部标记为True则表示事件发生了,反之就是没发生 事件的接口包括: clear() 事件内部标记为False is_set() 返回事件的内部标记 set() 调用则设置内部标记为True wait() 等待事件被标记为True,协程中该接口为协程 另外的过程等待事件的触发.我们用「生产者/消费者」模型的例子. 协程 import asyncio import random async def produce(event, n): for x in range(1, n + 1): # produce an item print('producing {}/{}'.format(x, n)) # simulate i/o operation using sleep await asyncio.sleep(random.random()) l.append(x) event.set() async def consume(event): while True: item = await event.wait() if item == False: break integer = l.pop() print('{} popped from list '.format(integer)) event.clear() await asyncio.sleep(random.random()) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) l = [] event = asyncio.Event(loop=loop) producer_coro = produce(event, 10) consumer_coro = consume(event) loop.run_until_complete(asyncio.gather(producer_coro, consumer_coro)) loop.close() producing 1/10 producing 2/10 1 popped from list producing 3/10 2 popped from list producing 4/10 3 popped from list producing 5/10 4 popped from list producing 6/10 5 popped from list producing 7/10 producing 8/10 7 popped from list producing 9/10 8 popped from list producing 10/10 9 popped from list 10 popped from list --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) in () 31 producer_coro = produce(event, 10) 32 consumer_coro = consume(event) ---> 33 loop.run_until_complete(asyncio.gather(producer_coro, consumer_coro)) 34 loop.close() ~/anaconda3/lib/python3.6/asyncio/base_events.py in run_until_complete(self, future) 452 future.add_done_callback(_run_until_complete_cb) 453 try: --> 454 self.run_forever() 455 except: 456 if new_task and future.done() and not future.cancelled(): ~/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self) 419 events._set_running_loop(self) 420 while True: --> 421 self._run_once() 422 if self._stopping: 423 break ~/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self) 1393 timeout * 1e3, dt * 1e3) 1394 else: -> 1395 event_list = self._selector.select(timeout) 1396 self._process_events(event_list) 1397 ~/anaconda3/lib/python3.6/selectors.py in select(self, timeout) 575 ready = [] 576 try: --> 577 kev_list = self._kqueue.control(None, max_ev, timeout) 578 except InterruptedError: 579 return ready KeyboardInterrupt: import time import asyncio from random import randint,choice TIMEOUT = 2 async def consumer(name,event, l): if await event.wait(): try: integer = l.pop() print('{} popped from list by {}'.format(integer, name)) event.clear() # 重置事件状态 except IndexError: # 为了让刚启动时容错 pass async def producer(): for i in range(1,10): interger = randint(10, 100) yield interger async def main(): event = asyncio.Event() l = [] async for i in producer(): l.append(i) print('{} appended to list '.format(i)) event.set() # 设置事件 consumers = [consumer( name,event ,l) for _, name in enumerate(('c1', 'c2'))] await choice(consumers) await asyncio.sleep(1) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) loop.close() 85 appended to list 85 popped from list by c1 67 appended to list 67 popped from list by c2 /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: RuntimeWarning: coroutine 'consumer' was never awaited 66 appended to list 66 popped from list by c2 81 appended to list 81 popped from list by c2 57 appended to list 57 popped from list by c2 97 appended to list 97 popped from list by c2 53 appended to list 53 popped from list by c1 43 appended to list 43 popped from list by c2 24 appended to list 24 popped from list by c2 /Users/huangsizhe/anaconda3/lib/python3.6/asyncio/events.py:145: RuntimeWarning: coroutine 'consumer' was never awaited self._callback(*self._args) 线程 import time import threading from random import randint TIMEOUT = 2 def consumer(event, l): t = threading.currentThread() while 1: try: event_is_set = event.wait(TIMEOUT) except Exception as e: print(e) break if event_is_set: try: integer = l.pop() print('{} popped from list by {}'.format(integer, t.name)) event.clear() # 重置事件状态 except IndexError: # 为了让刚启动时容错 pass else: break def producer(event, l): t = threading.currentThread() for i in range(10): integer = randint(10, 100) l.append(integer) print('{} appended to list by {}'.format(integer, t.name)) event.set() # 设置事件 time.sleep(1) event = threading.Event() l = [] threads = [] for name in ('consumer1', 'consumer2'): t = threading.Thread(name=name, target=consumer, args=(event, l)) t.start() threads.append(t) p = threading.Thread(name='producer1', target=producer, args=(event, l)) p.start() threads.append(p) for t in threads: t.join() 23 appended to list by producer1 23 popped from list by consumer1 80 appended to list by producer1 80 popped from list by consumer1 67 appended to list by producer1 67 popped from list by consumer1 49 appended to list by producer1 49 popped from list by consumer1 96 appended to list by producer1 96 popped from list by consumer1 91 appended to list by producer1 91 popped from list by consumer2 55 appended to list by producer1 55 popped from list by consumer2 29 appended to list by producer1 29 popped from list by consumer1 31 appended to list by producer1 31 popped from list by consumer1 36 appended to list by producer1 36 popped from list by consumer2 条件Condition 条件用于信号通信,它的除了拥有锁的所有接口外,还有接口: notify(n=1) 释放出通知,让使用相同Condition对象的几个过程知道这个条件已被激活 notify_all() 释放出通知,让使用相同Condition对象的所有过程知道这个条件已被激活 wait() 等待使用相同Condition对象的过程的通知. wait_for(predicate) 相当于 while not predicate(): cv.wait() 一个过程等待特定条件,而另一个过程发出特定条件满足的信号.最好说明的例子就是「生产者/消费者」模型： 协程方式 import asyncio import functools async def consumer(cond, name, second): await asyncio.sleep(second) async with cond: await cond.wait() print('{}: Resource is available to consumer'.format(name)) async def producer(cond): await asyncio.sleep(2) async with cond: print('Making resource available') cond.notify_all() async def main(loop): condition = asyncio.Condition() task = loop.create_task(producer(condition)) consumers = [consumer(condition, name, index) for index, name in enumerate(('c1', 'c2'))] await asyncio.wait(consumers) task.cancel() loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main(loop)) loop.close() Making resource available c1: Resource is available to consumer c2: Resource is available to consumer 线程方式 import time import threading def consumer(cond): t = threading.currentThread() with cond: cond.wait() # wait()方法创建了一个名为waiter的锁， #并且设置锁的状态为locked。这个waiter锁用于线程间的通讯 print('{}: Resource is available to consumer'.format(t.name)) def producer(cond): t = threading.currentThread() with cond: print('{}: Making resource available'.format(t.name)) cond.notify_all() # 释放waiter锁，唤醒消费者 condition = threading.Condition() c1 = threading.Thread(name='c1', target=consumer, args=(condition,)) c2 = threading.Thread(name='c2', target=consumer, args=(condition,)) p = threading.Thread(name='p', target=producer, args=(condition,)) c1.start() time.sleep(1) c2.start() time.sleep(1) p.start() p: Making resource available c1: Resource is available to consumer c2: Resource is available to consumer 进程方式 %%writefile src/cond.py import time import multiprocessing def consumer(cond): t = multiprocessing.current_process() with cond: cond.wait() # wait()方法创建了一个名为waiter的锁， #并且设置锁的状态为locked。这个waiter锁用于线程间的通讯 print('{}: Resource is available to consumer'.format(t.name)) def producer(cond): t = multiprocessing.current_process() with cond: print('{}: Making resource available'.format(t.name)) cond.notify_all() # 释放waiter锁，唤醒消费者 if __name__=='__main__': condition = multiprocessing.Condition() c1 = multiprocessing.Process(name='c1', target=consumer, args=(condition,)) c2 = multiprocessing.Process(name='c2', target=consumer, args=(condition,)) p = multiprocessing.Process(name='p', target=producer, args=(condition,)) c1.start() time.sleep(1) c2.start() time.sleep(1) p.start() Overwriting src/cond.py !python src/cond.py p: Making resource available c1: Resource is available to consumer c2: Resource is available to consumer 队列 使用队列是最常见的同步方式.也是生产者消费者模式最常见使用的工具 队列的接口有: qsize() 返回队列的大致大小 empty() 如果队列为空返回True full() 如果队列满了,则返回空 put(item, block=True, timeout=None) 将元素放入队列,协程中是协程 put_nowait(item) 立即将元素放入队列 get(block=True, timeout=None) 获取元素,并且在队列中删除该元素,协程中是协程 get_nowait() 立即获取元素,并且在队列中删除该元素 task_done() 表明以前入队的任务是否已经完成。 join() 阻塞直到队列中的所有项目都被获取和处理.协程中是协程 常见的队列有两种: queue 先进先出队列 LifoQueue 先进后出队列 PriorityQueue 优先权队列,放入的元素必须是Tuple[int,Any],第一位就是权重 对不同方式使用的队列为: 协程--asyncio.Queue(maxsize) 线程--queue.Queue(maxsize) 进程--multiprocessing.Queue(maxsize) 依然用生产消费模式做例子 协程 import asyncio import random def double(n): return n * 2 async def producer(queue, n): count = 0 while True: if count > 5: break pri = randint(0, 100) print('put :{}'.format(pri)) await queue.put((pri, double, pri)) # (priority, func, args) count += 1 async def consumer(queue): while True: pri, task, arg = await queue.get() print('[PRI:{}] {} * 2 = {}'.format(pri, arg, task(arg))) await asyncio.sleep(random.random()) queue.task_done() async def run(n): queue = asyncio.PriorityQueue(10) # schedule the consumer consume = asyncio.ensure_future(consumer(queue)) # run the producer and wait for completion await producer(queue, n) # wait until the consumer has processed all items await queue.join() # the consumer is still awaiting for an item, cancel it consume.cancel() loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(run(10)) loop.close() put :76 put :25 put :98 put :35 put :6 put :9 [PRI:6] 6 * 2 = 12 [PRI:9] 9 * 2 = 18 [PRI:25] 25 * 2 = 50 [PRI:35] 35 * 2 = 70 [PRI:76] 76 * 2 = 152 [PRI:98] 98 * 2 = 196 线程 import time import threading from random import randint from queue import PriorityQueue q = PriorityQueue(10) def double(n): return n * 2 def producer(): count = 0 while True: if count > 5: break pri = randint(0, 100) print('put :{}'.format(pri)) q.put((pri, double, pri)) # (priority, func, args) count += 1 def consumer(): while True: if q.empty(): break pri, task, arg = q.get() print('[PRI:{}] {} * 2 = {}'.format(pri, arg, task(arg))) q.task_done() time.sleep(0.1) t = threading.Thread(target=producer) t.start() time.sleep(1) t = threading.Thread(target=consumer) t.start() put :61 put :63 put :10 put :8 put :69 put :98 [PRI:8] 8 * 2 = 16 [PRI:10] 10 * 2 = 20 [PRI:61] 61 * 2 = 122 [PRI:63] 63 * 2 = 126 [PRI:69] 69 * 2 = 138 [PRI:98] 98 * 2 = 196 进程 import time from multiprocessing import Process from random import randint from multiprocessing import JoinableQueue q = JoinableQueue(10) def double(n): return n * 2 def producer(): count = 0 while True: if count > 5: break pri = randint(0, 100) print('put :{}'.format(pri)) q.put((pri, double, pri)) # (priority, func, args) count += 1 def consumer(): while True: if q.empty(): break pri, task, arg = q.get() print('[PRI:{}] {} * 2 = {}'.format(pri, arg, task(arg))) q.task_done() time.sleep(0.1) t = Process(target=producer) t.start() time.sleep(1) t = Process(target=consumer) t.start() put :17 put :42 put :82 put :43 put :1 put :47 [PRI:17] 17 * 2 = 34 [PRI:42] 42 * 2 = 84 [PRI:82] 82 * 2 = 164 [PRI:43] 43 * 2 = 86 [PRI:1] 1 * 2 = 2 [PRI:47] 47 * 2 = 94 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/流程控制/结语.html":{"url":"语法篇/流程控制/结语.html","title":"结语","keywords":"","body":"结语 python协程的现状 有很长一段时间,大多数Python高手开发网络应用时喜欢使用异步编程,但是总会遇到一个问题——挑选的库之间不兼容。 Twisted 是 Node.js 的灵感来源之一;而在 Python 中,Tornado 拥护使用协程做面向事件编程;同时第三方的协程库gevent,eventlet,greenlet等由于简单好用也长期存在并发展迅速.直到python3.5之前我都是gevent的忠实用户. 在 JavaScript 社区里还有争论,有些人推崇使用简单的回调,而有些人提倡使用与回调处于竞争地位的各种高层抽象方式.Node.js早期版本的API使用的是Promise对象(类似于Python中的期物),但是后来Ryan Dahl决定统一只用回调. Python社区的争论已经结束: asyncio包添加到标准库中之后,协程和期物被确定为符合 Python 风格的异步代码编写方式。此外,asyncio包为异步期物和事件循环定义了标准接口,为二者提供了实现参考。 正如\"Python 之禅\"所说: 肯定有一种——通常也是唯一一种——最佳的解决方案 python的协程工具一开始并不易于理解,不过一段时间之后我理解了。 更重要的是,设计asyncio包时考虑到了使用外部包替换自身的事件循环,因此才有 asyncio.get_event_loop 和 set_event_loop 函数——二者是抽象的事件循环策略. Tornado 已经有实现 asyncio.AbstractEventLoop 接口的类——AsyncIOMainLoop,因此在同一个事件循环中可以使用这两 个库运行异步代码。此外,Quamash项目也很有趣,它把asyncio包集成到Qt事件循环中,以便使用PyQt或PySide开发GUI应用.我只是举两个例子,说明asyncio包能把面向事件的包集成在一起。 智能的HTTP客户端,例如单页Web应用(如Gmail)或智能手机应用,需要快速、轻量级的响应和推送更新。鉴于这样的需求,服务器端最好使用异步框架,不要使用传统的Web框架(如Django).传统框架的目的是渲染完整的 HTML 网页,而且不支持异步访问数据库。 WebSockets协议的作用是为始终连接的客户端(例如游戏和流式应用)提供实时更新,因此,高并发的异步服务器要不间断地与成百上千个客户端交互.asyncio包的 架构能很好地支持WebSockets,而且至少有两个库已经在asyncio包的基础上实现了WebSockets协议: Autobahn|Python WebSockets '实时 Web'的整体发展趋势迅猛,这是Node.js需求量不断攀升的主要因素,也是 Python 生态系统积极向asyncio靠拢的重要原因.不过,要做的事还有很多.为了便于入门,我们要在标准库中提供异步HTTP服务器和客户端API,异步数据库API 3.0,以及使用asyncio包构建的新数据库驱动. 相关扩展和模块 eventlet python2,3通用的协程工具.提供猴子补丁为socket提供异步支持 gevent 更加通用协程工具.提供猴子补丁为标准库中的大部分提供协程支持 pychan go风格的的channel,使用的是线程. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/异常和警告.html":{"url":"语法篇/异常和警告.html","title":"异常和警告","keywords":"","body":"异常和警告 通常我们会在程序的编程的过程中就可以预期到一些会导致程序错误退出的事件,这种预期中的异常事件被称作异常(Exception). 而有些时候我们判断需要通过一些途径向用户发送消息以提醒用户在程序中的某些条件下不能保证引发异常并终止程序但又有一定的威胁.例如,当程序使用过时的模块时,我们就应该使用警告(warnings).在python中警告也是一种异常. 异常和警告是python语言中框架/服务开发重要工具.它为框架/服务提供了业务流的提醒和退出机制. 本节的预备知识包括: 流程控制中的上下文管理器 异常 异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。 一般情况下，在Python无法正常处理程序时就会发生一个异常。 异常是Python对象，表示一个错误。 当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。 python的标准异常可以在官网文档中查看,常用的如下: 异常名称 描述 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 LookupError 无效数据查询的基类 IndexError 序列中没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告 异常捕获处理 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它 try: #运行别的代码 except ： #如果在try部份引发了'name'异常 except ，: #如果引发了'name'异常，获得附加的数据 else: #如果没有异常发生 finally: #退出try时总会执行 try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。 如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。 如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印缺省的出错信息）。 如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。 无论是否有异常,finally都将被执行,它一般作为存放收尾动作的地方,但是注意,finally有陷阱: 如果主干上的错误分支中没有对应的捕捉,那么他将被保存在一个临时的位置,而如果同时finally中有错误,则这个临时的错误会被finally中的错误给替代. 使用异常捕获处理语句应该尽量精准地包裹可能有错误的代码. Python遵守尽早失败原则,认为程序应该尽早报告错误。例如,Python中没有“未定义”的值:在初始化之前引用变量会报错;如果k不存在,my_dict[k] 会抛出异常(JavaScript 则不然)。还有一例:在 Python 中通过元组 拆包做并行赋值,必须显式处理元组的每一个元素才行;而在 Ruby 中,如果 = 两边的元 素数量不一致,右边未用到的元素会被忽略,或者把 nil 赋给左边多余的变量。 因为尽早失败原则,python代码中try语句会比较多,但即便如此,我们的单个try结构应该尽量精准的包裹可能出错的代码. 抛出异常 我们可以使用raise语句自己触发异常 raise语法格式如下 raise [Exception [, args [, traceback]]] 自定义异常 如果自己写模块,最好自定义模块的异常,一方面可以更好的分析代码,另一方面也让用模块的用户更容易追踪错误. class Networkerror(RuntimeError): def __init__(self, arg): self.args = arg try: raise Networkerror(\"Bad hostname\") except Networkerror as e: print(e.args) ('B', 'a', 'd', ' ', 'h', 'o', 's', 't', 'n', 'a', 'm', 'e') 输出警告 警告不应被像异常一样抛出以中断业务流,但应该被输出以提醒用户,在python中有专门做这个事情的标准库warnings. import warnings 抛出警告 抛出警告使用warnings.warn(message:str, warning:Warning)来实现,它不会像用raise抛出一样中断业务流 raise DeprecationWarning(\"Deprecation\") print(\"next\") --------------------------------------------------------------------------- DeprecationWarning Traceback (most recent call last) in () ----> 1 raise DeprecationWarning(\"Deprecation\") 2 print(\"next\") DeprecationWarning: Deprecation warnings.warn(\"Deprecation\", DeprecationWarning) print(\"next\") next /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Deprecation \"\"\"Entry point for launching an IPython kernel. 捕获警告 警告的捕获也不使用try语句,而是使用上下文管理器warnings.catch_warnings结合行为过滤器warnings.simplefilter或者warnings.filterwarnings进行. def fxn(): warnings.warn(\"deprecated\", DeprecationWarning) with warnings.catch_warnings(): warnings.simplefilter(\"ignore\") fxn() 其中simplefilter的参数ignore是指定捕获后行为用的,可选的有: 取值 描述 \"error\" 将匹配的警告转化为异常 \"ignore\" 从不打印匹配的警告 \"always\" 始终打印匹配的警告 \"default\" 打印出现警告的每个位置的首次匹配警告 \"module\" 打印出现警告的每个模块的首次匹配警告 \"once\" 不管位置如何,只打印首次出现的匹配警告 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 11:44:06 "},"语法篇/内置容器/":{"url":"语法篇/内置容器/","title":"内置容器","keywords":"","body":"**内置容器 python是重视用户体验的语言,它提供了简单好用的数据结构而忽视了数据结构的效率. 然而这并不代表它们就不好用,恰恰相反,这提高了开发效率,python语言的一致性也给更加高效的用c 语言写的数据结构可以方便的替代默认的数据结构. 序列对象 映射对象 可迭代对象与生成器 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:41:41 "},"语法篇/内置容器/序列对象.html":{"url":"语法篇/内置容器/序列对象.html","title":"序列对象","keywords":"","body":"序列对象 Python标准库用C语言实现了丰富的序列类型,从底层实现的角度来分类,可以分为容器序列和扁平序列.列举如下. 容器序列 list、tuple 和 collections.deque这些序列能存放异构(不同类型的)数据.本质上存储的内容是引用,关于引用,可以看python数据模型部分的相关介绍. 扁平序列 str、bytes、bytearray、memoryview ,array.array 以及准标准库numpy.array.这类序列只能容纳同构(同一种类型的)数据. 容器序列存放的是它们所包含的任意类型的对象的引用,而扁平序列里存放的是值而不是引用.换句话说,扁平序列其实是一段连续的内存空间. 由此可见扁平序列其实更加紧凑,但是它里面只能存放诸如字符、字节和数值这种基础类型. 序列类型还能按照能否被修改来分类: 可变序列MutableSequence list、bytearray、array.array、collections.deque和memoryview. 不可变序列Sequence tuple、str、bytes和numpy.ndarray 下图显示了可变序列和不可变序列的差异,同时也能看出前者从后者那里继承了一些方法.虽然内置的序列类型并不是直接从Sequence和 MutableSequence这两个抽象基类继承而来的.但是了解这些基类可以帮助我们总结出那些完整的序列类型包含了哪些功能: 扁平序列内置类型相关的操作可以看文本文件与字节序相关的内容. 另一个准标准库numpy提供了一套更加高效的同构定长数组工具,它属于向量计算部分的范畴,本节不做介绍. 本章需要的先验知识包括: 协议与接口与抽象基类 序列操作 python是高度一致性理念下的产物,它的序列很能够体现这一特点.不同类型的序列虽然特性不同,但都满足一致的接口协议,因此有着一致的行为.了解序列操作只要了解这些接口协议即可 只要满足Iterable,我们的序列就可以使用for循环遍历 for i in (1,2,3,4,5): print(i) 1 2 3 4 5 只要满足Sized我们的序列就可以使用len内置方法求取序列的长度 len((1,2,3,4,5)) 5 只要满足Container我们的序列就可以使用in语句判断元素是否在序列中 1 in (1,2,3,4,5) True 只要满足Sequence我们就可以使用切片操作,翻转序列,使用count方法和index方法 切片操作 python用[]来取值和切片,它对应的魔术方法是__getitem__. python内置类型有一套非常便捷的切片逻辑 取位 比如[1]代表取第一位的值(序列中为第2个元素).[-1]代表最后一个元素 (1,2,3,4,5)[0] 1 切片 而当[]中有两个被:分割开得数时就成了切片,比如[2:4]代表取从第2位到第3位的元素组成一个与原来序列相同类型的新序列,:分隔的两边可以没有指定,意味头尾元素,后一位可以为负数,意为倒着数 (1,2,3,4,5)[:-2] (1, 2, 3) 按步长切片 而当[]中有三个被:分割开得数时就成了切片,比如[0:4:2]代表每2个元素从第0位到第3位取出组成一个与原来序列相同类型的新序列,第二位可以为负数,意为倒着数,最后一位可以为负数,意味从尾到头获取. (1,2,3,4,5)[:-4:-2] (5, 3) count计算元素在序列中出现的次数 (1,2,3,4,5,2).count(2) 2 reversed翻转序列 翻转序列操作返回的是一个可迭代对象并非序列 tuple(reversed((1,2,3,4,5,2))) (2, 5, 4, 3, 2, 1) 只要满足MutableSequence我们就可以使用insert,append,pop,extend,remove操作 list.append(obj) 在列表末尾添加新的对象 list.extend(seq) 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） list.insert(index, obj) 将对象插入列表 list.pop(obj=list[-1]) 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 list.remove(obj) 移除列表中某个值的第一个匹配项 对序列使用+,*,+=,*= Python的内置序列类型会默认支持+ 和* 操作的.+和*分别对应特殊方法__add__和__mul__ 通常+号两侧的序列由相同类型的数据所构成,在拼接的过程中,两个被操作的序列都不会被修改,Python 会新建一个包含同样类型数据的序列来作为拼接的结果. 如果想要把一个序列复制几份然后再拼接起来,更快捷的做法是把这个序列乘以一个整数.同样,这个操作会产生一个新序列: +和*都遵循这个规律，不修改原有的操作对象，而是构建一个全新的序列。 l = (1, 2, 3) l * 5 (1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3) 5 * 'abcd' 'abcdabcdabcdabcdabcd' 增量赋值运算符+= 和*= 的表现取决于它们的第一个操作对象.简单起见,我们把讨论集中在增量加法（+=）上,但是这些概念对*=和其他增量运算符来说都是一样的.+= 背后的特殊方法是__iadd__(用于\"就地加法\").但是如果一个类没有实现这个方法的话,Python 会退一步调用__add__.考虑下面这个简单的表达式: a += b 如果a 实现了__iadd__ 方法,就会调用这个方法.同时对可变序列(例如list、bytearray 和array.array)来说,a会就地改动,就像调用了a.extend(b)一样.但是如果a没有实现__iadd__的话,a += b这个表达式的效果就变得跟a = a + b 一样了: 首先计算a + b,得到一个新的对象 然后赋值给a 也就是说,在这个表达式中,变量名会不会被关联到新的对象,完全取决于这个类型有没有实现__iadd__这个方法. 总体来讲,可变序列一般都实现了__iadd__ 方法,因此+=是就地加法.而不可变序列根本就不支持这个操作,对这个方法的实现也就无从谈起. 上面所说的这些关于+= 的概念也适用于*=,不同的是,后者相对应的是__imul__. 列表list 最重要也最基础的序列类型应该就是列表(list)了.list是一个可变序列,并且能同时存放不同类型的元素.本质上list就是类似c++中vector的数据结构.因此它的效率并不高.list是单向序列,因此使用list存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了. list是线性存储，数据量大的时候，插入和删除效率很低. 列表的构造函数是list(*items),python中也可以使用[]来构造 列表推导 所谓列表解析就是在列表中写入代码段,吧代码段生成的结果放入列表中.列表解析除了支持使用for循环构建列表,也支持使用if筛选数据 [i for i in range(10)] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [i for i in range(10) if i%2==0] [0, 2, 4, 6, 8] 双向队列deque collections.deque是一个是一个线程安全,高效实现插入和删除操作的双向列表,适合用于队列和栈 deque除了实现list的append()和pop()外，还支持appendleft()和popleft(),这样就可以非常高效地往头部添加或删除元素. from collections import deque q = deque(['a', 'b', 'c']) q.append('x') q.appendleft('y') q deque(['y', 'a', 'b', 'c', 'x']) 如果想要有一种数据类型来存放\"最近用到的几个元素\",deque 也是一个很好的选择.这是因为在新建一个双向队列的时候,你可以指定这个队列的大小,如果这个队列满员了,还可以从反向端删除过期的元素,然后在尾端添加新的元素. 双向队列也付出了一些代价,从队列中间删除元素的操作会慢一些,因为它只对在头尾的操作进行了优化 dq = deque(range(10), maxlen=10) dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) q.rotate(3)#队列的旋转操作接受一个参数n，当n > 0 时， #队列的最右边的n 个元素会被移动到队列的左边。当n dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) dq.rotate(-4) dq deque([4, 5, 6, 7, 8, 9, 0, 1, 2, 3]) dq.extend([11, 22, 33]) dq deque([7, 8, 9, 0, 1, 2, 3, 11, 22, 33]) dq.extendleft([10, 20, 30, 40]) dq deque([40, 30, 20, 10, 7, 8, 9, 0, 1, 2]) 除了deque之外,还有些其他的Python标准库也有对队列的实现. queue 提供了同步(线程安全)类Queue、LifoQueue和PriorityQueue,不同的线程可以利用这些数据类型来交换信息.这三个类的构造方法都有一个可选参数maxsize,它接收正整数作为输入值,用来限定队列的大小.但是在满员的时候,这些类不会扔掉旧的元素来腾出位置.相反,如果队列满了,它就会被锁住,直到另外的线程移除了某个元素而腾出了位置.这一特性让这些类很适合用来控制活跃线程的数量. multiprocessing.Queue 这个包实现了自己的Queue,它跟queue.Queue类似,是设计给进程间通信用的.同时还有一个专门的multiprocessing.JoinableQueue类型,可以让任务管理变得更方便. asyncio.Queue Python 3.4新提供的包,里面有Queue、LifoQueue、PriorityQueue和JoinableQueue,这些类受到queue和multiprocessing模块的影响,但是为异步编程里的任务管理提供了专门的便利. 以上的队列基本都是为并行计算设计的,会在流程控制部分细讲 heapq堆 跟上面三个模块不同的是,heapq 没有队列类,而是提供了heappush 和heappop 方法,让用户可以把可变序列当作堆队列或者优先队列来使用. import heapq import heapq class PriorityQueue: def __init__(self): self._queue = [] self._index = 0 def push(self, item, priority): heapq.heappush(self._queue, (-priority, self._index, item)) self._index += 1 def pop(self): return heapq.heappop(self._queue)[-1] class Item: def __init__(self, name): self.name = name def __repr__(self): return 'Item({!r})'.format(self.name) q = PriorityQueue() q.push(Item('foo'), 1) q.push(Item('bar'), 5) q.push(Item('spam'), 4) q.push(Item('grok'), 1) q.pop() Item('bar') q.pop() Item('spam') 元组tuple 元组是不可变序列,构造函数为tuple(seq),也可以使用(,)来快速构建. 元组如果保存元素都不是容器,那么元组就是真正的不可变的,否则还是会根据内部元素的改变而改变. 具名元组 collections.namedtuple是一个工厂函数,它可以用来构建一个带字段名的元组和一个有名字的类——这个带名字的类对调试程序有很大帮助. 用namedtuple构建的类的实例所消耗的内存跟元组是一样的,因为字段名都被存在对应的类里面.这个实例跟普通的对象实例比起来也要小一些,因为Python不会用__dict__来存放这些实例的属性. from collections import namedtuple City = namedtuple('City', 'name country population coordinates') tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) tokyo City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 139.691667)) tokyo.population 36.933 除了从普通元组那里继承来的属性之外,具名元组还有一些自己专有的属性.下面的例子展示了几个最有用的: _fields 类属性 _fields属性是一个包含这个类所有字段名称的元组. City._fields ('name', 'country', 'population', 'coordinates') 类方法_make(iterable) _make()通过接受一个可迭代对象来生成这个类的一个实例 LatLong = namedtuple('LatLong', 'lat long') delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889)) delhi = City._make(delhi_data) 实例方法_asdict() _asdict()把具名元组以collections.OrderedDict的形式返回,我们可以利用它来把元组里的信息友好地呈现出来 delhi._asdict() OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', LatLong(lat=28.613889, long=77.208889))]) for key, value in delhi._asdict().items(): print(key + ':', value) name: Delhi NCR country: IN population: 21.935 coordinates: LatLong(lat=28.613889, long=77.208889) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:11:26 "},"语法篇/内置容器/映射对象.html":{"url":"语法篇/内置容器/映射对象.html","title":"映射对象","keywords":"","body":"映射对象 python的实现中映射对象被大量使用,对象中元素的自省默认就是用映射实现的.由于有内置的映射对象,python的表现力高于许多其他语言. 本节的先验知识有: 协议与接口与抽象基类 映射和集合对象的范畴 python中的映射类型分为两类: 可变映射 不可变映射 python目前的内建映射包括dict,defaultdict ,OrderedDict,集合包括set和frozenset,其中都是可变映射 字典类型不但在各种程序里广泛使用,它也是Python语言的基石.模块的命名空间、实例的属性和函数的关键字参数中都可以看到字典的身影.跟它有关的内置函数都在__builtins__.__dict__模块中. 正是因为字典至关重要,Python对它的实现做了高度优化,而散列表则是字典类型性能出众的根本原因. 集合(set)的实现其实也依赖于散列表,因此映射类型的关键就在于理解散列表的原理. dict的实现的优缺点 下面的内容会讨论使用散列表给dict带来的优势和限制都有哪些 键必须是可散列的 一个可散列的对象必须满足以下要求 支持hash()函数，并且通过__hash__()方法所得到的散列值是不变的 支持通过__eq__()方法来检测相等性 若a == b为真，则hash(a) == hash(b)也为真. 键的次序取决于添加顺序 当往dict里添加新键而又发生散列冲突的时候,新键可能会被安排存放到另一个位置.于是下面这种情况就会发生:由dict([key1, value1), (key2, value2)] 和dict([key2,value2], [key1, value1])得到的两个字典,在进行比较的时候它们是相等的;但是如果在key1 和key2被添加到字典里的过程中有冲突发生的话,这两个键出现在字典里的顺序是不一样的. 往字典里添加新键可能会改变已有键的顺序 无论何时往字典里添加新的键,Python解释器都可能做出为字典扩容的决定.扩容导致的结果就是要新建一个更大的散列表,并把字典里已有的元素添加到新表里.这个过程中可能会发生新的散列冲突,导致新散列表中键的次序变化.要注意的是上面提到的这些变化是否会发生以及如何发生都依赖于字典背后的具体实现,因此你不能很自信地说自己知道背后发生了什么.如果你在迭代一个字典的所有键的过程中同时对字典进行修改,那么这个循环很有可能会跳过一些键——甚至是跳过那些字典中已经有的键.由此可知不要对字典同时进行迭代和修改.如果想扫描并修改一个字典,最好分成两步来进行:首先对字典迭代,以得出需要添加的内容,把这些内容放在一个新字典里;迭代结束之后再对原有字典进行更新. 键查询很快 dict 的实现是典型的空间换时间:字典类型有着巨大的内存开销,但它们提供了无视数据量大小的快速访问——只要字典能被装在内存里 字典在内存上的开销巨大 由于字典使用了散列表,而散列表又必须是稀疏的,这导致它在空间上的效率低下.举例而言,如果你需要存放数量巨大的记录,那么放在由元组或是具名元组构成的列表中会是比较好的选择;最好不要根据JSON的风格,用由字典组成的列表来存放这些记录.用元组取代字典就能节省空间的原因有两个: 避免了散列表所耗费的空间 无需把记录中字段的名字在每个元素里都存一遍 在用户自定义的类型中,__slots__属性可以改变实例属性的存储方式,由dict变成tuple 集合和字典使用的实现类似,因此字典的特点也可以套用在集合中. 从UML图中可以看出,与序列对象也是Contaner,也是Sized也是Iterable,而不同之处就是在于Mapping和MutableMapping. 这些接口为字典对象带来了很多实用接口 字典 字典的方法: adict.clear() 删除字典中的所有项或元素; adict.copy() 返回一个字典浅拷贝的副本; adict.fromkeys(seq, val=None) 创建并返回一个新字典,以seq中的元素做该字典的键,val做该字典中所有键对应的初始值(默认为None); adict.get(key, default = None) 返回字典中key对应的值,若key不存在字典中,则返回default的值(default默认为None); adict.has_key(key) 如果key在字典中,返回True,否则返回False.现在用in 、 not in; adict.items() 返回一个包含所有(键,值)元祖的列表; adict.keys() 返回所有的keys形成的列表; adict.pop(key[,default]) 和get方法相似.如果字典中存在key,删除并返回key对应的vuale;如果key不存在,且没有给出default的值,则引发keyerror异常; adict.popitem() 和pop类似,只是返回一个(key,value)的元组; adict.setdefault(key, default=None) 和set()方法相似,但如果字典中不存在Key键，由adict[key] = default为它赋值; adict.update(bdict) 将字典bdict的键值对添加到字典adict中; adict.values() 返回一个包含字典所有value的列表; 而defaultdict的额外接口为: adict.default_factory()在__missing__函数中被调用的函数,用以给未找到的元素设置值 d.__missing__(k) 当__getitem__找不到对应键的时候,这个方法会被调用.所有的映射类型在处理找不到的键的时候,都会牵扯到__missing__方法.这也是这个方法称作\"missing\"的原因.虽然基类dict并没有定义这个方法,但是dict是知道有这么个东西存在的.也就是说,如果有一个类继承了dict,然后这个继承类提供了__missing__方法,那么在__getitem__碰到找不到的键的时候,Python 就会自动调用它,而不是抛出一个KeyError异常 而OrderedDict与一般字典一样,只是它内部的元素有顺序 字典推导 字典也可以通过字典推导来构建,它需要一个可迭代对象来创建,同样也支持if语句做筛选 {i[0]:i[1] for i in ((\"a\",1),(\"b\",2),(\"c\",3),(\"d\",3))} {'a': 1, 'b': 2, 'c': 3, 'd': 3} 字典的变种 collections标准库中包含两种字典变种 collections.ChainMap 该类型可以容纳数个不同的映射对象,然后在进行键查找操作的时候,这些对象会被当作一个整体被逐个查找,直到键被找到为止.这个功能在给有嵌套作用域的语言做解释器的时候很有用,可以用一个映射对象来代表一个作用域的上下文. from collections import ChainMap a = {\"a\":1,\"b\":2,\"c\":3} b= {\"q\":1,\"w\":2,\"e\":3} c = ChainMap(a,b) c ChainMap({'a': 1, 'b': 2, 'c': 3}, {'q': 1, 'w': 2, 'e': 3}) for i,k in c.items(): print(i,k) a 1 b 2 w 2 c 3 q 1 e 3 collections.Counter 这个映射类型会给键准备一个整数计数器.每次更新一个键的时候都会增加这个计数器.所以这个类型可以用来给可散列表对象计数,或者是当成多重集来用——多重集合就是集合里的元素可以出现不止一次.Counter实现了+ 和- 运算符用来合并记录,还有像most_common([n])这类很有用的方法most_common([n]) 会按照次序返回映射里最常见的n个键和它们的计数 from collections import Counter a_count = Counter('abracadabra') a_count Counter({'a': 5, 'b': 2, 'c': 1, 'd': 1, 'r': 2}) b_count = Counter('abracadabra') b_count Counter({'a': 5, 'b': 2, 'c': 1, 'd': 1, 'r': 2}) a_count+b_count Counter({'a': 10, 'b': 4, 'c': 2, 'd': 2, 'r': 4}) 映射的弹性建查询 有时候为了方便起见,就算某个键在映射里不存在,我们也希望在通过这个键读取值的时候能得到一个默认值.有两个途径能帮我们达到这个目的,一个是通过defaultdict这个类型而不是普通的dict,另一个是给自己定义一个dict 的子类,然后在子类中实现__missing__方法.下面将介绍这两种方法 defaultdict 在用户创建defaultdict对象的时候,就需要给它配置一个为找不到的键创造默认值的方法. 具体而言，在实例化一个defaultdict的时候,需要给构造方法提供一个可调用对象,这个可调用对象会在__getitem__碰到找不到的键的时候被调用,让__getitem__ 返回某种默认值. 比如，我们新建了这样一个字典:dd = defaultdict(list),如果键'new-key'在dd中还不存在的话,表达式dd['new-key']会按照以下的步骤来行事. 调用list() 来建立一个新列表 把这个新列表作为值,'new-key'作为它的键,放到dd 中 返回这个列表的引用 而这个用来生成默认值的可调用对象存放在名为default_factory 的实例属性里. 创建一个从单词到其出现情况的映射 from collections import defaultdict import re WORD_RE = re.compile(r'\\w+') # 把list 构造方法作为default_factory 来创建一个defaultdict # 如果index 并没有word 的记录，那么default_factory 会被调用，为查询不到的键创造 #一个值。这个值在这里是一个空的列表，然后这个空列表被赋值给index[word]，继而 # 被当作返回值返回，因此.append(location) 操作总能成功。 index = defaultdict(list) line = input(\"输入一句话:\") for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = column_no index[word].append(location) for word in sorted(index, key=str.upper): print(word, index[word]) 输入一句话: 如果在创建defaultdict 的时候没有指定default_factory,查询不存在的键会触发KeyError defaultdict 里的default_factory只会在__getitem__ 里被调用,在其他的方法里完全不会发挥作用.比如,dd 是个defaultdict,k 是个找不到的键,dd[k]这个表达式会调用default_factory 创造某个默认值,而dd.get(k)则会返回None 所有这一切背后的功臣其实是特殊方法__missing__.它会在defaultdict遇到找不到的键的时候调用default_factory,而实际上这个特性是所有映射类型都可以选择去支持的. 特殊方法__missing__ 所有的映射类型在处理找不到的键的时候,都会牵扯到__missing__ 方法.这也是这个方法称作\"missing\"的原因.虽然基类dict并没有定义这个方法,但是dict 是知道有这么个东西存在的.也就是说如果有一个类继承了dict,然后这个继承类提供了__missing__ 方法,那么在__getitem__碰到找不到的键的时候,Python 就会自动调用它,而不是抛出一个KeyError 异常. 自定义映射类型 如果要自定义一个映射类型,更合适的策略其实是继承collections.UserDict类.这里我们从dict继承.下面一个例子我们自定义一个在查询的时候把非字符串的键转换为字符串的字典子类 from collections import UserDict class StrKeyDict(UserDict): def __missing__(self, key): if isinstance(key, str): raise KeyError(key) return self[str(key)] def __setitem__(self, key, item): self.data[str(key)] = item def __contains__(self, key): return str(key) in self.data 不可变映射类型MappingProxyType 标准库里所有的映射类型都是可变的,但有时候你会有这样的需求,比如不能让用户错误地修改某个映射. 从Python 3.3开始,types 模块中引入了一个封装类名叫MappingProxyType.如果给这个类一个映射,它会返回一个只读的映射视图.虽然是个只读视图,但是它是动态的.这意味着如果对原映射做出了改动,我们通过这个视图可以观察到,但是无法通过这个视图对原映射做出修改.下面的简短地对这个类的用法做了个演示. from types import MappingProxyType d = {1:'A'} d_proxy = MappingProxyType(d) d_proxy mappingproxy({1: 'A'}) d_proxy[1] 'A' d_proxy[2] = 'x' --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 d_proxy[2] = 'x' TypeError: 'mappingproxy' object does not support item assignment d[2] = 'B' d_proxy mappingproxy({1: 'A'}) d_proxy[2] --------------------------------------------------------------------------- KeyError Traceback (most recent call last) in () ----> 1 d_proxy[2] KeyError: 2 集合 python中的集合有两种类型: set 标准集合 frozenset 可散列集合 集合的本质是许多唯一对象的聚集.因此,集合可以用于去重. 集合中的元素必须是可散列的,set类型本身是不可散列的,但是frozenset可以.因此可以创建一个包含不同frozenset 的set. l = ['spam', 'spam', 'eggs', 'spam'] set(l) {'eggs', 'spam'} frozenset(l) frozenset({'eggs', 'spam'}) 除了保证唯一性,集合还实现了很多基础的中缀运算符.给定两个集合a和b: a | b ,a |= b,a.union(b,c,d...) 返回的是它们的合集 a & b,a &= b,a.intersection(b,c,d...),a.intersection_update(b,c,d...) 得到的是交集 a - b ,a -= b,a.difference(b,c,d...),a.difference_update(b,c,d...)得到的是差集 a ^ b,s ^= z,a.symmetric_difference_update(b,c,d...)得到的是对称差集 s.__contains__(e) 元素e 是否属于s s s 是否为z 的子集 s.issubset(it) 把可迭代的it 转化为集合，然后查看s 是否为它的子集 s s 是否为z 的真子集 s >= z s 是否为z 的父集 s.issuperset(it) 把可迭代的it 转化为集合，然后查看s 是否为它的父集 s > z s 是否为z 的真父集 合理地利用这些操作,不仅能够让代码的行数变少,还能减少Python程序的运行时间.这样做同时也是为了让代码更易读,从而更容易判断程序的正确性,因为利用这些运算符可以省去不必要的循环和逻辑操作. 例如:我们有一个电子邮件地址的集合haystack,还要维护一个较小的电子邮件地址集合needles,然后求出needles中有多少地址同时也出现在了heystack 里.借助集合操作,我们只需要一行代码就可以了 found = len(needles & haystack) 集合字面量 除空集之外,集合的字面量——{1}、{1, 2},等等——看起来跟它的数学形式一模一样 如果是空集,那么必须写成set()的形式. 在Python 3里面,除了空集，集合的字符串表示形式总是以{...}的形式出现 s = {1} type(s) set s {1} s.pop() 1 s set() 像{1, 2, 3}这种字面量句法相比于构造方法(set([1, 2, 3]))要更快且更易读.后者的速度要慢一些,因为Python 必须先从set这个名字来查询构造方法,然后新建一个列表,最后再把这个列表传入到构造方法里.但是如果是像{1, 2, 3}这样的字面量,Python 会利用一个专门的叫作BUILD_SET的字节码来创建集合. 由于Python里没有针对frozenset 的特殊字面量句法,我们只能采用构造方法. 集合推导 Python 2.7带来了集合推导(setcomps)和之前在3.2 节里讲到过的字典推导类似 例子:把编码在32~255 之间的字符的名字里有\"SIGN\"单词的挑出来,放到一个集合里. from unicodedata import name {chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i),'')} {'#', '$', '%', '+', '', '¢', '£', '¤', '¥', '§', '©', '¬', '®', '°', '±', 'µ', '¶', '×', '÷'} *可散列对象 在Python 词汇表中,关于可散列类型的定义有这样一段话: 如果一个对象是可散列的,那么在这个对象的生命周期中,它的散列值是不变的,而且这个对象需要实现__hash__()方法.另外可散列对象还要有__qe__() 方法,这样才能跟其他键做比较.如果两个可散列对象是相等的,那么它们的散列值一定是一样的. 原子不可变数据类型(str、bytes 和数值类型)都是可散列类型,frozenset也是可散列的,因为根据其定义,frozenset里只能容纳可散列类型.元组的话,只有当一个元组包含的所有元素都是可散列类型的情况下,它才是可散列的. 一般来讲用户自定义的类型的对象都是可散列的,散列值就是它们的id()函数的返回值,所以所有这些对象在比较的时候都是不相等的.如果一个对象实现了__eq__方法,并且在方法中用到了这个对象的内部状态的话,那么只有当所有这些内部状态都是不可变的情况下,这个对象才是可散列的. *散列表 散列表其实是一个稀疏数组(总是有空白元素的数组称为稀疏数组).在一般的数据结构教材中,散列表里的单元通常叫作表元(bucket).在dict的散列表当中,每个键值对都占用一个表元,每个表元都有两个部分,一个是对键的引用,另一个是对值的引用.因为所有表元的大小一致,所以可以通过偏移量来读取某个表元. 因为Python会设法保证大概还有三分之一的表元是空的,所以在快要达到这个阈值的时候,原有的散列表会被复制到一个更大的空间里面.如果要把一个对象放入散列表,那么首先要计算这个元素键的散列值.Python中可以用hash()方法来做这件事情,接下来会介绍这一点. 散列值和相等性 内置的hash()方法可以用于所有的内置类型对象.如果是自定义对象调用hash()的话,实际上运行的是自定义的__hash__.如果两个对象在比较的时候是相等的,那它们的散列值必须相等,否则散列表就不能正常运行了.例如,如果1 == 1.0 为真,那么hash(1) ==hash(1.0)也必须为真,但其实这两个数(整型和浮点)的内部结构是完全不一样的.为了让散列值能够胜任散列表索引这一角色,它们必须在索引空间中尽量分散开来.这意味着在最理想的状况下,越是相似但不相等的对象,它们散列值的差别应该越大. 从Python 3.3开始,str、bytes 和datetime对象的散列值计算过程中多了随机的\"加盐\"这一步.所加盐值是Python进程内的一个常量,但是每次启动Python解释器都会生成一个不同的盐值.随机盐值的加入是为了防止DOS攻击而采取的一种安全措施. *散列表算法 在映射中,为了获取my_dict[search_key] 背后的值,Python首先会调用hash(search_key)来计算search_key的散列值,把这个值最低的几位数字当作偏移量,在散列表里查找表元(具体取几位,得看当前散列表的大小).若找到的表元是空的,则抛出KeyError异常.若不是空的,则表元里会有一对found_key:found_value.这时候Python会检验search_key ==found_key是否为真,如果它们相等的话,就会返回found_value.如果search_key和found_key不匹配的话,这种情况称为散列冲突.发生这种情况是因为,散列表所做的其实是把随机的元素映射到只有几位的数字上,而散列表本身的索引又只依赖于这个数字的一部分.为了解决散列冲突,算法会在散列值中另外再取几位,然后用特殊的方法处理一下,把新得到的数字再当作索引来寻找表元. 若这次找到的表元是空的,则同样抛出KeyError; 若非空,或者键匹配,则返回这个值; 或者又发现了散列冲突,则重复以上的步骤. 添加新元素和更新现有键值的操作几乎跟上面一样.只不过对于前者,在发现空表元的时候会放入一个新元素,对于后者在找到相对应的表元后,原表里的值对象会被替换成新值.另外在插入新值时Python可能会按照散列表的拥挤程度来决定是否要重新分配内存为它扩容.如果增加了散列表的大小,那散列值所占的位数和用作索引的位数都会随之增加,这样做的目的是为了减少发生散列冲突的概率. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:33:41 "},"语法篇/内置容器/可迭代对象与生成器.html":{"url":"语法篇/内置容器/可迭代对象与生成器.html","title":"可迭代对象与生成器","keywords":"","body":"可迭代对象与生成器 可迭代对象和生成器是python的核心卖点之一,这一特性让它看起来像是函数式编程语言,也让他的性能和表现力上了一个层次,同时它让用户可以面向流编程.这个特性的来源应该是古老的Lisp,而受Python影响javascript也在ES6中新增了生成器相关的工具,总而言之这个语法点非常重要. 本节的先验知识有: 协议与接口与抽象基类 可迭代对象,迭代器的范畴 凡是满足Iterable协议的都是可迭代对象.因此所有的容器都是可迭代对象,可迭代对象不管容量的大小,只要每次for循环都可以取出对象即可,因此迭代是数据处理的基石.扫描内存中放不下的数据集时，我们要找到一种惰性获取数据项的方式，即按需一次获取一个数据项.这就是迭代器模式(Iterator pattern).而符合这一特征的数据类型就是Iterator迭代器.Iterator除了有__iter__外还要实现next方法. 生成器 生成器是python中最中要的数据模型之一,由它衍生而来的协程可以看这篇文章了解. 生成器实现需要实现接口__iter__,__next__,send,throw这4个方法,但也有更加简单的方式实现就是使用生成器函数 生成器函数就是带有yield的函数,它停止需要抛出StopIteration异常 最简单的可迭代对象--生成器表达式 列表解析通过一定的操作可以产生一个列表,而如果去掉[],那就是惰性的生成器表达式了 何时使用生成器表达式 根据我的经验,选择使用哪种句法很容易判断--如果生成器表达式要分成多行写,我倾向于定义生成器函数以便提高可读性.此外生成器函数有名称,因此可以重用. a = (i for i in range(10)) type(a) generator for i in a: print(i) 0 1 2 3 4 5 6 7 8 9 iter函数 用于创建迭代器 iter函数可以将一个可迭代对象转换为一个迭代器 a = iter([i for i in range(10)]) 序列可以迭代的原因在于解释器需要迭代对象时,会自动调用iter. 内置的iter 函数有以下作用: 检查对象是否实现了__iter__ 方法,如果实现了就调用它,获取一个迭代器. 如果没有实现__iter__ 方法,但是实现了__getitem__ 方法,Python会创建一个迭代器,尝试按顺序(从索引0开始)获取元素. 如果尝试失败,Python 抛出TypeError异常,通常会提示'xxx object is not iterable' 当iter有第二个参数的时候,iter的作用是使用常规的函数或任何可调用的对象创建迭代器.这样使用时， 第一个参数必须是可调用的对象,用于不断调用(没有参数),产出各个值 第二个值是哨符,这是个标记值,当可调用的对象返回这个值时,触发迭代器抛出StopIteration异常,而不产出哨符. from random import randint b = iter(lambda : randint(1,10),5) for i in b: print(i) 7 1 9 9 3 3 7 7 3 2 7 1 10 7 8 1 1 10 8 可迭代对象的操作 拆包操作 python3支持可迭代对象的拆包操作,并且可以结合通配符达到一些很酷的效果 _,x,*last=range(10) x 1 last [2, 3, 4, 5, 6, 7, 8, 9] 排序操作 内置函数sorted(iterable,key,reverse=False,)会新建一个列表作为返回值.这个方法可以接受任何形式的可迭代对象作为参数,而不管sorted接受的是怎样的参数,它最后都会返回一个列表. 其中参数reverse如果被设定为True,被排序的序列里的元素会以降序输出(也就是说把最大值当作最小值来排序). 参数key则为一个只有一个参数的函数,这个函数会被用在序列里的每一个元素上,所产生的结果将是排序算法依赖的对比关键字.比如说,在对一些字符串排序时,可以用key=str.lower来实现忽略大小写的排序,或者是用key=len进行基于字符串长度的排序.这个参数的默认值是恒等函数identity function,也就是默认用元素自己的值来排序 sorted([11,3,4,2,5]) [2, 3, 4, 5, 11] 堆排序 python的标准库heapq提供了将列表转换为堆的算法支持 堆是二叉树,每个父节点具有小于或等于其任何子节点的值.该实现使用数组,对于所有k,从零开始计数元素, heap [k] 和heap [k] 为了比较,不存在的元素被认为是无限的.堆的有趣属性是它的最小元素总是根heap[0]. 方法有: heapq.heappush(heap, item) 向堆中插入元素 heapq.heappop(heap) 从堆中取出最小元素 heapq.heappushpop(heap, item) 插入元素在取出最小元素 heapq.heapify(x) 将一个列表注册为堆 heapq.heapreplace(heap, item) 移除堆中的某个元素 heapq.merge(*iterables, key=None, reverse=False) 将多个排序输入合并到单个排序的输出(例如，从多个日志文件中合并时间戳条目).返回排序值的迭代器 heapq.nlargest(n, iterable, key=None) 取可迭代对象中最大的n个元素 heapq.nsmallest(n, iterable, key=None) 取可迭代对象中最大的n个元素 import heapq def heapsort(iterable): h = [] for value in iterable: heapq.heappush(h, value) return [heapq.heappop(h) for i in range(len(h))] heapsort([11,3,4,2,5]) [2, 3, 4, 5, 11] c = [11,3,4,2,5] heapq.heapify(c) c [2, 3, 4, 11, 5] [heapq.heappop(c) for i in range(len(c))] [2, 3, 4, 5, 11] 排序性能测试 from random import randint,random a = [randint(1,100) for i in range(50)] aa = [randint(1,10000) for i in range(5000)] aaa = [randint(1,1000000) for i in range(5000000)] b = [random() for i in range(50)] bb = [random() for i in range(5000)] bbb = [random() for i in range(5000000)] %timeit heapsort(a) 15.9 µs ± 229 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit sorted(a) 2.92 µs ± 79.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit heapsort(aa) 2.11 ms ± 19.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) %timeit sorted(aa) 877 µs ± 11.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) %timeit heapsort(aaa) 13.2 s ± 72 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) %timeit sorted(aaa) 3.95 s ± 14.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) %timeit heapsort(b) 15.1 µs ± 65.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit sorted(b) 2.78 µs ± 45.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit heapsort(bb) 2.25 ms ± 52.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) %timeit sorted(bb) 905 µs ± 4.76 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) %timeit heapsort(bbb) 9.84 s ± 524 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) %timeit sorted(bbb) 3.38 s ± 61.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) 可以看出,堆排序效率并不如自带的排序算法效率高,那么堆有什么作用呢?简单来说就是插入和查找方便,堆会在每次都将数据存入与自己大小匹配的 用bisect来管理已排序的序列 bisect模块的主要作用是管理有序序列. bisect模块包含两个主要函数bisect 和insort,两个函数都利用二分查找算法来在有序序列中查找或插入元素. bisect(a, x[, lo[, hi]]) bisect的作用是查找x元素在a序列中的位置.它的表现可以从两个方面来调教: 首先可以用它的两个可选参数——lo和hi——来缩小搜寻的范围,lo的默认值是0,hi的默认值是序列的长度,即len()作用于该序列的返回值 bisect函数其实是bisect_right函数的别名，后者还有个姊妹函数叫bisect_left.的区别在于,bisect_left返回的插入位置是原序列中跟被插入元素相等的元素的位置,也就是新元素会被放置于它相等的元素的前面,而bisect_right返回的则是跟它相等的元素之后的位置.这个细微的差别可能对于整数序列来讲没什么用,但是对于那些值相等但是形式不同的数据类型来讲结果就不一样了. insort(a, x[, lo[, hi]]) 排序很耗时,因此在得到一个有序序列之后,我们最好能够保持它的有序.bisect.insort就是为了这个而存在的.insort(seq, item) 把变量item 插入到序列seq中,并能保持seq的升序顺序. 例子:用bisect来搜索 bisect(haystack, needle)|bisect_left(haystack, needle) 在haystack(干草垛)里搜索needle(针)的位置,该位置满足的条件是:把needle 插入这个位置之后,haystack 还能保持升序.也就是在说这个函数返回的位置前面的值,都小于或等于needle的值.其中haystack必须是一个有序的序列. 你可以先用bisect(haystack, needle) 查找位置index,再用haystack.insert(index,needle)来插入新值.但你也可用insort来一步到位,并且后者的速度更快一些. import bisect import sys HAYSTACK = [1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30] NEEDLES = [0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31] ROW_FMT = '{0:2d} @ {1:2d} {2}{0: def demo(bisect_fn): for needle in reversed(NEEDLES): position = bisect_fn(HAYSTACK, needle) offset = position * ' |' print(ROW_FMT.format(needle, position, offset)) bisect_fn = bisect.bisect print('DEMO:', bisect_fn.__name__) print('haystack ->', ' '.join('%2d' % n for n in HAYSTACK)) demo(bisect_fn) DEMO: bisect haystack -> 1 4 5 6 8 12 15 20 21 23 23 26 29 30 31 @ 14 | | | | | | | | | | | | | |31 30 @ 14 | | | | | | | | | | | | | |30 29 @ 13 | | | | | | | | | | | | |29 23 @ 11 | | | | | | | | | | |23 22 @ 9 | | | | | | | | |22 10 @ 5 | | | | |10 8 @ 5 | | | | |8 5 @ 3 | | |5 2 @ 1 |2 1 @ 1 |1 0 @ 0 0 bisect_fn = bisect.bisect_left print('DEMO:', bisect_fn.__name__) print('haystack ->', ' '.join('%2d' % n for n in HAYSTACK)) demo(bisect_fn) DEMO: bisect_left haystack -> 1 4 5 6 8 12 15 20 21 23 23 26 29 30 31 @ 14 | | | | | | | | | | | | | |31 30 @ 13 | | | | | | | | | | | | |30 29 @ 12 | | | | | | | | | | | |29 23 @ 9 | | | | | | | | |23 22 @ 9 | | | | | | | | |22 10 @ 5 | | | | |10 8 @ 4 | | | |8 5 @ 2 | |5 2 @ 1 |2 1 @ 0 1 0 @ 0 0 例:用bisect.insort插入新元素 import bisect import random SIZE=7 random.seed(1729) my_list = [] for i in range(SIZE): new_item = random.randrange(SIZE*2) bisect.insort(my_list, new_item) print('%2d ->' % new_item, my_list) 10 -> [10] 0 -> [0, 10] 6 -> [0, 6, 10] 8 -> [0, 6, 8, 10] 7 -> [0, 6, 7, 8, 10] 2 -> [0, 2, 6, 7, 8, 10] 10 -> [0, 2, 6, 7, 8, 10, 10] 内置的可迭代对象 可迭代对象作为python最中要的特性之一,已经被很多语言借鉴吸收,比如javascript在ES6标准中实现了生成器. python3有大量的内置可迭代对象 range(start,end,step) 生成整数等差数列对象 [i for i in range(1,10,3)] [1, 4, 7] 更多的可迭代对象可以则包括在标准库itertools中 itertools.count(start,step) 生成无穷等差数列 from itertools import count gen = count(1,0.5) for i in range(5): print(next(gen)) 1 1.5 2.0 2.5 3.0 itertools.cycle(it) 从it 中产出各个元素,存储各个元素的副本,然后按顺序重复不断地产出各个元素 from itertools import cycle gen = cycle([1,2,3]) for i in range(5): print(next(gen)) 1 2 3 1 2 itertools.repeat(item, [times]) 重复不断地产出指定的元素，除非提供times，指定次数 from itertools import repeat gen = repeat(1) for i in range(5): print(next(gen)) 1 1 1 1 1 itertools.permutations(it,out_len=None) 把out_len 个it 产出的元素排列在一起,然后产出这些排列;out_len 的默认值等于len(list(it)) from itertools import permutations gen = permutations([1,2,3],2) for i in gen: print(i) (1, 2) (1, 3) (2, 1) (2, 3) (3, 1) (3, 2) itertools.combinations(it,out_len) 把it 产出的out_len 个元素组合在一起,然后产出 from itertools import combinations gen = combinations([1,2,3],2) for i in gen: print(i) (1, 2) (1, 3) (2, 3) itertools.combinations_with_replacement(it, out_len) 把it产出的out_len个元素组合在一起,然后产出,包含相同元素的组合 from itertools import combinations_with_replacement gen = combinations_with_replacement([1,2,3],2) for i in gen: print(i) (1, 1) (1, 2) (1, 3) (2, 2) (2, 3) (3, 3) 内置的的迭代器函数 迭代器函数是用来处理迭代器的函数,主要功能包括 过滤迭代器--用于从迭代器中剔除部分元素 映射迭代器--用于对迭代器中的元素做同样的处理 合并迭代器--用于合并多个可迭代对象从而生成一个新迭代器对象 重排迭代器--用于重新排列元素 过滤迭代器 filter(predicate, it) 把it 中的各个元素传给predicate,如果predicate(item)返回真值,那么产出对应的元素;如果predicate 是None,那么只产出真值元素 itertools.compress(it, selector_it) 并行处理两个可迭代的对象;如果selector_it中的元素是真值,产出it中对应的元素 itertools.dropwhile(predicate, it) 处理it，跳过predicate 的计算结果为真值的元素,然后产出剩下的各个元素(不再进一步检查) itertools.filterfalse(predicate, it) 与filter 函数的作用类似,不过predicate的逻辑是相反的--predicate 返回假值时产出对应的元素 itertools.islice(it, stop) 或islice(it,start, stop, step=1) 产出it的切片,作用类似于s[:stop] 或s[start:stop:step],不过it可以是任何可迭代的对象,而且这个函数实现的是惰性操作 itertools takewhile(predicate, it) predicate 返回真值时产出对应的元素,然后立即停止,不再继续检查 映射迭代器 enumerate(iterable, start=0) 产出由两个元素组成的元组,结构是(index, item),其中index 从start 开始计数,item 则从iterable 中获取 map(func, it1, [it2, ..., itN]) 把it中的各个元素传给func,产出结果;如果传入N 个可迭代的对象,那么func 必须能接受N 个参数,而且要并行处理各个可迭代的对象 itertools.accumulate(it, [func]) 产出累积的总和;如果提供了func,那么把前两个元素传给它,然后把计算结果和下一个元素传给它,以此类推，最后产出结果 itertools.starmap(func, it) 把it中的各个元素传给func,产出结果;输入的可迭代对象应该产出可迭代的元素iit,然后以func(*iit) 这种形式调用func 合并迭代器 zip(it1, ..., itN) 并行从输入的各个可迭代对象中获取元素,产出由N个元素组成的元组,只要有一个可迭代的对象到头了,就默默地停止 itertools.chain(it1, ..., itN) 先产出it1中的所有元素,然后产出it2中的所有元素,以此类推,无缝连接在一起 itertools.chain.from_iterable(it) 产出it 生成的各个可迭代对象中的元素,一个接一个,无缝连接在一起;it 应该产出可迭代的元素,例如可迭代的对象列表 itertools.product(it1, ...,itN, repeat=1) 计算笛卡儿积:从输入的各个可迭代对象中获取元素,合并成由N个元素组成的元组,与嵌套的for循环效果一样;repeat指明重复处理多少次输入的可迭代对象 itertools zip_longest(it1, ...,itN, fillvalue=None) 并行从输入的各个可迭代对象中获取元素,产出由N个元素组成的元组,等到最长的可迭代对象到头后才停止,空缺的值使用fillvalue填充 重排迭代器 itertools.groupby(it,key=None) 产出由两个元素组成的元素,形式为(key, group),其中key是分组标准,group 是生成器,用于产出分组里的元素 itertools.tee(it, n=2) 产出一个由n个生成器组成的元组,每个生成器用于单独产出输入的可迭代对象中的元素 可迭代的归约函数 所谓归约函数指接受一个可迭代的对象,然后返回单个结果的函数.python内置了许多这种函数 all(it) it 中的所有元素都为真值时返回True,否则返回False;all([]) 返回True sum(it, start=0) it 中所有元素的总和,如果提供可选的start,会把它加上(计算浮点数的加法时,可以使用math.fsum函数提高精度) any(it) 只要it中有元素为真值就返回True,否则返回False;any([]) 返回False max(it, [key=,][default=]) 返回it中值最大的元素;key 是排序函数,与sorted函数中的一样;如果可迭代的对象为空,返回default min(it, [key=,][default=]) 返回it中值最小的元素;key 是排序函数,与sorted 函数中的一样;如果可迭代的对象为空,返回default functools reduce(func, it,[initial]) 把前两个元素传给func,然后把计算结果和第三个元素传给func,以此类推,返回最后的结果;如果提供了initial,把它当作第一个元素传入 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:11:33 "},"语法篇/内置容器/结语.html":{"url":"语法篇/内置容器/结语.html","title":"结语","keywords":"","body":"结语 不同的情况使用不同的数据结构和算法 下面是Python中最常用数据结构常用操作的时间复杂度表: 容器 使用环境 list 一般用用 tuple 当内部元素不需要改变的时候用 heapq 双端队列,当元素数量巨幅变动频繁的时候使用 bisect 当元素较多且需要频繁查找时使用 deque 堆,当需要排序时使用 array 数组,当类型相同时可以使用,可以减少内存占用 set 当需要去重的时候使用 相关扩展和模块 pyrsistent 满足python内置相关协议的不可变类型扩展 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/函数/":{"url":"语法篇/函数/","title":"函数","keywords":"","body":"**函数 函数是一种组织代码的形式,而python中函数也是对象.这种一致性其实也暗合了计算的本质. 现代计算机语言往往将操作与数据区别开,但本质上操作和代码都是一样的而进制代码而已,而在数学中,函数映射和数据也是相互可以转化的. 函数式一等对象 变量作用域与闭包 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:39:03 "},"语法篇/函数/函数是一等对象.html":{"url":"语法篇/函数/函数是一等对象.html","title":"函数是一等对象","keywords":"","body":"函数是一等对象 python从来不是一门函数式编程语言,但函数确实是一等对象,准确的说函数和其他对象一样,都是平等的. 编程语言理论家把'一等对象'定义为满足下述条件的程序实体: 在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 Python函数是对象.这里我们创建了一个函数,然后调用它,读取它的__doc__属性,并且确定函数对象本身是function类的实例 def factorial(n): \"\"\"return n!\"\"\" return 1 if n factorial(42) 1405006117752879898543142606244511569936384000000000 factorial.__doc__ 'return n!' type(factorial) function 可以看到它和其他对象形式上是保持一致的. 有了一等函数,就可以使用函数式风格编程.函数式编程的特点之一是使用高阶函数 高阶函数 接受函数为参数,或者把函数作为结果返回的函数是高阶函数(higher-order function).内置的map,reduce,filter,sorted等都是高阶函数的代表,这边不再复述. 最为人熟知的高阶函数有map、filter、reduce 和 apply. apply函数在Python 3中已经移除了,因为不再需要它了.如果想使用不定量的参数调用函数,可以编写fn(*args, **keywords),不用再编写apply(fn, args, kwargs) map,filter 和reduce这三个高阶函数还能见到,不过多数使用场景下都有更好的替代品. map、filter和reduce的现代替代品 函数式语言通常会提供map、filter和reduce三个高阶函数(有时使用不同的名称).在Python 3中,map和 filter还是内置函数,但是由于引入了列表推导和生成器表达式,它们变得没那么重要了.列表,字典,集合推导或生成器表达式具有map 和filter两个函数的功能,而且更易于阅读,具体的可以看数据结构预算法中相关的内容. 内置的高阶函数与可迭代对象有着很强的关联.这是python3的一项优化,通过延迟计算可以节省内存. 匿名函数 lambda关键字在Python表达式内创建匿名函数. 然而,Python 简单的句法限制了lambda函数的定义体只能使用纯表达式.换句话说,lambda函数的定义体中不能赋值,也不能使用while和try等 Python 语句. 在参数列表中最适合使用匿名函数.比如sorted中就可以用lambda表达式 fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] sorted(fruits, key=lambda word: word[::-1]) ['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry'] 除了作为参数传给高阶函数之外,Python 很少使用匿名函数.由于句法上的限制,非平凡的lambda表达式要么难以阅读,要么无法写出 如果使用lambda表达式导致一段代码难以理解,PIL的作者\"Fredrik Lundh\"建议像下面这样重构 编写注释,说明lambda表达式的作用。 研究一会儿注释,并找出一个名称来概括注释. 把lambda表达式转换成def语句,使用那个名称来定义函数. 删除注释. lambda句法只是语法糖--与def语句一样,lambda表达式会创建函数对象.这是Python中几种可调用对象的一种.下一节会说明所有可调用对象 可调用对象 除了用户定义的函数,调用运算符(即 ())还可以应用到其他对象上.如果想判断对象能否调用,可以使用内置的callable()函数.Python数据模型文档列出了8种可调用对象. 用户定义的函数 使用def语句或lambda表达式创建 内置函数 使用C语言(CPython)实现的函数,如len或time.strftime 内置方法使用 C 语言实现的方法,如dict.get 方法 在类的定义体中定义的函数 类 调用类既是创建实例 类的实例 如果类定义了__call__方法,那么它的实例可以作为函数调用 生成器函数 使用yield关键字的函数或方法.调用生成器函数返回的是生成器对象 协程 使用async def创建 callable(...)函数可以用于判定对象是否是可调用的对象 用户定义的可调用类型 不仅Python函数是真正的对象,任何Python对象都可以表现得像函数.为此只需实现实例方法__call__. 例:BingoCage类.这个类的实例使用任何可迭代对象构建,而且会在内部存储一个随机顺序排列的列表.调用实例会取出一个元素 import random class BingoCage: def __init__(self, items): self._items = list(items) random.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): return self.pick() bingo = BingoCage(range(3)) bingo.pick() 2 bingo() 1 callable(bingo) True 函数内省 函数对象还有很多属性.使用dir函数可以探知函数具有的属性.这其中大多数属性是Python对象共有的.与函数对象相关的几个属性有: __annotations__参数和返回值的注解 __call__实现 () 运算符;即可调用对象协议 __closure__函数闭包,即自由变量的绑定(通常是 None) __code__编译成字节码的函数元数据和函数定义体 __defaults__形式参数的默认值 __get__实现只读描述符协议 __globals__函数所在模块中的全局变量 __kwdefaults__仅限关键字形式参数的默认值 __name__ 函数名称 __qualname__函数的限定名称,如 Random.choice 从定位参数到仅限关键字参数 Python最好的特性之一是提供了极为灵活的参数处理机制,而且Python 3进一步提供了仅 限关键字参数(keyword-only argument).与之密切相关的是,调用函数时使用*和**\"展开\"可迭代对象,映射到单个参数. 仅限关键字参数是Python 3新增的特性.用于指定参数只能通过关键字参数指定,而一定不会捕获未命名的定位参数. 定义函数时若想指定仅限关键字参数,要把它们放到前面有*的参数后面.如果不想支持数量不定的定位参数,但是想支持仅限关键字参数,在签名中放一个*. def f(a, *, b): return a, b f(1, b=2) (1, 2) f(1,2) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 f(1,2) TypeError: f() takes 1 positional argument but 2 were given 仅限关键字参数不一定要有默认值,可以像上例中 b 那样,强制必须传入实参. 要获取一个函数的参数签名,可以使用inspect模块 inspect.signature函数返回一个inspect.Signature对象,它有一个parameters属性,这是一个有序映射,把参数名和inspect.Parameter对象对应起来.各个Parameter属性也有自己的属性,例如name、default 和 kind.特殊的inspect._empty值表示没有默认值.考虑到None是有效的默认值(也经常这么做),而且这么做是合理的.kind属性的值是_ParameterKind类中的5个值之一,列举如下: POSITIONAL_OR_KEYWORD 可以通过定位参数和关键字参数传入的形参(多数 Python 函数的参数属于此类) VAR_POSITIONAL 定位参数元组 VAR_KEYWORD 关键字参数字典 KEYWORD_ONLY 仅限关键字参数 POSITIONAL_ONLY 仅限定位参数;目前,Python 声明函数的句法不支持,但是有些使用 C 语言实现且不接受关键字参数的函数(如divmod)支持 除了name、default 和 kind,inspect.Parameter 对象还有一个annotation属性,它的值通常是inspect._empty,这部分与类型注释和检验有关 from inspect import signature sig = signature(f) for name, param in sig.parameters.items(): print(param.kind, ':', name, '=', param.default) POSITIONAL_OR_KEYWORD : a = KEYWORD_ONLY : b = inspect.Signature对象有个bind方法,它可以把任意个参数绑定到签名中的形参上,所用的规则与实参到形参的匹配方式一样.框架可以使用这个方法在真正调用函数前验证参数 my_tag = {\"a\":22,\"b\":12} bound_args = sig.bind(**my_tag) bound_args for name, param in bound_args.arguments.items(): print(name, '=', param) a = 22 b = 12 支持函数式编程的包 虽然python之父 \"Guido\" 明确表明,Python的目标不是变成函数式编程语言,但是得益于operator和functools等包的支持,函数式编程风格也可以信手拈来. operator模块 在函数式编程中,经常需要把算术运算符当作函数使用.例如,不使用递归计算阶乘.求和可以使用sum函数,但是求积则没有这样的函数.我们可以使用reduce函数,但是需要一个函数计算序列中两个元素之积. operator模块为多个算术运算符提供了对应的函数,从而避免编写lambda a, b: a*b这种平凡的匿名函数. from functools import reduce from operator import mul def fact(n): return reduce(mul, range(1, n+1)) operator模块中还有一类函数,能替代从序列中取出元素或读取对象属性的lambda表达式,因此itemgetter 和 attrgetter 其实会自行构建函数 metro_data = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] from operator import itemgetter for city in sorted(metro_data, key=itemgetter(1)): print(city) ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)) ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)) ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)) ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)) 如果把多个参数传给 itemgetter,它构建的函数会返回提取的值构成的元组: cc_name = itemgetter(1, 0) for city in metro_data: print(cc_name(city)) ('JP', 'Tokyo') ('IN', 'Delhi NCR') ('MX', 'Mexico City') ('US', 'New York-Newark') ('BR', 'Sao Paulo') itemgetter 使用[]运算符,因此它不仅支持序列,还支持映射和任何实现__getitem__ 方 法的类attrgetter与 itemgetter 作用类似,它创建的函数根据名称提取对象的属性。如果把多个属性名传给attrgetter,它也会返回提取的值构成的元组。此外,如果参数名中包含.(点号),attrgetter 会深入嵌套对象,获取指定的属性。 我们构建一个嵌套结构,这样才能展示attrgetter如何处理包含点号的属性名. 定义一个namedtuple,名为metro_data,演示使用attrgetter处理它 from collections import namedtuple LatLong = namedtuple('LatLong', 'lat long') Metropolis = namedtuple('Metropolis', 'name cc pop coord') metro_areas = [Metropolis(name, cc, pop, LatLong(lat, long)) for name, cc, pop, (lat, long) in metro_data] metro_areas[0] Metropolis(name='Tokyo', cc='JP', pop=36.933, coord=LatLong(lat=35.689722, long=139.691667)) metro_areas[0].coord.lat 35.689722 from operator import attrgetter name_lat = attrgetter('name', 'coord.lat') for city in sorted(metro_areas, key=attrgetter('coord.lat')): print(name_lat(city)) ('Sao Paulo', -23.547778) ('Mexico City', 19.433333) ('Delhi NCR', 28.613889) ('Tokyo', 35.689722) ('New York-Newark', 40.808611) 具体符号如下: Operation Syntax Function Addition a + b add(a, b) Concatenation seq1 + seq2 concat(seq1, seq2) Containment Test obj in seq contains(seq, obj) Division a / b truediv(a, b) Division a // b floordiv(a, b) Bitwise And a & b and_(a, b) Bitwise Exclusive Or a ^ b xor(a, b) Bitwise Inversion ~ a invert(a) Bitwise Or a l b or_(a, b) Exponentiation a ** b pow(a, b) Identity a is b is_(a, b) Identity a is not b is_not(a, b) Indexed Assignment obj[k] = v setitem(obj, k, v) Indexed Deletion del obj[k] delitem(obj, k) Indexing obj[k] getitem(obj, k) Left Shift a lshift(a, b) Modulo a % b mod(a, b) Multiplication a * b mul(a, b) Matrix Multiplication a @ b matmul(a, b) Right Shift a >> b rshift(a, b) Slice Assignment seq[i:j] = values setitem(seq, slice(i, j), values) Slice Deletion del seq[i:j] delitem(seq, slice(i, j)) Slicing seq[i:j] getitem(seq, slice(i, j)) String Formatting s % obj mod(s, obj) Subtraction a - b sub(a, b) Truth Test obj truth(obj) Ordering a lt(a, b) Ordering a le(a, b) Equality a == b eq(a, b) Difference a != b ne(a, b) Ordering a >= b ge(a, b) Ordering a > b gt(a, b) Matrix Multiplication a @ b matmul(a, b) Negation (Arithmetic) a neg(a) Negation (Logical) not a not_(a) Positive a pos(a) 使用functools.partial冻结参数 functools.partial这个高阶函数用于部分应用一个函数.部分应用是指,基于一个函数创建一个新的可调用对象,把原函数的某些参数固定.使用这个函数可以把接受一个或多个参数的函数改编成需要回调的API,这样参数更少. functools.partialmethod函数的作用与partial一样,不过是用于处理方法的.我们以partial来作为例子 from operator import mul from functools import partial triple = partial(mul, 3) triple(7) 21 list(map(triple, range(1, 10))) [3, 6, 9, 12, 15, 18, 21, 24, 27] 使用unicode.normalize函数再举个例子,这个示例更有实际意义.如果处理多国语言编写的文本,在比较或排序之前可能会想使用unicode.normalize('NFC', s)处理所有字符串s如果经常这么做,可以定义一个nfc函数. import unicodedata import functools nfc = functools.partial(unicodedata.normalize, 'NFC') s1 = 'café' s2 = 'cafe\\u0301' s1, s2 ('café', 'café') s1 == s2 True nfc(s1) == nfc(s2) True Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/函数/变量作用域与闭包.html":{"url":"语法篇/函数/变量作用域与闭包.html","title":"变量作用域与闭包","keywords":"","body":"变量作用域 python的变量是有其作用域的,也就是说变量必须保存在上下文中,离开了这个上下文环境就找不到了. LEGB原则 python的变量作用域遵循LEGB原则,即: L-Local(function)；函数内的命名空间 E-Enclosing function locals；外部嵌套函数的命名空间(例如closure) G-Global(module)；函数定义所在模块(文件)的命名空间 B-Builtin(Python)；Python内置模块的命名空间 python遵循从上到下的查找方式,我们来看个例子,从闭包中观察LEGB规则. global语句 global语句用来在函数内声明一个变量是全局变量 Pi = 3 def acreage(r): global Pi Pi = 3.14 return Pi*r**2 def perimeters(r): return Pi*r*2 def acreage1(r): Pi = 3.1 return Pi*r**2 print(perimeters(2)) print(acreage1(2)) print(acreage(2)) print(acreage1(2)) print(perimeters(2)) 12 12.4 12.56 12.4 12.56 可以看出 acreage中用global声明改变了全局的Pi值,而acreage1中的pi是本地的所以只在本地有效而已. 如果要查看有哪些全局变量的话,也只需要使用内置函数globals()即可 nolocal语句 nolocal语句是用来声明一个变量不是本地的,它常在闭包中使用. 我们知道global声明是明确指定一个变量作用域为模块全局,而nolocal是声明变量在外部嵌套函数的名字空间,这样就可以在local中修改外部嵌套函数中的变量了. X = 1 def a(): X = 2 def b(): X = 3 print(X) return b a()() 3 X = 1 def a(): X = 2 def b(): global X X = 11 print(X) return b a()() print(X) 11 11 X = 1 def a(): X = 2 print(X) def b(): nonlocal X X = 22 print(X) return X b() print(X) return b a()() 2 22 22 22 22 突破界限–用字典打破LEGB规则 python中字典是一个神奇的存在,它可以跨界,这主要是得益于字典是可变容器 d = {\"x\":1} def a(): d[\"x\"]+=1 print(d[\"x\"]) a() print(d[\"x\"]) 1 2 def a(): d={\"x\":1} print(d[\"x\"]) def b(): d[\"x\"]+=1 return d[\"x\"] b() print(d[\"x\"]) return b a()() 1 2 3 不论是global还是nonlocal都是LEGB原则下高级别作用域中修改低级别作用域变量的方法. 而在python中也可以用字典来作为迂回跳开LEGB的规则限制. 闭包 所谓闭包是指一种组织代码的结构.函数的对象也是有作用域的,我们希望一个函数可以不依赖于外界的函数或者变量,自己就可以实现它的既定功能(也就是没有副作用),那么,有的时候我们就需要在函数的内部定义函数,这就是闭包了. 在博客圈,人们有时会把闭包和匿名函数弄混.这是有历史原因的: 在函数内部定义函数不常见,直到开始使用匿名函数才会这样做.而且,只有涉及嵌套函数时才有闭包问题.因此,很多人是同时知道这两个概念的. 其实,闭包指延伸了作用域的函数,其中包含函数定义体中引用、但是不在定义体中定义的非全局变量.函数是不是匿名的没有关系,关键是它能访问定义体之外定义的非全局变量. 这个概念难以掌握,最好通过示例理解 假如有个名为avg的函数,它的作用是计算不断增加的系列值的均值;例如,整个历史中某个商品的平均收盘价.每天都会增加新价格,因此平均值要考虑至目前为止所有的价格.起初avg是这样使用的: class Averager(): def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return total/len(self.series) avg = Averager() avg(10) 10.0 avg(11) 10.5 avg(12) 11.0 如果使用闭包可以这样实现 def make_averager(): series = [] def averager(new_value): series.append(new_value) total = sum(series) return total/len(series) return averager avg = make_averager() avg(10) 10.0 avg(11) 10.5 注意,这两个示例有共通之处:调用Averager()或make_averager()得到一个可调用对象avg,它会更新历史值,然后计算当前均值.不管怎样,我们都只需调用 avg(n),把 n 放入系列值中, 然后重新计算均值. Averager类的实例avg在哪里存储历史值很明显:self.series实例属性. 但是第二个示例中的avg函数在哪里寻找series呢? 注意,series 是 make_averager 函数的局部变量,因为那个函数的定义体中初始化了series:series = []。可是,调用 avg(10) 时,make_averager 函数已经返回了,而它的本地作用域也一去不复返了 在 averager 函数中,series 是自由变量(free variable).这是一个技术术语,指未在本地作用域中绑定的变量: 审查返回的 averager 对象,我们发现 Python 在 __code__ 属性(表示编译后的函数定义体)中保存局部变量和自由变量的名称 avg.__code__.co_varnames ('new_value', 'total') avg.__code__.co_freevars ('series',) series的绑定在返回的avg函数的__closure__ 属性中.avg.__closure__ 中的各个元素对应于avg.__code__.co_freevars 中的一个名称.这些元素是cell对象,有个cell_ contents属性保存着真正的值. avg.__code__.co_freevars ('series',) avg.__closure__ (,) avg.__closure__[0].cell_contents [10, 11] 综上,闭包是一种函数,它会保留定义函数时存在的自由变量的绑定,这样调用函数时,虽然定义作用域不可用了,但是仍能使用那些绑定. 注意,只有嵌套在其他函数中的函数才可能需要处理不在全局作用域中的外部变量 闭包生成器 我们想输出一个包含不同参数方法的列表 def closure1(): return [lambda : i*i for i in range(1, 4)] def main1(): for j in closure1(): print(j()) main1() 9 9 9 看到结果都是9是不是觉得很诡异,其实这就是因为函数f要寻找变量i,在函数内部找不到i,那就会在外部嵌套函数中寻找,外部嵌套中i已经从1走到3了,也就是i=3了,那就都是为啥结果都是9了 def closure2(): return (lambda :i*i for i in range(1, 4)) def main2(): for j in closure2(): print(j()) main2() 1 4 9 这是为啥呢?其实是因为生成器是一步一步执行的,不进行next程序就没跑完,所以当我们跑main2的时候实际上i在每一步都不一样 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/函数/结语.html":{"url":"语法篇/函数/结语.html","title":"结语","keywords":"","body":"结语 匿名函数的问题 除了 Python 独有的句法上的局限,在任何一门语言中,匿名函数都有一个严重的缺点:没有名称。 函数有名称,栈跟踪更易于阅读。匿名函数是一种便利的简洁方式,人们乐于使用它们,但是有时会忘乎所以, 尤其是在鼓励深层嵌套匿名函数的语言和环境中,如JavaScript和Node.js. 匿名函数嵌套的层级太深,不利于调试和处理错误。Python中的异步编程结构更好,或许就是因为lambda表达式有局限 关于函数式编程(Functional programming) 函数式编程最近忽然大火,其实是个很老的东西.首先函数式编程是一种编程范式,本质上来说语言无关,各种语言只有设计的时候有没有考虑这种范式的问题.就像C语言一样可以写出面向对象风格的代码一样,很多函数式编程语言也可以面向对象编程. 有一种古老的动态语言叫lisp,它很出名,也出名的难用...它可以说是函数式编程语言的老祖宗(有个更老的FLPL,不过它更像Fortran的扩展因此咱不算它). 函数式编程的大致特点是: 函数是第一等公民,说简单点就是函数可以作为参数也可以作为返回值 只有纯的,没有副作用的函数,才是合格的函数.说白了也就是不使用全局变量 有不少人认为python是函数式编程语言其实不然.老实说python在各个方面都是个\"半吊子\",它对oop和fp都是只使用了一些其中的思想让其可以有限的支持这种范式而已.比如说: python的匿名函数内部只能使用表达式,这大大限制了其使用范围. python没有const这种关键字来指示常量 python的递归有深度限制等 没有柯理化 然而这种'半吊子'个人认为很实用,可以避免很多麻烦 js中匿名函数随处都是,代码很难维护 const关键字限制了代码的灵活性.也让开发者不得不对全局变量做区分 递归的滥用本来就对程序没有好处,设置深度限制让递归受限也更利于程序稳定运行. python不提供柯理化工具,但提供了偏函数 如果要稍微更加深入一点的理解函数式编程,可以看阮一峰大大的这篇文章这篇文章的代码是js写的,不过没关系.有点c语言基础的都能看懂,我也有篇js的攻略,虽然没怎么认真写,但还是可以粗略看看. 相关扩展和模块 toolz 纯python实现的更加全面的函数式编程工具,它有个分支项目cytools funcy 一个更加偏向实用的函数式编程库,提供了不少实用的装饰器 calysto_scheme scheme是一个lisp的方言,这个项目是一个scheme的pyhton实现,可以调用python中的模块....性能不要有期待 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/面向对象惯用法/":{"url":"语法篇/面向对象惯用法/","title":"面向对象惯用法","keywords":"","body":"**面向对象惯用法 python是不折不扣的面向对象语言,什么都是平等的对象,这也是它运行速度慢的重要原因. 所谓面向对象往往讲的特点是封装,多态和继承,而对于动态语言的python,很多东西都是自然而然的. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:39:57 "},"语法篇/面向对象惯用法/python中的对象.html":{"url":"语法篇/面向对象惯用法/python中的对象.html","title":"python中的对象","keywords":"","body":"python中的对象 python中万物都是对象,构造这些对象的都是由继承自object的类型创建而得.而得益于python数据模型,自定义类型的行为可以像内置类型那样自然。实现如此自然的行为,靠的不是继承,而是鸭子类型(duck typing):我们只需按照预定行为实现对象所需的方法即可. 面向对象惯用法部分我们会用一个贯穿始终的例子--自定义向量,来解释python中的类与对象.这边先将这个类的最基本形式写出来 from math import hypot,atan2 from array import array class Vector2D: # 在 Vector2d 实例和字节序列之间转换时使用 typecode = 'd' __slots__ = ('__x', '__y') @classmethod def frombytes(cls, octets): # 使用传入的`octets`字节序列创建一个 memoryview, # 然后使用 typecode 转换。 # 拆包转换后的 memoryview,得到构造方法所需的一对参数。 typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(*memv) def __init__(self, x=0, y=0): # 把 x 和 y 转换成浮点数,尽早捕获错误, # 以防调用 Vector2d 函数时传入不当参数。 self.__x = float(x) self.__y = float(y) @property def x(self): return self.__x @property def y(self): return self.__y def __iter__(self): # 定义 `__iter__` 方法,把 Vector2d 实例变成可迭代的对象 # 这样才能拆包(例如`x, y = my_vector`) # 这个方法的实现方式很简单,直接调用生成器表达式一个接一个产出分量. return (i for i in (self.x, self.y)) def __repr__(self): # `__repr__` 方法使用 `{!r}` 获取各个分量的表示形式,然后插值,构成一个字符串; #因为Vector2d 实例是可迭代的对象,所以 `*self` 会把` x `和` y `分量提供给 `format` 函数 class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) def __str__(self): return str(tuple(self)) def __bytes__(self): # 为了生成字节序列,我们把 typecode 转换成字节序列, #然后迭代 Vector2d 实例,得到一个数组,再把数组转换成字节序列. return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self))) def __format__(self, fmt_spec=''): # 使用内置的 format 函数把 fmt_spec 应用到向量的各个分量上,构建一个可迭代的格式化字符串。 # 再把格式化字符串代入公式 '(x, y)' 中。 if fmt_spec.endswith('p'): fmt_spec = fmt_spec[:-1] coords = (abs(self), self.angle()) outer_fmt = '' else: coords = self outer_fmt = '({}, {})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components) def __eq__(self, other): return tuple(self) == tuple(other) def __hash__(self): return hash(self.x) ^ hash(self.y) def __abs__(self): # 模是 x 和 y 分量构成的直角三角形的斜边长 return hypot(self.x, self.y) def __bool__(self): # __bool__ 方法使用 abs(self) 计算模,然后把结果转换成布尔值, # 因此,0.0 是 False,非零值是 True。 return bool(abs(self)) def __add__(self, other): x = self.x + other.x y = self.y + other.y return type(self)(x, y) def __mul__(self, scalar): return type(self)(self.x * scalar, self.y * scalar) def angle(self): return atan2(self.y, self.x) def __complex__(self): return complex(self.x, self.y) v1 = Vector2D(3, 4) print(v1.x, v1.y) x, y = v1 x,y v1 Vector2D(3.0, 4.0) v1_clone = eval(repr(v1)) v1 == v1_clone print(v1) (3.0, 4.0) octets = bytes(v1) octets abs(v1) 5.0 bool(v1), bool(Vector2D(0, 0)) (True, False) 对象表示形式 每门面向对象的语言至少都有一种获取对象的字符串表示形式的标准方式.Python提供了两种方式. repr() 以便于开发者理解的方式返回对象的字符串表示形式. str() 以便于用户理解的方式返回对象的字符串表示形式. 估计你也猜到了,我们要实现接口__repr_和__str__特殊方法,为repr()和str()提供支持. 为了给对象提供其他的表示形式,还会用到另外两个特殊方法: __bytes__ __bytes__方法与__str__方法类似:bytes()函数调用它获取对象的字节序列表示形式. __format__ __format__方法会被内置的format()函数和str.format()方法调用,使用特殊的格式代码显示对象的字符串表示形式. 格式化显示 内置的format()函数和str.format()方法把各个类型的格式化方式委托给相应的.__format__(format_spec)方法.format_spec是格式说明符,它是: format(my_obj, format_spec)的第二个参数,或者 str.format()方法的格式字符串,{}里代换字段中冒号后面的部分 brl = 1/2.43 brl 0.4115226337448559 format(brl, '0.4f') '0.4115' '1 BRL = {rate:0.2f} USD'.format(rate=brl) '1 BRL = 0.41 USD' 格式规范微语言为一些内置类型提供了专用的表示代码.比如,b和x分别表示二进制和十六进制的int类型,f表示小数形式的float类型,而%表示百分数形式 format(42, 'b') '101010' format(2/3, '.1%') '66.7%' 格式规范微语言是可扩展的,因为各个类可以自行决定如何解释format_spec参数.例如,datetime模块中的类,它们的 __format__方法使用的格式代码与strftime()函数一样.下面是内置的format()函数和str.format()方法的几个示例: from datetime import datetime now = datetime.now() format(now, '%H:%M:%S') '23:01:26' \"It's now {:%I:%M %p}\".format(now) \"It's now 11:01 PM\" 如果类没有定义__format__方法,从object继承的方法会返回str(my_object)我们为Vector2D类定义了__str__方法,因此可以这样做. 我们实现自己的微语言来解决这个问题.首先,假设用户提供的格式说明符是用于格式化向量中各个浮点数分量的. 要在微语言中添加一个自定义的格式代码: 如果格式说明符以'p'结尾,那么在极坐标中显示向量,即,其中r是模,θ(西塔)是弧度;其他部分('p' 之前的部分)像往常那样解释. 为自定义的格式代码选择字母时,我会避免使用其他类型用过的字母.在格式规范微语言中我们看到, 整数使用的代码有'bcdoxXn' 浮点数使用的代码有'eEfFgGn%' 字符串使用的代码有's' 因此,我为极坐标选的代码是'p'(polar coordinates).各个类使用自己的方式解释格式代码,在自定义的格式代码中重复使用代码字母不会出错,但是可能会让用户困惑. 对极坐标来说,我们已经定义了计算模的__abs__方法,因此还要定义一个简单的angle方法,使用math.atan2()函数计算角度 这样便可以增强__format__方法,计算极坐标. v1 = Vector2D(3, 4) format(v1) '(3.0, 4.0)' format(v1, '.3f') '(3.000, 4.000)' format(v1, '.3e') '(3.000e+00, 4.000e+00)' format(Vector2D(1, 1), 'p') '' format(Vector2D(1, 1), '.3ep') '' format(Vector2D(1, 1), '0.5fp') '' 静态方法和类方法 Python使用classmethod和staticmethod装饰器声明类方法和静态方法.学过Java面向对象编程的人可能觉得奇怪,为什么Python提供两个这样的装饰器,而不是只提供一个?java中只有静态方法. 先来看classmethod它的用法:定义操作类,而不是操作实例的方法.classmethod改变了调用方法的方式,因此类方法的第一个参数是类本身,而不是实例.classmethod最常见的用途是定义备选构造方法. 再看staticmethod装饰器也会改变方法的调用方式,但是第一个参数不是特殊的值.其实,静态方法就是普通的函数,只是碰巧在类的定义体中,而不是在模块层定义. classmethod装饰器非常有用,但是我从未见过不得不用staticmethod的情况.如果想定义不需要与类交互的函数,那么在模块中定义就好了.有时,函数虽然从不处理类,但是函数的功能与类紧密相关,因此想把它放在近处.即便如此,在同一模块中的类前面或后面定义函数也就行了. 下面的例子是静态方法与类方法的对比 class Demo: @classmethod def klassmeth(*args): return args @staticmethod def statmeth(*args): return args Demo.klassmeth() (__main__.Demo,) Demo.klassmeth('spam') (__main__.Demo, 'spam') Demo.statmeth() () Demo.statmeth('spam') ('spam',) 备选构造方法 我们可以把Vector2D实例转换成字节序列了;同理,也应该能从字节序列转换成Vector2D实例. 在标准库中探索一番之后,我们发现array.array有个类方法 .frombytes正好符合需求. v1 = Vector2D(3, 4) v1 Vector2D(3.0, 4.0) vb1 = bytes(v1) vb1 b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@' v2 = Vector2D.frombytes(vb1) v2 Vector2D(3.0, 4.0) 可散列的对象 如果对象不是可散列的,那么就不能放入集合(set)中,而要可散列必须保证3点: 必须实现__hash__方法 必须实现__eq__ 方法 要让向量不可变 *使用特性让对象的分量只读 property装饰器可以把读值方法标记为特性. 我们让这些向量不可变是有原因的,因为这样才能实现__hash__方法.这个方法应该返回一个整数,理想情况下还要考虑对象属性的散列值(__eq__方法也要使用),因为相等的对象应该具有相同的散列值.Vector2d.__hash__方法的代码十分简单--使用位运算符异或(^)混合各分量的散列值. 要想创建可散列的类型,不一定要实现特性,也不一定要保护实例属性.只需正确地实现 __hash__ 和 __eq__ 方法即可.但是,实例的散列值绝不应该变化,因此我们借机提到了只读特性. Python的私有属性和\"受保护的\"属性 Python不能像Java那样使用private修饰符创建私有属性,但是Python有个简单的机制,能避免子类意外覆盖\"私有\"属性. 举个例子:有人编写了一个名为Dog的类,这个类的内部用到了mood实例属性,但是没有将其开放.现在,你创建了Dog类的子类:Beagle.如果你在毫不知情的情况下又创建了名为mood的实例属性,那么在继承的方法中就会把Dog类的mood属性覆盖掉.这是个难以调试的问题. 为了避免这种情况,如果以__mood的形式(两个前导下划线,尾部没有或最多有一个下划线)命名实例属性,Python会把属性名存入实例的__dict__属性中,而且会在前面加上一个下划线和类名.因此,对Dog类来说,__mood会变成_Dog__mood;对Beagle类来说,会变成_Beagle__mood.这个语言特性叫名称改写(name mangling). 名称改写是一种安全措施,不能保证万无一失:它的目的是避免意外访问,不能防止故意做错事,只要知道改写私有属性名的机制,任何人都能直接读取私有属性——这对调试和序列化倒是有用.此外,只要编写v1._Vector__x = 7这样的代码,就能轻松地为 Vector2D实例的私有分量直接赋值.如果真在生产环境中这么做了,出问题时可别抱怨. 不是所有Python程序员都喜欢名称改写功能,也不是所有人都喜欢 self.__x 这种不对称的名称。有些人不喜欢这种句法,他们约定使用一个下划线前缀编写\"受保护\"的属性(如self._x)。批评使用两个下划线这种改写机制的人认为,应该使用命名约定来避免意外覆盖属性.Ian Bicking有一句话,那句话的完整表述如下: 绝对不要使用两个前导下划线,这是很烦人的自私行为.如果担心名称冲突,应该明确使用一种名称改写方式(如 _MyThing_blahblah).这其实与使用双下划线一样,不过自己定的规则比双下划线易于理解. Python解释器不会对使用单个下划线的属性名做特殊处理,不过这是很多 Python 程序员严格遵守的约定,他们不会在类外部访问这种属性.遵守使用一个下划线标记对象的私有属性很容易,就像遵守使用全大写字母编写常量那样容易. Python文档的某些角落把使用一个下划线前缀标记的属性称为\"受保护的\"属性.使用self._x这种形式保护属性的做法很常见,但是很少有人把这种属性叫作\"受保护的\"属性.有些人甚至将其称为\"私有\"属性. 总之,Vector2D的分量都是\"私有的\",而且Vector2D实例都是\"不可变的\".我用了两对引号,这是因为并不能真正实现私有和不可变. 使用__slots__类属性节省空间 默认情况下,Python在各个实例中名为__dict__的字典里存储实例属性.为了使用底层的散列表提升访问速度,字典会消耗大量内存.如果要处理数百万个属性不多的实例,通过__slots__类属性,能节省大量内存,方法是让解释器在元组中存储实例 属性,而不用字典. 继承自超类的__slots__属性没有效果.Python只会使用各个类中定义的__slots__属性. 定义__slots__的方式是,创建一个类属性,使用__slots__这个名字,并把它的值设为一个字符串构成的可迭代对象,其中各个元素表示各个实例属性.我喜欢使用元组,因为这样定义的__slots__中所含的信息不会变化. 在类中定义__slots__属性的目的是告诉解释器:\"这个类中的所有实例属性都在这儿了!\"这样,Python会在各个实例中使用类似元组的结构存储实例变量,从而避免使用消耗内存的__dict__属性.如果有数百万个实例同时活动,这样做能节省大量内存. 在类中定义__slots__属性之后,实例不能再有__slots__中所列名称之外的其他属性.这只是一个副作用,不是__slots__存在的真正原因.不要使用__slots__属性禁止类的用户新增实例属性.__slots__是用于优化的,不是为了约束程序员. 然而,\"节省的内存也可能被再次吃掉\":如果把__dict__这个名称添加到__slots__中,实例会在元组中保存各个实例的属性,此外还支持动态创建属性,这些属性存储在常规的__dict__中.当然,把 __dict__ 添加到__slots__中可能完全违背了初衷,这取决于各个实例的静态属性和动态属性的数量及其用法.粗心的优化甚至比提早优化还糟糕. 此外,还有一个实例属性可能需要注意,即__weakref__属性,为了让对象支持弱引用,必须有这个属性.用户定义的类中默认就有__weakref__属性.可是,如果类中定义了__slots__属性,而且想把实例作为弱引用的目标,那么要把 __weakref__添加到__slots__中. 综上,__slots__属性有些需要注意的地方,而且不能滥用,不能使用它限制用户能赋值的属性.处理列表数据时__slots__属性最有用,例如模式固定的数据库记录,以及特大型数据集. __slots__的问题 总之,如果使用得当,__slots__能显著节省内存,不过有几点要注意. 每个子类都要定义 __slots__ 属性,因为解释器会忽略继承的__slots__属性。 实例只能拥有 __slots__ 中列出的属性,除非把 __dict__ 加入 __slots__中(这样做就失去了节省内存的功效). 如果不把 __weakref__ 加入 __slots__,实例就不能作为弱引用的目标. 如果你的程序不用处理数百万个实例,或许不值得费劲去创建不寻常的类,那就禁止它创 建动态属性或者不支持弱引用.与其他优化措施一样,仅当权衡当下的需求并仔细搜集资料后证明确实有必要时,才应该使用__slots__属性. 覆盖类属性 Python有个很独特的特性:类属性可用于为实例属性提供默认值.Vector2D中有个typecode类属性,__bytes__方法两次用到了它,而且都故意使用self.typecode读取它的值.因为Vector2D实例本身没有typecode属性,所以self.typecode默认获取的是Vector2D.typecode类属性的值. 但是,如果为不存在的实例属性赋值,会新建实例属性.假如我们为typecode实例属性赋值,那么同名类属性不受影响.然而,自此之后,实例读取的self.typecode是实例属性typecode,也就是把同名类属性遮盖了.借助这一特性,可以为各个实例的typecode属性定制不同的值. Vector2D.typecode属性的默认值是'd',即转换成字节序列时使用8字节双精度浮点数表示向量的各个分量.如果在转换之前把Vector2D实例的typecode属性设为'f',那么使用4字节单精度浮点数表示各个分量. 现在你应该知道为什么要在得到的字节序列前面加上typecode的值了:为了支持不同的格式.如果想修改类属性的值,必须直接在类上修改,不能通过实例修改.如果想修改所有实例(没有typecode实例变量)的typecode属性的默认值,可以这么做: Vector2d.typecode = 'f' 然而,有种修改方法更符合Python风格,而且效果持久,也更有针对性.类属性是公开的,因此会被子类继承,于是经常会创建一个子类,只用于定制类的数据属性. v11 = Vector2D(3, 4) v11.x, v11.y (3.0, 4.0) v11.x = 123 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 v11.x = 123 AttributeError: can't set attribute v22 = Vector2D(3.1, 4.2) hash(v11), hash(v22) (7, 384307168202284039) len(set([v11, v22])) 2 用于构建,解构,反射对象的工具 __new__构造运算符 也就是面向对象编程中常提到的构造方法了 这是一旦被调用就会执行的运算符,也是正常情况下一个实例第一个执行的运算符.该方法会返回一个对应对象的实例.我们来看看他的特性. 例: 建立一个可以记录调用次数的类 class Count_new: counter = 0 def __new__(cls): cls.counter += 1 print(cls.counter,\" times has been called. \") return super(Count_new,cls).__new__(cls) Count_new()#没有指定变量也会返回一个对象 1 times has been called. a = Count_new() 2 times has been called. __init__实例初始化 最常见的运算符重载应用就是__init__方法了,即实例初始化方法.该方法无返回值. 这个方法我们在将继承的时候就有过接触,所以不多说,主要看看他和__new__的关系. __new__运算符返回的是一个对象,这个对象就是类对象 class Count_new_init: counter = 0 def __new__(cls): cls.counter += 1 print(cls.counter,\" times has been called. \") return object.__new__(cls) def __init__(self): self.name = self.counter Count_new_init() 1 times has been called. My name is 4 , you've Created me! a = Count_new_init() 2 times has been called. My name is 8 , you've Created me! b = Count_new_init() 3 times has been called. My name is 12 , you've Created me! c = b.__new__(Count_new_init) 4 times has been called. d = c.__init__() My name is 16 , you've Created me! e = a.__new__(Count_new_init) 5 times has been called. __del__析构运算符 析构运算符__del__定义当对象实例被删除或者释放时的操作,继续修改那个例子 class Count_new_init__del(object): counter = 0 def __new__(cls): cls.counter += 1 print(cls.counter,\" times has been called. \") return super(Count_new_init__del,cls).__new__(cls) def __init__(self): self.name = self.counter c = Count_new_init__del() 1 times has been called. My name is 4 , you've Created me! c = 1 I'm 4 , I'll leave now! d = Count_new_init__del() 2 times has been called. My name is 8 , you've Created me! del d I'm 8 , I'll leave now! __dir__()反射实现的所有属性,包括特殊方法 v11.__dir__() ['__module__', 'typecode', '__slots__', 'frombytes', '__init__', 'x', 'y', '__iter__', '__repr__', '__str__', '__bytes__', '__format__', '__eq__', '__hash__', '__abs__', '__bool__', '__add__', '__mul__', 'angle', '__complex__', '_Vector2D__x', '_Vector2D__y', '__doc__', '__getattribute__', '__setattr__', '__delattr__', '__lt__', '__le__', '__ne__', '__gt__', '__ge__', '__new__', '__reduce_ex__', '__reduce__', '__subclasshook__', '__init_subclass__', '__sizeof__', '__dir__', '__class__'] __class__反射对象所属的类 v11.__class__ __main__.Vector2D __sizeof__()反射对象所占的内存空间 v11.__sizeof__() 32 类作为对象 python中类也是对象,Python数据模型为每个类定义了很多属性. cls.__class__ 构造类对象的对象(元类) cls.__bases__ 由类的基类组成的元组. cls.__qualname__和cls.__name__ Python 3.3新引入的属性,其值是类或函数的限定名称,即从模块的全局作用域到类的点分路径.内部类ClassTwo的 __qualname__ 属性,其值是字符串'ClassOne.ClassTwo',而__name__属性的值是'ClassTwo'. cls.__subclasses__() 这个方法返回一个列表,包含类的直接子类.这个方法的实现使用弱引用,防止在超类和子类(子类在__bases__属性中储存指向超类的强引用)之间出现循环引用.这个方法返回的列表中是内存里现存的子类. cls.__mro__ 记录类的继承顺序 cls.mro() 构建类时,如果需要获取储存在类属性__mro__ 中的超类元组,解释器会调用这个方法.元类可以覆盖这个方法,定制要构建的类解析方法的顺序. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:37:54 "},"语法篇/面向对象惯用法/协议与接口与抽象基类.html":{"url":"语法篇/面向对象惯用法/协议与接口与抽象基类.html","title":"协议,接口与抽象基类","keywords":"","body":"协议和鸭子类型 在Python中创建功能完善的序列类型无需使用继承,只需实现符合序列协议的方法.不过,这里说的协议是什么呢? 在面向对象编程中,协议是非正式的接口,只在文档中定义(也可以在typehint中定义),在代码中不定义.例如, Python的序列协议只需要__len__和 __getitem__两个方法.任何类(如Spam),只要使用标准的签名和语义实现了这两个方法,就能用在任何期待序列的地方.Spam是不是哪个类的子类无关紧要,只要提供了所需的方法即可. Python文化中的接口和协议 引入抽象基类之前,Python就已经非常成功了,即便现在也很少有代码使用抽象基类. 我们把协议定义为非正式的接口,是让Python这种动态类型语言实现多态的方式. 接口在动态类型语言中是怎么运作的呢? 首先,基本的事实是Python语言没有interface关键字,而且除了抽象基类每个类都有接口: 类实现或继承的公开属性,包括特殊方法,如__getitem__或__add__. 按照定义,受保护的属性和私有属性不在接口中:即便\"受保护的\"属性也只是采用命名约定实现的(单个前导下划线),私有属性可以轻松地访问,原因也是如此.不要违背这些约定. 另一方面,不要觉得把公开数据属性放入对象的接口中不妥,因为如果需要,总能实现读值方法和设值方法,把数据属性变成特性,使用obj.attr句法的客户代码不会受到影响. 关于接口,这里有个实用的补充定义: 对象公开方法的子集,让对象在系统中扮演特定的角色. Python文档中的\"文件类对象\"或\"可迭代对象\"就是这个意思,这种说法指的不是特定的类.接口是实现特定角色的方法集合,其他动态语言社区都借鉴了这个术语.协议与继承没有关系.一个类可能会实现多个接口,从而让实例扮演多个角色. 协议是接口,但不是正式的(只由文档和约定定义),因此协议不能像正式接口那样施加限制(后面会说明抽象基类对接口一致性的强制).一个类可能只实现部分接口,这是允许的.有时某些API只要求\"文件类对象\"返回字节序列的.read()方法.在特定的上下文中可能需要其他文件操作方法,也可能不需要. 对Python程序员来说,\"X 类对象\",\"X 协议\"和\"X 接口\"都是一个意思. 抽象基类和白鹅类型 我们讲: 当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子,那么这只鸟就可以被称为鸭子. 鸭子类型忽略对象的真正类型,转而关注对象有没有实现所需的方法、签名和语义.对Python来说,这基本上是指避免使用isinstance检查对象的类型,这样做没有任何好处,甚至禁止最简单的继承方式. 然而从进化的角度讲,平行进化往往会导致不相关的种产生相似的特征,形态和举止方面都是如此,但是生态位的相似性是偶然的,不同的种仍属不同的生态位.编程语言中也有这种\"偶然的相似性\"，比如说下述经典的面向对象编程示例 class Artist: def draw(self): pass class Gunslinger: def draw(self): pass class Lottery: def draw(self): pass 语言上的歧义造成了完全不应相关的两个类有着一样的接口,因此我们需要额外的外部知识来将鸭子类型提供的等价性维持在一定的层次上. 这种时候我们应该有这样的一种规定: 只要cls是抽象基类,即cls的元类是abc.ABCMeta,就可以使用isinstance(obj, cls) 这一思想来自于Alex Martelli的一篇文章,他管这叫白鹅类型,在流畅的python一书中有引用. 继承抽象基类很简单,只需要实现所需的方法,这样也能明确表明开发者的意图.这一意图还能通过注册虚拟子类来实现.此外,使用isinstance和issubclass测试抽象基类更为人接受.过去,这两个函数用来测试鸭子类型,但用于抽象基类会更灵活.毕竟如果某个组件没有继承抽象基类,事后 还可以注册,让显式类型检查通过. 然而即便是抽象基类,也不能滥用isinstance检查,用得多了可能导致代码异味,即表明面向对象设计得不好.在一连串if/elif/elif中使用isinstance做检查,然后根据对象的类型执行不同的操作,通常是不好的做法;此时应该使用多态;即采用一定的方式定义类,让解释器把调用分派给正确的方法,而不使用if/elif/elif块硬编码分派逻辑 另一方面,如果必须强制执行API契约,通常可以使用isinstance检查抽象基类.这对采用插入式架构的系统来说特别有用.在框架之外,鸭子类型通常比类型检查更简单,也更灵活. 要抑制住创建抽象基类的冲动.滥用抽象基类会造成灾难性后果,表明语言太注重表面形式,这对以实用和务实著称的Python可不是好事. 标准库中的抽象基类 从Python 2.6 开始,标准库提供了抽象基类.大多数抽象基类在collections.abc模块中定义,不过其他地方也有.例如,numbers和io包中有一些抽象基类.但是,collections.abc中的抽象基类最常用.我们来看看这个模块中有哪些抽象基类. collections.abc模块中的抽象基类 标准库中有两个名为abc的模块,这里说的是collections.abc.为了减少加载时间,Python3.4在collections包之外实现这个模块,因此要与collections分开导入.另一个abc模块就是abc这里定义的是abc.ABC类.每个抽象基类都依赖这个类,但是不用导入它,除非定义新抽象基类. collections.abc中定义了如下容器抽象基类: ABC 继承自 抽象方法 Mixin 方法 Container --- __contains__ --- Hashable --- __hash__ --- Iterable --- __iter__ --- Iterator Iterable __next__ __iter__ Reversible Iterable __reversed__ --- Generator Iterator send, throw close, __iter__, __next__ Sized --- __len__ --- Callable --- __call__ --- Collection Sized, Iterable, Container __contains__, __iter__,__len__ --- Sequence Reversible, Collection __getitem__, __len__ __contains__, __iter__, __reversed__, index,count MutableSequence Sequence __getitem__, __setitem__,__delitem__, __len__, insert Sequence实现的方法以及append,reverse, extend,pop, remove, __iadd__ ByteString Sequence __getitem__,__len__ Sequence实现的方法 Set Collection __contains__, __iter__, __len__ __le__, __lt__, __eq__, __ne__, __gt__, __ge__, __and__, __or__,__sub__, __xor__,isdisjoint MutableSet Set __contains__,__iter__, __len__, add, discard Set实现的方法以及clear, pop, remove, __ior__,__iand__,__ixor__, __isub__ Mapping Collection __getitem__, __iter__, __len__ __contains__,keys, items, values, get, __eq__, __ne__ MutableMapping Mapping __getitem__, __setitem__, __delitem__, __iter__, __len__ Mapping实现的方法以及pop, popitem, clear,update, setdefault MappingView Sized --- __len__ ItemsView MappingView, Set --- __contains__, __iter__ KeysView MappingView, Set --- __contains__,__iter__ ValuesView MappingView --- __contains__, __iter__ Awaitable --- __await__ --- Coroutine Awaitable send,throw close AsyncIterable --- __aiter__ --- AsyncIterator AsyncIterable __anext__ __aiter__ AsyncGenerator AsyncIterator asend, athrow aclose, __aiter__, __anext__ 除此之外,其中还包括了两个特殊的抽象基类: Callable Hashable 这两个抽象基类与集合没有太大的关系,只不过因为collections.abc是标准库中定义抽象基类的第一个模块,而它们又太重要了,因此才把它们放到其中 .这两个抽象基类的主要作用是为内置函数isinstance提供支持,以一种安全的方式判断对象能不能调用或散列. numbers模块中的抽象基类 numbers包定义的是\"数字塔\"(即各个抽象基类的层次结构是线性的),其中Number是位于最顶端的超类,随后是Complex子类,依次往下,最底端是Integral类： Number Complex Real Rational Integral 因此,如果想检查一个数是不是整数.可以使用isinstance(x, numbers.Integral),这样代码就能接受int、bool(int 的子类),或者外部库使用numbers抽象基类注册的其他类型.为了满足检查的需要,你或者你的API的用户始终可以把兼容的类型注册为numbers.Integral的虚拟子类. 与之类似,如果一个值可能是浮点数类型,可以使用isinstance(x, numbers.Real)检查.这样代码就能接受bool、int、float、fractions.Fraction,或者外部库(如NumPy,它做了相应的注册)提供的非复数类型. decimal.Decimal没有注册为numbers.Real的虚拟子类,这有点奇怪.没注册的原因是,如果你的程序需要Decimal的精度,要防止与其他低精度数字 类型混淆,尤其是浮点数. 定义一个抽象基类 为了证明有必要定义抽象基类,我们要在框架中找到使用它的场景.想象一下这个场景: 你要在网站或移动应用中显示随机广告,但是在整个广告清单轮转一遍之前,不重复显示广告.假设我们在构建一个广告管理框架,名为ADAM.它的职责之一是,支持用户提供随机挑选的无重复类. 为了让ADAM的用户明确理解\"随机挑选的无重复\"组件是什么意思,我们将定义一个抽象基类. 受到'栈'和'队列'启发,我将使用现实世界中的物品命名这个抽象基类: 宾果机和彩票机是随机从有限的集合中挑选物品的机器,选出的物品没有重复,直到选完为止. 我们把这个抽象基类命名为Tombola,这是宾果机和打乱数字的滚动容器的意大利名. Tombola抽象基类有四个方法， 其中两个是抽象方法: load(...):把元素放入容器. .pick():从容器中随机拿出一个元素,返回选中的元素. 另外两个是具体方法: loaded():如果容器中至少有一个元素,返回True。 inspect():返回一个有序元组,由容器中的现有元素构成,不会修改容器的内容 定义抽象基类需要使用abc模块,继承abc.ABC就可以构建抽象基类,这样它就无法实例化, 装饰器@abc.abstractmethod则可以申明方法为抽象方法,而且定义体中通常只有文档字符串.其实,抽象方法可以有实现代码.即便实现了,子类也必须覆盖抽象方法,但是在子类中可以使用super()函数调用抽象方法,为它添加功能,而不是从头开始实现. 除了@abstractmethod之外,abc模块还定义了@abstractclassmethod、@abstractstaticmethod和@abstractproperty 三个装饰器.然而,后三个装饰器从Python 3.3起废弃了,因为装饰器可以在@abstractmethod上堆叠，那三个就显得多余了.例如声明抽象类方法的推荐方 式是: class MyABC(abc.ABC): @classmethod @abc.abstractmethod def an_abstract_classmethod(cls, ...): pass PS:typehint应当使用@typing.overload标注子类中的抽象方法实现为方法覆写. import abc class Tombola(abc.ABC): @abc.abstractmethod def load(self, iterable): \"\"\"从可迭代对象中添加元素。\"\"\" pass @abc.abstractmethod def pick(self): \"\"\"随机删除元素，然后将其返回。 如果实例为空，这个方法应该抛出`LookupError`。 \"\"\" pass def loaded(self): \"\"\"如果至少有一个元素，返回`True`，否则返回`False`。\"\"\" return bool(self.inspect()) def inspect(self): \"\"\"返回一个有序元组，由当前元素构成。\"\"\" items = [] while True: try: items.append(self.pick()) except LookupError: break self.load(items) return tuple(sorted(items)) 使用__init_subclass__(cls)在基类中定义子类的初始化函数[3.6] 定制类的创建使用新协议进行了简化 Simpler customisation of class creation提供了一种可以在不使用元类的情况下自定义子类的方法.每当创建一个新的子类时,新的init_subclass类方法会被调用,可以将其理解为子类创建前的一个钩子： class PluginBase: subclasses = [] def __init__(self,name = \"base\"): self.name = name def __init_subclass__(cls, **kwargs): print(\"subclass\") super().__init_subclass__(**kwargs) cls.subclasses.append(cls) class Plugin1(PluginBase): # def __init__(self): # print(\"init\") pass class Plugin2(PluginBase): # def __init__(self): # print(\"init\") pass subclass subclass Plugin1() Plugin2() PluginBase.subclasses [__main__.Plugin1, __main__.Plugin2] 定义抽象基类的子类 定义好Tombola抽象基类之后,我们要开发两个具体子类,满足Tombola规定的接口. import random class BingoCage(Tombola): def __init__(self, items): self._randomizer = random.SystemRandom() self._items = [] self.load(items) def load(self, items): self._items.extend(items) self._randomizer.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): self.pick() import random class LotteryBlower(Tombola): def __init__(self, iterable): self._balls = list(iterable) def load(self, iterable): self._balls.extend(iterable) def pick(self): try: position = random.randrange(len(self._balls)) except ValueError: raise LookupError('pick from empty LotteryBlower') return self._balls.pop(position) def loaded(self): return bool(self._balls) def inspect(self): return tuple(sorted(self._balls)) 白鹅类型的重要动态特性了:使用register 方法声明虚拟子类 python的抽象基类还有一个重要的实用优势:可以使用register类方法在终端用户的代码中把某个类\"声明\"为一个抽象基类的\"虚拟子类\"(为此,被注 册的类必须满足抽象基类对方法名称和签名的要求,最重要的是要满足底层语义契约.但是开发那个类时不用了解抽象基类,更不用继承抽象基类).这大大地打破了严格的强耦合,与面向对象编程人员掌握的知识有很大出入,因此使用继承时要小心. 白鹅类型的一个基本特性(也是值得用水禽来命名的原因):即便不继承,也有办法把一个类注册为抽象基类的虚拟子类.这样做时我们保证注册的类忠实地实现了抽象基类定义的接口,而Python会相信我们,从而不做检查.如果我们说谎了,那么常规的运行时异常会把我们捕获. 注册虚拟子类的方式是在抽象基类上调用register方法.这么做之后,注册的类会变成抽象基类的虚拟子类,而且issubclass和isinstance等函数都能识别,但是注册的类不会从抽象基类中继承任何方法或属性. 虚拟子类不会继承注册的抽象基类，而且任何时候都不会检查它是否符合抽象基类的接口，即便在实例化时也不会检查。为了避免运行时错误，虚拟子类要实现所需的全部方法. register方法通常作为普通的函数调用,不过也可以作为装饰器使用.我们使用装饰器句法实现了TomboList类,这是Tombola 的一个虚拟子类. from random import randrange @Tombola.register class TomboList(list): def pick(self): if self: position = randrange(len(self)) return self.pop(position) else: raise LookupError('pop from empty TomboList') load = list.extend def loaded(self): return bool(self) def inspect(self): return tuple(sorted(self)) t = TomboList([12,23,34]) isinstance(t,Tombola) True Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/面向对象惯用法/多重继承和Mixin.html":{"url":"语法篇/面向对象惯用法/多重继承和Mixin.html","title":"多重继承和Mixin","keywords":"","body":"多重继承 很多人觉得多重继承得不偿失.不支持多重继承的 Java 显然没有什么损失,C++ 对多重继承的滥用伤害了很多人,这可能还坚定了使用 Java 的决心.然而,Java的巨大成功和广泛影响,也导致很多刚接触Python的程序员没怎么见过真实的代码使用多重继承. 子类化内置类型很麻烦 在 Python 2.2 之前,内置类型(如list或dict)不能子类化.在Python2.2之后,内置类型可以子类化了,但是有个重要的注意事项--内置类型(使用 C 语言编写)不会调用用户定义的类覆盖的特殊方法. class DoppelDict(dict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2) dd = DoppelDict(one=1) dd {'one': 1} dd['two'] = 2 dd {'one': 1, 'two': [2, 2]} dd.update(three=3) dd {'one': 1, 'three': 3, 'two': [2, 2]} 原生类型的这种行为违背了面向对象编程的一个基本原则:始终应该从实例(self)所属的类开始搜索方法,即使在超类实现的类中调用也是如此.在这种糟糕的局面中,__missing__方法却能按预期方式工作,不过这只是特例. 不只实例内部的调用有这个问题(self.get()不调用self.__getitem__()),内置类型的方法调用的其他类的方法,如果被覆盖了,也不会被调用. 例子:dict.update方法会忽略AnswerDict.__getitem__方法 class AnswerDict(dict): def __getitem__(self, key): return 42 ad = AnswerDict(a='foo') ad['a'] 42 d = {} d.update(ad) d['a'] 'foo' d {'a': 'foo'} 直接子类化内置类型(如dict、list 或str)容易出错,因为内置类型的方法通常会忽略用户覆盖的方法.不要子类化内置类型,用户自己定义的类应该继承collections模块中的类,例如 UserDict、UserList 和 UserString,这些类做了特殊设计,因此 易于扩展. 如果不子类化 dict,而是子类化collections.UserDict,上面例子中暴露的问题便迎刃而解了 import collections class DoppelDict2(collections.UserDict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2) dd = DoppelDict2(one=1) dd {'one': [1, 1]} dd['two'] = 2 dd {'one': [1, 1], 'two': [2, 2]} dd.update(three=3) dd {'one': [1, 1], 'two': [2, 2], 'three': [3, 3]} class AnswerDict2(collections.UserDict): def __getitem__(self, key): return 42 ad = AnswerDict2(a='foo') ad['a'] 42 d = {} d.update(ad) d['a'] 42 d {'a': 42} 多重继承和方法解析顺序 任何实现多重继承的语言都要处理潜在的命名冲突,这种冲突由不相关的祖先类实现同名方法引起.这种冲突称为'菱形问题' class A: def ping(self): print('ping:', self) class B(A): def pong(self): print('pong:', self) class C(A): def pong(self): print('PONG:', self) class D(B, C): def sp(self): return super() def ping(self): super().ping() print('post-ping:', self) def pingpong(self): self.ping() super().ping() self.pong() super().pong() C.pong(self) d = D() d.sp() > d.pong()# 直接调用 d.pong() 运行的是 B 类中的版本。 pong: C.pong(d) #超类中的方法都可以直接调用,此时要把实例作为显式参数传入 PONG: Python能区分d.pong()调用的是哪个方法,是因为Python会按照特定的顺序遍历继承图.这个顺序叫方法解析顺序(Method Resolution Order,MRO).类都有一个名为__mro__的属性,它的值是一个元组,按照方法解析顺序列出各个超类,从当前类一直向上,直到object类.D 类的__mro__属性如下: D.__mro__ (__main__.D, __main__.B, __main__.C, __main__.A, object) 若想把方法调用委托给超类,推荐的方式是使用内置的super()函数.在Python 3中,这种方式变得更容易了.然而有时可能需要绕过方法解析顺序,直接调用某个超类的方法--这样做有时更方便,例如,D.ping方法可以这样写: class D(B, C): def ping(self): A.ping(self) # 而不是super().ping() print('post-ping:', self) def pingpong(self): self.ping() super().ping() self.pong() super().pong() C.pong(self) d = D() d.ping() ping: post-ping: 使用super()处理父类引用 super()方法是python用于处理超类引用的推荐方法 super(type, obj_or_type)会按照MRO的順序去委託type的超类或兄弟类的方法來调用.光super()则是会指向定义类时最左边的那个超类. 下例中: super().__init__(author)会找到并调用其__init__(author) super(Song, self).__init__(name)会找到並調用其 __init__(name) class Song(object): def __init__(self, author): self._author = author print(\"init Song\") class Singer(object): def __init__(self, name): self._name = name print(\"init Singer\") class Mtv(Song, Singer): def __init__(self, name, author): super().__init__(author) # init Song super(Song, self).__init__(name) # init Singer mtv = Mtv('name', 'author') init Song init Singer Mtv.__mro__ (__main__.Mtv, __main__.Song, __main__.Singer, object) Mixin 我们知道多重继承是危险的,很容易造成继承混乱,如何解决这个问题呢,就是使用mixin.原则上,应该只在使用Mixin组件制作工具时进行多重继承. mixin是一个行为的集合,是受限制的多重继承.mixin定义的这个行为可以被加到任意class里,然而在一些情况下,使用mix-in的类,可以要求宿主满足一些协议(contract),这个协议可以是属性也可以是方法.如果有协议要求的话,协议应该是被声明在mixin内的.这样更容易复用. Mixin是一种非常谨慎的多重继承用法,它的特点是: Mixin 类是单一职责的 Mixin 类对宿主类一无所知 不存在超类方法调用(super)以避免引入 MRO 查找顺序问题 例:把内存中的python对象转换为字典形式 class ToDictMixin: def to_dict(self): return self._traverse_dict(self.__dict__) def _traverse_dict(self,instance_dict): output = {} for key,value in instance_dict.items(): output[key] = self._traverse(key,value) return output def _traverse(self,key,value): \"\"\"递归的将对象转化为字典形式\"\"\" if isinstance(value,ToDictMixin): return value.to_dict() elif isinstance(value,dict): return self._traverse_dict(value) elif isinstance(value,list): return [self._traverse(key,i) for i in value] elif hasattr(value,'__dict__'): return self._traverse_dict(value.__dict__) else: return value class BinaryTree(ToDictMixin): def __init__(self,value,left=None,right=None): self.value = value self.left = left self.right = right tree = BinaryTree(10, left=BinaryTree(7, right = BinaryTree(9)), right = BinaryTree(13, left = BinaryTree(11)) ) tree.to_dict() {'left': {'left': None, 'right': {'left': None, 'right': None, 'value': 9}, 'value': 7}, 'right': {'left': {'left': None, 'right': None, 'value': 11}, 'right': None, 'value': 13}, 'value': 10} Mixin最大的优势是使用者可以随时安插这些功能,并且可以在必要的时候覆写他们,比如二叉树中节点也要求有指向父节点的引用,那么上面的树就会陷入死循环,解决办法是可以在其中覆写_traverse方法以避免这个问题. class BinaryTreeWithParent(BinaryTree): def __init__(self,value,left=None,right=None,parent = None): super().__init__(value,left=left,right=right) self.parent = parent def _traverse(self,key,value): if isinstance(value,BinaryTreeWithParent) and key == 'parent': return value.value else: return super()._traverse(key,value) root = BinaryTreeWithParent(10) root.left = BinaryTreeWithParent(7,parent = root) root.left.right = BinaryTreeWithParent(9,parent = root.left) root.to_dict() {'left': {'left': None, 'parent': 10, 'right': {'left': None, 'parent': 7, 'right': None, 'value': 9}, 'value': 7}, 'parent': None, 'right': None, 'value': 10} 并且如果其他类的某个属性也是BinaryTreeWithParent,那么ToDictMixin也会自动处理好这些属性 class NamedSubTree(ToDictMixin): def __init__(self,name,tree_with_parent): self.name = name self.tree_with_parent = tree_with_parent mytree = NamedSubTree(\"foobar\",root.left.right) mytree.to_dict() {'name': 'foobar', 'tree_with_parent': {'left': None, 'parent': 7, 'right': None, 'value': 9}} 多个Mixin之间也可以相互转化组合,例如可以编写一个这样的Mixin,可以将任意类提供通用的JSON序列化功能.我们这个Mixin要求宿主类提供to_dict接口. from typing import Callable,Dict import json class JsonMixin: to_dict:Callable[...,Dict] @classmethod def from_json(cls,data): kwargs = json.loads(data) return cls(**kwargs) def to_json(self): return json.dumps(self.to_dict()) 有了这样的Mixin后,我们只需要极少的代码既可以通过继承体系轻松创建相关工具类. class NamedSubTree(ToDictMixin,JsonMixin): def __init__(self,name,tree_with_parent): self.name = name self.tree_with_parent = tree_with_parent mytree = NamedSubTree(\"foobar\",root.left.right) mytree.to_json() '{\"name\": \"foobar\", \"tree_with_parent\": {\"value\": 9, \"left\": null, \"right\": null, \"parent\": 7}}' 处理多重继承的原则 继承有很多用途,而多重继承增加了可选方案和复杂度.使用多重继承容易得出令人费解和脆弱的设计.我们还没有完整的理论,根据上面的内容,下面是总结的避免把类图搅乱的一些建议: 把接口继承和实现继承区分开 使用多重继承时,一定要明确一开始为什么创建子类.主要原因可能有: 继承接口,创建子类型,实现“是什么”关系 继承实现,通过重用避免代码重复 其实这两条经常同时出现,不过只要可能,一定要明确意图.通过继承重用代码是实现细节,通常可以换用组合和委托模式.而接口继承则是框架的支柱. 使用抽象基类显式表示接口 现代的 Python 中,如果类的作用是定义接口,应该明确把它定义为抽象基类.Python 3.4及以上的版本中,我们要创建abc.ABC或其他抽象基类的子类. 通过混入重用代码 如果一个类的作用是为多个不相关的子类提供方法实现,从而实现重用,但不体现\"是什么\"关系,应该把那个类明确地定义为混入类(mixin class).从概念上讲,混入不定义新类型,只是打包方法,便于重用.混入类绝对不能实例化,而且具体类不能只继承混入类.混入类应该提供某方面的特定行为,只实现少量关系非常紧密的方法. 在名称中明确指明混入 因为在Python中没有把类声明为混入的正规方式,所以强烈推荐在名称中加入xxxMixin后缀. 抽象基类可以作为混入,反过来则不成立 抽象基类可以实现具体方法,因此也可以作为混入使用.不过,抽象基类会定义类型,而混入做不到.此外,抽象基类可以作为其他类的唯一基类,而混入决不能作为唯一的超类,除非继承另一个更具体的混入--真实的代码很少这样做. 抽象基类有个局限是混入没有的:抽象基类中实现的具体方法只能与抽象基类及其超类中的方法协作.这表明,抽象基类中的具体方法只是一种便利措施,因为这些方法所做的一切,用户调用抽象基类中的其他方法也能做到. 不要子类化多个具体类 具体类可以没有,或最多只有一个具体超类.也就是说,具体类的超类中除了这一个具体超类之外,其余的都是抽象基类或混入.例如,在下述代码中,如果 Alpha 是具体类,那么 Beta 和 Gamma 必须是抽象基类或混入: class MyConcreteClass(Alpha, Beta, Gamma): \"\"\"这是一个具体类,可以实例化。\"\"\" # ......更多代码...... 为用户提供聚合类 如果抽象基类或混入的组合对客户代码非常有用,那就提供一个类,使用易于理解的方式把它们结合起来.Grady Booch把这种类称为聚合类(aggregate class). 例如,下面是 tkinter.Widget 类的完整代码: class Widget(BaseWidget, Pack, Place, Grid): \"\"\"Internal class. Base class for a widget which can be positioned with the geometry managers Pack, Place or Grid. \"\"\" pass \"优先使用对象组合,而不是类继承\" 这句话引自\"设计模式:可复用面向对象软件的基础\"一书. 熟悉继承之后,就太容易过度使用它了.出于对秩序的诉求,我们喜欢按整洁的层次结构放置物品,程序员更是乐此不疲.然而,优先使用组合能让设计更灵活.例如,对tkinter.Widget类来说,它可以不从全部几何管理器中继承方法,而是在小组件实例中维护一个几何管理器引用,然后通过它调用方法.毕竟小组件\"不是\"几何管理器,但是可以通过委托使用相关的服务.这样,我们可以放心添加新的几何管理器,不必担心会触动小组件类的层次结构,也不必担心名称冲突.即便是单继承,这个原则也能提升灵活性,因为子类化是一种紧耦合,而且较高的继承树容易倒.组合和委托可以代替混入,把行为提供给不同的类,但是不能取代接口继承去定义类型层次结构. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/面向对象惯用法/自定义序列Vector.html":{"url":"语法篇/面向对象惯用法/自定义序列Vector.html","title":"自定义序列Vector","keywords":"","body":"自定义序列Vector 本篇通过自定义Vector来看如何使用组合模式实现Vector类,而不使用继承.既然是使用组合,那么我们首先想到的就是Mixin. 向量的分量存储在浮点数数组中,而且还将实现不可变扁平序列所需的方法. 不过,在实现序列方法之前,我们要确保Vector类与之前定义的Vector2D类兼容,除非有些地方让二者兼容没有什么意义. 第一版--与Vector2D兼容 from array import array from typing import Sequence,Optional,Iterator import reprlib from math import sqrt class VectorBase: typecode:str = 'd' _components:Optional[array]=None def __init__(self, components:Sequence): self._components = array(self.typecode, components) self._dimension = None def __iter__(self)->Iterator: return iter(self._components) def __bool__(self)->bool: return bool(abs(self)) class DimensionMixin: _components:Optional[array]=None _dimension:Optional[int]=None def __len__(self)->int: return len(self._components) @property def dimension(self)->int: if not self._dimension: self._dimension = len(self) return self._dimension class AbsMixin: def __abs__(self)->float: return sqrt(sum(x * x for x in self)) from typing import Optional from array import array class LiteralMixin: _components:Optional[array]=None def __str__(self)->str: return str(tuple(self)) def __repr__(self)->str: \"\"\" 如果 Vector 实例的分量超过 6 个,`repr()` 生成的字符串就会使用 ... 省略一 部分, 包含大量元素的集合类型一定要这么做,因为字符串表示形式是用于调试的 (因此不想让大型对象在控制台或日 志中输出几千行内容). 使用 reprlib 模块可以生成长度有限的表示形式. \"\"\" components = reprlib.repr(self._components) components = components[components.find('['):-1] return 'Vector({})'.format(components) def __format__(self,fmt_spec='')->str: return NotImplemented from array import array class CodecMixin: typecode:str _components:Optional[array] def __bytes__(self)->bytes: return (bytes([ord(self.typecode)]) + bytes(self._components)) @classmethod def frombytes(cls, octets:bytes)->'VectorBase': typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(memv) class Vector(VectorBase,DimensionMixin,AbsMixin, LiteralMixin,CodecMixin): pass Vector([3.1, 4.2]) Vector([3.1, 4.2]) Vector((3, 4, 5)) Vector([3.0, 4.0, 5.0]) Vector(range(10)) Vector([0.0, 1.0, 2.0, 3.0, 4.0, ...]) bytes(Vector(range(10))) b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@\\x00\\x00\\x00\\x00\\x00\\x00\\x14@\\x00\\x00\\x00\\x00\\x00\\x00\\x18@\\x00\\x00\\x00\\x00\\x00\\x00\\x1c@\\x00\\x00\\x00\\x00\\x00\\x00 @\\x00\\x00\\x00\\x00\\x00\\x00\"@' Vector.frombytes(b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@\\x00\\x00\\x00\\x00\\x00\\x00\\x14@\\x00\\x00\\x00\\x00\\x00\\x00\\x18@\\x00\\x00\\x00\\x00\\x00\\x00\\x1c@\\x00\\x00\\x00\\x00\\x00\\x00 @\\x00\\x00\\x00\\x00\\x00\\x00\"@') Vector([0.0, 1.0, 2.0, 3.0, 4.0, ...]) Vector([3.1, 4.2]).dimension 2 第二版--实现可切片的序列 实现可切片需要实现__len__ 和__getitem__,我们希望切片后得到的还是Vector.实际上切片是通过slice实现 class MySeq: def __getitem__(self, index): return index s = MySeq() s[1] 1 s[1:4] slice(1, 4, None) s[1:4:2] slice(1, 4, 2) s[1:4:2, 9] (slice(1, 4, 2), 9) s[1:4:2, 7:9] (slice(1, 4, 2), slice(7, 9, None)) 切片原理 slice是内置的类型.它有start、stop 和step数据属性，以及indices方法. indices这个方法有很大的作用,但是鲜为人知.help(slice.indices)给出的信息如下: S.indices(len) -> (start, stop, stride) 给定长度为len的序列,计算S表示的扩展切片的起始(start)和结尾(stop)索引,以及步幅(stride).超出边界的索引会被截掉,这与常规切片的处理方式一样. 换句话说,indices方法开放了内置序列实现的棘手逻辑,用于优雅地处理缺失索引和负数索引,以及长度超过目标序列的切片.这个方法会\"整顿\"元组,把start、stop 和stride都变成非负数,而且都落在指定长度序列的边界内. slice(None, 10, 2).indices(5) (0, 5, 2) slice(-3, None, None).indices(5) (2, 5, 1) from array import array import numbers from typing import Optional,Union class SliceMixin: \"\"\"需要实现`__len__`\"\"\" _components:array def __getitem__(self, index:int)->Optional[Union[VectorBase,float]]: cls = type(self) if isinstance(index, slice): return cls(self._components[index]) elif isinstance(index, numbers.Integral): return self._components[index] else: msg = '{cls.__name__} indices must be integers' raise TypeError(msg.format(cls=cls)) class Vector(VectorBase,AbsMixin,DimensionMixin, LiteralMixin,CodecMixin,SliceMixin): pass v7 = Vector(range(7)) v7[-1] 6.0 v7[1:4] Vector([1.0, 2.0, 3.0]) v7[-1:] Vector([6.0]) v7[1,2] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 v7[1,2] in __getitem__(self, index) 13 else: 14 msg = '{cls.__name__} indices must be integers' ---> 15 raise TypeError(msg.format(cls=cls)) TypeError: Vector indices must be integers 第三版 动态存取属性 Vector2D变成Vector之后,就没办法通过名称访问向量的分量了(如v.x 和v.y).现在我们处理的向量可能有大量分量.不过,若能通过单个字母访问前几个分量的话会比较方便.比如,用x、y和z代替v[0]、v[1] 和v[2]. 我们想额外提供下述句法,用于读取向量的前四个分量: v = Vector(range(10)) v.x >>> 0.0 v.y, v.z, v.t >>> (1.0, 2.0, 3.0) 在Vector2D中,我们使用@property装饰器把x和y标记为只读特性.我们可以在Vector中编写四个特性,但这样太麻烦.特殊方法__getattr__提供了更好的方式. 属性查找失败后,解释器会调用__getattr__方法.简单来说，对my_obj.x表达式: Python会检查my_obj实例有没有名为x的属性 如果没有,到类（my_obj.__class__）中查找 如果还没有,顺着继承树继续查找 如果依旧找不到,调用myobj所属类中定义的`_getattr`方法,传入self 和属性名称的字符串形式(如'x') 下例中列出的是我们为Vector类定义的__getattr__方法.这个方法的作用很简单,它检查所查找的属性是不是xyzt中的某个字母 from typing import Optional class DynamicAccessMixin: shortcut_names = 'xyzt' def __getattr__(self, name:str)->Optional[float]: cls = type(self) if len(name) == 1: pos = cls.shortcut_names.find(name) if 0 class Vector(VectorBase,AbsMixin, DimensionMixin,LiteralMixin,CodecMixin,SliceMixin,DynamicAccessMixin): pass v = Vector(range(5)) v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) v.x 0.0 v.x = 10 v.x 10 v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) 可以看到,为v.x 赋值没有抛出错误但是前后矛盾.上面之所以前后矛盾是__getattr__的运作方式导致的: 仅当对象没有指定名称的属性时,Python才会调用那个方法,这是一种后备机制. 可是像v.x = 10这样赋值之后v对象有x属性了,因此使用v.x获取x属性的值时不会调用__getattr__方法了,解释器直接返回绑定到v.x上的值即10.另一方面,__getattr__方法的实现没有考虑到self._components之外的实例属性,而是从这个属性中获取shortcut_names中所列的\"虚拟属性\". 为了避免这种前后矛盾的现象,我们要改写mixin中设置属性的逻辑 多数时候,如果实现了__getattr__方法,那么也要定义__setattr__方法,以防对象的行为不一致 class DynamicAccessMixin: shortcut_names = 'xyzt' def __getattr__(self, name:str)->Optional[float]: cls = type(self) if len(name) == 1: pos = cls.shortcut_names.find(name) if 0 bool: cls = type(self) if len(name) == 1: if name in cls.shortcut_names: error = 'readonly attribute {attr_name!r}' elif name.islower(): error = \"can't set attributes 'a' to 'z' in {cls_name!r}\" else: error = '' if error: msg = error.format(cls_name=cls.__name__, attr_name=name) raise AttributeError(msg) return True class Vector(VectorBase,AbsMixin,DimensionMixin, LiteralMixin,CodecMixin,SliceMixin, DynamicAccessMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v = Vector(range(5)) v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) v.x 0.0 v.x = 10 v.x --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 v.x = 10 2 v.x in __setattr__(self, name, value) 1 class Vector(VectorBase,AbsMixin,DimensionMixin, LiteralMixin,CodecMixin,SliceMixin, DynamicAccessMixin): 2 def __setattr__(self, name:str, value:float): ----> 3 self._setattr_error_handler(name) 4 super().__setattr__(name, value) in _setattr_error_handler(self, name) 21 if error: 22 msg = error.format(cls_name=cls.__name__, attr_name=name) ---> 23 raise AttributeError(msg) 24 return True AttributeError: readonly attribute 'x' v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) Vector类第4版：散列和快速等值测试 我们要再次实现__hash__方法.加上现有的__eq__方法,这会把Vector实例变成可散列的对象. 我们的散列方式就是计算各个分量的散列值,然后聚合求异或 from functools import reduce from operator import xor class HashableMixin: def __eq__(self, other:VectorBase)->VectorBase: \"\"\"使用`and`运算符的截断特性和迭代器工具惰性计算特性判断是否一致,一旦有不一致就会终止后面的计算\"\"\" return len(self) == len(other) and all(a == b for a, b in zip(self, other)) def __hash__(self)->int: hashes = (hash(x) for x in self._components) # return reduce(xor, hashes, 0) class Vector(VectorBase,AbsMixin, DimensionMixin,LiteralMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) 但是还没暖点每次这这有 Vector类第5版:格式化 Vector类的__format__方法与Vector2D类的相似,但是不使用极坐标,而使用超球面坐标,因为Vector类支持n个维度,而超过四维后,球体变成了\"超球体\". 因此,我们会把自定义的格式后缀由'p'变成'h' from math import sqrt,atan2,pi from typing import Tuple class HypersphereMixin: \"\"\"需要实现`__len__`\"\"\" def angle(self, n:int)->float: \"\"\"使用[\"n 维球体\"词条](http://en.wikipedia.org/wiki/N-sphere)中的公式计算某个角坐标\"\"\" r = sqrt(sum(x * x for x in self[n:])) a = atan2(r, self[n-1]) if (n == len(self) - 1) and (self[-1] Tuple[float]: \"\"\"创建生成器表达式，按需计算所有角坐标\"\"\" return (self.angle(n) for n in range(1, len(self))) from itertools import chain class LiteralMixin: \"\"\"需要HypersphereMixin\"\"\" _components:Optional[array]=None def __str__(self)->str: return str(tuple(self)) def __repr__(self)->str: \"\"\" 如果 Vector 实例的分量超过 6 个,`repr()` 生成的字符串就会使用 ... 省略一 部分, 包含大量元素的集合类型一定要这么做,因为字符串表示形式是用于调试的 (因此不想让大型对象在控制台或日 志中输出几千行内容). 使用 reprlib 模块可以生成长度有限的表示形式. \"\"\" components = reprlib.repr(self._components) components = components[components.find('['):-1] return 'Vector({})'.format(components) def __format__(self,fmt_spec:str='')->str: if fmt_spec.endswith('h'): # 超球面坐标 fmt_spec = fmt_spec[:-1] coords = chain([abs(self)],self.angles()) outer_fmt = '' else: coords = self outer_fmt = '({})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(', '.join(components)) class Vector(VectorBase, AbsMixin,DimensionMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin,HypersphereMixin,LiteralMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v = Vector(range(5)) format(v) '(0.0, 1.0, 2.0, 3.0, 4.0)' format(Vector([2, 2, 2, 2]), '.3eh') '' Vector类第6版:运算符重载 向量的求反运算就是每位求反 向量的求和运算就是对应位求和. 向量的标量乘法就是每位乘以一个常数 向量点乘则是各位相乘后再相加 class PositiveNegativeMixin: def __neg__(self)->VectorBase: cls = type(self) return cls(-x for x in self) def __pos__(self)->VectorBase: cls = type(self) return cls(self) from itertools import zip_longest class AddMixin: def __add__(self, other:VectorBase)->VectorBase: cls = type(self) if isinstance(other, cls) and self.dimension == other.dimension: try: pairs = zip_longest(self, other, fillvalue=0.0) result = cls(a + b for a, b in pairs) return result except TypeError: return NotImplemented else: return NotImplemented def __radd__(self, other:VectorBase)->VectorBase: print(\"radd\") return self + other import numbers class MulMixin: def __mul__(self, scalar:numbers.Real)->VectorBase: cls = type(self) if isinstance(scalar, numbers.Real): return cls(n * scalar for n in self) else: return NotImplemented def __rmul__(self, scalar:numbers.Real)->VectorBase: return self * scalar class MatmulMixin: def __matmul__(self, other:VectorBase)->float: cls = type(self) if isinstance(other,cls) and self.dimension == other.dimension: try: return sum(a * b for a, b in zip(self, other)) except TypeError: return NotImplemented else: return NotImplemented def __rmatmul__(self, other): return self @ other class CalculMixin(PositiveNegativeMixin,AddMixin,MulMixin,MatmulMixin): pass class Vector(VectorBase, AbsMixin,DimensionMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin,HypersphereMixin,LiteralMixin, CalculMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v1 = Vector([1,2,3,4,5]) v2 = Vector([1,2,3,4,5,6]) v3 = Vector([5,4,3,2,1]) n = 10 v1+v2 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 v1+v2 TypeError: unsupported operand type(s) for +: 'Vector' and 'Vector' v1+v3 Vector([6.0, 6.0, 6.0, 6.0, 6.0]) v1*3 Vector([3.0, 6.0, 9.0, 12.0, 15.0]) 3*v1 Vector([3.0, 6.0, 9.0, 12.0, 15.0]) v1@v3 35.0 -v1 Vector([-1.0, -2.0, -3.0, -4.0, -5.0]) Vector类第7版:比较符号 使用==或者!=判断两个向量是否一致 class EqualityMixin: def __eq__(self, other): cls = type(self) if isinstance(other, cls): return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) else: return NotImplemented class Vector(VectorBase, AbsMixin,DimensionMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin,HypersphereMixin,LiteralMixin, CalculMixin,EqualityMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v1 = Vector([1,2,3,4,5]) v2 = Vector([1,2,3,4,5,6]) v3 = Vector([1,2,3,4,5]) v1==v2 False v1==v3 True v1 != v2 True Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/面向对象惯用法/结语.html":{"url":"语法篇/面向对象惯用法/结语.html","title":"结语","keywords":"","body":"结语 想想哪些类是真正需要的 大多数程序员编写应用程序而不开发框架.即便是开发框架的那些人,多数时候(或大多数时候)也是在编写应用程序. 编写应用程序时,我们通常不用设计类的层次结构。我们至多会编写子类、继承抽象基类或框架提供的其他类. 作为应用程序开发者, 我们极少需要编写作为其他类的超类的类.我们自己编写的类几乎都是末端类(即继承树的叶子). 如果作为应用程序开发者,你发现自己在构建多层类层次结构,可能是发生了下述事件中的一个或多个. 你在重新发明轮子。去找框架或库,它们提供的组件可以在应用程序中重用. 你使用的框架设计不良。去寻找替代品. 你在过度设计.记住要遵守 KISS 原则. 你厌烦了编写应用程序,决定新造一个框架.恭喜,祝你好运! 这些事情你可能都会遇到: 你厌倦了,决定重新发明轮子,自己构建设计过度和不良的框架,因此不得不编写一个又一个类去解决鸡毛蒜皮的小事. 希望你能乐在其中, 至少得到应有的回报. python的封装--私有属性的安全性和保障性 Perl 不会强制你保护隐私。你应该待在客厅外,因为你没收到邀请,而不是因为 里面有把枪。 ——Larry Wall Perl 之父 Python 和 Perl 在很多方面的做法是截然相反的,但是Larry和Guido似乎都同意要保护对象的隐私. 我发现很多人都对Java提供的隐私保障推崇备至.可事实是,Java 的 private 和 protected 修饰符 往往只是为了防止意外(即一种安全措施).只有使用安全管理器部署应用时才能保障绝对安全,防止恶意访问; 但是,实际上很少有人这么做,即便在企业中也少见. 把协议当作非正式的接口 协议不是 Python 发明的。Smalltalk 团队,也就是\"面向对象\"的发明者,使用\"协议\"这个词表示现在我们称 之为接口的特性.某些 Smalltalk 编程环境允许程序员把一组方法标记为协议,但这只不过是一种文档, 用于辅助导航,语言不对其施加特定措施.因此,向熟悉正式(而且编译器会施加措施)接口的人解释\"协议\"时, 我会简单地说它是\"非正式的接口\". 动态类型语言中的既定协议会自然进化.所谓动态类型是指在运行时检查类型,因为方法签名和变量没有静态类型信息. Ruby是一门重要的面向对象动态类型语言,它也使用协议. 在 Python 文档中,如果看到\"文件类对象\"这样的表述,通常说的就是协议.这是一种简短的说法,意思是: \"行为基本与文件一致,实现了部分文件接口,满足上下文相关需求的东西.\" 你可能觉得只实现协议的一部分不够严谨,但是这样做的优点是简单. 不要为了满足过度设计的接口契约和让编译器开心,而去实现不需要的方法,我们要遵守KISS原则. 类型提示 2014年,Python世界最大的新闻应该是 Guido van Rossum 同意实现可选的静态类型检查,这与检查程序 Mypy(http://www.mypy-lang.org)的做法类似,即使用函数注解实现。这一消息出自 8 月 15 日发表在 Python-ideas邮件列表中的一个话题,题为 Optional static typing —the crossroads. 一个月后,“PEP 484—Type Hints”草案发布了,发起人是 Guido. 这个功能的目的是让程序员在函数定义中使用注解声明参数和返回值的类型,但这是可选的. 关键在于“可选”二字.仅当你想得到注解的好处和限制时才需要添加注解,而且可以在一些函数中添加,在另一些函数中不添加. 从表面上看,这与 Microsoft 对 TypeScript采取的方式类似,不过 TypeScript 做得更进一步: TypeScript 添加了新的语言结构(如模块、类、显式接口, 等等),允许声明变量类型,而且最终编译成常规的JavaScript 目前来看,Python的可选静态类型没这么大的雄心.但似乎cython团队打算好好利用这一语言特性. 为了理解这个提案的动机,不能忽略 Guido 在 2014 年 8 月 15 日发送的那封重要邮件中的这段话: 我还得做个假设:这个功能主要供 lint 程序、IDE 和文档生成工具使用.这些工具有个共同点:即使类型检查失败了,程序仍能运行。此外,程序中添加的类 型不能降低性能(也不能提升性能 :-)). 因此,这一举动并不像乍一看那么激进.PEP 484—Type Hints提到了PEP 482—Literature Overview for Type Hints,后者概述了第三方 Python 工具和其他语言实现类型提示的方式. 不管激进不激进,类型提示都已经到来: 最后,PEP 484明确指出: 还要强调一点,Python 依旧是一门动态类型语言,作者从未打算强制要求使用类型提示,甚至不会把它变成约定. 接口中的隐喻和习惯用法 隐喻能打破壁垒,让人更易于理解.使用\"栈\"和\"队列\"描述基本的数据类型就有这样的功效: 这两个词清楚地道出了添加或删除元素的方式. 另一方面,Alan Cooper 在《交互设计精髓(第 4 版)》中写道: 严格奉行隐喻设计毫无必要,却把界面死死地与物理世界的运行机制捆绑在一起. 他说的是用户界面,但对 API 同样适用。不过 Cooper 同意,当\"真正合适的\"隐喻\"正中下怀\"时,可以使用隐喻(他用的词是\"正中下怀\",因为合适的隐喻可遇不可求). Python 语言的基本协议就是 Cooper 所说的\"习惯用法\"。知道\"序列\"是什么之后,可以把这些知识应用到不同的场合. Python这门语言的学习最关键的就是学习基本惯用法,让你的代码简洁、高效且可读。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/元编程/":{"url":"语法篇/元编程/","title":"元编程","keywords":"","body":"*元编程 Meta-这个前缀在希腊语中的本意是「在…后，越过…的」，类似于拉丁语的 post-，比如 metaphysics 就是「在物理学之后」，这个词最开始指一些亚里士多德的著作，因为它们通常排序在《物理学》之后。但西方哲学界在几千年中渐渐赋予该词缀一种全新的意义：关于某事自身的某事。比如meta-knowledge就是「关于知识本身的知识」，meta-data 就是「关于数据的数据」，meta-language 就是「关于语言的语言」，而 meta-programming 也是由此而来，是「关于编程的编程」。弄清了词源和字面意思，可知大陆将 meta-这个前缀译为「元」并不恰当。台湾译为「后设」，稍微好一点点，但仍旧无法望文生义。也许「自相关」是个不错的选择，「自相关数据」、「自相关语言」、「自相关编程」——但是好像又太罗嗦了。 怎样才算meta-programming呢？泛泛来说，只要是与编程相关的编程就算是meta-programming了——比如，若编程甲可以输出 A - Z，那么写程序甲算「编程」；而程序乙可以生成程序甲（也许还会连带着运行它输出 A - Z），那么编写程序乙的活动，就可以算作meta-programming，「元编程」.注意，程序甲和程序乙并不一定是同一种语言. 不过metaprogramming更狭义的意思应该是指「编写能改变语言语法特性或者运行时特性的程序」.换言之，一种语言本来做不到的事情，通过你编程来修改它，使得它可以做到了，这就是元编程. python的元编程主要实现方式有: 加载时修改代码行为 运算符重载 装饰器 元类编程 描述符 import hook 运行时改变代码行为 动态编译 动态属性 猴子补丁和热更新 等手段编写能改变语言语法特性或者运行时特性的程序. 元编程常用于高度抽象,或者改造接口,它相对比较难以理解,一般也用不着.本部分主要讲这个技术. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:30:26 "},"语法篇/元编程/运算符重载.html":{"url":"语法篇/元编程/运算符重载.html","title":"运算符重载","keywords":"","body":"运算符重载 运算符重载在任何语言中都算得上是高级特性,因为它可以改变语言本身即元编程. Python支持有限的运算符重载,并有几个特殊的运算符可以改变类的一些特性. 本节需要的先验知识有: 面向对象惯用法 受限制的运算符重载 在某些圈子中,运算符重载的名声并不好.这个语言特性可能(已经)被滥用,让程序员困惑,导致缺陷和意料之外的性能瓶颈.但是,如果使用得当,API会变得好用,代码会变得易于阅读.Python施加了一些限制,做好了灵活性、可用性和安全性方面的平衡： 不能重载内置类型的运算符 不能新建运算符,只能重载现有的 某些运算符不能重载——is、and、or 和not（不过位运算符&、| 和~ 可以） 下面是python所有可以重载的运算符以及对应的特殊方法: 一元运算符 特殊方法 + __pos__ - __neg__ ~ __invert__ abs(...) __abs__ 二元运算符 特殊方法 + __add__,__radd__ += __iaddr__ - __sub__,__rsub__ * __mul__,__rmul__ / __div__,__rdiv__,__truediv__,__rtruediv__ // __floordiv__,__rfloordiv__ % __mod__,__rmod__ ** __pow__,__rpow__ __lshift__,__rlshift__ >> __rshift__,__rrshift__ & __and__,__rand__ ^ __xor__,__rxor__ l __or__,__ror_ -= __isub__ *= __imul__ /= __idiv__,__itruediv__ //= __ifloordiv__ %= __imod__ **= __ipow__ __ilshift__ >>= __irshift__ &= __iand__ ^= __ixor__ l= __ior__ == __eq__ !=,<> __ne__ > __get__ __lt__ >= __ge__ __le__ @ __matmul__(),__rmatmul__() @= __imatmul__() 例: 定义一个数组类,实现减法索引打印等操作 class Array: def __init__(self,*args):#构造函数 self.value = args def __sub__(self,other):#减法运算符 if isinstance(other,(int ,float)): new = Array(*list(map(lambda x : x-other,self.value))) return new if isinstance(other,Array): new = Array(*list(map(lambda x,y : x-y,self.value,other.value))) return new else: raise ValueError(\"Illegal operations\") def __repr__(self):#打印 return \"Array: \"+str(self.value) def __str__(self):#字符串化 return \"Array: \"+str(self.value) def __getitem__(self,index):#索引分片,有了分片也就有了迭代,但不如迭代器好 new = Array(*self.value[index]) return new arr1=Array(1,2,3,4) arr2=Array(10,20,30,40) arr2-arr1 Array: (9, 18, 27, 36) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:12:45 "},"语法篇/元编程/特性与描述符.html":{"url":"语法篇/元编程/特性与描述符.html","title":"特性与描述符","keywords":"","body":"特性与描述符 除了属性之外,我们还可以创建特性(property),在不改变类接口的前提下,使用存取方法(即读值方法和设值方法)修改数据属性.这与统一访问原则相符--不管服务是由存储还是计算实现的,一个模块提供的所有服务都应该通过统一的方式使用. property是一个用于类中方法的装饰器,用于将方法属性转换为特性,如果要设定特性的增删改查能力,则可以使用.setter,.deleter定义. class Event(DbRecord): @property def venue(self): '''The Event attribute''' return self.__venue @venue.setter def venue(self,value): self.__venue = value @venue.deleter def venue(self,value): del self.__venue 虽然内置的property经常用作装饰器,但它其实是一个类.在Python中,函数和类通常可以互换,因为二者都是可调用的对象,而且没有实例化对象的new运算符,所以调用构造方法与调用工厂函数没有区别.此外,只要能返回新的可调用对象,代替被装饰的函数,二者都可以用作装饰器. property构造方法的完整签名如下： property(fget=None, fset=None, fdel=None, doc=None) 所有参数都是可选的,如果没有把函数传给某个参数,那么得到的特性对象就不允许执行相应的操作. 某些情况下,这种经典形式比装饰器句法好.但是在方法众多的类定义体中使用装饰器的话,一眼就能看出哪些是读值方法,哪些是设值方法,而不用按照惯例在方法名的前面加上get和set.类中的特性能影响实例属性的寻找方式,而一开始这种方式可能会让人觉得意外. 特性都是类属性,但是特性管理的其实是实例属性的存取.如果实例和所属的类有同名数据属性,那么实例属性会覆盖(或称遮盖)类属性--至少通过那个实例读取属性时是这样. 本节的先验知识有: 面向对象惯用法 python的数据模型 装饰器 实例属性遮盖类的数据属性 class Class: data = 'the class data attr' @property def prop(self): return 'the prop value' obj = Class() vars(obj) {} obj.data 'the class data attr' obj.data = 'bar' vars(obj) {'data': 'bar'} obj.data 'bar' Class.data 'the class data attr' 实例属性不会遮盖类特性 Class.prop obj.prop 'the prop value' obj.prop = 'foo' --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 obj.prop = 'foo' AttributeError: can't set attribute obj.__dict__['prop'] = 'foo' vars(obj) {'data': 'bar', 'prop': 'foo'} obj.prop 'the prop value' Class.prop obj.prop 'the prop value' 新添的类特性遮盖现有的实例属性 obj.data 'bar' Class.data 'the class data attr' Class.data = property(lambda self: 'the \"data\" prop value') obj.data 'the \"data\" prop value' del Class.data obj.data 'bar' 特性的文档 控制台中的help()函数或IDE等工具需要显示特性的文档时,会从特性的__doc__属性中提取信息. 如果使用经典调用句法,为property对象设置文档字符串的方法是传入doc参数: weight = property(get_weight, set_weight, doc='weight in kilograms') 使用装饰器创建property对象时,读值方法(有@property装饰器的方法)的文档字符串作为一个整体,变成特性的文档. 使用特性获取链接的记录 下图是用到的几个类 Record __init__ 方法与schedule1.py 脚本（见示例19-9）中的一样;为了辅助测试,增加了__eq__方法. DbRecord Record类的子类,添加了__db 类属性,用于设置和获取__db属性的set_db 和get_db静态方法,用于从数据库中获取记录的fetch类方法,以及辅助调试和测试的__repr__实例方法. Event DbRecord类的子类,添加了用于获取所链接记录的venue和speakers属性,以及特殊的__repr__方法. import inspect DB_NAME = 'schedule2_db' CONFERENCE = 'conference.115' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) def __eq__(self, other): if isinstance(other, Record): return self.__dict__ == other.__dict__ else: return NotImplemented class MissingDatabaseError(RuntimeError): \"\"\"需要数据库但没有指定数据库时抛出。\"\"\" pass class DbRecord(Record): __db = None @staticmethod def set_db(db): DbRecord.__db = db @staticmethod def get_db(): return DbRecord.__db @classmethod def fetch(cls, ident): db = cls.get_db() try: return db[ident] except TypeError: if db is None: msg = \"database not set; call '{}.set_db(my_db)'\" raise MissingDatabaseError(msg.format(cls.__name__)) else: raise def __repr__(self): if hasattr(self, 'serial'): cls_name = self.__class__.__name__ return ''.format(cls_name, self.serial) else: return super().__repr__() class Event(DbRecord): @property def venue(self): key = 'venue.{}'.format(self.venue_serial) return self.__class__.fetch(key) @property def speakers(self): if not hasattr(self, '_speaker_objs'): spkr_serials = self.__dict__['speakers'] fetch = self.__class__.fetch self._speaker_objs = [fetch('speaker.{}'.format(key)) for key in spkr_serials] return self._speaker_objs def __repr__(self): if hasattr(self, 'name'): cls_name = self.__class__.__name__ return ''.format(cls_name, self.name) else: return super().__repr__() def load_db(db): raw_data = load() warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): record_type = collection[:-1] cls_name = record_type.capitalize() cls = globals().get(cls_name, DbRecord) if inspect.isclass(cls) and issubclass(cls, DbRecord): factory = cls else: factory = DbRecord for record in rec_list: key = '{}.{}'.format(record_type, record['serial']) record['serial'] = key db[key] = factory(**record) import shelve db = shelve.open(DB_NAME) if CONFERENCE not in db: load_db(db) DbRecord.set_db(db) event = DbRecord.fetch('event.33950') event event.venue event.venue.name 'Portland 251' for spkr in event.speakers: print('{0.serial}: {0.name}'.format(spkr)) speaker.3471: Anna Martelli Ravenscroft speaker.5199: Alex Martelli db.close() 使用特性验证属性 目前,我们只介绍了如何使用@property装饰器实现只读特性.本节要创建一个可读写的特性 LineItem类第1版：表示订单中商品的类 假设有个销售散装有机食物的电商应用,客户可以按重量订购坚果、干果或杂粮.在这个系统中,每个订单中都有一系列商品,而每个商品都可以使用. class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) raisins.subtotal() 69.5 raisins.weight = -20 raisins.subtotal() -139.0 这个类没法限制参数.比如作为一个商品订单,它的值可以是负的. LineItem类第2版：能验证值的特性 class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price @property def weight(self): return self.__weight @weight.setter def weight(self, value): if value > 0: self.__weight = value else: raise ValueError('value must be > 0') 特性工厂函数 我们的weight 和price有相似的特点,都不能为负.如果一个类有很多这样的特性,那一个一个写特性会很麻烦,因此可以使用特性工厂函数来产生一样特点的特性. 我们将定义一个名为quantity的特性工厂函数,取这个名字是因为,在这个应用中要管理的属性表示不能为负数或零的量.下例是LineItem类的简洁版,用到了quantity特性的两个实例: 一个用于管理weight属性， 另一个用于管理price属性。 def quantity(storage_name): def qty_getter(instance): return instance.__dict__[storage_name] def qty_setter(instance, value): if value > 0: instance.__dict__[storage_name] = value else: raise ValueError('value must be > 0') return property(qty_getter, qty_setter) class LineItem: weight = quantity('weight') price = quantity('price') def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price nutmeg = LineItem('Moluccan nutmeg', 8, 13.95) nutmeg.weight, nutmeg.price (8, 13.95) sorted(vars(nutmeg).items()) [('description', 'Moluccan nutmeg'), ('price', 13.95), ('weight', 8)] 工厂函数构建的特性利用了特性覆盖实例属性的行为,因此对self.weight或nutmeg.weight的每个引用都由特性函数处理,只有直接存取__dict__属性才能跳过特性的处理逻辑. 在真实的系统中,分散在多个类中的多个字段可能要做同样的验证,此时最好把quantity工厂函数放在实用工具模块中,以便重复使用.最终可能要重构那个简单的工厂函数,改成更易扩展的描述符类,然后使用专门的子类执行不同的验证. 属性描述符 描述符是对多个属性运用相同存取逻辑的一种方式,ORM 中的字段类型是往往使用描述符，把数据库记录中字段里的数据与Python对象的属性对应起来. 描述符是实现了特定协议的类,这个协议包括__get__、__set__ 和__delete__方法. property类实现了完整的描述符协议.通常可以只实现部分协议.其实我们在真实的代码中见到的大多数描述符只实现了__get__ 和__set__方法,还有很多只实现了其中的一个.描述符是Python的独有特征,不仅在应用层中使用,在语言的基础设施中也有用到.除了特性之外,使用描述符的Python功能还有方法及classmethod和staticmethod装饰器.理解描述符是精通Python的关键. LineItem类第3版：一个简单的描述符 实现了__get__、__set__ 或__delete__方法的类是描述符.描述符的用法是,创建一个实例,作为另一个类的类属性. 我们将定义一个Quantity描述符用来代替特性工厂函数,LineItem类会用到两个Quantity实例: 一个用于管理weight属性 另一个用于管理price属性 从现在开始我会使用下述定义: 描述符类 实现描述符协议的类.在上图中,是Quantity类. 托管类 把描述符实例声明为类属性的类——上图中的LineItem类 描述符实例 描述符类的各个实例,声明为托管类的类属性.在上图中,各个描述符实例使用箭头和带下划线的名称表示(在UML中下划线表示类属性).与黑色菱形接触的LineItem类包含描述符实例. 托管实例 托管类的实例.在这个示例中,LineItem实例是托管实例 储存属性 托管实例中存储自身托管属性的属性.在上图中,LineItem实例的weight 和price属性是储存属性.这种属性与描述符属性不同,描述符属性都是类属性. 托管属性 托管类中由描述符实例处理的公开属性,值存储在储存属性中.也就是说描述符实例和储存属性为托管属性建立了基础. class Quantity: def __init__(self, storage_name): self.storage_name = storage_name def __set__(self, instance, value): if value > 0: instance.__dict__[self.storage_name] = value else: raise ValueError('value must be > 0') 各个托管属性的名称与储存属性一样,而且读值方法不需要特殊的逻辑,所以Quantity类不需要定义__get__方法. 编写__set__方法时，要记住self 和instance参数的意思: self 是描述符实例， instance 是托管实例 管理实例属性的描述符应该把值存储在托管实例中.因此Python才为描述符中的那个方法提供了instance参数. class LineItem: weight = Quantity('weight') price = Quantity('price') def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price truffle = LineItem('White truffle', 100, 0) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 truffle = LineItem('White truffle', 100, 0) in __init__(self, description, weight, price) 5 self.description = description 6 self.weight = weight ----> 7 self.price = price 8 def subtotal(self): 9 return self.weight * self.price in __set__(self, instance, value) 6 instance.__dict__[self.storage_name] = value 7 else: ----> 8 raise ValueError('value must be > 0') ValueError: value must be > 0 上面的方式还是不够简洁,我们不得不在申明LineItem时为每个属性指定Quantity()的参数--属性的名称. 可问题是赋值语句右手边的表达式先执行,而此时变量还不存在. Quantity()表达式计算的结果是创建描述符实例,而此时Quantity类中的代码无法猜出要把描述符绑定给哪个变量(例如weight或price). 因此上例必须明确指明各个Quantity实例的名称.这样不仅麻烦,还很危险--如果程序员直接复制粘贴代码而忘了编辑名称,比如写成price = Quantity('weight')，那么程序的行为会大错特错，设置price的值时会覆盖weight的值. LineItem类第4版：自动获取储存属性的名称 为了避免在描述符声明语句中重复输入属性名,我们将为每个Quantity实例的storage_name属性生成一个独一无二的字符串.下图是更新后的Quantity和LineItem类的UML类图. 为了生成storage_name,我们以'_Quantity#'为前缀,然后在后面拼接一个整数: Quantity.__counter类属性的当前值,每次把一个新的Quantity描述符实例依附到类上,都会递增这个值.在前缀中使用井号能避免storage_name与用户使用点号创建的属性冲突,因为nutmeg._Quantity#0是无效的Python句法.但是,内置的getattr 和setattr函数可以使用这种\"无效的\"标识符获取和设置属性,此外也可以直接处理实例属性__dict__ class Quantity: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): if value > 0: setattr(instance, self.storage_name, value) else: raise ValueError('value must be > 0') class LineItem: weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price coconuts = LineItem('Brazilian coconut', 20, 17.95) coconuts.weight, coconuts.price (20, 17.95) getattr(coconuts, '_Quantity#0'), getattr(coconuts, '_Quantity#1') (20, 17.95) LineItem类第5版：一种新型描述符 我们虚构的有机食物网店遇到一个问题: 不知怎么回事儿有个商品的描述信息为空,导致无法下订单. 为了避免出现这个问题,我们要再创建一个描述符NonBlank.在设计NonBlank的过程中,我们发现它与Quantity描述符很像,只是验证逻辑不同. 回想Quantity的功能，我们注意到它做了两件不同的事： 管理托管实例中的储存属性 验证用于设置那两个属性的值 由此可知,我们可以重构,并创建两个基类 AutoStorage 自动管理储存属性的描述符类 Validated 扩展AutoStorage类的抽象子类,覆盖__set__ 方法,调用必须由子类实现的validate方法 我们重写Quantity类,并实现NonBlank,让它继承Validated类,只编写validate方法.类之间的关系见图. Validated、Quantity和NonBlank 三个类之间的关系体现了模板方法设计模式.具体而言，Validated.__set__ 方法正是Gamma等四人所描述的模板方法的例证--一个模板方法用一些抽象的操作定义一个算法，而子类将重定义这些操作以提供具体的行为. import abc class AutoStorage: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value class LineItem: description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price coconuts = LineItem('Brazilian coconut', 20, 17.95) coconuts.weight, coconuts.price (20, 17.95) raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#0', '_Quantity#0', '_Quantity#1'] LineItem.description.storage_name '_NonBlank#0' 覆盖型与非覆盖型描述符 Python存取属性的方式特别不对等.通过实例读取属性时,通常返回的是实例中定义的属性;但是如果实例中没有指定的属性,那么会获取类属性.而为实例中的属性赋值时,通常会在实例中创建属性,根本不影响类.这种不对等的处理方式对描述符也有影响.其实根据是否定义__set__方法,描述符可分为两大类.其中覆盖型又可以分为2小类. 覆盖型 定义__set__,描述符的__set__方法使用托管实例中的同名属性覆盖(即插手接管)了要设置的属性,这种类型描述符的典型用途是管理数据属性 没有__get__方法的覆盖型描述符 通常，覆盖型描述符既会实现__set__ 方法,也会实现__get__方法,不过也可以只实现__set__ 方法.此时,只有写操作由描述符处理.通过实例读取描述符会返回描述符对象本身,因为没有处理读操作的__get__ 方法.如果直接通过实例的__dict__属性创建同名实例属性,以后再设置那个属性时,仍会由__set__ 方法插手接管,但是读取那个属性的话,就会直接从实例中返回新赋予的值,而不会返回描述符对象.也就是说实例属性会遮盖描述符,不过只有读操作是如此 非覆盖型 没有实现__set__方法的描述符是非覆盖型描述符.如果设置了同名的实例属性,描述符会被遮盖,致使描述符无法处理那个实例的那个属性.方法是以非覆盖型描述符实现的 我们通过下面的例子观察这两类描述符的行为差异 def cls_name(obj_or_cls): cls = type(obj_or_cls) if cls is type: cls = obj_or_cls return cls.__name__.split('.')[-1] def display(obj): cls = type(obj) if cls is type: return ''.format(obj.__name__) elif cls in [type(None), int]: return repr(obj) else: return ''.format(cls_name(obj)) def print_args(name, *args): pseudo_args = ', '.join(display(x) for x in args) print('-> {}.__{}__({})'.format(cls_name(args[0]), name, pseudo_args)) class Overriding: \"\"\"覆盖型描述符 也称数据描述符或强制描述符\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner) def __set__(self, instance, value): print_args('set', self, instance, value) class OverridingNoGet: \"\"\"没有`__get__`方法的覆盖型描述符\"\"\" def __set__(self, instance, value): print_args('set', self, instance, value) class NonOverriding: \"\"\"也称非数据描述符或遮盖型描述符\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner) class Managed: over = Overriding() over_no_get = OverridingNoGet() non_over = NonOverriding() def spam(self): print('-> Managed.spam({})'.format(display(self))) 覆盖型描述符的行为 上面的例子都是覆盖型描述符 obj = Managed() obj.over -> Overriding.__get__(, , ) Managed.over -> Overriding.__get__(, None, ) obj.over = 7 -> Overriding.__set__(, , 7) obj.over -> Overriding.__get__(, , ) obj.__dict__['over'] = 8 vars(obj) {'over': 8} obj.over -> Overriding.__get__(, , ) 没有__get__的覆盖型描述符的行为 只有写操作由描述符处理.通过实例读取描述符会返回描述符对象本身 obj.over_no_get Managed.over_no_get obj.over_no_get = 7 -> OverridingNoGet.__set__(, , 7) obj.over_no_get obj.__dict__['over_no_get'] = 9 obj.over_no_get 9 obj.over_no_get = 7 -> OverridingNoGet.__set__(, , 7) obj.over_no_get 9 非覆盖型描述符的行为 如果设置了同名的实例属性,描述符会被遮盖,致使描述符无法处理那个实例的那个属性 obj = Managed() obj.non_over -> NonOverriding.__get__(, , ) obj.non_over = 7 obj.non_over 7 Managed.non_over -> NonOverriding.__get__(, None, ) del obj.non_over obj.non_over -> NonOverriding.__get__(, , ) 在类中覆盖描述符 依附在类上的描述符无法控制为类属性赋值的操作.其实,这意味着为类属性赋值能覆盖描述符属性.这是一种猴子补丁技术,不过在下例中,我们把描述符替换成了整数,这其实会导致依赖描述符的类不能正确地执行操作. obj = Managed() Managed.over = 1 Managed.over_no_get = 2 Managed.non_over = 3 obj.over, obj.over_no_get, obj.non_over (1, 2, 3) 读类属性的操作可以由依附在托管类上定义有__get__ 方法的描述符处理,但是写类属性的操作不会由依附在托管类上定义有__set__方法的描述符处理. 若想控制设置类属性的操作,要把描述符依附在类的类上,即依附在元类上.默认情况下,对用户定义的类来说,其元类是type,而我们不能为type 添加属性,但我们可以自定义元类. 描述符协议增强[3.6] 上面的LineItem有个缺陷--就是初始化的时候都明确让属性的值绑定在Integer上的name属性上,而无法获知所有者类的属性名.如果使用自定义内部名字,又会难以调试.使用在PEP487上提供的可选的__set_name__()可以获得这个属性名字,并且可以自定义这部分内容: class AutoStorage: def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.name) def __set__(self, instance, value): setattr(instance, self.name, value) def __set_name__(self, owner, name): cls = self.__class__ prefix = cls.__name__ index = name self.name = '_{}#{}'.format(prefix, index) class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value class LineItem: description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#description', '_Quantity#price', '_Quantity#weight'] LineItem.description.name '_NonBlank#description' 方法是描述符 在类中定义的函数属于绑定方法(bound method),因为用户定义的函数都有__get__方法,所以依附到类上时,就相当于描述符.函数没有实现__set__方法,因此是非覆盖型描述符. 与描述符一样,通过托管类访问时,函数的__get__方法会返回自身的引用.但是通过实例访问时,函数的__get__方法返回的是绑定方法对象--一种可调用的对象,里面包装着函数,并把托管实例(例如obj)绑定给函数的第一个参数(即self),这与functools.partial函数的行为一致 描述符用法建议 下面根据刚刚论述的描述符特征给出一些实用的结论: 使用特性以保持简单 内置的property 类创建的其实是覆盖型描述符,__set__方法和__get__ 方法都实现了,即便不定义设值方法也是如此.特性的__set__方法默认抛出AttributeError:can't set attribute,因此创建只读属性最简单的方式是使用特性,这能避免下一条所述的问题. 只读描述符必须有__set__方法 如果使用描述符类实现只读属性,要记住__get__ 和__set__ 两个方法必须都定义,否则实例的同名属性会遮盖描述符.只读属性的__set__方法只需抛出AttributeError异常,并提供合适的错误消息. 用于验证的描述符可以只有__set__方法 对仅用于验证的描述符来说,__set__ 方法应该检查value参数获得的值,如果有效,使用描述符实例的名称为键,直接在实例的__dict__属性中设置.这样从实例中读取同名属性的速度很快,因为不用经过__get__方法处理. 仅有__get__方法的描述符可以实现高效缓存 如果只编写了__get__方法,那么创建的是非覆盖型描述符.这种描述符可用于执行某些耗费资源的计算,然后为实例设置同名属性,缓存结果.同名实例属性会遮盖描述符,因此后续访问会直接从实例的__dict__属性中获取值,而不会再触发描述符的__get__方法. 非特殊的方法可以被实例属性遮盖 由于函数和方法只实现了__get__ 方法,它们不会处理同名实例属性的赋值操作.因此，像my_obj.the_method = 7 这样简单赋值之后,后续通过该实例访问the_method得到的是数字7——但是不影响类或其他实例.然而,特殊方法不受这个问题的影响.解释器只会在类中寻找特殊的方法,也就是说repr(x)执行的其实是x.__class__.__repr__(x),因此x的__repr__ 属性对repr(x)方法调用没有影响.出于同样的原因,实例的__getattr__属性不会破坏常规的属性访问规则. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:12:34 "},"语法篇/元编程/装饰器.html":{"url":"语法篇/元编程/装饰器.html","title":"装饰器","keywords":"","body":"装饰器 函数装饰器用于在源码中\"标记\"函数,以某种方式增强函数的行为.严格来说装饰器这种形式是一种语法糖. 装饰器的特点有两个: 装饰器是可调用的对象,其参数是另一个可调用对象. 装饰器可能会处理被装饰的可调用对象,然后把它返回,或者将其替换成另一个可调用对象 装饰器在加载模块时立即执行 装饰器的形式如下: @decorator def call(args): pass 它等价于 call(args) = decorator(call(args)) 本章需要的先验知识有: 面向对象惯用法 函数 实现装饰器 下面这个例子定义了一个装饰器,用来在每次调用被装饰的函数时计时,然后把经过的时间,传入的参数和调用的结果打印出来. import time def timer(func): def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) elapsed = time.perf_counter() - t0 name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked @timer def snooze(seconds): time.sleep(seconds) snooze(2) [used:2.0047967199934646s] function snooze(2)->None @timer def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(5) [used:7.310009095817804e-07s] function factorial(1)->1 [used:0.0001588229788467288s] function factorial(2)->2 [used:0.0001920460199471563s] function factorial(3)->6 [used:0.00022201001411303878s] function factorial(4)->24 [used:0.00025161399389617145s] function factorial(5)->120 120 factorial.__name__ 'clocked' 包装装饰器 上面的装饰器有个缺点--遮盖了被装饰函数的__name__ 和__doc__ 属性.这时可以使用functools.wraps 装饰器把相关的属性从func复制到clocked中 import functools def timer(func): @functools.wraps(func) def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) elapsed = time.perf_counter() - t0 name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked @timer def snooze(seconds): time.sleep(seconds) snooze(2) [used:2.0031150709837675s] function snooze(2)->None @timer def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(6) [used:6.059999577701092e-07s] function factorial(1)->1 [used:0.00015848499606363475s] function factorial(2)->2 [used:0.0001919149945024401s] function factorial(3)->6 [used:0.0002199050213675946s] function factorial(4)->24 [used:0.00024739297805354s] function factorial(5)->120 [used:0.0002766310062725097s] function factorial(6)->720 720 factorial.__name__ 'factorial' 带参数的装饰器 我们修改之前的timer,希望它可以添加一个参数,用于指定秒数的精确位数.这样就需要写一个带参数的装饰器. 带参数的装饰器我们还需要再在外面套一层用来返回我们的装饰器函数. import time import functools def timer(rd=3): def decorate(func): @functools.wraps(func) def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) rs = time.perf_counter() - t0 elapsed = round(rs ,rd) name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked return decorate @timer() def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(2) [used:0.0s] function factorial(1)->1 [used:0.0s] function factorial(2)->2 2 @timer(7) def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(2) [used:7e-07s] function factorial(1)->1 [used:0.000142s] function factorial(2)->2 2 factorial.__name__ 'factorial' factorial.__doc__ 'factorial' 当然了返回装饰器函数的对象只要是可执行对象就行.因此或许用类来实现看起来会更加自然一些 class timer: def __call__(self,func): @functools.wraps(func) def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) rs = time.perf_counter() - t0 elapsed = round(rs ,self.rd) name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked def __init__(self,rd=3): self.rd = rd @timer(7) def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(3) [used:4e-07s] function factorial(1)->1 [used:8.65e-05s] function factorial(2)->2 [used:0.0001159s] function factorial(3)->6 6 factorial.__name__ 'factorial' 但从开销角度来看,显然使用函数闭包实现带参数装饰器会比使用带__call__方法的类实例来的更加好,毕竟函数一旦定义,调用的开销远比实例化一个类小的多,但如果需要实现一些复杂的状态管理功能,这种开销或许也是值得的. 类装饰器 装饰器除了可以装饰函数,也可以装饰类,原理也差不多,参数是一个类,而返回的也是一个类,下面以之前的LineItem作为例子讲解如何定义和使用类装饰器. 定制描述符的类装饰器 在特性与描述符部分的倒数第二个LineItem例子中储存属性的名称不具有描述性,即属性(如weight)的值存储在名为_Quantity#0的实例属性中,这样的名称不便于调试的问题.单靠描述符无法存储属性名字,因为实例化描述符时无法得知托管属性(即绑定到描述符上的类属性,例如前述示例中的weight)的名称. 可是,一旦组建好整个类,而且把描述符绑定到类属性上之后,我们就可以审查类,并为描述符设置合理的储存属性名称.LineItem类的__new__方法可以做到这一点,因此，在__init__方法中使用描述符时,储存属性已经设置了正确的名称, 为了解决这个问题而使用__new__ 方法纯属白费力气--每次新建LineItem实例时都会运行__new__ 方法中的逻辑,可是，一旦LineItem类构建好了,描述符与托管属性之间的绑定就不会变了.因此,我们要在创建类时设置储存属性的名称. 使用3.6的新接口__set_name__,类装饰器或元类都可以做到这一点.这边的例子使用类装饰器 def entity(cls): for key, attr in cls.__dict__.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) return cls import abc class AutoStorage: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) def __set_name__(self, owner, name): self.name = name class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value @entity class LineItem: description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#description', '_Quantity#price', '_Quantity#weight'] LineItem.description.storage_name '_NonBlank#description' 类装饰器能以较简单的方式做到元类做的事情——创建类时定制类. 但类装饰器也有个重大缺点:只对直接依附的类有效.这意味着,被装饰的类的子类可能继承也可能不继承装饰器所做的改动,具体情况视改动的方式而定. 标准库中的装饰器 Python内置了三个用于装饰方法的函数:property、classmethod 和staticmethod.这三个在面向对象惯用法部分讲. 而剩下的装饰器中 functools.total_ordering是用来装饰类的 functools.lru_cache,functools.singledispatch是用来装饰函数/方法的 functools.total_ordering自动添加比较特殊方法 functools.total_ordering装饰器可以装饰一个类,只要其中有实现__lt__、__le__、__gt__、__ge__中的至少一个,它就会将其他的补全 from functools import total_ordering @total_ordering class Student: def __eq__(self, other): return ((self.lastname.lower(), self.firstname.lower()) == (other.lastname.lower(), other.firstname.lower())) def __lt__(self, other): return ((self.lastname.lower(), self.firstname.lower()) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__'] 使用functools.lru_cache(maxsize=128, typed=False)做备忘 functools.lru_cache 是非常实用的装饰器,它实现了备忘（memoization）功能.这是一项优化技术,它把耗时的函数的结果保存起来,避免传入相同的参数时重复计算.LRU 三个字母是\"Least Recently Used\"的缩写,表明缓存不会无限制增长,一段时间不用的缓存条目会被扔掉. maxsize参数指定存储多少个调用的结果.缓存满了之后,旧的结果会被扔掉,腾出空间.为了得到最佳性能,maxsize 应该设为2的幂. typed 参数如果设为True,把不同参数类型得到的结果分开保存,即把通常认为相等的浮点数和整数参数(如1 和1.0)区分开. 因为lru_cache使用字典存储结果,而且键根据调用时传入的定位参数和关键字参数创建,所以被lru_cache 装饰的函数,它的所有参数都必须是可散列的. 生成第n个斐波纳契数这种慢速递归函数适合使用lru_cache @timer(7) def fibonacci(n): if n fibonacci(6) [used:5e-07s] function fibonacci(0)->0 [used:9e-07s] function fibonacci(1)->1 [used:0.0001972s] function fibonacci(2)->1 [used:5e-07s] function fibonacci(1)->1 [used:5e-07s] function fibonacci(0)->0 [used:5e-07s] function fibonacci(1)->1 [used:6.06e-05s] function fibonacci(2)->1 [used:0.0001216s] function fibonacci(3)->2 [used:0.0003805s] function fibonacci(4)->3 [used:5e-07s] function fibonacci(1)->1 [used:4e-07s] function fibonacci(0)->0 [used:5e-07s] function fibonacci(1)->1 [used:5.92e-05s] function fibonacci(2)->1 [used:0.0001174s] function fibonacci(3)->2 [used:4e-07s] function fibonacci(0)->0 [used:6e-07s] function fibonacci(1)->1 [used:5.86e-05s] function fibonacci(2)->1 [used:4e-07s] function fibonacci(1)->1 [used:5e-07s] function fibonacci(0)->0 [used:6e-07s] function fibonacci(1)->1 [used:5.96e-05s] function fibonacci(2)->1 [used:0.0001193s] function fibonacci(3)->2 [used:0.0002366s] function fibonacci(4)->3 [used:0.0004132s] function fibonacci(5)->5 [used:0.0008534s] function fibonacci(6)->8 8 浪费时间的地方很明显:fibonacci(1)调用了8 次,fibonacci(2)调用了5 次……但是,如果增加两行代码,使用lru_cache,性能会显著改善 from functools import lru_cache @lru_cache() @timer(7) def fibonacci(n): if n fibonacci(6) [used:4e-07s] function fibonacci(0)->0 [used:4e-07s] function fibonacci(1)->1 [used:7.52e-05s] function fibonacci(2)->1 [used:9e-07s] function fibonacci(3)->2 [used:0.0001163s] function fibonacci(4)->3 [used:6e-07s] function fibonacci(5)->5 [used:0.0001564s] function fibonacci(6)->8 8 PS:装饰器的叠放顺序也是有讲究的,它是从下向上执行的,因此最终执行的结果是最上面一层的包装. 使用functools.singledispatch实现单分配泛函 假设我们在开发一个调试Web应用的工具,我们想生成HTML,显示不同类型的Python对象,我们可能会编写这样的函数: import html def htmlize(obj): content = html.escape(repr(obj)) return '{}'.format(content) 这个函数适用于任何Python类型,但是现在我们想做个扩展,让它使用特别的方式显示某些类型. str：把内部的换行符替换为\\\\n；不使用\\，而是使用\\。 int：以十进制和十六进制显示数字。 list：输出一个HTML列表，根据各个元素的类型进行格式化。 因为Python不支持重载方法或函数,所以我们不能使用不同的签名定义htmlize的变体,也无法使用不同的方式处理不同的数据类型.在Python中,一种常见的做法是把htmlize变成一个分派函数,使用一串if/elif/elif,调用专门的函数,如htmlize_str,htmlize_int,等等,这样不便于模块的用户扩展,还显得笨拙:时间一长，分派函数htmlize会变得很大,而且它与各个专门函数之间的耦合也很紧密. functools.singledispatch装饰器可以把整体方案拆分成多个模块,甚至可以为你无法修改的类提供专门的函数.使用@singledispatch 装饰的普通函数会变成泛函数(generic function):根据第一个参数的类型,以不同方式执行相同操作的一组函数. from functools import singledispatch from collections import abc import numbers import html @singledispatch def htmlize(obj): content = html.escape(repr(obj)) return '{}'.format(content) @htmlize.register(str) def _(text): content = html.escape(text).replace('\\n', '\\n') return '{0}'.format(content) @htmlize.register(numbers.Integral) def _(n): return '{0} (0x{0:x})'.format(n) @htmlize.register(tuple) @htmlize.register(abc.MutableSequence) def _(seq): inner = '\\n'.join(htmlize(item) for item in seq) return '\\n' + inner + '\\n' htmlize(123) '123 (0x7b)' htmlize('123') '123' htmlize([1,2,3]) '\\n1 (0x1)\\n2 (0x2)\\n3 (0x3)\\n' 只要可能,注册的专门函数应该处理抽象基类(如numbers.Integral和abc.MutableSequence),不要处理具体实现(如int 和list).这样,代码支持的兼容类型更广泛.例如,Python扩展可以子类化numbers.Integral,使用固定的位数实现int 类型. singledispatch机制的一个显著特征是,你可以在系统的任何地方和任何模块中注册专门函数.如果后来在新的模块中定义了新的类型,可以轻松地添加一个新的专门函数来处理那个类型.此外,你还可以为不是自己编写的或者不能修改的类添加自定义函数. singledispatch 是经过深思熟虑之后才添加到标准库中的,它提供的特性很多,这里无法一一说明.这个机制最好的文档是PEP 443 — Single-dispatch generic functions. @singledispatch不是为了把Java的那种方法重载带入Python.在一个类中为同一个方法定义多个重载变体,比在一个函数中使用一长串if/elif/elif/elif块要更好.但是这两种方案都有缺陷,因为它们让代码单元(类或函数)承担的职责太多.@singledispath的优点是支持模块化扩展:各个模块可以为它支持的各个类型注册一个专门函数. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:12:39 "},"语法篇/元编程/元类编程.html":{"url":"语法篇/元编程/元类编程.html","title":"元类编程","keywords":"","body":"元类编程 元类是产生类的类,元类编程是一种使用这一特性,通过定制元类实现元编程的方法.也是python中最\"正统\"的元编程方式 本节需要的先验知识有: 面向对象惯用法 属性描述符 type--类工厂 有时,我觉得应该有类似nametuple的工厂函数,用于创建可变对象.假设我在编写一个宠物店应用程序,我想把狗的数据当作简单的记录处理.编写下面的样板代码让人厌烦: class Dog: def __init__(self, name, weight, owner): self.name = name self.weight = weight self.owner = owner rex = Dog('Rex', 30, 'Bob') rex 各个字段名称出现了三次.写了这么多样板代码,甚至字符串表示形式都不友好. 参考namedtuple,下面我们创建一个record_factory函数,即时创建简单的类 def record_factory(cls_name, field_names): try: field_names = field_names.replace(',', ' ').split() except AttributeError: # 不能调用.replace或.split方法 pass # 假定field_names本就是标识符组成的序列 field_names = tuple(field_names) def __init__(self, *args, **kwargs): attrs = dict(zip(self.__slots__, args)) attrs.update(kwargs) for name, value in attrs.items(): setattr(self, name, value) def __iter__(self): for name in self.__slots__: yield getattr(self, name) def __repr__(self): values = ', '.join('{}={!r}'.format(*i) for i in zip(self.__slots__, self)) return '{}({})'.format(self.__class__.__name__, values) cls_attrs = dict(__slots__ = field_names, __init__ = __init__,__iter__ = __iter__,__repr__ = __repr__) return type(cls_name, (object,), cls_attrs) Cat = record_factory('Cat', 'name weight owner') rex = Cat('Rex', 30, 'Bob') rex Cat(name='Rex', weight=30, owner='Bob') name, weight, _ = rex name, weight ('Rex', 30) \"{2}'s dog weighs {1}kg\".format(*rex) \"Bob's dog weighs 30kg\" rex.weight = 32 rex Cat(name='Rex', weight=32, owner='Bob') Cat.__mro__ (__main__.Cat, object) 可以看出上面的工厂函数核心就在于type()的使用.通常,我们把type视作函数,因为我们像函数那样使用它,例如,调用type(my_object) 获取对象所属的类——作用与my_object.__class__相同. 然而,type是一个类.当成类使用时,传入三个参数可以新建一个类: MyClass = type('MyClass', (MySuperClass, MyMixin),{'x': 42, 'x2': lambda self: self.x * 2}) type的三个参数分别是name、bases 和dict.最后一个参数是一个映射,指定新类的属性名和值. 元类 元类是制造类的工厂,不过不是函数而是类. 根据Python对象模型,类是对象,因此类肯定是另外某个类的实例.默认情况下,Python中的类是type类的实例.也就是说,type是大多数内置的类和用户定义的类的元类. 'spam'.__class__ str str.__class__ type type.__class__ type 为了避免无限回溯,type 是其自身的实例,如最后一行所示. 注意，我没有说str或其他对象继承自type.我的意思是,str和其他对象是type的实例.这两个类是object的子类.下图是他们的关系 两个示意图都是正确的.左边的示意图强调str、type 和LineItem 是object 的子类.右边的示意图则清楚地表明str、object 和LineItem是type的实例.因为它们都是类. 除了type,标准库中还有一些别的元类.例如ABCMeta和Enum.如下述代码片段所示,collections.Iterable 所属的类是abc.ABCMeta.Iterable是抽象类,而ABCMeta不是--不管怎样,Iterable是ABCMeta的实例. import collections collections.Iterable.__class__ import abc abc.ABCMeta.__class__ abc.ABCMeta.__mro__ (abc.ABCMeta, type, object) 向上追溯,ABCMeta最终所属的类也是type.所有类都直接或间接地是type的实例,不过只有元类同时也是type的子类.若想理解元类,一定要知道这种关系:元类(如ABCMeta)从type类继承了构建类的能力. 我们要抓住的重点是,所有类都是type的实例,但是元类还是type的子类,因此可以作为制造类的工厂.具体来说,元类可以通过实现__init__方法定制实例.元类的__init__方法可以做到类装饰器能做的任何事情,但是作用更大. %%writefile evaltime_meta.py from evalsupport import deco_alpha from evalsupport import MetaAleph print(' evaltime_meta module start') @deco_alpha class ClassThree(): print(' ClassThree body') def method_y(self): print(' ClassThree.method_y') class ClassFour(ClassThree): print(' ClassFour body') def method_y(self): print(' ClassFour.method_y') class ClassFive(metaclass=MetaAleph): print(' ClassFive body') def __init__(self): print(' ClassFive.__init__') def method_z(self): print(' ClassFive.method_z') class ClassSix(ClassFive): print(' ClassSix body') def method_z(self): print(' ClassSix.method_z') if __name__ == '__main__': print(' ClassThree tests', 30 * '.') three = ClassThree() three.method_y() print(' ClassFour tests', 30 * '.') four = ClassFour() four.method_y() print(' ClassFive tests', 30 * '.') five = ClassFive() five.method_z() print(' ClassSix tests', 30 * '.') six = ClassSix() six.method_z() print(' evaltime_meta module end') Overwriting evaltime_meta.py import evaltime_meta evalsupport module start MetaAleph body evalsupport module end evaltime_meta module start ClassThree body deco_alpha ClassFour body ClassFive body MetaAleph.__init__ ClassSix body MetaAleph.__init__ evaltime_meta module end !python evaltime_meta.py evalsupport module start MetaAleph body evalsupport module end evaltime_meta module start ClassThree body deco_alpha ClassFour body ClassFive body MetaAleph.__init__ ClassSix body MetaAleph.__init__ ClassThree tests .............................. deco_alpha:inner_1 ClassFour tests .............................. ClassFour.method_y ClassFive tests .............................. ClassFive.__init__ MetaAleph.__init__:inner_2 ClassSix tests .............................. ClassFive.__init__ MetaAleph.__init__:inner_2 evaltime_meta module end 元类的定义和使用: 元类继承自type,行为通过实现 __new__(meta,name,bases,class_dict) 类似于类中的__new__,用于定义元类的创建行为 __init__(cls, name, bases,attr_dict) 类似于类中的__init__,用于初始化元类,通过元类产生类时会用到. __call__(cls) 定义类实例化时的行为. 类方法__prepare__(meta, name, bases) 解释器调用元类的__new__ 方法之前会先调用__prepare__ 方法,使用类定义体中的属性创建映射.__prepare__ 方法的第一个参数是元类,随后两个参数分别是要构建的类的名称和基类组成的元组,返回值必须是映射.元类构建新类时,__prepare__方法返回的映射会传给__new__ 方法的最后一个参数,然后再传给__init__ 方法. 使用元类的类实例化产出类的顺序是: meta.__prepare__ meta.__new__ meta.__init__ 类实例化对象的顺序是: clz.__call__ clz.__new__ clz.__init__ class meta_A(type): def __call__(clz,*args, **kwargs): print(\"clz.call\") return super().__call__(*args, **kwargs) def __new__(meta,name,bases,class_dict): print(\"meta.new\") return type.__new__(meta,name,bases,class_dict) def __init__(cls, name, bases,attr_dict): print(\"meta.init\") super().__init__(name, bases,attr_dict) @classmethod def __prepare__(meta, name, bases): print('meta.prepare') return dict() class A(metaclass = meta_A): def __new__(cls,*args, **kwargs): print('clz.new') return super().__new__(cls) def __init__(self,name): self.name=name print('clz.init') meta.prepare meta.new meta.init a = A(\"qw\") clz.call clz.new clz.init a.name 'qw' 元类的基本用途 一般来说能不用元类就别用元类,或者说元编程的部分都是这个原则,能不用就别用,但很多时候为了实现一些特殊功能我们不得不用元类来实现 用来验证子类 元类的最简单用途就是用来验证其子类是否定义正确.构建复杂类体系时我们可能需要确保类风格一致,确保某些方法得到了覆写,或者确保类属性之间具有某些严格的关系. 元类提供了一种可靠的验证方式,每当开发者定义新类时,他会运行验证代码,确保符合规定. 实现这个功能并非必须使用元类,可以在__init__中写验证代码,在类初始化的时候验证,但如果想构建的时候就验证,那就需要使用元类了. 例: 确保类及其子类定义的图形边数大于3: class ValidatePolygon(type): def __new__(meta,name,bases,class_dict): if bases != (object): if class_dict['sides'] is not None and class_dict['sides'] class Polygon(metaclass=ValidatePolygon): sides = None @classmethod def interior_angles(cls): return (cls.sides-2) * 180 class Triangle(Polygon): sides = 3 class Line(Polygon): print(\"before sides\") sides = 1 print(\"after sides\") before sides after sides --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 class Line(Polygon): 2 print(\"before sides\") 3 sides = 1 4 print(\"after sides\") in __new__(meta, name, bases, class_dict) 3 if bases != (object): 4 if class_dict['sides'] is not None and class_dict['sides'] 5 raise ValueError('Polygons need 3+ sides') 6 return type.__new__(meta,name,bases,class_dict) ValueError: Polygons need 3+ sides 用来注册子类 元类的另一个用途是在程序中自动注册类型,对于需要反向查找(reverse lookup)的场合会有用.它使我们可以在简单的标识符与对应的类之间建立映射. 例: 我们希望使用下面的这个类将python对象表示为json格式的序列化数据.但同时我们希望可以反序列化,这就要用到元类了. import json registry = {} def register_class(target): registry[target.__name__] = target def deserialize(data): params = json.loads(data) name = params[\"class\"] target_class = registry[name] return target_class(*params[\"args\"]) class Meta(type): def __new__(meta,name,bases,class_dict): cls = type.__new__(meta,name,bases,class_dict) register_class(cls) return cls class Serializable: def __init__(self,*args): self.args = args def serialize(self): return json.dumps({ 'class':self.__class__.__name__, 'args':self.args, }) class RegisterSerializable(Serializable,metaclass = Meta): pass class Vector3D(RegisterSerializable): def __init__(self,x,y,z): super().__init__(x,y,z) self.x,self.y,self.z = x,y,z v3 = Vector3D(10,-7,3) v3.serialize() '{\"class\": \"Vector3D\", \"args\": [10, -7, 3]}' v = deserialize(v3.serialize()) v.args (10, -7, 3) 用来与描述符结合使用注解属性 用来解决LineItem倒数第二版问题的另一个方法就是使用元类 import abc class AutoStorage: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) def __set_name__(self, owner, name): self.name = name class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value class EntityMeta(type): \"\"\"元类，用于创建带有验证字段的业务实体\"\"\" def __init__(cls, name, bases, attr_dict): super().__init__(name, bases, attr_dict) for key, attr in attr_dict.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) class Entity(metaclass=EntityMeta): \"\"\"带有验证字段的业务实体\"\"\" 用户级别的代码只需继承Entity类,Validated 字段就能自动获得储存属性的名称. class LineItem(Entity): description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#description', '_Quantity#price', '_Quantity#weight'] LineItem.description.storage_name '_NonBlank#description' 如前所述type构造方法及元类的__new__和__init__ 方法都会收到要计算的类的定义体,形式是名称到属性的映像.然而在默认情况下,那个映射是字典;也就是说元类或类装饰器获得映射时,属性在类定义体中的顺序已经丢失了. 这个问题的解决办法是,使用Python3引入的特殊方法__prepare__.解释器调用元类的__new__ 方法之前会先调用__prepare__方法，使用类定义体中的属性创建映射. __prepare__方法的第一个参数是元类,随后两个参数分别是要构建的类的名称和基类组成的元组,返回值必须是映射. 元类构建新类时,__prepare__方法返回的映射会传给__new__方法的最后一个参数,然后再传给__init__方法. import collections class EntityMeta(type): \"\"\"元类，用于创建带有验证字段的业务实体\"\"\" @classmethod def __prepare__(cls, name, bases): return collections.OrderedDict() def __init__(cls, name, bases, attr_dict): super().__init__(name, bases, attr_dict) cls._field_names = [] for key, attr in attr_dict.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) cls._field_names.append(key) class Entity(metaclass=EntityMeta): \"\"\"带有验证字段的业务实体\"\"\" @classmethod def field_names(cls): for name in cls._field_names: yield name class LineItem(Entity): description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price for name in LineItem.field_names(): print(name) description weight price Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:12:22 "},"语法篇/元编程/import_hook.html":{"url":"语法篇/元编程/import_hook.html","title":"import_hook","keywords":"","body":"import_hook 所谓import hook就是指直接自定义finder和loader,并将finder放入导入过程,以实现一些特殊的运行时行为的技巧. 利用这个可以做到很多非常神奇的事情,比如 import某个特定模块时触发某个回调函数来通知我们 import一个远程服务器上的模块 直接import其他语言的模块来使用 本节需要的先验知识包括: 模块的导入方式 动态编译 使用f2py为python嵌入fortran代码 import hook的基本形式 import hook通常是以一个单文件模块的形式出现的,其中的过程说白了就是自定义finder和loader,因此自定义这两个类都是必须的,然后就是将定义的finder实例化,并将这个实例加入sys.meta_path.下面是模板代码. import importlib from importlib.abc import ( MetaPathFinder, PathEntryFinder, Loader ) from importlib.machinery import ModuleSpec import sys from collections import defaultdict class ClientImportLoader(Loader): @classmethod def create_module(clz,spec): \"\"\"用于创建模块的.\"\"\" module = __create_module_from_spec(spec) return module or None @classmethod def exec_module (clz, module): \"\"\"每次执行引入模块或者重载模块时会执行的操作\"\"\" pass loader= ClientImportLoader() class ClientImportFinder(MetaPathFinder): @classmethod def find_spec (klass, full_name, paths=None, target=None): \"\"\"查找模块的逻辑\"\"\" pass return ModuleSpec(full_name, loader, origin=module_full_path) sys.meta_path.insert(0, ClientImportFinder()) 当这个定义import hook的模块被加载后,他就可以正常的执行自己的功能了,因此通常这个import hook的模块需要优先加载. import某个特定模块时触发某个回调函数来通知我们 这个例子来自python cookbook,不过上面的代码已经比较过时了,这边给出python3.5+推荐的写法 import importlib from importlib.abc import ( MetaPathFinder, PathEntryFinder, Loader ) from importlib.machinery import ModuleSpec import sys from collections import defaultdict _post_import_hooks = defaultdict(list) class ClientImportLoader(Loader): def __init__(self, finder): self._finder = finder def create_module(self,spec): \"\"\"这边只要调用父类的实现即可.\"\"\" return super().create_module(spec) def exec_module (self, module): \"\"\"在_post_import_hooks中查找对应模块中的回调函数并执行.\"\"\" for func in _post_import_hooks[module.__name__]: func(module) self._finder._skip.remove(module.__name__) class ClientImportFinder(MetaPathFinder): def __init__(self): self._skip = set() def find_spec(self, full_name, paths=None, target=None): if full_name in self._skip: return None self._skip.add(full_name) loader = ClientImportLoader(self) return ModuleSpec(full_name, loader, origin=paths) def when_imported(fullname): def decorate(func): if fullname in sys.modules: func(sys.modules[fullname]) else: _post_import_hooks[fullname].append(func) return func return decorate finder = ClientImportFinder() sys.meta_path.insert(0, finder) @when_imported('numpy') def warn_numpy(mod): print('numpy? Are you crazy?') import numpy ********None ['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_finder', 'create_module', 'exec_module', 'load_module', 'module_repr'] import a ********None finder._skip set() 为了避免陷入无线循环,ClientImportFinder维护了一个所有被加载过的模块集合_skip,如果一个模块在加载过程中又有另一个地方来加载,那么就会跳过这个加载器 import一个远程服务器上的模块 这个例子主要是复写finder以可以查找到目标服务器上的模块文件.同时复写loader的create_module方法用远端的代码生成服务. 我们的远程代码以http服务的形式放在静态服务器上 testcode-| |-spam.py |-fib.py |-grok-| |-__init__.py |-blah.py spam.py print(\"I'm spam\") def hello(name): print('Hello %s' % name) fib.py print(\"I'm fib\") def fib(n): if n grok/__init__.py print(\"I'm grok.__init__\") grok/blah.py print(\"I'm grok.blah\") 使用python自带的http服务启动: cd source/testcode python3 -m http.server 15000 import requests n = requests.get(\"http://localhost:15000/fib.py\") print(n.content.decode(\"utf-8\")) print(\"I'm fib\") def fib(n): if n 最简单的方法 这个流程也描述了最通用的模块导入流程.我们可以使用imp.new_module新建一个空的模块对象,再使用内置方法compile()将源码编译到一个代码对象中,然后在模块对象的字典中来执行它. 这种方式没有嵌入到通常的import语句中,如果要支持更高级的结构比如包就需要更多的工作了. 下面是使用这个函数的方式: import imp import urllib.request import sys def load_module(url): u = urllib.request.urlopen(url) source = u.read().decode('utf-8') mod = sys.modules.setdefault(url, imp.new_module(url)) code = compile(source, url, 'exec') mod.__file__ = url mod.__package__ = '' exec(code, mod.__dict__) return mod fib = load_module('http://localhost:15000/fib.py') I'm fib fib.fib(10) 89 fib 使用 import hook实现隐式调用远端模块 如果我们想要导入文件系统中某个文件作为模块,我们会这样写以确保文件目录Python解释器可以找到. import sys sys.path.append('') 我们希望远端的也可以实现这种与标准流程统一的方式,这时候就需要使用import hook了. 因为访问的地址和文件系统不同,因此可以使用sys.path_hooks为这个特定的地址设置一个finder 此处我们需要 定义finder 定义loader 定义handle_url()函数作为钩子 sys.path_hooks.append(handle_url)变量中注册着查找sys.path的钩子,当sys.path的实体被处理时会调用sys.path_hooks中的函数.如果任何一个函数返回了一个finder,那么这个对象就被用来为sys.path实体加载模块. 这个例子完全使用标准库实现 %%writefile urlimport.py import warnings import sys import importlib.abc from importlib.machinery import ModuleSpec import imp from urllib.request import urlopen from urllib.error import HTTPError, URLError from html.parser import HTMLParser # Get links from a given URL def _get_links(url): \"\"\"在指定url查找包含的其他url\"\"\" class LinkParser(HTMLParser): \"\"\"解析html文件,从中获取a标签中的url\"\"\" def handle_starttag(self, tag, attrs): if tag == 'a': attrs = dict(attrs) links.add(attrs.get('href').rstrip('/')) links = set() try: warnings.warn(f'Getting links from {url}',UserWarning) u = urlopen(url) parser = LinkParser() parser.feed(u.read().decode('utf-8')) except Exception as e: warnings.warn(f'Could not get links. {e}',UserWarning) warnings.warn(f'links: {links}',UserWarning) return links class UrlPathFinder(importlib.abc.PathEntryFinder): \"\"\"查找url及其中a标签中指向的url中的模块.\"\"\" def __init__(self, baseurl): self._links = None # 保存一个baseurl中指定的可用url路径 #self._loader = UrlModuleLoader(baseurl) # 指定默认的loader self._baseurl = baseurl # def find_spec(self, fullname, paths=None, target=None): warnings.warn(f'find_loader: {fullname}', UserWarning) parts = fullname.split('.') basename = parts[-1] # 查看links和初始化links if self._links is None: self._links = [] self._links = _get_links(self._baseurl) spec = None # 检查links是不是package,判断的标准是有没有.py if basename in self._links: warnings.warn(f'find_loader: trying package {fullname}', UserWarning) fullurl = self._baseurl + '/' + basename try: loader = UrlPackageLoader(fullurl) loader.load_module(fullname)# warnings.warn(f'find_loader: package {fullname} loaded', UserWarning) spec = ModuleSpec(fullname, loader, origin=paths) except ImportError as ie: warnings.warn(f'find_loader: {fullname} is a namespace package', UserWarning) spec = None except Exception as e: raise e elif (basename + '.py') in self._links: # 正常module的处理 warnings.warn(f'find_loader: module {fullname} found', UserWarning) loader = UrlModuleLoader(self._baseurl) spec = ModuleSpec(fullname, loader, origin=paths) else: warnings.warn(f'find_loader: module {fullname} not found', UserWarning) return spec def invalidate_caches(self): warnings.warn(\"invalidating link cache\", UserWarning) self._links = None # Module Loader for a URL class UrlModuleLoader(importlib.abc.SourceLoader): def __init__(self, baseurl): self._baseurl = baseurl self._source_cache = {} def create_module(self,spec): \"\"\"这边只要调用父类的实现即可.\"\"\" mod = sys.modules.setdefault(spec.name, imp.new_module(spec.name)) mod.__file__ = self.get_filename(spec.name) mod.__loader__ = self mod.__package__ = spec.name.rpartition('.')[0] return mod def exec_module (self, module): \"\"\"在_post_import_hooks中查找对应模块中的回调函数并执行.\"\"\" code = self.get_code(module.__name__) exec(code, module.__dict__) # Optional extensions def get_code(self, fullname): src = self.get_source(fullname) return compile(src, self.get_filename(fullname), 'exec') def get_data(self, path): pass def get_filename(self, fullname): return self._baseurl + '/' + fullname.split('.')[-1] + '.py' def get_source(self, fullname): filename = self.get_filename(fullname) warnings.warn(f'loader: reading {filename}', UserWarning) if filename in self._source_cache: warnings.warn(f'loader: cached {fullname} not found', UserWarning) return self._source_cache[filename] try: u = urlopen(filename) source = u.read().decode('utf-8') warnings.warn(f'loader: {filename} loaded', UserWarning) self._source_cache[filename] = source return source except (HTTPError, URLError) as e: warnings.warn(f'loader: {filename} failed. {e}', UserWarning) raise ImportError(\"Can't load %s\" % filename) def is_package(self, fullname): return False # Package loader for a URL class UrlPackageLoader(UrlModuleLoader): def create_module(self, spec): mod = super().create_module(spec) mod.__path__ = [ self._baseurl ] mod.__package__ = spec.name return mod def get_filename(self, fullname): return self._baseurl + '/' + '__init__.py' def is_package(self, fullname): return True # Check path to see if it looks like a URL _url_path_cache = {} def handle_url(path): if path.startswith(('http://', 'https://')): warnings.warn(f'Handle path? {path}. [Yes]', UserWarning) if path in _url_path_cache: finder = _url_path_cache[path] else: finder = UrlPathFinder(path) _url_path_cache[path] = finder return finder else: warnings.warn(f'Handle path? {path}. [No]', UserWarning) def install_path_hook(): sys.path_hooks.append(handle_url) sys.path_importer_cache.clear() warnings.warn('Installing handle_url', UserWarning) def remove_path_hook(): sys.path_hooks.remove(handle_url) sys.path_importer_cache.clear() warnings.warn('Removing handle_url', UserWarning) install_path_hook() Overwriting urlimport.py import fib --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) in () ----> 1 import fib ModuleNotFoundError: No module named 'fib' import urlimport /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/元编程/urlimport.py:162: UserWarning: Installing handle_url warnings.warn('Installing handle_url', UserWarning) import fib /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/元编程/urlimport.py:157: UserWarning: Handle path? /Users/huangsizhe/anaconda3/lib/python36.zip. [No] warnings.warn(f'Handle path? {path}. [No]', UserWarning) --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) in () ----> 1 import fib ModuleNotFoundError: No module named 'fib' import sys sys.path.append('http://localhost:15000') import fib fib.fib(5) 8 直接import其他语言的模块来使用 一个更加酷的用法是直接导入别的语言的代码成为模块.这有两种途径 通过一个自定义的编译器将源码编译为python可以直接import的动态链接库,之后再导入这个动态链接库 通过一个自定义的语法解释器将特定源码转化为python对象 导入Fortran代码作为模块 这个例子我们来尝试第一种方法,其基本流程是: 定义一个finder用于找到以.f,.f90或者.f95位后缀的文件作为源文件 需要注意的这个需求依然会用到文件系统,Fortran的源码很大的可能性与python的原生源文件共存,因此不适合使用sys.path_hook. 使用numpy中自带的工具f2py来实现Fortran代码的编译工作 f2py无法指定输出的动态链接库位置,需要进一步的文件系统操作.这边可以利用标准库Pathlib和shutil 将编译成功后的动态链接库导入到程序中. 需要注意引入动态链接库时不能使用import或者__import__或者importlib.import_module这些直接生成完整模块对象的方式,否则会递归调用. 此处应该使用如下的方式借由生成spec来生成模块. wrap_spec = importlib.util.spec_from_file_location( spec.name, str(target_path) ) mod = importlib.util.module_from_spec(wrap_spec) 再借由这个spec的loader来执行模块 wrap_spec.loader.exec_module(mod) 当然了这个例子并没有考虑fortain本身的语法和多文件编译的问题,可能还会有些问题. import sys sys.path_hooks [zipimport.zipimporter, .path_hook_for_FileFinder>] %%writefile fortranimport.py import os import sys import hashlib import shutil import warnings from pathlib import Path import importlib from importlib.abc import ( MetaPathFinder, PathEntryFinder, Loader ) from importlib.machinery import ModuleSpec from numpy import f2py class FortranImportLoader(Loader): def __init__(self, source_path): self._source_path = source_path with open(str(self._source_path), \"rb\") as f: self.source = f.read() self.source_hash = hashlib.md5(self.source) self.wrap_spec = None def _check_source(self): with open(str(self._source_path), \"rb\") as f: source = f.read() source_hash = hashlib.md5(source) if self.source_hash == source_hash: return False else: self.source_hash = source_hash self.source = source return True def _compile(self): modulename = self._source_path.stem suffix = self._source_path.suffix complie_result = f2py.compile( self.source, modulename=modulename, verbose=False, extra_args=\"--quiet\", extension=suffix ) if complie_result != 0: raise ImportError(\"complie failed\") else: root = Path(\".\").resolve() find_files = [ i for i in root.iterdir() if i.match(f\"{modulename}*.pyd\") or i.match(f\"{modulename}*.so\") ] if len(find_files) != 1: raise ImportError(f\"find {len(find_files)} Dynamic Link Library\") file = find_files[0] target_path = self._source_path.with_name(file.name) if file != target_path: try: shutil.move(str(file), str(target_path)) except shutil.SameFileError as sfe: pass except Exception as e: raise e del_target = [i for i in root.iterdir() if i.match(str(file)+\".*\")] for i in del_target: try: i.chmod(0o777) i.unlink() except Exception as e: warnings.warn(f'can not delete file {i}:{type(e)}--{e}', UserWarning) return target_path def create_module(self, spec): self._check_source() target_path = self._compile() self.wrap_spec = importlib.util.spec_from_file_location( spec.name, str(target_path) ) mod = importlib.util.module_from_spec(self.wrap_spec) mod = sys.modules.setdefault(spec.name, mod) return mod def exec_module(self, module): \"\"\"在_post_import_hooks中查找对应模块中的回调函数并执行.\"\"\" self.wrap_spec.loader.exec_module(module) class FortranImportFinder(MetaPathFinder): def find_spec(self, fullname, paths=None, target=None): relative_path = fullname.replace(\".\", \"/\") base_path = None full_path = None for path in sys.path: base_path = Path(path).resolve() abs_path = base_path.joinpath(relative_path) if abs_path.with_suffix(\".f\").exists(): full_path = abs_path.with_suffix(\".f\") break elif abs_path.with_suffix(\".f90\").exists(): full_path = abs_path.with_suffix(\".f90\") break elif abs_path.with_suffix(\".f95\").exists(): full_path = abs_path.with_suffix(\".f95\") break else: return None warnings.warn(f'FortranImportFinder find_spec: {fullname}', UserWarning) loader = FortranImportLoader(full_path) spec = ModuleSpec(fullname, loader, origin=paths) return spec finder = FortranImportFinder() sys.meta_path.insert(0, finder) warnings.warn('now you can import a fortain file', UserWarning) Overwriting fortranimport.py import fortranimport /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/元编程/fortranimport.py:122: UserWarning: now you can import a fortain file warnings.warn('now you can import a fortain file', UserWarning) import demo /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/元编程/fortranimport.py:114: UserWarning: FortranImportFinder find_spec: demo warnings.warn(f'FortranImportFinder find_spec: {fullname}', UserWarning) In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpg1hdbzxv/src.macosx-10.7-x86_64-3.6/demomodule.c:16: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpg1hdbzxv/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpg1hdbzxv/src.macosx-10.7-x86_64-3.6/demomodule.c:109:12: warning: unused function 'f2py_size' [-Wunused-function] static int f2py_size(PyArrayObject* var, ...) ^ 2 warnings generated. In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpg1hdbzxv/src.macosx-10.7-x86_64-3.6/fortranobject.c:2: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpg1hdbzxv/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpg1hdbzxv/src.macosx-10.7-x86_64-3.6/fortranobject.c:138:18: warning: comparison of integers of different signs: 'Py_ssize_t' (aka 'long') and 'unsigned long' [-Wsign-compare] if (size --[Errno 1] Operation not permitted: '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/元编程/demo.cpython-36m-darwin.so.dSYM' warnings.warn(f'can not delete file {i}:{type(e)}--{e}', UserWarning) demo.sum_of_square([1,2,3,4,5]) 55.0 import demopackage.demo1 /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/元编程/fortranimport.py:114: UserWarning: FortranImportFinder find_spec: demopackage.demo1 warnings.warn(f'FortranImportFinder find_spec: {fullname}', UserWarning) In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmponoxb1eb/src.macosx-10.7-x86_64-3.6/demo1module.c:16: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmponoxb1eb/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmponoxb1eb/src.macosx-10.7-x86_64-3.6/demo1module.c:109:12: warning: unused function 'f2py_size' [-Wunused-function] static int f2py_size(PyArrayObject* var, ...) ^ 2 warnings generated. In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmponoxb1eb/src.macosx-10.7-x86_64-3.6/fortranobject.c:2: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmponoxb1eb/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmponoxb1eb/src.macosx-10.7-x86_64-3.6/fortranobject.c:138:18: warning: comparison of integers of different signs: 'Py_ssize_t' (aka 'long') and 'unsigned long' [-Wsign-compare] if (size --[Errno 1] Operation not permitted: '/Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/语法篇/元编程/demo1.cpython-36m-darwin.so.dSYM' warnings.warn(f'can not delete file {i}:{type(e)}--{e}', UserWarning) demopackage.demo1.sum_of_square([1,2,3,4,5]) 55.0 使用警告 import hook是python中非常高级的语言技巧,并不提倡用户使用,如果非要使用,请使用warnning在导入时提醒用户 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:12:17 "},"语法篇/元编程/动态编译.html":{"url":"语法篇/元编程/动态编译.html","title":"动态编译","keywords":"","body":"动态编译 动态编译指的是在运行时接收字符串,动态的将其编译为python可执行的代码的功能. python提供了两个函数用于实现动态编译: exec和eval函数 eval(exp[, globals[, locals]]) globals是字典形式,表示全局命名空间,如果传入globals的字典中缺少__builtins__ 的时候,当前的全局命名空间将作为globals参数输入并在表达式计算之前被解析. locals则为任何映射对象,表示局部命名空间,与globals两者默认相同. 如果两者都省略则表示在eval的调用环境中执行 exec() 与eval()类似的是exec()方法,但exec是翻译并执行.exec常与文件读取操作结合使用,直接传递python的代码文件运行 a = eval(\"lambda *x: sum(x)\") a(1,2,3,4,5) 15 %timeit a(1,2,3,4,5,6,7,8,9) 258 ns ± 2.81 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) %timeit lambda *x:sum(x)(1,2,3,4,5,6,7,8,9) 58 ns ± 0.763 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) exec(\"aa = lambda x: x\") aa(10) 10 eval和exec有两个弊端: 降低运算效率 如上面看到的,运行时间上差距不小 安全性 这主要是因为可以调用一些危险的方法而没有设限.也就是所谓的代码注入攻击. 当然了,我们也可以通过限制globals和locals来实现对可用项的限制. 如果只是为了传入参数,那么可以使用ast库的literal_eval函数,它是安全的 import ast ast.literal_eval(\"[1,2,3]\") [1, 2, 3] 在Python中做元编程时,最好不用exec 和eval 函数.如果接收的字符串(或片段)来自不可信的源,那么这两个函数会带来严重的安全风险.Python提供了充足的内省工具,大多数时候都不需要使用exec和eval函数.然而,Python核心开发者实现namedtuple函数时选择了使用exec函数,这样做是为了让生成的类代码能通过._source获取. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/元编程/动态属性.html":{"url":"语法篇/元编程/动态属性.html","title":"动态属性","keywords":"","body":"动态属性 在Python中,数据的属性和处理数据的方法统称属性attribute.其实,方法只是可调用的属性. Python提供了丰富的API,用于控制属性的访问权限,以及实现动态属性. 使用点号访问属性时(如obj.attr),Python解释器会调用特殊的方法(如__getattr__和__setattr__)计算属性.用户自己定义的类可以通过__getattr__方法实现\"虚拟属性\".当访问不存在的属性时(如obj.no_such_attribute),即时计算属性的值. 动态创建属性照理说是一种元编程,框架的作者经常这么做.然而在Python中,相关的基础技术十分简单,任何人都可以使用,甚至在日常的数据转换任务中也能用到.下面以这种任务开启本章的话题. 本节需要的先验知识有: 面向对象惯用法 python的数据模型 序列化 影响属性处理方式的特殊属性 __class__ 对象所属类的引用(即obj.__class__ 与type(obj) 的作用相同).Python 的某些特殊方法,例如__getattr__,只在对象的类中寻找,而不在实例中寻找. __dict__ 一个映射,存储对象或类的可写属性.有__dict__ 属性的对象,任何时候都能随意设置新属性.如果类有__slots__属性,它的实例可能没有__dict__属性.参见下面对__slots__ 属性的说明. __slots__ 类可以定义这个这属性,限制实例能有哪些属性.__slots__属性的值是一个字符串组成的元组,指明允许有的属性.如果__slots__ 中没有'__dict__',那么该类的实例没有__dict__ 属性,实例只允许有指定名称的属性. 处理属性的内置函数 下述5个内置函数对对象的属性做读、写和内省操作. dir([object]) 列出对象的大多数属性.dir 函数的目的是交互式使用,因此没有提供完整的属性列表,只列出一组\"重要的\"属性名.dir 函数能审查有或没有__dict__属性的对象.dir函数不会列出__dict__属性本身,但会列出其中的键.dir 函数也不会列出类的几个特殊属性,例如__mro__、__bases__和__name__.如果没有指定可选的object参数,dir 函数会列出当前作用域中的名称. getattr(object,name[, default]) 从object 对象中获取name字符串对应的属性.获取的属性可能来自对象所属的类或超类。如果没有指定的属性,getattr 函数抛出AttributeError异常,或者返回default参数的值(如果设定了这个参数的话). hasattr(object, name) 如果object对象中存在指定的属性,或者能以某种方式(例如继承)通过object对象获取指定的属性,返回True setattr(object, name, value) 把object对象指定属性的值设为value,前提是object对象能接受那个值.这个函数可能会创建一个新属性,或者覆盖现有的属性. vars([object]) 返回object对象的__dict__属性;如果实例所属的类定义了__slots__ 属性,实例没有__dict__属性,那么vars函数不能处理那个实例(相反,dir 函数能处理这样的实例).如果没有指定参数,那么vars()函数的作用与locals()函数一样:返回表示本地作用域的字典. 处理属性的特殊方法 在用户自己定义的类中,下述特殊方法用于获取,设置,删除和列出属性. 使用点号或内置的getattr、hasattr 和setattr函数存取属性都会触发下述列表中相应的特殊方法.但是直接通过实例的__dict__属性读写属性不会触发这些特殊方法——如果需要,通常会使用这种方式跳过特殊方法. 对用户自己定义的类来说,如果隐式调用特殊方法,仅当特殊方法在对象所属的类型上定义,而不是在对象的实例字典中定义时,才能确保调用成功. 要假定特殊方法从类上获取,即便操作目标是实例也是如此.因此,特殊方法不会被同名实例属性遮盖. __delattr__(self, name) 只要使用del语句删除属性,就会调用这个方法.例如,del obj.attr语句触发Class.__delattr__(obj, 'attr')方法. __dir__(self) 把对象传给dir函数时调用,列出属性.例如，dir(obj) 触发Class.__dir__(obj)方法. __getattr__(self, name) 仅当获取指定的属性失败，搜索过obj、Class和超类之后调用.表达式obj.no_such_attr、getattr(obj, 'no_such_attr') 和hasattr(obj, 'no_such_attr')可能会触发Class.__getattr__(obj, 'no_such_attr') 方法,但仅当在obj、Class 和超类中找不到指定的属性时才会触发. __getattribute__(self, name) 尝试获取指定的属性时总会调用这个方法,不过寻找的属性是特殊属性或特殊方法时除外.点号与getattr 和hasattr 内置函数会触发这个方法.调用__getattribute__方法且抛出AttributeError 异常时,才会调用__getattr__ 方法.为了在获取obj实例的属性时不导致无限递归,__getattribute__方法的实现要使用super().__getattribute__(obj, name) __setattr__(self, name, value) 尝试设置指定的属性时总会调用这个方法.点号和setattr内置函数会触发这个方法.例如obj.attr = 42和setattr(obj,'attr', 42) 都会触发Class.__setattr__(obj,attr’, 42) 方法 其实特殊方法__getattribute__ 和__setattr__不管怎样都会调用,几乎会影响每一次属性存取,因此比__getattr__ 方法(只处理不存在的属性名)更难正确使用.与定义这些特殊方法相比,使用特性或描述符相对不易出错. 例子 我们要使用动态属性处理\"O’Reilly 为OSCON 2014 大会\"提供的JSON格式数据源. 那个JSON源中有895条记录,整个数据集是一个JSON 对象,里面有一个键,名为\"Schedule\";这个键对应的值也是一个映像,有4个键:\"conferences\"、\"events\"、\"speakers\" 和\"venues\".这4个键对应的值都是一个记录列表.列表中有成百上千条记录.不过,\"conferences\"键对应的列表中只有一条记录,如上述示例所示.这4个列表中的每个元素都有一个名为\"serial\"的字段,这是元素在各个列表中的唯一标识符. 第一个脚本只用于下载那个OSCON数据源.为了避免浪费流量,我会先检查本地有没有副本.这么做是合理的,因为OSCON 2014 大会已经结束,数据源不会再更新. 第一个例子没用到元编程,几乎所有代码的作用可以用这一个表达式概括:json.load(fp).不过,这样足以处理那个数据集了.osconfeed.load 函数会在后面几个示例中用到. import requests import warnings import os import json URL = 'http://www.oreilly.com/pub/sc/osconfeed' JSON = 'osconfeed.json' def load(): if not os.path.exists(JSON): msg = 'downloading {} to {}'.format(URL, JSON) warnings.warn(msg) with open(JSON, 'w') as local: remote = requests.get(URL) json.dump(remote.json(),local) with open(JSON) as fp: return json.load(fp) raw_feed = load() sorted(raw_feed['Schedule'].keys()) ['conferences', 'events', 'speakers', 'venues'] for key, value in sorted(raw_feed['Schedule'].items()): print('{:3} {}'.format(len(value), key)) 1 conferences 494 events 357 speakers 53 venues raw_feed['Schedule']['speakers'][-1]['name'] 'Carina C. Zona' raw_feed['Schedule']['speakers'][-1]['serial'] 141590 raw_feed['Schedule']['events'][40]['name'] 'There *Will* Be Bugs' raw_feed['Schedule']['events'][40]['speakers'] [3471, 5199] 使用动态属性访问JSON类数据 feed['Schedule']['events'][40]['name'] 这种句法很冗长.在JavaScript中,可以使用feed.Schedule.events[40].name获取那个值.在Python中可以实现一个近似字典的类(网上有大量实现)以达到同样的效果.我自己实现了FrozenJSON类,比大多数实现都简单,因为只支持读取,即只能访问数据.不过这个类能递归,自动处理嵌套的映射和列表. from collections import abc class FrozenJSON: \"\"\"一个只读接口，使用属性表示法访问JSON类对象 \"\"\" def __init__(self, mapping): self.__data = dict(mapping) def __getattr__(self, name): # `__getattr__`特殊方法用于重载`.`符号获取值的行为 if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON.build(self.__data[name]) @classmethod def build(cls, obj): if isinstance(obj, abc.Mapping): return cls(obj) elif isinstance(obj, abc.MutableSequence): return [cls.build(item) for item in obj] else: return obj feed = FrozenJSON(raw_feed) len(feed.Schedule.speakers) 357 sorted(feed.Schedule.keys()) ['conferences', 'events', 'speakers', 'venues'] feed.Schedule.speakers[-1].name 'Carina C. Zona' talk = feed.Schedule.events[40] type(talk) __main__.FrozenJSON talk.name 'There *Will* Be Bugs' talk.speakers [3471, 5199] talk.flavor --------------------------------------------------------------------------- KeyError Traceback (most recent call last) in () ----> 1 talk.flavor in __getattr__(self, name) 10 return getattr(self.__data, name) 11 else: ---> 12 return FrozenJSON.build(self.__data[name]) 13 14 @classmethod KeyError: 'flavor' 处理无效属性名 FrozenJSON类有个缺陷:没有对名称为Python关键字的属性做特殊处理.比如说像下面这 样构建一个对象: grad = FrozenJSON({'name': 'Jim Bo', 'class': 1982}) 此时无法读取grad.class的值,因为在Python中class是保留字: grad.class File \"\", line 1 grad.class ^ SyntaxError: invalid syntax 但是FrozenJSON类的目的是为了便于访问数据,因此更好的方法是检查传给Frozen-JSON.__init__ 方法的映射中是否有键的名称为关键字,如果有，那么在键名后加上_. 这种有问题的键在Python3中易于检测,因为str类提供的s.isidentifier()方法能根据语言的语法判断s是否为有效的Python标识符.但是,把无效的标识符变成有效的属性名却不容易.对此,有两个简单的解决方法: 一个是抛出异常 另一个是把无效的键换成通用名称，例如attr_0、attr_1，等等. 为了简单起见,我将忽略这个问题. 对动态属性的名称做了一些处理之后,我们要分析FrozenJSON类的另一个重要功能——类方法build的逻辑.这个方法把嵌套结构转换成FrozenJSON实例或FrozenJSON实例列表,因此__getattr__ 方法使用这个方法访问属性时,能为不同的值返回不同类型的对象. import keyword from collections import abc class FrozenJSON: \"\"\"一个只读接口，使用属性表示法访问JSON类对象 \"\"\" def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if keyword.iskeyword(key): key += '_' self.__data[key] = value def __getattr__(self, name): # `__getattr__`特殊方法用于重载`.`符号获取值的行为 if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON.build(self.__data[name]) @classmethod def build(cls, obj): if isinstance(obj, abc.Mapping): return cls(obj) elif isinstance(obj, abc.MutableSequence): return [cls.build(item) for item in obj] else: return obj grad = FrozenJSON({'name': 'Jim Bo', 'class': 1982}) grad.class_ 1982 使用__new__方法以灵活的方式创建对象 除了在类方法中实现这样的逻辑之外,还可以在特殊的__new__方法中实现. 我们通常把__init__称为构造方法,这是从其他语言借鉴过来的术语.其实，用于构建实例的是特殊方法__new__--这是个类方法(使用特殊方式处理,因此不必使用@classmethod装饰器),必须返回一个实例.返回的实例会作为第一个参数(即self)传给__init__方法.因为调用__init__方法时要传入实例,而且禁止返回任何值,所以__init__方法其实是\"初始化方法\".真正的构造方法是__new__.我们几乎不需要自己编写__new__方法,因为从object类继承的实现已经足够了. 刚才说明的过程,即从__new__方法到__init__方法,是最常见的,但不是唯一的. __new__方法也可以返回其他类的实例,此时,解释器不会调用__init__方法. 下面是FrozenJSON类的另一个版本,把之前在类方法build中的逻辑移到了__new__方法中. import keyword from collections import abc class FrozenJSON: \"\"\"一个只读接口，使用属性表示法访问JSON类对象 \"\"\" def __new__(cls, arg): if isinstance(arg, abc.Mapping): return super().__new__(cls) elif isinstance(arg, abc.MutableSequence): return [cls(item) for item in arg] else: return arg def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if keyword.iskeyword(key): key += '_' self.__data[key] = value def __getattr__(self, name): # `__getattr__`特殊方法用于重载`.`符号获取值的行为 if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON.build(self.__data[name]) __new__方法的第一个参数是类,因为创建的对象通常是那个类的实例.所以,在FrozenJSON.__new__方法中,super().__new__(cls)表达式会调object.__new__(FrozenJSON), 而object类构建的实例其实是FrozenJSON实例,即那个实例的__class__属性存储的是 FrozenJSON类的引用.不过,真正的构建操作由解释器调用C语言实现的object.__new__方法执行. OSCON的JSON数据源有一个明显的缺点:索引为40的事件,即名为There *Will* Be Bugs的那个,有两位演讲者,3471和5199,但却不容易找到他们,因为提供的是编号,而Schedule.speakers列表没有使用编号建立索引.此外每条事件记录中都有venue_serial字段,存储的值也是编号,但是如果想找到对应的记录,那就要线性搜索Schedule.venues列表.接下来的任务是,调整数据结构,以便自动获取所链接的记录. 使用shelve模块调整OSCON数据源的结构 标准库中有个shelve(架子)模块,这名字听起来怪怪的,可是如果知道pickle(泡菜)是Python对象序列化格式的名字,还是在那个格式与对象之间相互转换的某个模块的名字,就会觉得以shelve命名是合理的.泡菜坛子摆放在架子上,因此shelve模块提供了pickle存储方式. shelve.open高阶函数返回一个shelve.Shelf实例,这是简单的键值对象数据库,背后由dbm模块支持,具有下述特点: shelve.Shelf是abc.MutableMapping的子类,因此提供了处理映射类型的重要方法. 此外shelve.Shelf类还提供了几个管理I/O的方法,如sync和close.它也是一个上下文管理器. 只要把新值赋予键,就会保存键和值 键必须是字符串 值必须是pickle模块能处理的对象 shelve模块为识别OSCON的日程数据提供了一种简单有效的方式.我们将从JSON文件中读取所有记录,将其存在一个shelve.Shelf对象中,键由记录类型和编号组成(例如,event.33950或speaker.3471),而值是我们即将定义的Record类的实例. import warnings DB_NAME = 'schedule1_db' CONFERENCE = 'conference.115' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) def load_db(db): raw_data = load() warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): record_type = collection[:-1] for record in rec_list: key = '{}.{}'.format(record_type, record['serial']) record['serial'] = key db[key] = Record(**record) import shelve db = shelve.open(DB_NAME) if CONFERENCE not in db: load_db(db) speaker = db['speaker.3471'] type(speaker) __main__.Record speaker.name, speaker.twitter ('Anna Martelli Ravenscroft', 'annaraven') db.close() Record.__init__方法展示了一个流行的Python技巧.我们知道,对象的__dict__ 属性中存储着对象的属性——前提是类中没有声明__slots__属性.因此,更新实例的__dict__属性,把值设为一个映射,能快速地在那个实例中创建一堆属性. 示例中定义的Record类太简单了,因此你可能会问,为什么之前没用,而是使用更复杂的FrozenJSON类.原因有两个: 第一,FrozenJSON类要递归转换嵌套的映射和列表;而Record类不需要这么做,因为转换好的数据集中没有嵌套的映射和列表,记录中只有字符串、整数、字符串列表和整数列表. 第二.FrozenJSON类要访问内嵌的__data__属性(值是字典,用于调用keys等方法),而现在我们也不需要这么做 像上面那样调整日程数据集之后,我们可以扩展Record类,让它提供一个有用的服务--自动获取event记录引用的venue 和speaker记录.这与Django ORM访问models.ForeignKey字段时所做的事类似--得到的不是键，而是链接的模型对象. 动态绑定方法 python中方法只是可以调用的属性,因此方法也是可以动态绑定的.尤其实例方法的动态绑定尤其实用. 动态绑定实例方法 动态绑定实例方法需要借助types.MethodType from types import MethodType class Student(object): age = 10 def set_age(self, age): # 定义一个函数作为实例方法 self.age = age s = Student() s.set_age = MethodType(set_age, s) # 给实例绑定一个方法 s.age 10 s.set_age(12) s.age 12 动态绑定类方法 动态绑定类方法与前面类似,只是MethodType的第一个参数改成了类名 def set_score(clz, score):#定义一个函数作为类的方法 clz.score = score Student.set_score = MethodType(set_score, Student) Student.set_score(30) Student.score 30 s.score 30 动态绑定静态方法 动态绑定静态方法更加简单了,只要直接在类名后面像添加元素一样添加即可 def echo(score):#定义一个函数作为类的方法 return score Student.echo = echo Student.echo(123) 123 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 13:12:28 "},"语法篇/元编程/结语.html":{"url":"语法篇/元编程/结语.html","title":"结语","keywords":"","body":"结语 特性有助于减少前期投入 默认情况下,Python的所有实例属性和类属性都是公开的. 如果觉得应该避免意外更新属性,可以实现特性,但是代码的其他部分没有变化. 这表明我们可以先以最简单的方式定义类,也就是使用公开属性,因为如果以后需要对读值方法和设值方法增加控制, 那就可以实现特性,这样做对一开始通过公开属性的名称(如 x 和 y)与对象交互的代码没有影响. Java语言采用的方式则截然相反: Java 程序员不能先定义简单的公开属性,然后在需要时再实现特性,因为Java语言没有特性. 因此,在Java中编写读值方法和设值方法是常态,就算这些方法没做什么有用的事情也得这么做, 因为API不能从简单的公开属性变成读值方法和设值方法,同时又不影响使用那些属性的代码. 而且到处都使用读值方法和设值方法是愚蠢的行为。如果想编写下面的代码: my_object.set_foo(my_object.get_foo() + 1) 这样做就行了: my_object.foo += 1 维基的发明人和极限编程先驱 Ward Cunningham 建议问这个问题:\"做这件事最简单的方法是什么?\" 意即,我们应该把焦点放在目标上.提前实现设值方法和读值方法偏离了目标.在 Python 中,我们可以先使用公开属性,然后等需要时再变成特性. python作为动态语言,这些特性也让他非常适合敏捷开发. 运算符重载的优缺点 James Gosling决定不让Java支持运算符重载.在那次访谈中(“The C Family of Languages: Interview with Dennis Ritchie, Bjarne Stroustrup, and James Gosling”,他说: 大约 20% 到 30% 的人觉得运算符重载是罪恶之源;有些人对运算符的重载惹怒了很多人, 因为他们使用+做列表插入,导致生活一团糟.这类问题大都源于一个事实--世界上有成千上万个运算符, 但是只有少数几个适合重载.因此, 我们要挑选,但是有时所作的决定违背直觉. Guido van Rossum为运算符重载采取了一种折中方式--不放任用户随意创建运算符, 如: 或 :-),这样防止了用户对运算符的异想天开,而且能让Python解析器保持简单. 此外,Python 还禁止重载内置类型的运算符,这个限制也能增强可读性和可预知的性能. Gosling 接着说道: 社区中约有10%的人能正确地使用和真正关心运算符重载,对这些人来说,运算符重载是极其重要的. 这部分人几乎专门处理数字,在这一领域中,为了符合人类的直觉,表示法特别重要,因为他们进入这一领域时, 直觉中已经知道`+`的意思,他们知道`“a + b”`中的`a`和`b`可以是复数、矩阵或其他合理的东西. 表示法方面的问题不能低估.下面以金融领域为例说明.在Python中,可以使用下述 公式计算复利: interest = principal * ((1 + rate) ** periods - 1) 不管涉及什么数字类型,这种表示法都成立.因此,如果是做重要的金融工作,你要确保periods是整数, rate``interest和principal是精确的数字(Python 中 decimal.Decimal类的实例), 这样上述公式就能完好运行. 但是在Java中,如果把float换成精度不定的BigDecimal,就无法再使用中缀运算符, 因为中缀运算符只支持基本类型.在 Java 中,支持 BigDecimal数字的公式要这样写: BigDecimal interest = principal.multiply(BigDecimal.ONE.add(rate) .pow(periods).subtract(BigDecimal.ONE)); 显然,使用中缀运算符的公式更易读,至少对大多数人来说如此.为了让中缀运算符表示法支持非基本类型, 运算符必须能重载.Python是门高级语言,易于使用,支持运算符重载可能就是它这些年在科学计算领域得到广泛使用的主要原因. 当然,语言不支持运算符重载也有好处.对极为重视性能和安全的低级系统语言而言,这无疑是正确的决定. 新近出现的Go语言在这方面效仿了Java,它不支持运算符重载. 但是,重载的运算符,如果使用得当,的确能让代码更易于阅读和编写.对现代的高级语言来说,这是个好功能. 猴子补丁 猴子补丁的名声不太好.如果滥用,会导致系统难以理解和维护. 补丁通常与目标紧密耦合,因此很脆弱. 另一个问题是,打了猴子补丁的两个库可能相互牵绊,因为第二个库可能撤销了第一个库的补丁. 不过猴子补丁也有它的作用,例如可以在运行时让类实现协议.适配器设计模式通过实现全新的类解决这种问题. 为 Python 打猴子补丁不难,但是有些局限.Python 不允许为内置类型打猴子补丁.其实我觉得这是优点, 因为这样可以确保 str对象的方法始终是那些.这一局限能减少外部库打的补丁有冲突的概率. Python 装饰器和装饰器设计模式 Python 函数装饰器符合Gamma等人在《设计模式:可复用面向对象软件的基础》一 书中对“装饰器”模式的一般描述: “动态地给一个对象添加一些额外的职责。就扩展功能而言,装饰器模式比子类化更灵活。” 在实现层面,Python装饰器与“装饰器”设计模式不同,但是有些相似之处: 在设计模式中,Decorator 和 Component 是抽象类. 为了给具体组件添加行为,具体装饰器的实例要包装具体组件的实例.《设计模式:可复用面向对象软件的基础》一书是 这样说的: 装饰器与它所装饰的组件接口一致,因此它对使用该组件的客户透明.它将客户请求转发给该组件,并且可能在转发前后执行一些额外的操作(例如绘制一个边框)。透明性使得你可以递归嵌套多个装饰器,从而可以添加任意多的功能.(第 115页) 在 Python 中,装饰器函数相当于Decorator的具体子类,而装饰器返回的内部函数相当于装饰器实例.返回的函数包装了被装饰的函数,这相当于“装饰器”设计模式中的组件.返回的函数是透明的,因为它接受相同的参数,符合组件的接口.返回的函数把调用转发给组件,可以在转发前后执行额外的操作.因此,前面引用那段话的最 后一句可以改成:“透明性使得你可以递归嵌套多个装饰器,从而可以添加任意多的行为.”这就是叠放装饰器的理论基础. 注意,我不是建议在 Python 程序中使用函数装饰器实现“装饰器”模式。在特定情况下确实可以这么做,但是一般来说,实现“装饰器”模式时最好使用类表示装饰器和要包装的组件。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"语法篇/结语.html":{"url":"语法篇/结语.html","title":"结语","keywords":"","body":"结语 中庸之道 中国最古老的中庸之道其实讲究的就是\"合适\",就是\"刚刚好\".python从这个角度上讲深合中庸之道.似乎多一分就略过激进,少一分有太过保守.恐怕这也是为什么它可以广受好评. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "},"嵌入与扩展篇/":{"url":"嵌入与扩展篇/","title":"嵌入与扩展篇","keywords":"","body":"嵌入与扩展篇 python的性能是比较让人诟病的,但它却是最好的胶水语言之一,因此很多高性能工具将其作为前端使用,比如tensorflow. 有gil的python擅长的并不是cpu密集型的任务而是io密集型的任务的快速开发,即便不依赖其他语言也是可以在快速开发的同时满足大部分性能要求的.当需要进行cpu密集型任务时,可以使用多进程或者使用C/C++/Fortran编写扩展模块.本篇主要就是讲如何使用其他语言嵌入和扩展python的性能. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:55:26 "},"嵌入与扩展篇/使用Cython优化python程序的性能/":{"url":"嵌入与扩展篇/使用Cython优化python程序的性能/","title":"使用Cython优化python程序的性能","keywords":"","body":"使用Cython优化python程序的性能 Cython是最流行的python扩展方式,虽然它还有很多不足之处,但其易用性,简单渐进式的语法以及对C++的支持已经非常够用. Cython本身还在发展,在不就后以后会有包括type hints支持在内更多的便利特性. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:57:07 "},"嵌入与扩展篇/使用Cython优化python程序的性能/Cython的简单介绍.html":{"url":"嵌入与扩展篇/使用Cython优化python程序的性能/Cython的简单介绍.html","title":"Cython的简单介绍","keywords":"","body":"Cython的简单介绍 Cython是针对python模块的一个优化工具,它并不使用jit技术,因此它的使用有一定局限性的. Cython可以做以下的事情: 将python代码翻译为C语言代码, 将python代码编译为python可以直接调用的动态链接库 通过为python代码指定类型静态化模块,生成python可以直接调用的动态链接库 编译python语法的的超集,Cython语法的源文件.pyx文件生成python可以直接调用的动态链接库 通过Cython语法的头文件.pxd申明C/C++语言的库,再通过Cython语法的源文件.pyx文件生成python可以直接调用的动态链接库 需要注意的是cython编译出来的C/C++语句依然需要使用python的动态库libpython,因此要手动使用C编译器编译就需要制定这个库的位置. Cython提供了两个名,命令行工具 cython 将指定的python,cython源文件翻译为C/C++源文件 cythonize 使用标准库的distutils调用C/C++编译器编译由cython翻译出来的C/C++源文件. 另外cython为jupyter notebook提供了专用的魔术命令%%cython,使用它可以直接在notebook上执行cython语法的语句. Cython的使用方式 Cython需要编译,本质上来说Cython只是把Cython代码编译成C/C++代码而已. 编写符合Cython语法的.pyx源文件 (可选)用.pxd申明.pyx源文件或者c++源文件的接口,它类似c++中的.h文件 将源码编译为动态链接库 在其他python包中import这个动态链接库进行包装或者调用 Cython项目的文件组成 Cython解释器可以识别.py,.cpp,.c,.h,.pyx,.pxd,.pxi,其中 .py是python的源码,一般用在纯净模式下 .cpp,.c,.h是c/c++的源码和头文件,一般用在包装模式下 .pyx,.pxd,.pxi是cython源码和头文件,用在一般模式下. 而cython源文件中 .pyx 为源码文件 pxd为申明文件 申明文件可以包含: 任何一种C型声明 extern C函数或变量声明 模块实现的声明 扩展类型的定义部分 外部函数库的所有声明等 申明文件不能包含: + 任何非外部C变量声明 + C或Python功能的实现 + Python类定义和Python可执行语句 + 任何被定义为公共的声明即申明可以被其他Cython模块访问.这是没有必要的，因为它是自动的.而且公共声明只需要使外部C代码可以访问. .pxi为包含文件 任何Cython代码,因为整个文件都是文字嵌入在引入处的位置,类似于c++中#include的机制 hellowold %%writefile helloworld/helloworld.pyx # distutils: language=c++ def run(): print(\"Hello World\") return True Overwriting helloworld/helloworld.pyx Cython的编译方式 Cython的编译有两种途径: 使用setup.py编译并安装模块 使用cythonize工具编译模块 无论是使用哪种方式编译,都是调用标准库distutils.而且都需要用到C/C++的编译器,因此一个比较方便的方法是使用setup.cfg文件指明模块的编译参数, [build_ext] inplace=1 [build] compiler = msvc 接下来我们来编译上面的helloword例子 使用setup.py编译并安装模块 使用setup.py编译模块并安装的步骤如下: 编写setup.py安装文件,其中使用Cython.Build.cythonize函数构建模块 命令行使用python setup.py build_ext来编译源文件生成模块,如果没有写setup.cfg,我们可以在后面添加 --inplace指定编译后的动态链接库在源文件目录; --compiler或者-c以指定使用的C/C++编译器.比如windows上msvc是指的微软的vc编译器,mingw32指的是mingw32编译器等 %%writefile setup.py from pathlib import Path from distutils.core import setup from Cython.Build import cythonize dir_path = Path(__file__).absolute().parent setup( ext_modules = cythonize(str(dir_path.joinpath(\"helloworld.pyx\"))) ) Overwriting setup.py !python setup.py build_ext Compiling C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.pyx because it changed. [1/1] Cythonizing C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.pyx running build_ext building 'helloworld' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpC:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.obj helloworld.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_helloworld build\\temp.win-amd64-3.6\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.cp36-win_amd64.lib helloworld.obj : warning LNK4197: export 'PyInit_helloworld' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython的基本工作流程\\helloworld.cp36-win_amd64.exp Generating code Finished generating code import helloworld helloworld.run() Hello World True 使用cythonize工具编译模块 cythonize是cython官方提供的编译工具,用起来和gcc差不太多.但是无法指定使用的C编译器,因此只能先用setup.cfg配置好编译器再执行. 常用的参数有: -3 指明使用的是python3语法 -i 指明编译时是inplace的 -a 输出编译为C后各行对应的代码 !cythonize -i -3 -a helloworld.pyx running build_ext 更加丰富的编译设置 如果你的模块像上面的例子中只有一个源文件.那么helloworld中的setup.py就已经可以了,但如果不止一个,或者有一些针对编译器的设置,那么如下的写法是更好的选择 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from distutils.extension import Extension from Cython.Distutils import build_ext extension = Extension( \"helloworld\", sources=[\"helloworld.pyx\"], #include_dirs=[numpy.get_include()], # 如果用到numpy language=\"c++\" ) setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(extension), ) Overwriting setup.py !python setup.py build_ext --inplace running build_ext 可选的编译器设置包括: cythonize 用来确定所要编译的内容,它的参数可以有: ext_modules = cythonize(\"src/*.pyx\"[, include_path = [...][,compiler_directives={=}]]) include_path是编译所需的源文件,这里可以是.py文件,.pyx文件,.pxd文件,.c文件,.h文件等,也可以是几个扩展类 型distutils.extension.Extension的对象,而Extension对象又可以这样定义: Extension(name, [source...], include_dirs = [...], libraries = [...], library_dirs = [...]) compiler_directives则是编译的选项,有如下关键字: boundscheck (True / False) 如果设置为False，Cython可以自由地假定代码中的索引操作,将不会导致任何IndexErrors被抛出。 只有当索引可以被确定为非负数（或者wraparound为False），列表，元组和字符串才会受影响。 通常触发IndexError的条件可能会导致segfault或数据损坏，如果这被设置为False。 默认值为True。 wraparound (True / False) 在Python中，数组可以相对于结束索引(负索引)。而在C中是不支持负索引的。 如果设置为False，Cython既不检查也不正确处理负索引，可能导致段错误或数据损坏。 默认值为True。 initializedcheck (True / False) 如果设置为True，Cython会在访问或分配内存视图时检查它是否被初始化。 将此设置为False将禁用这些检查。 默认值为True。 nonecheck (True / False) 如果设置为False，Cython可以自由地假定 对变量类型的本地字段访问为扩展类型,或者 当变量被设为None时,对缓冲区变量的缓冲区访问永远不会发生。否则插入一个检查并引发适当的异常。 由于性能原因，默认情况下关闭。 默认值为False。 overflowcheck (True / False) 如果设置为True，当溢出的C整数算术运算上引发了异常时，会执行适度的运行时惩罚,但即便如此还是比python的int运算快很多,默认为False overflowcheck.fold (True / False) 如果设置为True，并且overflowcheck为True，则检查嵌套的溢出位,和有副作用的算术表达式,而不是每个步骤都检查。 依赖于不同的编译器，体系结构和优化设置，这项选项可能有助于提高性能也可能损害性能。 默认值为True。 embedsignature (True / False) 如果设置为True，Cython将在所有Python可见函数和类的docstring中嵌入调用签名的文本副本。 像IPython和epydoc这样的工具可以显示签名，否则编译后就无法检索。 默认值为False。 cdivision (True / False) 如果设置为False，Cython将调整余数和商值运算符C类型以匹配Python的int（当操作数具有相反的符号时不同），并且当右操作数为0时产生ZeroDivisionError。这将会有超过35％的性能损失. 如果设置为True，则不执行任何检查。 cdivision_warnings (True / False) 如果设置为True，当使用负操作数执行除法时，Cython将发出运行时警告。 默认值为False. always_allow_keywords (True / False) 在构造取零或一个参数的函数/方法时，METH_NOARGS和METH_O置空。 对具有多个参数的特殊方法和函数没有影响。 METH_NOARGS和METH_O签名提供了更快的调用约定，但不允许使用关键字 profile (True / False) 为编译成的C代码写上python分析的钩子,默认为False linetrace (True / False) 为编译后的C代码写入Python分析器或覆盖报告的跟踪钩子。 这也会启用profile。 默认值为False。 infer_types (True / False) 推断函数体中未声明类型变量的类型。默认值为None，表示只允许安全（语义上不变的）推断。特别地，推断用于算术表达式中的变量的整数类型被认为是不安全的（由于可能的溢出），并且必须被明确请求。 language_level (2/3) 全局设置要用于模块编译的Python语言级别。默认为与Python 2兼容。要启用Python 3源代码语义，请在模块开头将其设置为3，或将“-3”命令行选项传递给编译器。请注意，cimport和包含的源文件从正在编译的模块继承此设置，除非他们明确设置自己的语言级别。 c_string_type (bytes / str / unicode) 从char *或std :: string全局设置隐式强制的类型 c_string_encoding (ascii, default, utf-8, etc.) 全局设置在将char *或std：string隐式强制转化为unicode对象时使用的编码。从unicode对象到C类型的强制只允许设置为ascii或默认，后者意思是在Python 3中是utf-8 type_version_tag (True / False) 通过设置类型标志Py_TPFLAGS_HAVE_VERSION_TAG，在CPython中启用扩展类型的属性缓存。 默认值为True，表示为Cython实现的类型启用了缓存。 在类型需要在内部与其tp_dict进行协调而不关注缓存一致性的罕见情况下禁用它，可以将此选项设置为False。 unraisable_tracebacks (True / False) 是否在抑制不可取消的异常时打印回溯。 在Cython源文件中声明编译设置 上面的方法将编译设置都放在setup.py中,这样做略繁琐,也无法在源文件中体现.一个更加优雅的方法是使用类似python中声明编码一样,在源文件的初始几行中.这种方式也是现在官方推荐的写法,使用这种方式也可以更加方便的在jupyter notebook中使用C++的一些特性 %load_ext Cython %%cython # distutils: language=c++ def f(double x): return x**2-x def integrate_f(double a, double b, int N): cdef int i cdef double s, dx s = 0 dx = (b-a)/N for i in range(N): s += f(a+i*dx) return s * dx 这种方式的setup.py文件也更加简单,只需用cythonize函数指定所有.pyx文件即可 from distutils.core import setup from Cython.Build import cythonize setup( ext_modules = cythonize(\"*.pyx\") ) 分析 Cython 程序瓶颈 Cython 中类型声明非常重要，但是我们不加类型标注它依然是一个合法的Cython程序,所以自然而然地,我们会担心漏加类型声明.不过好在 Cython 提供了一个很好的工具,可以方便地检查 Cython 程序中哪里可能可以进一步优化. !cython -a helloworld.pyx 之后我们的文件夹下就会看到一个html文件,其中黄色的部分就是与python交互的部分,也就是性能瓶颈 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:58:35 "},"嵌入与扩展篇/使用Cython优化python程序的性能/Cython的基本模式.html":{"url":"嵌入与扩展篇/使用Cython优化python程序的性能/Cython的基本模式.html","title":"Cython的基本模式","keywords":"","body":"使用.pyx改写python程序 在纯净模式中,我的代码实现手段很有限: 只能直接使用python模块和对象 无法使用c++的容器和算法 无法使用cimport %load_ext Cython %%cython # distutils: language=c++ from libcpp.vector cimport vector from libcpp.string cimport string #from libc.stdio cimport printf cpdef print_vect(string content): cdef vector[int] vect cdef int i for i in range(10): vect.push_back(i) for i in vect: #printf(\"%d\",vect[i]) print(vect[i]) for i in content: #printf(\"%d\",vect[i]) print(i) print_vect(\"黑龙江\".encode()) 0 1 2 3 4 5 6 7 8 9 -23 -69 -111 -23 -66 -103 -26 -79 -97 Cython语法 Cython是python的超集,所以python解释器无法解释cython代码,必须编译才可以. 静态化参数 Cython是一个Python编译器。这意味着它可以编译普通的Python代码，而不会有任何改变（除了一些尚未支持的语言功能之外，还有一些明显的例外）.然而，对于性能关键代码，添加静态类型声明通常是有帮助的，因为它们将允许Cython退出Python代码的动态特性，并生成更简单更快的C代码.但是，必须注意的是，类型声明会使源代码更加冗长，因而可读性更低.因此，不要在没有正当理由的情况下使用它们，例如基准测试证明他们在性能关键部分真正使代码更快速地使用它们是不鼓励的.通常在正确的地方有几种类型可以走很长的路.所有C类型都可用于类型声明:整数和浮点类型，复数，结构体，联合和指针类型. Cython可以在分配类型之间自动正确地进行转换.这也包括Python的任意大小的整数类型，其中转换为C类型的值溢出会在运行时引发Python OverflowError.(但是，在进行算术时，不会检查是否溢出).在这种情况下，生成的C代码将正确安全地处理C类型的依赖于平台的大小. 在python函数中使用c语言的类型指明翻译为C语言后的参数类型 由于这些参数被传递到Python声明的函数中，它们会转换为指定的C类型值.但这只适用于数字和字符串类型 %%cython def f(double x): return x**2-x def integrate_f(double a, double b, int N): cdef int i cdef double s, dx s = 0 dx = (b-a)/N for i in range(N): s += f(a+i*dx) return s * dx f(1.2) 0.24 C级别申明 作为一种动态语言，Python鼓励了一种根据方法和属性考虑类和对象的编程风格，而不仅仅局限于类层次结构中.这可以使Python成为一种非常轻松和舒适的语言，用于快速开发，但有一个代价 -- 管理数据类型的\"繁文缛节\"被转储到翻译器上.在运行时，解释器在搜索命名空间，获取属性和解析参数和关键字元组方面做了大量工作。与\"早期绑定\"语言（如C++）相比，这种运行时\"后期绑定\"是Python相对较慢的主要原因.然而使用Cython可以通过使用\"早期绑定\"编程技术获得显着的加速. cdef语句用于创建C级声明 申明变量 cdef int i, j, k cdef float f, g[42], *h 申明结构体 cdef struct Grail: int age float volume 申明联合体 cdef union Food: char *spam float *eggs 申明枚举 cdef enum CheeseType: cheddar, edam, camembert 申明函数 cdef int eggs(unsigned long l, float f): cdef关键字指定早期绑定,默认是私有的,只有在申明时指定public才会暴露 类型转换 在cython中使用yyy操作符来进行类型转换,其使用方式与C中类似. cdef char *p, float *q p = q 值得注意的是cython中python的bool类型会转化为bint,而python中的自定义类的实例则对应的object 类型检测 和C中类似,类型转换时使用yyy会先进行检测 字符串 C级别无论是字符数组还是c++的string,都只接收python的bytes作为转换来源.返回的也只会转换为bytes.因此需要注意. 函数,方法申明 Cython中有三种类型的函数声明. Python的可调用对象(def) 这种类型的函数特点: 使用def申明 可以被Python解释器调用 可以被Python对象调用 返回Python对象 参数可以静态化 C的可调用对象 (cdef) 这种类型的函数特点: 用cdef语句声明 无法在python解释器中访问 可以被Python对象或C值调用 内部变量必须申明 可以返回Python对象或C值 Python和C的可调用(cpdef) 这种类型的函数特点: 用cpdef语句声明. 可以从任何地方调用 当从其他Cython代码调用时,使用更快的C调用约定 cython的内置函数 Cython将对大多数内置函数的调用编译为对相应的Python / C API例程的直接调用,使它们特别快。 只有使用这些名称的直接函数调用已优化.如果你使用这些名称中的一个假设它是一个Python对象，例如将它分配给一个Python变量，然后调用它，那么该调用将作为一个Python函数调用. 内置函数 返回类型 相当于Python/C API中的类型 abs(obj) object, double, ... PyNumber_Absolute, fabs, fabsf, ... callable(obj) bint PyObject_Callable delattr(obj, name) None PyObject_DelAttr exec(code, [glob, [loc]]) object dir(obj) list PyObject_Dir divmod(a, b) tuple PyNumber_Divmod getattr(obj, name, [default]) object PyObject_GetAttr hasattr(obj, name) bint PyObject_HasAttr hash(obj) int / long PyObject_Hash intern(obj) object Py*_InternFromString isinstance(obj, type) bint PyObject_IsInstance issubclass(obj, type) bint PyObject_IsSubclass iter(obj, [sentinel]) object PyObject_GetIter len(obj) Py_ssize_t PyObject_Length pow(x, y, [z]) object PyNumber_Power reload(obj) object PyImport_ReloadModule repr(obj) object PyObject_Repr setattr(obj, name) void PyObject_SetAttr 类申明(扩展类型) cython扩展类型可以使用cdef class来定义. 属性 其中的元素可以使用cdef来定义,默认是私有的,但可以使用public或者readonly关键字指定其封装形式. %%cython cdef class Rectangle: cdef public int x0 cdef readonly int y0 cdef int x1, y1 def __init__(self, int x0, int y0, int x1, int y1): self.x0 = x0; self.y0 = y0; self.x1 = x1; self.y1 = y1 cdef int _area(self): cdef int area area = (self.x1 - self.x0) * (self.y1 - self.y0) if area r = Rectangle(1, 2, 3, 1) r.x0 1 r.y0 2 r.x1 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 r.x1 AttributeError: '_cython_magic_31443cea76eb5b8780ecd933e92cc406.Rec' object has no attribute 'x1' r.x0=2 r.x0 2 r.y0 = 4 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 r.y0 = 4 AttributeError: attribute 'y0' of '_cython_magic_31443cea76eb5b8780ecd933e92cc406.Rectangle' objects is not writable r.area() 1 r._area() --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 r._area() AttributeError: '_cython_magic_31443cea76eb5b8780ecd933e92cc406.Rec' object has no attribute '_area' 特性 cython特性除了一般python语句一样的装饰器语法外,还可以使用如下特殊定义方式,两者效果一致. cdef class Spam: property cheese: \"A doc string can go here.\" def __get__(self): # This is called when the property is read. ... def __set__(self, value): # This is called when the property is written. ... def __del__(self): # This is called when the property is deleted. __get__()，__set__()和__del__()方法都是可选的.如果省略，属性访问会引发异常. 不推荐这种写法,因为看起来和python差别太大 %%cython cdef class CheeseShop: cdef object cheeses def __cinit__(self): self.cheeses = [] property cheese: # note that this syntax is deprecated def __get__(self): return \"We don't have: %s\" % self.cheeses def __set__(self, value): self.cheeses.append(value) def __del__(self): del self.cheeses[:] shop = CheeseShop() print(shop.cheese) shop.cheese = \"camembert\" print(shop.cheese) shop.cheese = \"cheddar\" print(shop.cheese) del shop.cheese print(shop.cheese) We don't have: [] We don't have: ['camembert'] We don't have: ['camembert', 'cheddar'] We don't have: [] 方法 Rectangle中_area是C级别的函数,不可被访问,所以需要使用area方法来封装.不过通常是使用cpdef直接实现的 %%cython cdef class Rectangle: cdef int x0, y0 cdef int x1, y1 def __init__(self, int x0, int y0, int x1, int y1): self.x0 = x0; self.y0 = y0; self.x1 = x1; self.y1 = y1 cpdef int area(self): cdef int area area = (self.x1 - self.x0) * (self.y1 - self.y0) if area r = Rectangle(1, 2, 3, 1) 方法重载 在扩展类型中同一申明方式的可以相互重载,而不同申明方式的则有一套优先级: cpdef可以重载cdef,而反过来就不行 def可以重载cpdef,而反过来就不行 %%cython cdef class A: cdef foo(self): print(\"A\") cdef class AA(A): cdef foo(self): print(\"AA\") cpdef bar(self): self.foo() AA().bar() AA %%cython cdef class A: cdef foo(self): print(\"A\") cdef class B(A): cpdef foo(self, x=None): print(\"B\", x) class C(B): def foo(self, x=True, int k=3): print(\"C\", x, k) B(12).foo() B None C().foo() C True 3 继承 基类的完整定义必须可用于Cython，因此如果基类是内置类型，它必须先前已声明为extern扩展类型.如果基类型在另一个Cython模块中定义，则必须声明为extern扩展类型或使用cimport语句导入. 一个扩展类型只能有一个基类(cython的扩展类不支持多重继承).但可以被python类继承,这种继承支持多继承. 有一种方法可以防止扩展类型在Python中被子类化.这是通过final指令完成的，通常使用装饰器在扩展类型上设置 cimport cython @cython.final cdef class Parrot: def done(self): pass 扩展类型快速实例化 Cython提供了两种方法来加速扩展类型的实例化. 第一个是直接调用__new__()特殊静态方法，如从Python中所知。对于例子扩展类型Penguin，可以使用以下代码： %%cython cdef class Penguin: cdef public object food def __cinit__(self, food): self.food = food def __init__(self, food): print(\"eating!\") normal_penguin = Penguin('fish') eating! normal_penguin.food 'fish' fast_penguin = Penguin.__new__(Penguin, 'wheat') fast_penguin.food 'wheat' __new__()实例化的对象会不运行__init__()只会运行__cinit__() 第二个性能改进适用于经常在一行中创建和删除的类型，以便他们可以从freelist中受益. Cython为此提供了装饰器@cython.freelist(N)，它为给定类型创建了一个静态大小的N个实例的freelist.例： %%cython cimport cython @cython.freelist(8) cdef class Penguin: cdef object food def __cinit__(self, food): self.food = food penguin = Penguin('fish 1') penguin = None penguin = Penguin('fish 2') 特殊方法 cython也支持特殊方法,它支持的特殊方法可在这里看到 扩展类型的特殊方法必须用def，而不是cdef声明,这不会影响他们的性能 -- Python使用不同的调用约定来调用这些特殊方法. 这边列举几个比较中要的: 初始化方法：__cinit__() 和__init__() 有两种方法与初始化对象有关. __cinit__() 方法是应该执行对象的基本C级初始化，包括对象将拥有的任何C数据结构的分配.你需要小心你在__cinit__()方法中做什么，因为对象可能还不是完全有效的Python对象.因此，你应该小心调用任何Python可能触摸对象的操作,特别是其方法. 在调用__cinit__()方法时，已经为对象分配了内存，并且任何C属性已初始化为0或null。(任何Python属性也被初始化为None，但是你可能不应该依赖它.)你的__cinit__()方法一定只会被调用一次. 如果扩展类型有基类，那么在调用__cinit __()方法之前，将自动调用基类的__cinit__()方法,你不能显式调用基类的__cinit__()方法。如果需要将修改的参数列表传递给基类,则必须在__init__()方法中执行初始化的相关部分(其中调用继承方法的正常规则适用). __init__() 在__cinit__()方法中不能安全完成的任何初始化都应该在__init__()方法中完成.当调用__init __()时，对象是一个完全有效的Python对象，所有操作都是安全的.在某些情况下,__init__()可能被多次调用或根本不被调用. 传递给构造函数的任何参数都将传递给__cinit __()方法和__init__()方法。如果你预计在Python中继承扩展类型,可能会将参数以*和**参数的形式传给__cinit__()方法，以便它可以接受和忽略额外的参数.否则，任何具有带有不同签名的__init __()的Python子类都必须覆盖__new __()以及__init __()，明显这样很不友好.或者，为了方便起见，如果你声明你的__cinit__()方法没有参数(除了self)，它将简单地忽略传递给构造函数的任何额外的参数.这种方式可能更加保险. 析构方法：__dealloc__() 与__cinit__()方法的逆向方法是__dealloc__()方法。__cinit__()方法中显式分配内存的任何C数据(例如通过malloc分配的空间)应在__dealloc__()方法中释放.你需要小心你在__dealloc __()方法中的操作.在调用__dealloc__()方法时，对象可能已经被部分销毁，并且对于Python而言可能不处于有效状态，如果你坚持只是释放C数据是最好的选择. 你不需要担心释放对象的Python属性，因为在__dealloc __()方法返回后，它将由Cython完成. 当子类化扩展类型时,请注意，超类的__dealloc__()方法将始终被调用，即使它被覆盖.这与典型的Python行为不同. 注意： 扩展类型没有__del__()方法。 逻辑运算方法 算术运算符方法(如__add__())的行为与Python对应方法不同。这些方法没有单独的“反转”版本(__radd __()等).相反，如果第一个操作数不能执行操作，则调用第二个操作数的相同方法，操作数的顺序相同. 运算比较操作 对于不同的比较操作(__eq__()，__le__()等等)Cython没有单独的方法.而是有一个方法__richcmp __()，它接受一个整数，指示要执行哪种操作，如下所示: 操作 指示 0 == 2 > 4 1 != 3 >= 5 错误处理 如果你不做任何特殊的事情，用cdef声明的函数不返回任何Python对象，这样这个cdef函数就没有办法向其调用者报告其Python异常.如果在此类函数中检测到异常，则会打印一条警告消息，并忽略该异常. 如果你想要一个不返回Python对象的C函数能够将异常传播给它的调用者，你需要声明一个异常值。这里是一个例子： cdef int spam() except -1: ... 使用此声明，每当spam()函数内发生异常时，它将立即返回值-1.此外，每当对spam()的调用返回-1时，将假定异常已经发生并将被传播. 当为函数声明异常值时，不应显式或隐式返回该值.特别是，如果异常返回值是一个False值，那么你应该确保函数永远不会通过隐式或空返回终止. 如果所有可能的返回值都是合法的，并且你不能完全保留一个用于信号错误，则可以使用异常值声明的替代形式： cdef int spam() except? -1: ... '?'号表示-1是个异常值，在这种情况下，Cython通过生成一个函数PyErr_Occurred()进行返回，从而知道该函数发生了异常值. 还有第三种定义方式： cdef int spam() except *: ... 这种形式导致Cython在每次调用spam()后生成对PyErr_Occurred()的调用，而不管它返回什么值。如果你有一个函数返回void需要传播错误，你将不得不使用这种形式，因为没有任何返回值来测试.否则这种形式的定义应该尽量少用. 需要注意的是： 异常值只能为返回 整数， 枚举， 浮点 指针类型的函数声明. 并且该值必须是常量表达式。 void函数只能使用except *形式. 异常值规范是函数签名的一部分。如果将指针作为参数传递给函数或将其指定给变量，则声明的参数或变量的类型必须具有相同的异常值规范(或缺少).下面是一个具有异常值的指针到函数声明的示例： int (*grail)(int, char*) except -1 模块导入 cython中的导入方式有3种: python的import 用于导入python模块,一般只在实现文件中导入 cython的cimport 用于导入cpython中.pxd文件中申明的内容和一些cpython封装好的标准模块,可以在申明文件或者实现文件中导入 cython的include include语句用于导入.pxi文件.这种语法类似C/C++中的#include,是直接将目标文件内容复制到当前位置 使用C++的stl和C标准库 大多数C++标准库的容器已在位于/Cython /Includes/libcpp的pxd文件中声明.这些容器是： deque 双向队列 list 列表 map 映射 pair 对 queue 队列 set集合 stack栈 vector 向量 这些容器的使用方法可以看C++的stl部分. 因此现在想用这些容器只需简单的cimport进来即可 %%cython # distutils: language = c++ from libcpp.vector cimport vector cdef vector[int] vect cdef int i for i in range(10): vect.push_back(i) for i in range(10): print(vect[i]) 0 1 2 3 4 5 6 7 8 9 现在在Cython中STL容器会从相应的Python内建类型中强制转换。转换通过对类型化变量（包括类型化函数参数）的赋值或显式转换触发，例如： %%cython # distutils: language = c++ from libcpp.string cimport string from libcpp.vector cimport vector cdef string s = b'py_bytes_object' print(s) cpp_string = 'py_unicode_object'.encode('utf-8') cdef vector[int] vect = xrange(1, 10, 2) print(vect) # [1, 3, 5, 7, 9] cdef vector[string] cpp_strings = b'ab cd ef gh'.split() print(cpp_strings[1]) # b'cd' b'py_bytes_object' [1, 3, 5, 7, 9] b'cd' 以下强制可用： Python type => C++ type => Python type bytes std::string bytes iterable std::vector list iterable std::list list iterable std::set set iterable (len 2) std::pair tuple (len 2) 所有转换都会创建一个新的容器并将数据复制到该容器中.容器中的项目会自动转换为相应的类型,包括递归转换容器内的容器,例如字符串map转换为vector. 支持在stl容器(或实际上任何类与begin()和end()方法返回支持递增,取消引用和比较的对象)通过for语法支持.包括列表解析.例如如下代码: %%cython # distutils: language = c++ from libcpp.vector cimport vector cdef func(value): return value**2 cdef vector[int] v = [1,2,3,4,5,6,7,8] for value in v: print(func(value)) y = [x*x for x in v if x % 2 == 0] 1 4 9 16 25 36 49 64 y [4, 16, 36, 64] Cython中的array Python有一个内置1维数组的原始类型的动态数组模块.可以从Cython中访问Python数组的底层C数组.同时,它们是普通的Python对象，可以存储在列表中并在多进程之间进行序列化. 与malloc()和free()的手动控制内存方法相比，这提供了对Python的安全和自动内存管理，与Numpy数组相比,无需安装依赖关系,因为数组模块内置于cPython和cython中. 使用内存视图的安全使用方式 注意：cython中需要同时导入cython级别的数组和常规Python数组对象引入到命名空间中. 当一个Python数组被分配给一个类型为内存视图的变量时，构造内存视图将会有一些微小的开销.但是,从这个角度来看,变量可以传递给其他函数而不需要开销,只要它被输入: %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) cdef int[:] ca = a print(ca[0]) 1 %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) cdef int[:] ca = a cdef int overhead(object a): cdef int[:] ca = a return ca[0] cdef int no_overhead(int[:] ca): return ca[0] print(overhead(a)) # new memory view will be constructed, overhead print(no_overhead(ca)) # ca is already a memory view, so no overhead 1 1 零开销，不安全访问原始C指针 为了避免任何开销，并且能够将C指针传递给其他函数，可以以底层的连续数组作为指针.没有类型或边界检查,所以要小心使用正确的类型和签名. 请注意,数组对象上的任何长度变化操作都可能使指针无效. %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) # access underlying pointer: print(a.data.as_ints[0]) from libc.string cimport memset memset(a.data.as_voidptr, 0, len(a) * sizeof(int)) 1 克隆，扩展数组 为避免使用Python模块中的数组构造函数，可以创建与模板类型相同的新数组,并预先分配给定数量的元素.数组在请求时初始化为零. %%cython from cpython cimport array import array cdef array.array int_array_template = array.array('i', []) cdef array.array newarray # create an array with 3 elements with same type as template newarray = array.clone(int_array_template, 3, zero=False) 一个数组也可以被扩展和调整大小;这避免了重复的内存重新分配,如果元素被逐个附加或删除,则会发生这种重新分配. %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) cdef array.array b = array.array('i', [4, 5, 6]) # extend a with b, resize as needed array.extend(a, b) # resize a, leaving just original three elements array.resize(a, len(a) - len(b)) 相关接口 将内容强制转换 data.as_voidptr data.as_chars data.as_schars data.as_uchars data.as_shorts data.as_ushorts data.as_ints data.as_uints data.as_longs data.as_ulongs data.as_longlongs # requires Python >=3 data.as_ulonglongs # requires Python >=3 data.as_floats data.as_doubles data.as_pyunicodes 操作的相关函数 int resize(array self, Py_ssize_t n) except -1 快速调整大小/ realloc.不适合重复，小增量;将底层数组调整到正确的请求量. int resize_smart(array self, Py_ssize_t n) except -1 小增量更加有效;使用提供摊销线性时间附加的增长模式. cdef inline array clone(array template, Py_ssize_t length, bint zero) 给定一个模板数组，快速创建一个新数组.类型将与模板相同.如果为零,则将使用零初始化新数组. cdef inline array copy(array self) 复制一个数组 cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1 对相同类型的新数据(例如，相同数组类型),高效附加n个元素数量的长度 cdef inline int extend(array self, array other) except -1 使用另一个数组的数据扩展数组;类型必须匹配。 cdef inline void zero(array self) 将数组内容全部置0 Memoryviews内存视图 类型化的内存视图可以有效地访问内存缓冲区,例如NumPy数据库中的缓冲区,而不会导致任何Python开销. Memoryview类似于当前的NumPy数组缓冲区支持(np.ndarray [np.float64_t，ndim = 2]),但它们具有更多的功能和更清晰的语法.内存访问比旧的NumPy数组缓冲区支持更通用,因为它们可以处理更多种类的数组数据源.例如,他们可以处理C数组和Cython数组类型(Cython数组).可以在任何上下文(函数参数，模块级，cdef类属性等)中使用内存视图,并且可以从几乎任何通过PEP 3118缓冲区接口暴露可写缓冲区的对象获得. 如果习惯使用NumPy，以下示例应该让您开始使用Cython内存视图. %%cython from cython.view cimport array as cvarray import numpy as np # Memoryview on a NumPy array narr = np.arange(27, dtype=np.dtype(\"i\")).reshape((3, 3, 3)) cdef int [:, :, :] narr_view = narr # Memoryview on a C array cdef int carr[3][3][3] cdef int [:, :, :] carr_view = carr # Memoryview on a Cython array cyarr = cvarray(shape=(3, 3, 3), itemsize=sizeof(int), format=\"i\") cdef int [:, :, :] cyarr_view = cyarr # Show the sum of all the arrays before altering it print(\"NumPy sum of the NumPy array before assignments: %s\" % narr.sum()) # We can copy the values from one memoryview into another using a single # statement, by either indexing with ... or (NumPy-style) with a colon. carr_view[...] = narr_view cyarr_view[:] = narr_view # NumPy-style syntax for assigning a single value to all elements. narr_view[:, :, :] = 3 # Just to distinguish the arrays carr_view[0, 0, 0] = 100 cyarr_view[0, 0, 0] = 1000 # Assigning into the memoryview on the NumPy array alters the latter print(\"NumPy sum of NumPy array after assignments: %s\" % narr.sum()) # A function using a memoryview does not usually need the GIL cpdef int sum3d(int[:, :, :] arr) nogil: cdef size_t i, j, k cdef int total = 0 I = arr.shape[0] J = arr.shape[1] K = arr.shape[2] for i in range(I): for j in range(J): for k in range(K): total += arr[i, j, k] return total # A function accepting a memoryview knows how to use a NumPy array, # a C array, a Cython array... print(\"Memoryview sum of NumPy array is %s\" % sum3d(narr)) print(\"Memoryview sum of C array is %s\" % sum3d(carr)) print(\"Memoryview sum of Cython array is %s\" % sum3d(cyarr)) # ... and of course, a memoryview. print(\"Memoryview sum of C memoryview is %s\" % sum3d(carr_view)) NumPy sum of the NumPy array before assignments: 351 NumPy sum of NumPy array after assignments: 81 Memoryview sum of NumPy array is 81 Memoryview sum of C array is 451 Memoryview sum of Cython array is 1351 Memoryview sum of C memoryview is 451 基本语法 内存视图使用Python切片语法，与NumPy类似。要在一维int缓冲区上创建一个完整的视图： 一维视图: cdef int[:] view1D = exporting_object 三维视图: cdef int[:,:,:] view3D = exporting_object 2D视图将缓冲区的第一维度限制为从第二个(索引1)开始的100行，然后每秒(奇数)行跳过： cdef int[1:102:2,:] partial_view = exporting_object 这也可以方便地作为函数参数 def process_3d_buffer(int[1:102:2,:] view not None): ... 该参数的not None声明自动拒绝无值作为输入,否则将允许.默认情况下允许None的原因是它方便地用于返回参数: def process_buffer(int[:,:] input not None, int[:,:] output = None): if output is None: output = ... # e.g. numpy.empty_like(input) # process 'input' into 'output' return output Cython将自动拒绝不兼容的缓冲区，例如将三维缓冲区传递到需要二维缓冲区的函数将引发ValueError。 索引 在Cython中，内存视图上的索引访问将自动转换为内存地址。以下代码向其中请求一个二维内存视图的C类型的项目和索引： cdef int[:,:] buf = exporting_object print(buf[1,2]) 负指数也从各自的维度结束起计算： print(buf[-1,-2]) 以下函数循环遍历2D数组的每个维度，并为每个项添加1： def add_one(int[:,:] buf): for x in xrange(buf.shape[0]): for y in xrange(buf.shape[1]): buf[x,y] += 1 可以使用或不使用GIL进行索引和切片。它基本上像NumPy一样工作.如果为每个维指定了索引，您将获得基本类型的元素(例如int).否则将获得一个新的视图.省略号意味着可以为每个未指定维度获得连续的切片： cdef int[:, :, :] my_view = exporting_object # These are all equivalent my_view[10] my_view[10, :, :] my_view[10, ...] 复制 内存视图可以复制 cdef int[:, :, :] to_view, from_view ... # copy the elements in from_view to to_view to_view[...] = from_view # or to_view[:] = from_view # or to_view[:, :, :] = from_view 它们也可以用copy（）和copy_fortran（）方法复制 转置 在大多数情况下内存视图可以以与NumPy切片相同的方式进行转置： cdef int [:, :: 1] c_contig = ... cdef int [:: 1，：] f_contig = c_contig.T 这一操作会给出一个新的，转置过的数据视图。调换要求存储器视图的所有维度都具有直接访问存储器布局(即，通过指针不存在任何指令). 内存视图与数组 这些类型对象的内存视图可以转换为Python memoryview对象(cython.view.memoryview).这些Python对象是可索引的，可切片的并且以与原始内存访问相同的方式进行转座。它们也可以随时转换回Cython-space memoryviews. 它们具有以下属性： shape: size in each dimension, as a tuple. strides: stride along each dimension, in bytes. suboffsets ndim: number of dimensions. size: total number of items in the view (product of the shape). itemsize: size, in bytes, of the items in the view. nbytes: equal to size times itemsize. base T 当然还有上述的T属性（Transpose）。这些属性具有与NumPy相同的语义.例如，要检索原始对象： %%cython import numpy cimport numpy as cnp cdef cnp.int32_t[:] a = numpy.arange(10, dtype=numpy.int32) a = a[::2] print(a) print(numpy.asarray(a)) print(a.base) [0 2 4 6 8] [0 1 2 3 4 5 6 7 8 9] 请注意，此示例返回从中获取视图的原始对象，同时视图已被重新生成. 每当复制Cython内存视图（使用任何copy或copy_fortran方法）时，都会获得新创建的cython.view.array对象的新内存视图.这个数组也可以手动使用,并会自动分配一个数据块.它可以随后被分配给C或Fortran连续片(或跨片).它可以像下面: from cython cimport view my_array = view.array(shape=(10, 2), itemsize=sizeof(int), format=\"i\") cdef int[:, :] my_slice = my_array 它还需要一个可选的参数模式（'c'或'fortran'）和一个布尔的allocate_buffer，它指示当超出范围时是否应该分配和释放缓冲区： cdef view.array my_array = view.array(..., mode=\"fortran\", allocate_buffer=False) my_array.data = my_data_pointer # define a function that can deallocate the data (if needed) my_array.callback_free_data = free 还可以将数组的指针或C数组转换为数组： cdef view.array my_array = my_data_pointer cdef view.array my_array = my_c_array 当然，也可以立即将cython.view.array指定给类型化的内存视图切片.可以将C数组直接分配给内存视图切片： cdef int[:, ::1] myslice = my_2d_c_array 数组可以像Python空间一样可索引和可切换，就像memoryview对象一样，并且具有与memoryview对象相同的属性. cython.view.array的替代方法是Python标准库中的数组模块。在Python 3中，array.array类型本身支持缓冲区接口，所以在没有额外的设置的情况下，memoryviews就可以工作. %%cython cimport cpython.array def sum_array(int[:] view): \"\"\" >>> from array import array >>> sum_array( array('i', [1,2,3]) ) 6 \"\"\" cdef int total for i in range(view.shape[0]): total += view[i] return total 请注意，cimport还为阵列类型启用旧的缓冲区语法.因此,以下内容也起作用: from cpython cimport array def sum_array(array.array[int] arr): # using old buffer syntax 内存控制 动态内存分配大多时候在Python中不是一个问题.一切都是一个对象,引用计数系统和垃圾收集器会在不再使用系统时自动返回内存.当涉及到更低级别的数据缓冲区时,Cython通过NumPy,内存视图或Python的stdlib数组类型,为简单类型的(多维)数组提供了特殊的支持.它们是全功能,带垃圾收集,比C中的裸指针更容易工作;同时仍然保持速度和静态类型的好处.然而,在某些情况下,这些对象仍然会产生不可接受的开销,从而可以在C中进行手动内存管理. 简单的C语言值和结构(例如局部变量cdef double x)通常分配在堆栈上并通过值传递.但是对于较大和更复杂的对象(例如动态大小的双精度列表),必须手动请求内存并发布. C为此提供了malloc()，realloc()和free()的功能，可以从clibc.stdlib导入cython.他们的签名是： void* malloc(size_t size) void* realloc(void* ptr, size_t size) void free(void* ptr) 下面是一个简单的例子: %%cython import random from libc.stdlib cimport malloc, free def random_noise(int number=1): cdef int i # allocate number * sizeof(double) bytes of memory cdef double *my_array = malloc(number * sizeof(double)) if not my_array: raise MemoryError() try: ran = random.normalvariate for i in range(number): my_array[i] = ran(0,1) return [ my_array[i] for i in range(number) ] finally: # return the previously allocated memory to the system free(my_array) random_noise(10) [-1.6609585787562682, 0.2930416975778874, 1.0867854313042287, 0.4215754219750379, -0.020794290445162556, -0.9283056817997914, 1.1385359763229776, -0.6051526240377219, -0.6630213916869704, -0.14696302042299017] 请注意，在Python堆上分配内存的C-API函数通常比上面的低级C函数更为优先,因为它们提供的内存实际上是在Python的内部存储器管理系统中解决的.它们还对较小的内存块进行了特殊优化,从而通过避免昂贵的操作系统调用来加快其分配. C-API函数可以在cpython.mem标准声明文件中找到： from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free 它们的接口和用法与相应的低级C函数的接口和用法相同. 需要记住的一个重要的事情是,使用malloc()或PyMem_Malloc()获取的内存块必须在不再使用时对其调用free()或PyMem_Free()进行手动释放(并且必须始终使用匹配类型的自由功能).否则，直到python进程退出才会被回收.这被称为内存泄漏. 如果一块内存需要比可以由try...finally块管理的更长的生命周期，另一个有用的习惯是将其生命周期与Python对象相结合，以利用Python运行时的内存管理，例如： %%cython from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free cdef class SomeMemory: cdef double* data def __cinit__(self, size_t number): # allocate some memory (uninitialised, may contain arbitrary data) self.data = PyMem_Malloc(number * sizeof(double)) if not self.data: raise MemoryError() def resize(self, size_t new_number): # Allocates new_number * sizeof(double) bytes, # preserving the current content and making a best-effort to # re-use the original data location. mem = PyMem_Realloc(self.data, new_number * sizeof(double)) if not mem: raise MemoryError() # Only overwrite the pointer if the memory was really reallocated. # On error (mem is NULL), the originally memory has not been freed. self.data = mem def __dealloc__(self): PyMem_Free(self.data) # no-op if self.data is NULL 去除gil限制 Cython提供了解除和使用全局锁（GIL）的设施。当从多线程代码调用（外部C）代码可能会阻止或希望从（本地）C线程回调使用Python时，这可能很有用.显然，释放GIL应该只对线程安全的代码或使用其他防止种族条件和并发问题的保护措施的代码进行.注意，获取GIL是一个阻塞线程同步操作，因此是潜在的昂贵开销。可能不值得发布GIL进行微小的计算。通常，并行代码中的I / O操作和实质性计算将从中受益. 释放GIL 可以使用nogil语句释放GIL周围的一段代码： with nogil: 在语句正文中的代码不得以任何方式引发异常或操纵Python对象，并且不得先调用任何操作Python对象的操作，从而无需先重新获取GIL.例如，Cython在编译时验证这些操作，但不能查看外部C函数.它们必须被正确声明为要求或不要求GIL（见下文），以使Cython的检查生效. 获得GIL 要用作没有GIL执行的C代码的回调的C函数需要在操作Python对象之前获取GIL。这可以通过在函数头中指定gil来完成： cdef void my_callback(void *data) with gil: ... 如果可以从另一个非Python线程调用回调函数，则必须首先通过调用PyEval_InitThreads()来初始化GIL。如果你已经在你的模块中使用cython.parallel，这个已经被照顾了.GIL也可以通过gil语句获得： with gil: 声明一个可调用的不受gil限制的的函数 您可以在C函数头或函数类型中指定nogil，以声明在没有GIL的情况下可以安全地调用： cdef void my_gil_free_func(int spam) nogil: ... 当您在Cython中实现这样的函数时，它不能有任何Python参数或Python对象返回类型.此外,涉及Python对象(包括调用Python函数)的任何操作必须首先明确获取GIL,例如:通过使用gil块或调用已经用gil定义的函数.这些限制由Cython检查,如果在nogil代码部分找到任何Python交互,您将收到编译错误. 注意nogil函数注释声明在没有GIL的情况下调用该函数是安全的.完全可以在持有GIL的同时执行它.如果调用者持有该功能,本身并不释放GIL. 用gil来声明一个函数（即获取输入的GIL）也隐含地使它的签名nogil. 并行编程(使用openmp) Cython通过cython.parallel模块支持本机并行.要使用这种并行性,必须释放GIL（请参阅释放GIL）.它目前支持OpenMP，但后来可能会支持更多后端. cython.parallel.prange([start,] stop[, step][, nogil=False][, schedule=None[, chunksize=None]][, num_threads=None]) 此功能可用于并行循环.OpenMP自动启动一个线程池，并根据所使用的时间表分配工作.步骤不能为0.此功能只能与GIL一起使用.如果nogil为真，则循环将包裹在nogil部分。针对变量自动推断线程位置和裁减。如果您分配给一个prange块中的变量，它将变为lastprivate，这意味着该变量将包含上一次迭代中的值。如果在一个变量上使用一个inplace操作符，那么它会减少，这意味着该变量的线程本地副本的值将随着操作符而减少，并在循环后分配给原始变量。索引变量始终为lastprivate.与块并行分配的变量将在块之后是私有的和不可用的，因为没有连续的最后一个值的概念. schedule参数会传递给OpenMP，可以是以下之一： static静态的：如果提供了一个chunksize，迭代将在给定的chunksize块中提前分发给所有线程。如果没有给出chunksize，则迭代空间被分成大小相等的块，并且至多一个块预先分配给每个线程。当调度开销重要时，这是最合适的，并且可以将问题减少到已知具有大致相同运行时的大小相同的块. dynamic动态的:迭代被分发给线程，因为它们请求它们，默认块大小为1.当每个块的运行时间不同而不是预先知道时，这是适用的，因此使用较大数量的较小块来保持所有线程忙. guided有指导的:与动态调度一样,迭代被分配给线程,因为它们请求它们,但是随着块大小的减小.每个块的大小与未分配迭代次数除以参与线程数减少到1(或者提供的chunksize)成比例.这已超过纯动态调度的优势,事实证明,当最后一个块需要比预期或以其他方式被严重计划更多的时间,使大部分线程开始运行闲置而最后块正在只有线程数量较少的制作. runtime运行时的：调度和块大小取自运行时调度变量，可以通过openmp.omp_set_schedule()函数调用或OMP_SCHEDULE环境变量进行设置.请注意,这基本上禁用了调度代码本身的任何静态编译时间优化，因此可能会显示比在编译时静态配置相同调度策略时更差的性能. cython.parallel.threadid() 返回线程的ID。对于n个线程，ids的范围为0到n-1 cython.parallel.parallel(num_threads=None) 该指令可以作为with语句的一部分，并行执行代码序列.这对于设置由prange使用的线程本地缓冲区目前是有用的.一个包含的prange将是一个并行的工作共享循环，因此在并行部分中分配的任何变量对于prange也是私有的.并行块中私有的变量在并行块之后不可用. %%writefile testomp.pyx from cython.parallel import prange import numpy as np cimport numpy as np from math import exp from libc.math cimport exp as c_exp def array_f(X): Y = np.zeros(X.shape) index = X > 0.5 Y[index] = np.exp(X[index]) return Y def c_array_f(double[:] X): cdef int N = X.shape[0] cdef double[:] Y = np.zeros(N) cdef int i for i in range(N): if X[i] > 0.5: Y[i] = c_exp(X[i]) else: Y[i] = 0 return Y def c_array_f_multi(double[:] X): cdef int N = X.shape[0] cdef double[:] Y = np.zeros(N) cdef int i for i in prange(N, nogil=True): if X[i] > 0.5: Y[i] = c_exp(X[i]) else: Y[i] = 0 return Y Overwriting testomp.pyx %%writefile setup.py from distutils.core import setup from distutils.extension import Extension from Cython.Build import cythonize import numpy ext_modules = [ Extension( \"testomp\", [\"testomp.pyx\"], #extra_compile_args=['-fopenmp'], #extra_link_args=['-fopenmp'], include_dirs=[numpy.get_include()], extra_compile_args=['/openmp'], extra_link_args=['-/openmp'], ) ] setup( name='hello-parallel-world', ext_modules=cythonize(ext_modules), ) Overwriting setup.py ! python setup.py build_ext --inplace Compiling testomp.pyx because it changed. [1/1] Cythonizing testomp.pyx running build_ext building 'testomp' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /Tctestomp.c /Fobuild\\temp.win-amd64-3.6\\Release\\testomp.obj /openmp testomp.c c:\\users\\87\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_1_7_deprecated_api.h(12) : Warning Msg: Using deprecated NumPy API, disable it by #defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION testomp.c(2411): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data testomp.c(2675): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data testomp.c(2660): warning C4101: '__pyx_t_10': unreferenced local variable testomp.c(2663): warning C4101: '__pyx_t_13': unreferenced local variable testomp.c(2664): warning C4101: '__pyx_t_14': unreferenced local variable testomp.c(2661): warning C4101: '__pyx_t_11': unreferenced local variable testomp.c(2662): warning C4101: '__pyx_t_12': unreferenced local variable testomp.c(2665): warning C4101: '__pyx_t_15': unreferenced local variable testomp.c(21358): warning C4244: 'initializing': conversion from 'double' to 'float', possible loss of data testomp.c(21364): warning C4244: 'initializing': conversion from 'double' to 'float', possible loss of data C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_testomp build\\temp.win-amd64-3.6\\Release\\testomp.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的基本模式\\testomp.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\testomp.cp36-win_amd64.lib -/openmp LINK : warning LNK4044: unrecognized option '//openmp'; ignored testomp.obj : warning LNK4197: export 'PyInit_testomp' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\testomp.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\testomp.cp36-win_amd64.exp Generating code Finished generating code warning: testomp.pyx:37:12: Use boundscheck(False) for faster access warning: testomp.pyx:38:13: Use boundscheck(False) for faster access warning: testomp.pyx:38:26: Use boundscheck(False) for faster access warning: testomp.pyx:40:13: Use boundscheck(False) for faster access from testomp import c_array_f_multi,c_array_f import numpy as np X = -1 + 2*np.random.rand(10000000) %timeit c_array_f_multi(X) 10 loops, best of 3: 52.3 ms per loop %timeit c_array_f(X) 10 loops, best of 3: 81.3 ms per loop Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:58:58 "},"嵌入与扩展篇/使用Cython优化python程序的性能/静态化python模块.html":{"url":"嵌入与扩展篇/使用Cython优化python程序的性能/静态化python模块.html","title":"静态化python模块","keywords":"","body":"静态化python模块 Cython提供了一些装饰器和类型用于直接扩展python模块,先看一个例子: %%writefile logistic.py #cython: language_level=3 import cython from math import exp if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") @cython.boundscheck(False) @cython.ccall def logistic(x:cython.double)->cython.double: return 1/(1+exp(-x)) Writing logistic.py import logistic Just a lowly interpreted script. logistic.logistic(25) 0.999999999986112 %timeit logistic.logistic(25) 534 ns ± 70 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) !cythonize -i -3 logistic.py Compiling /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic.py because it changed. [1/1] Cythonizing /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic.py running build_ext building 'logistic' extension creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块 gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -I/Users/huangsizhe/LIB/CONDA/anaconda/include/python3.6m -c /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic.c -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic.o gcc -bundle -undefined dynamic_lookup -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -arch x86_64 /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp2i2j3uyu/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic.o -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic.cpython-36m-darwin.so import logistic Yep, I'm compiled. logistic.logistic(25) 0.999999999986112 %timeit logistic.logistic(25) 329 ns ± 3.74 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) %%writefile logistic_A.py #cython: language_level=3 import cython from math import exp if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") @cython.boundscheck(False) @cython.ccall def logistic(x): return 1/(1+exp(-x)) Writing logistic_A.py !cythonize -i -3 logistic_A.py Compiling /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_A.py because it changed. [1/1] Cythonizing /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_A.py running build_ext building 'logistic_A' extension creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块 gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -I/Users/huangsizhe/LIB/CONDA/anaconda/include/python3.6m -c /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_A.c -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_A.o gcc -bundle -undefined dynamic_lookup -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -arch x86_64 /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmp8dxpsjki/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_A.o -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_A.cpython-36m-darwin.so import logistic_A Yep, I'm compiled. logistic_A.logistic(25) 0.999999999986112 %timeit logistic_A.logistic(25) 364 ns ± 10.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) %%writefile logistic_B.pyx #cython: language_level=3 from math import exp cpdef double logistic(double x): return 1/(1+exp(-x)) Writing logistic_B.pyx !cythonize -i -3 logistic_B.pyx Compiling /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_B.pyx because it changed. [1/1] Cythonizing /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_B.pyx running build_ext building 'logistic_B' extension creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块 gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -I/Users/huangsizhe/LIB/CONDA/anaconda/include/python3.6m -c /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_B.c -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_B.o gcc -bundle -undefined dynamic_lookup -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -arch x86_64 /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpw9rfvum4/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_B.o -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_B.cpython-36m-darwin.so import logistic_B %timeit logistic_B.logistic(25) 299 ns ± 11.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) %%writefile logistic_C.py #cython: language_level=3 import cython from math import exp if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") @cython.boundscheck(False) @cython.ccall @cython.returns(cython.double) @cython.locals(x=cython.double) def logistic(x): return 1/(1+exp(-x)) Overwriting logistic_C.py !cythonize -i -3 logistic_C.py Compiling /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_C.py because it changed. [1/1] Cythonizing /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_C.py running build_ext building 'logistic_C' extension creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码 creating /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块 gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -I/Users/huangsizhe/LIB/CONDA/anaconda/include/python3.6m -c /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_C.c -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_C.o gcc -bundle -undefined dynamic_lookup -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -Wl,-rpath,/Users/huangsizhe/LIB/CONDA/anaconda/lib -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -headerpad_max_install_names -O2 -pipe -mcpu=arm1176jzf-s -mfpu=vfp -mfloat-abi=hard -w -arch x86_64 /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/tmpy87kng_s/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_C.o -L/Users/huangsizhe/LIB/CONDA/anaconda/lib -o /Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython/ipynbs/python性能优化/使用Cython优化python程序的性能/使用cython加速python源码/静态化python模块/logistic_C.cpython-36m-darwin.so import logistic_C Yep, I'm compiled. %timeit logistic_C.logistic(25) 382 ns ± 70.5 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:58:47 "},"嵌入与扩展篇/使用Cython优化python程序的性能/使用cython申明文件申明python源码类型.html":{"url":"嵌入与扩展篇/使用Cython优化python程序的性能/使用cython申明文件申明python源码类型.html","title":"使用cython申明文件申明python源码类型","keywords":"","body":"Cython纯净模式 所谓的纯净模式就是cython直接编译.py文件的模式. 在某些情况下,希望加速Python代码,而不会失去与Python解释器一起运行的能力.可以使用Cython编译纯Python脚本,但通常只能以20％-50％的速度增长. 为了超越此范围,Cython提供了语言结构,为Python模块添加静态类型和cythonic功能,使其在编译时运行得更快,同时仍然允许它被解释.有两种方案可以实现这一需求: 通过导入cython模块后使用其中的特殊功能和装饰器完成 通过扩展的.pxd文件 尽管通常不建议在.pyx文件中直接编写Cython代码,但更容易的测试,可以方便的与纯Python开发人员的协作等特点也为其提供了合理性. 在纯净python源文件下，你或多或少受限于在Python中的语法表达,如果希望跳过python语法,只能用具有扩展语言语法的.pyx文件完成,因为它依赖于Cython编译器的特性. cython可以使用cython.compiled来反射是否运行的是被编译的版本 .pxd文件中可以申明使用C/C++扩展,因此可以在.py文件中根据需要使用c/c++的编写的函数. 通过cython模块中的特殊功能和装饰器扩展 这种方式相比前面的使用pxd申明扩展的方式更加方便,所有这些特殊功能和装饰器都是非侵入式的,加上去掉都不会影响原本.py源代码在python解释器中的工作. 可用于申明的C类型 cython中常用的C语言类型有: cython中类型 类型说明 cython.int 整形 cython.long 长整形 cython.double 双精度浮点型 cython.char 字符型 其他的包括无符号整形之类的C语言中的基础类型也都有,这边不再复述. 另外一个特殊的类型就是指针,cython中指针类型就是基础类型前面加上p_,如整形数指针就是cython.p_int 常用的声明函数和装饰器有 不同于.pyx文件,.py文件需要符合python语法,因此很多申明和关键字需要使用函数或者类等对象来代替,纯净模式更多的是静态化参数以此来提高效率.下面是用于申明的函数和装饰器 cython.declare(**kws) 用于申明变量 cython.struct(**kws) 申明一个结构体 cython.union(**kws) 申明一个联合体 @cython.locals(**kws) 用于声明函数或者方法的参数和内部变量,即便是python方法也可以声明变量类型,这样静态化也可以获得提速 @cython.returns([cython_type]) 用于申明函数或者方法的参数和内部变量 @cython.ccall 申明可被python解释器调用的cython函数.相当于.pyx中的cpdef定义的函数或方法 @cython.cfunc 申明c/c++语言函数,这种函数会跳过运行时直接执行,而且隐藏在python解释器之下,只有模块中才可以调用 @cython.inline 申明函数为inline函数 常用的特殊函数 处理C语言函数时,我们很有可能需要使用一些关于内存指针的操作,这些操作python自己是没有的,因此Cython也提供一些这种特殊的函数 cython.address(x) 获取变量的指针地址 cython.sizeof(x) 获取变量的地址空间大小 cython.typedef(x) 用于获取一个给定指针名称下的变量类型的类型 cython.cast(T,x,typecheck=True) 用于将变量指定为某一类型,类似C/C++语言中的t.注意这个函数是不安全的,容易内存泄漏.可选参数typecheck=True相当于t 常用编译指示装饰器 @cython.boundscheck(bool) 用于设定是否进行边界检查,默认值为True。 @cython.wraparound(bool) 用于设定是否进行数组负索引检查,默认值为True。 @cython.initializedcheck(bool) 用于设定访问或分配内存视图时是否检查它是否被初始化.默认值为True。 @cython.overflowcheck 如果设置为True，当溢出的C整数算术运算上引发了异常时，会执行适度的运行时惩罚,但即便如此还是比python的int运算快很多,默认为False @cython.overflowcheck.fold 如果设置为True，并且overflowcheck为True，则检查嵌套的溢出位,和有副作用的算术表达式,而不是每个步骤都检查。 依赖于不同的编译器，体系结构和优化设置，这项选项可能有助于提高性能也可能损害性能。 默认值为True。 @cython.nonecheck 如果设置为False，Cython可以自由地假定 对变量类型的本地字段访问为扩展类型,或者 当变量被设为None时,对缓冲区变量的缓冲区访问永远不会发生。否则插入一个检查并引发适当的异常。 这些装饰器可以放在函数上标记好 常用的编译器指示注释 编译器可以识别在源文件开始部分的注释为全局的编译器指示,常见的有 #cython: language_level=3标记编译目标为python3 #cython: boundscheck = False设置全局不进行边界检查 编译器设置的参数可以在前面的Cython基本流程部分看到 %%writefile B.py #cython: language_level=3 import cython if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") @cython.boundscheck(False) @cython.ccall @cython.returns(cython.int) @cython.locals(x=cython.int, y=cython.int,a = cython.int) def myfunction(x, y=2): a = x-y return a + x * y @cython.cfunc @cython.returns(cython.double) @cython.locals(a = cython.double) def _helper(a): return a + 1 @cython.cclass class A: cython.declare(a=cython.int, b=cython.int) def __init__(self, b=0): self.a = 3 self.b = b @cython.ccall @cython.locals(x=cython.double) def foo(self, x): print(x + _helper(1.0)) Overwriting B.py import B Just a lowly interpreted script. B.myfunction(10) 28 a = B.A() a.foo(2.7) 4.7 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from Cython.Distutils import build_ext setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(\"B.py\",language=\"c++\") ) Overwriting setup.py !python setup.py build_ext --inplace Please put \"# distutils: language=c++\" in your .pyx or .pxd file(s) Compiling B.py because it changed. [1/1] Cythonizing B.py running build_ext building 'B' extension creating build creating build\\temp.win-amd64-3.6 creating build\\temp.win-amd64-3.6\\Release C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpB.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\B.obj B.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_B build\\temp.win-amd64-3.6\\Release\\B.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython纯净模式\\B.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\B.cp36-win_amd64.lib B.obj : warning LNK4197: export 'PyInit_B' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\B.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\B.cp36-win_amd64.exp Generating code Finished generating code import B Yep, I'm compiled. B.myfunction(10) 28 a = B.A() a.foo(2.7) 4.7 !cython -a B.py cython纯净模式福利--类型自动转换 C 类型 从pyhton中获得 返回到python中 [unsigned] char, [unsigned] short, int, long int int unsigned int, unsigned long, [unsigned] long long int int float, double, long double int, float float char* bytes bytes struct, union --- dict 除此之外同构定长列表/元组可以与c中数组自动转化 import cython @cython.locals(counts=cython.int[10], digit=cython.int) def count_digits(digits): \"\"\" >>> digits = '01112222333334445667788899' >>> count_digits(map(int, digits)) [1, 3, 4, 5, 3, 1, 2, 2, 3, 2] \"\"\" counts = [0] * 10 for digit in digits: assert 0 纯python文件扩展的局限性 这种方式的缺点在于: 语法不优雅,堆叠3个装饰器来装饰一个函数看起来很不美观 默认无法使用type hint,测试结果看cython解释器无法支持type hint,这个特性会在后续的版本中改善 使用.pxd申明要用的C/C++函数 使用上面这种方式有个很大的缺陷就是无法使用C/C++写好的函数,要让这个可行需要有一个.pxd文件用于声明用到的函数,并将其包装为cpdef的形式 %%writefile C.py #cython: language_level=3 import cython if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") from math import sin @cython.boundscheck(False) @cython.ccall @cython.returns(cython.int) @cython.locals(x=cython.int, y=cython.int,a = cython.int) def myfunction(x, y=2): a = x-y return a + x * y @cython.cfunc @cython.returns(cython.double) @cython.locals(a = cython.double) def _helper(a): return a + 1 @cython.returns(cython.double) @cython.locals(x=cython.double) def echo_sin(x): return sin(x) @cython.cclass class A: cython.declare(a=cython.int, b=cython.int) def __init__(self, b=0): self.a = 3 self.b = b @cython.ccall @cython.locals(x=cython.double) def foo(self, x): print(x + _helper(1.0)) Overwriting C.py %%writefile C.pxd #cython: language_level=3 cdef extern from \"math.h\": cpdef double sin(double x) Overwriting C.pxd import C Just a lowly interpreted script. %timeit C.echo_sin(3) The slowest run took 26.72 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 249 ns per loop %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from Cython.Distutils import build_ext setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(\"C.py\",language=\"c++\") ) Overwriting setup.py !python setup.py build_ext --inplace Please put \"# distutils: language=c++\" in your .pyx or .pxd file(s) Compiling C.py because it changed. [1/1] Cythonizing C.py running build_ext building 'C' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpC.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\C.obj C.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_C build\\temp.win-amd64-3.6\\Release\\C.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython纯净模式\\C.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\C.cp36-win_amd64.lib C.obj : warning LNK4197: export 'PyInit_C' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\C.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\C.cp36-win_amd64.exp Generating code Finished generating code import C Yep, I'm compiled. %timeit C.echo_sin(3) The slowest run took 51.80 times longer than the fastest. This could mean that an intermediate result is being cached. 10000000 loops, best of 3: 134 ns per loop 将所有申明迁移至.pxd文件 像上面这种写法已经引入了一个新的文件,既然如此为什么不把申明用的这些个装饰器都移到.pxd文件中增加可读性呢 下面是一个纯python源文件 %%writefile A.py import cython if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") from math import sin def myfunction(x, y=2): a = x-y return a + x * y def echo_sin(x): return sin(x) def _helper(a): return a + 1 class A: def __init__(self, b=0): self.a = 3 self.b = b def foo(self, x): print(x + _helper(1.0)) Overwriting A.py import A Just a lowly interpreted script. A.myfunction(10) 28 %timeit A.echo_sin(2.7) The slowest run took 25.54 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 225 ns per loop 使用.pxd为其申明 %%writefile A.pxd #cython: language_level=3 cdef extern from \"math.h\": cpdef double sin(double x) cpdef int myfunction(int x, int y=*) cdef double _helper(double a) cdef class A: cdef public int a,b cpdef foo(self, double x) Overwriting A.pxd 那么Cython将会将A.py编译成如下： cdef extern from \"math.h\": cpdef double sin(double x) cpdef int myfunction(int x, int y=2): a = x-y return a + x * y def double echo_sin(double x): return sin(x) cdef double _helper(double a): return a + 1 cdef class A: cdef public int a,b def __init__(self, b=0): self.a = 3 self.b = b cpdef foo(self, double x): print x + _helper(1.0) 注意: 使用*通配符可以将Python的参数默认值包装给.pxd中的定义，即可以从Python访问 cpdef int myfunction(int x, int y=*) 内部函数的C函数签名可以声明为cdef cdef double _helper(double a) cdef class用于申明扩展类型 如果属性有读取/写入Python访问权限，则cdef类属性必须声明为cdef public，cdef readonly为只读Python访问，或者是纯Cdef为内部C级属性 cdef class 中方法必须声明为 cpdef Python可见方法 cdef用于内部C方法 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from Cython.Distutils import build_ext setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(\"A.py\",language=\"c++\") ) Overwriting setup.py !python setup.py build_ext --inplace Please put \"# distutils: language=c++\" in your .pyx or .pxd file(s) Compiling A.py because it changed. [1/1] Cythonizing A.py running build_ext building 'A' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpA.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\A.obj A.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_A build\\temp.win-amd64-3.6\\Release\\A.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython纯净模式\\A.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\A.cp36-win_amd64.lib A.obj : warning LNK4197: export 'PyInit_A' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\A.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\A.cp36-win_amd64.exp Generating code Finished generating code import A Yep, I'm compiled. A.myfunction(12) 34 %timeit A.echo_sin(2.7) The slowest run took 90.59 times longer than the fastest. This could mean that an intermediate result is being cached. 10000000 loops, best of 3: 120 ns per loop 使用.pxd申明扩展纯python的局限性 使用.pxd扩展.py源文件的方式最大的缺点在于可维护性,一旦有改动那么无论.py和.pxd文件都得改动.而且因为使用cython语法定义.pxd文件,所以对于不会cython的用户很不友好. 另一局限性在于使用c/c++函数或者标准库时只能在.pxd文件下申明,因此必须在.py文件中判断是否被编译,而且必须实现一个同名的python对象来为纯python环境提供支持. 纯净模式的局限性 无论是否要使用.pxd申明文件,纯净模式都无法在实现上使用C++中STL容器和算法,也有很多cython语言特性无法实现. 使用typehits申明静态类型 在python3.5发布后,cython社区也提出了使用type hint来申明cython纯净模式的提议-- Python Typing Proposal.在0.27版本以后,cython已经完全支持这种静态类型申明的方式了.纯净模式代码可以比之前的优雅不少 %%writefile BB.py #cython: language_level=3 import cython if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") @cython.boundscheck(False) @cython.ccall def myfunction(x:cython.int, y:cython.int=2)->cython.int: a:cython.int a = x-y return a + x * y @cython.cfunc def _helper(a:cython.double)->cython.double: return a + 1 @cython.cclass class A: a:cython.int b:cython.int def __init__(self, b=0): self.a = 3 self.b = b @cython.ccall def foo(self, x:cython.double)->cython.double: print(x + _helper(1.0)) Overwriting BB.py import BB Just a lowly interpreted script. BB.myfunction(10) 28 a = BB.A() a.foo(2.7) 4.7 !cythonize -i -3 -a BB.py Compiling C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.py because it changed. [1/1] Cythonizing C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.py running build_ext building 'BB' extension creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87 creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能 creating C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式 C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ic:\\users\\87\\anaconda3\\include -Ic:\\users\\87\\anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /TcC:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.c /FoC:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.obj BB.c C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:c:\\users\\87\\anaconda3\\libs /LIBPATH:c:\\users\\87\\anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_BB C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.cp36-win_amd64.pyd /IMPLIB:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.cp36-win_amd64.lib BB.obj : warning LNK4197: export 'PyInit_BB' specified multiple times; using first specification Creating library C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.cp36-win_amd64.lib and object C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\tmpm5d7r9zk\\Release\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\使用Cython优化python程序的性能\\Cython纯净模式\\BB.cp36-win_amd64.exp Generating code Finished generating code import BB Yep, I'm compiled. BB.myfunction(10) 28 a = BB.A() a.foo(2.7) 4.7 0.0 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:58:41 "},"嵌入与扩展篇/使用Cython优化python程序的性能/Cython的包装模式.html":{"url":"嵌入与扩展篇/使用Cython优化python程序的性能/Cython的包装模式.html","title":"Cython的包装模式","keywords":"","body":"用Cython包装C++代码 Cython最大的作用其实是作为C/C++代码和python代码的桥梁,比如我们已经有一个C++写的程序了,但我们希望让python可以调用它,传统的做法是使用ctypes或者cffi作为桥,但这种方式需要有相当的C/C++知识.Cython的话基本可以无痛进行C++代码的包装,这是通过使用外部声明来声明库函数和要使用的库中的C函数来实现的. Cython现在原生的支持大多数的C++语法. 尤其是: 现在可以使用new和del关键字动态分配C++对象. C++对象可以进行堆栈分配 C++类可以使用新的关键字cppclass声明 支持模板化类和函数 支持重载函数 支持C++操作符(例如operator +,operator [],...)的重载 我们通过包装一个例子来看看cython是如何包装c/c++代码的 封装步骤 封装C/C++的步骤大致有如下几步: 在setup.py脚本中或在源文件中本地指定C ++语言。 使用cdef extern from 头文件创建一个或多个.pxd文件.在pxd文件中，以cdef cppclass来声明类并且声明公共名称(变量,方法和构造函数） 通过cimport引入pxd文件，进行pxd的实现代码，也就是.pyx文件。 最简单的一个例子 这个例子用来介绍Cython包装C/C++代码的步骤.例子是一个长方形类,C++代码部分如下: %load_ext Cython %%writefile Rectangle.h namespace shapes { class Rectangle { public: static int do_something(); int x0, y0, x1, y1; Rectangle(); Rectangle(int x0, int y0, int x1, int y1); ~Rectangle(); int getArea(); void getSize(int* width, int* height); void move(int dx, int dy); }; } Overwriting Rectangle.h %%writefile Rectangle.cpp #include \"Rectangle.h\" namespace shapes { Rectangle::Rectangle() { } int Rectangle::do_something(){ return 0; } Rectangle::Rectangle(int X0, int Y0, int X1, int Y1) { x0 = X0; y0 = Y0; x1 = X1; y1 = Y1; } Rectangle::~Rectangle() { } int Rectangle::getArea() { return (x1 - x0) * (y1 - y0); } void Rectangle::getSize(int *width, int *height) { (*width) = x1 - x0; (*height) = y1 - y0; } void Rectangle::move(int dx, int dy) { x0 += dx; y0 += dy; x1 += dx; y1 += dy; } } Overwriting Rectangle.cpp 用于包装的pyx文件 要包装C++文件,我们得先在cython中声明出这个C++的类,在cython中申明C或者C++的内容(接口)需要使用cdef extern from ....这种语法(外部声明). 在 %%writefile rect.pyx #cython: language_level=3 # distutils: language = c++ # distutils: sources = Rectangle.cpp cdef extern from \"Rectangle.h\" namespace \"shapes\": cdef cppclass Rectangle: Rectangle() except + Rectangle(int, int, int, int) except + int x0, y0, x1, y1 int getArea() void getSize(int* width, int* height) void move(int, int) @staticmethod int do_something() cdef class PyRectangle: cdef Rectangle c_rect # hold a C++ instance which we're wrapping def __cinit__(self, int x0, int y0, int x1, int y1): self.c_rect = Rectangle(x0, y0, x1, y1) def get_area(self): return self.c_rect.getArea() def get_size(self): cdef int width, height self.c_rect.getSize(&width, &height) return width, height def move(self, dx, dy): self.c_rect.move(dx, dy) @staticmethod def do_something(): return Rectangle.do_something() Overwriting rect.pyx 这样，我们就完成了C++的封装。而且从Python的开发角度来看，这个扩展类型看起来和感觉就像一个本地定义的Rectangle类。 需要注意的是，如果我们需要额外的属性设置方法，可以自己再添加. setup.py的写法 我们的setup.py和之前差不多的写法 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize setup( name = \"rectangleapp\", ext_modules = cythonize('*.pyx') ) Overwriting setup.py !python setup.py build_ext --inplace Compiling rect.pyx because it changed. [1/1] Cythonizing rect.pyx running build_ext building 'rect' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /Tprect.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\rect.obj rect.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpRectangle.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\Rectangle.obj Rectangle.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_rect build\\temp.win-amd64-3.6\\Release\\rect.obj build\\temp.win-amd64-3.6\\Release\\Rectangle.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的包装模式\\rect.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\rect.cp36-win_amd64.lib rect.obj : warning LNK4197: export 'PyInit_rect' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\rect.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\rect.cp36-win_amd64.exp Generating code Finished generating code import rect pyRect = rect.PyRectangle(100, 100, 300, 500) width, height = pyRect.get_size() print(\"size: width = %d, height = %d\" % (width, height)) size: width = 200, height = 400 pyRect.get_area() 80000 pyRect.do_something() 0 外部声明 默认情况下,在模块级声明的C函数和变量对模块是本地的(即它们具有C静态存储类).它们也可以声明为extern，以指定它们在其他位置定义，例如： cdef extern int spam_counter cdef extern void order_spam(int tons) Cython包装C/C++就是依赖这种外部申明 引用头文件 当你使用一个extern定义时，Cython在生成的C文件中包含一个声明.如果声明与其他C代码将看不到的声明不完全匹配，这可能会导致问题.例如，如果要封装现有的C库，那么生成的C代码必须与库的其余部分具有完全相同的声明. 为了实现这一点，你可以告诉Cython声明将在C头文件中找到，如下所示： cdef extern from \"spam.h\": int spam_counter void order_spam(int tons) 引用头文件用于引入C/C++中的声明,但我们依然需要手动将其中被声明的内容用cython语法重新写一遍,这样cython才可以识别. 这个cdef extern代码块定义了如下三件事情： 它指示Cython为生成的C代码中的命名头文件放置一个#include语句. 它阻止Cython为相关块中的声明生成任何C代码 它处理块中的所有声明，就像它们以cdef extern开头 重要的是要理解Cython本身不读取C头文件，所以你仍然需要提供Cython版本你要使用的声明.然而，Cython声明并不总是必须完全匹配C，在某些情况下，它们不应该或不能。尤其是： 不要使用任何平台特定的C语言扩展，例如__declspec() 如果头文件声明一个大结构，并且你只想使用几个成员，你只需要声明你感兴趣的成员.留下余下的没有任何危害，因为C编译器将使用头文件中的完整定义. 在某些情况下，你可能不需要任何struct的成员，在这种情况下，你可以只传递在struct声明的主体，例如： cdef extern from \"foo.h\": struct spam: pass 注意：你只能在一个cdef extern从块里面这样做;任何其他地方的struct声明必须是非空的。 如果头文件使用typedef名称（如word）来引用与平台相关的数值类型的风格，则需要一个相应的ctypedef语句，但不需要完全匹配类型,只是使用一些正确的一般类型(int，float等). 例如： ctypedef int word 将工作正常无论实际大小的单词是(提供的头文件正确定义它).与Python类型(如果有)之间的转换也将用于此新类型. 如果头文件使用宏来定义常量，则将它们转换为正常的外部变量声明。如果它们包含正常的int值，也可以将它们声明为枚举。请注意，Cython认为枚举等同于int，因此不要对非int值执行此操作. 如果头文件使用宏定义了一个函数，那么声明它就像是一个普通的函数，具有适当的参数和结果类型 如果你想包含一个C头，因为它是另一个头需要的，但不想使用它的任何声明，在extern-from块中放入pass关键字： cdef extern from \"spam.h\": pass 如果要包括系统标题，请在引号中加上尖括号： cdef extern from \"\": ... 如果你想包含一些外部声明，但不想指定一个头文件（因为它包含了你已经包含的其他头文件），你可以用*代替头文件名： cdef extern from *: ... 在C/C++中实现 另一种简单的写法是直接使用外部声明声明C/C++实现 %%writefile spam.c #include static int order_spam(int tons) { printf(\"Ordered %i tons of spam!\\n\", tons); return tons; } Overwriting spam.c %%writefile pyspam.pyx cdef extern from \"spam.c\": int order_spam(int tons) cpdef pyorder_spam(int tons): return order_spam(tons) Overwriting pyspam.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize setup( name = \"pyspam\", ext_modules = cythonize('pyspam.pyx') ) Overwriting setup.py !python setup.py build_ext --inplace Compiling pyspam.pyx because it changed. [1/1] Cythonizing pyspam.pyx running build_ext building 'pyspam' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /Tcpyspam.c /Fobuild\\temp.win-amd64-3.6\\Release\\pyspam.obj pyspam.c C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_pyspam build\\temp.win-amd64-3.6\\Release\\pyspam.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的包装模式\\pyspam.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\pyspam.cp36-win_amd64.lib pyspam.obj : warning LNK4197: export 'PyInit_pyspam' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\pyspam.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\pyspam.cp36-win_amd64.exp Generating code Finished generating code import pyspam pyspam.pyorder_spam(1) 1 需要注意的是这种方式函数必须是static 结构，联合和枚举声明的样式 在C头文件中可以使用两种主要方法来声明结构，联合和枚举： 使用标签名称 使用typedef 基于这些的各种组合也存在一些变化.重要的是使Cython声明与头文件中使用的样式相匹配,以便Cython能够对其生成的代码中的类型发出正确的引用. 为了实现这一点,Cython提供了两种不同的语法来声明结构,联合或枚举类型.上面介绍的样式对应于标签名的使用.要获得另一个样式,您需要在声明前面加上ctypedef,如下图所示. 下表显示了可以在头文件中找到的各种可能的样式，以及应该放在cdef extern from块中的相应Cython声明。用结构体声明作为例子;这同样适用于联合和枚举声明. 静态成员方法 如果开头我们定义的C++类Rectangle类具有静态成员,那么如上面的做法..就像python中一样,使用@staticmethod装饰器装饰对应的成员方法即可 运算符重载 这个例子是一个vector2d,实现了加和乘. %%writefile vector2d.h namespace algebra { class Vec2d { public: double x, y; Vec2d(); Vec2d(double x, double y); ~Vec2d(); Vec2d operator+(const Vec2d& b); Vec2d operator*(double k); }; } Overwriting vector2d.h %%writefile vector2d.cpp #include \"vector2d.h\" namespace algebra { Vec2d::Vec2d() { x=0; y=0; } Vec2d::Vec2d(double x, double y) { this->x = x; this->y = y; } Vec2d::~Vec2d() { } Vec2d Vec2d::operator+(const Vec2d& other){ Vec2d r = Vec2d(this->x+other.x,this->y+other.y); return r; } Vec2d Vec2d::operator*(double k){ Vec2d r = Vec2d(this->x*k,this->y*k); return r; } } Overwriting vector2d.cpp %%writefile vec2d_main.cpp #include \"vector2d.h\" #include using algebra::Vec2d; using std::cout; using std::endl; int main(){ Vec2d v1 = Vec2d(2.1,2.2); Vec2d v2 = Vec2d(2.3,2.4); Vec2d v3 = v1+v2; cout Overwriting vec2d_main.cpp !g++-7 -o a.out vec2d_main.cpp vector2d.cpp !./a.out 4.4 4.6 %%writefile vec2d.pyx #cython: language_level=3 # distutils: language = c++ # distutils: sources = vector2d.cpp cdef extern from \"vector2d.h\" namespace \"algebra\": cdef cppclass Vec2d: Vec2d() except + Vec2d(double, double) except + double x, y Vec2d operator+(Vec2d) Vec2d operator*(float) cdef class PyVec2d: cdef Vec2d c_vec2d # hold a C++ instance which we're wrapping def __cinit__(self, float x, float y): self.c_vec2d = Vec2d(x, y) @property def x(self): return self.c_vec2d.x @property def y(self): return self.c_vec2d.y cpdef add(self,PyVec2d other): cdef Vec2d c c = self.c_vec2d+other.c_vec2d return PyVec2d(c.x,c.y) cpdef mul(self,float k): cdef Vec2d c c = self.c_vec2d*k return PyVec2d(c.x,c.y) def __add__(self,PyVec2d other): return self.add(other) def __mul__(self,float k): return self.mul(k) Overwriting vec2d.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize setup( name = \"vec2dapp\", ext_modules = cythonize('vec2d.pyx') ) Overwriting setup.py !python setup.py build_ext --inplace Compiling vec2d.pyx because it changed. [1/1] Cythonizing vec2d.pyx running build_ext building 'vec2d' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /Tpvec2d.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\vec2d.obj vec2d.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /Tpvector2d.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\vector2d.obj vector2d.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_vec2d build\\temp.win-amd64-3.6\\Release\\vec2d.obj build\\temp.win-amd64-3.6\\Release\\vector2d.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的包装模式\\vec2d.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\vec2d.cp36-win_amd64.lib vec2d.obj : warning LNK4197: export 'PyInit_vec2d' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\vec2d.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\vec2d.cp36-win_amd64.exp Generating code Finished generating code import vec2d v1 = vec2d.PyVec2d(2.1,2.2) v2 = vec2d.PyVec2d(2.3,2.4) (v1+v2).x 4.399999618530273 模板 Cython使用括号语法进行模板化。下面是一个包装C ++ Vector的简单示例 %%cython #cython: language_level=3 # distutils: language = c++ # import dereference and increment operators from cython.operator cimport dereference as deref, preincrement as inc cdef extern from \"\" namespace \"std\": cdef cppclass vector[T]: cppclass iterator: T operator*() iterator operator++() bint operator==(iterator) bint operator!=(iterator) vector() void push_back(T&) T& operator[](int) T& at(int) iterator begin() iterator end() cdef vector[int] *v = new vector[int]() cdef int i for i in range(10): v.push_back(i) cdef vector[int].iterator it = v.begin() while it != v.end(): print(deref(it)) inc(it) del v 0 1 2 3 4 5 6 7 8 9 多个模板参数可以定义为列表，如[T，U，V]或[int，bool，char].可以通过写入[T，U，V = *]来指示可选的模板参数. 如果Cython需要显式引用不完整模板实例化的默认模板参数的类型,它将编写MyClass :: V，所以如果类为其模板参数提供了typedef，那么最好在这里使用该名称. 模板函数的定义与类模板类似，模板参数列表跟随函数名称： %%cython # cython: language_level=3 # distutils: language = c++ cdef extern from \"\" namespace \"std\": T max[T](T a, T b) print(max[long](3, 4)) print(max(1.5, 2.5)) # simple template argument deduction 4 2.5 使用默认构造函数简化包装 如果扩展类型使用默认构造函数(不传递任何参数)来实例化包装的C++类，则可以通过将其直接绑定到Python包装器对象的生命周期来简化生命周期处理。取代声明一个指针，我们可以声明一个实例 %%cython #cython: language_level=3 # distutils: language = c++ from libcpp.vector cimport vector cdef class VectorStack: cdef vector[int] v def push(self, x): self.v.push_back(x) def pop(self): if self.v.empty(): raise IndexError() x = self.v.back() self.v.pop_back() return x v = VectorStack() v.push(10) v.push(120) v.pop() 120 v.pop() 10 当Python对象被创建时，Cython将自动生成实例化C ++对象实例的代码，并在Python对象被垃圾回收时将其删除。 异常Exception处理 Cython不能抛出C++异常,或者使用try-except语句来捕获它们,但是有可能通过在声明函数时在其后加上except +来声明一个函数可能引发C++异常并将其转换为Python异常.例如长方体例子中的 Rectangle() except + Rectangle(int, int, int, int) except + 这将将try和C++错误翻译成适当的Python异常。根据下表执行翻译（C++标识符中省略了std ::前缀）： C++异常 Python异常 bad_alloc MemoryError bad_cast TypeError bad_typeid TypeError domain_error ValueError invalid_argument ValueError ios_base::failure IOError out_of_range IndexError overflow_error OverflowError range_error ArithmeticError underflow_error ArithmeticError (all others) RuntimeError 如果except +后面加上指定的python错误类型,则会将捕获到的C++异常转化为指定的python错误 cdef int bar() except +MemoryError 就会指定bar()函数报错后转化为MemoryError 同时也可以通过实现一个函数来指定捕获的错误转化为何种python异常 cdef int raise_py_error() cdef int something_dangerous() except +raise_py_error 如果有不可预知的错误代码引发了一个C++异常，那么raise_py_error将被调用，这允许一个人自定义C++到Python的错误“translations”.如果raise_py_error实际上并不引发一个异常，则会引发一个RuntimeError. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:58:52 "},"嵌入与扩展篇/使用Cython优化python程序的性能/使用Cython扩展numpy.html":{"url":"嵌入与扩展篇/使用Cython优化python程序的性能/使用Cython扩展numpy.html","title":"使用Cython扩展numpy","keywords":"","body":"使用Cython扩展numpy 下面的代码将图像与滤镜进行二维离散卷积.它是有效的Python和有效的Cython代码.我将其称为Python版本的convolve_py.py和Cython版本的convolve1.pyx %%writefile convolve_py.py import numpy as np def naive_convolve(f, g): # f is an image and is indexed by (v, w) # g is a filter kernel and is indexed by (s, t), # it needs odd dimensions # h is the output image and is indexed by (x, y), # it is not cropped if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1: raise ValueError(\"Only odd dimensions on filter supported\") # smid and tmid are number of pixels between the center pixel # and the edge, ie for a 5x5 filter they will be 2. # # The output size is calculated by adding smid, tmid to each # side of the dimensions of the input image. vmax = f.shape[0] wmax = f.shape[1] smax = g.shape[0] tmax = g.shape[1] smid = smax // 2 tmid = tmax // 2 xmax = vmax + 2*smid ymax = wmax + 2*tmid # Allocate result image. h = np.zeros([xmax, ymax], dtype=f.dtype) # Do convolution for x in range(xmax): for y in range(ymax): # Calculate pixel value for h at (x,y). Sum one component # for each pixel (s, t) of the filter g. s_from = max(smid - x, -smid) s_to = min((xmax - x) - smid, smid + 1) t_from = max(tmid - y, -tmid) t_to = min((ymax - y) - tmid, tmid + 1) value = 0 for s in range(s_from, s_to): for t in range(t_from, t_to): v = x - smid + s w = y - tmid + t value += g[smid - s, tmid - t] * f[v, w] h[x, y] = value return h Overwriting convolve_py.py import numpy as np N = 100 f = np.arange(N*N, dtype=np.int).reshape((N,N)) g = np.arange(81, dtype=np.int).reshape((9, 9)) from convolve_py import naive_convolve naive_convolve(f,g) array([[ 0, 0, 1, ..., 2056, 1477, 792], [ 0, 109, 329, ..., 8858, 6227, 3275], [ 900, 2127, 3684, ..., 23106, 16050, 8349], ..., [1850400, 3730389, 5639970, ..., 6230334, 4183464, 2106687], [1329300, 2678435, 4047407, ..., 4445402, 2983649, 1501849], [ 712800, 1435572, 2168317, ..., 2369524, 1589761, 799920]]) %timeit -n10 naive_convolve(f,g) 436 ms ± 12.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) 使用cython编译带numpy的代码需要在setup.py中指定include_dirs=[numpy.get_include()] 第一版迭代--使用cython编译以提高性能 代码不用改,直接编译以提高性能 %%writefile convolve1.pyx import numpy as np def naive_convolve_1(f, g): # f is an image and is indexed by (v, w) # g is a filter kernel and is indexed by (s, t), # it needs odd dimensions # h is the output image and is indexed by (x, y), # it is not cropped if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1: raise ValueError(\"Only odd dimensions on filter supported\") # smid and tmid are number of pixels between the center pixel # and the edge, ie for a 5x5 filter they will be 2. # # The output size is calculated by adding smid, tmid to each # side of the dimensions of the input image. vmax = f.shape[0] wmax = f.shape[1] smax = g.shape[0] tmax = g.shape[1] smid = smax // 2 tmid = tmax // 2 xmax = vmax + 2*smid ymax = wmax + 2*tmid # Allocate result image. h = np.zeros([xmax, ymax], dtype=f.dtype) # Do convolution for x in range(xmax): for y in range(ymax): # Calculate pixel value for h at (x,y). Sum one component # for each pixel (s, t) of the filter g. s_from = max(smid - x, -smid) s_to = min((xmax - x) - smid, smid + 1) t_from = max(tmid - y, -tmid) t_to = min((ymax - y) - tmid, tmid + 1) value = 0 for s in range(s_from, s_to): for t in range(t_from, t_to): v = x - smid + s w = y - tmid + t value += g[smid - s, tmid - t] * f[v, w] h[x, y] = value return h Overwriting convolve1.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from distutils.extension import Extension from Cython.Distutils import build_ext import numpy extension = Extension( \"convolve1\", sources=[\"convolve1.pyx\"], include_dirs=[numpy.get_include()], # 如果用到numpy language=\"c++\" ) setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(extension), ) Overwriting setup.py !python setup.py build_ext --inplace Compiling convolve1.pyx because it changed. [1/1] Cythonizing convolve1.pyx running build_ext building 'convolve1' extension gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/Users/huangsizhe/anaconda3/include/python3.6m -c convolve1.cpp -o build/temp.macosx-10.7-x86_64-3.6/convolve1.o \u001b[1mconvolve1.cpp:3172:26: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mcode will never be executed [-Wunreachable-code]\u001b[0m module = PyImport_ImportModuleLevelObject( \u001b[0;1;32m ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \u001b[0m1 warning generated. g++ -bundle -undefined dynamic_lookup -L/Users/huangsizhe/anaconda3/lib -arch x86_64 -L/Users/huangsizhe/anaconda3/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.7-x86_64-3.6/convolve1.o -o /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/嵌入与扩展篇/使用Cython优化python程序的性能/使用Cython扩展numpy/convolve1.cpython-36m-darwin.so clang: \u001b[0;1;35mwarning: \u001b[0mlibstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]\u001b[0m from convolve1 import naive_convolve_1 naive_convolve_1(f,g) array([[ 0, 0, 1, ..., 2056, 1477, 792], [ 0, 109, 329, ..., 8858, 6227, 3275], [ 900, 2127, 3684, ..., 23106, 16050, 8349], ..., [1850400, 3730389, 5639970, ..., 6230334, 4183464, 2106687], [1329300, 2678435, 4047407, ..., 4445402, 2983649, 1501849], [ 712800, 1435572, 2168317, ..., 2369524, 1589761, 799920]]) %timeit -n10 naive_convolve_1(f,g) 338 ms ± 13.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) 第一版什么也不改就可以提高1/4的性能 第二版迭代--静态化参数 将函数的参数以及中间变量都申明为静态类型以提高运行效率 %%writefile convolve2.pyx import numpy as np##必须为c类型和python类型的数据都申明一个np cimport numpy as np DTYPE = np.int ctypedef np.int_t DTYPE_t # 参数静态化 def naive_convolve_2(np.ndarray f, np.ndarray g): if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1: raise ValueError(\"Only odd dimensions on filter supported\") assert f.dtype == DTYPE and g.dtype == DTYPE #将中间变量都静态化 cdef int vmax = f.shape[0] cdef int wmax = f.shape[1] cdef int smax = g.shape[0] cdef int tmax = g.shape[1] cdef int smid = smax // 2 cdef int tmid = tmax // 2 cdef int xmax = vmax + 2*smid cdef int ymax = wmax + 2*tmid cdef np.ndarray h = np.zeros([xmax, ymax], dtype=DTYPE) cdef int x, y, s, t, v, w cdef int s_from, s_to, t_from, t_to cdef DTYPE_t value for x in range(xmax): for y in range(ymax): s_from = max(smid - x, -smid) s_to = min((xmax - x) - smid, smid + 1) t_from = max(tmid - y, -tmid) t_to = min((ymax - y) - tmid, tmid + 1) value = 0 for s in range(s_from, s_to): for t in range(t_from, t_to): v = x - smid + s w = y - tmid + t value += g[smid - s, tmid - t] * f[v, w] h[x, y] = value return h Writing convolve2.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from distutils.extension import Extension from Cython.Distutils import build_ext import numpy extension = Extension( \"convolve2\", sources=[\"convolve2.pyx\"], include_dirs=[numpy.get_include()], # 如果用到numpy language=\"c++\" ) setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(extension), ) Overwriting setup.py !python setup.py build_ext --inplace Compiling convolve2.pyx because it changed. [1/1] Cythonizing convolve2.pyx running build_ext building 'convolve2' extension gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/Users/huangsizhe/anaconda3/include/python3.6m -c convolve2.cpp -o build/temp.macosx-10.7-x86_64-3.6/convolve2.o In file included from convolve2.cpp:559: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: \u001b[1m/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001b[0m #warning \"Using deprecated NumPy API, disable it by \" \\ \u001b[0;1;32m ^ \u001b[0m\u001b[1mconvolve2.cpp:5845:26: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mcode will never be executed [-Wunreachable-code]\u001b[0m module = PyImport_ImportModuleLevelObject( \u001b[0;1;32m ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \u001b[0m2 warnings generated. g++ -bundle -undefined dynamic_lookup -L/Users/huangsizhe/anaconda3/lib -arch x86_64 -L/Users/huangsizhe/anaconda3/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.7-x86_64-3.6/convolve2.o -o /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/嵌入与扩展篇/使用Cython优化python程序的性能/使用Cython扩展numpy/convolve2.cpython-36m-darwin.so clang: \u001b[0;1;35mwarning: \u001b[0mlibstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]\u001b[0m from convolve2 import naive_convolve_2 naive_convolve_2(f,g) array([[ 0, 0, 1, ..., 2056, 1477, 792], [ 0, 109, 329, ..., 8858, 6227, 3275], [ 900, 2127, 3684, ..., 23106, 16050, 8349], ..., [1850400, 3730389, 5639970, ..., 6230334, 4183464, 2106687], [1329300, 2678435, 4047407, ..., 4445402, 2983649, 1501849], [ 712800, 1435572, 2168317, ..., 2369524, 1589761, 799920]]) %timeit -n10 naive_convolve_2(f,g) 330 ms ± 3.67 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) 第三版迭代--“缓冲”语法 提高np数组的效率,我们用一个特殊的“缓冲”语法来做到这一点，它必须告诉数据类型（第一个参数）和维数（“ndim”仅关键字参数，如果不提供，则假定一维 %%writefile convolve3.pyx import numpy as np##必须为c类型和python类型的数据都申明一个np cimport numpy as np DTYPE = np.int ctypedef np.int_t DTYPE_t # “缓冲”语法 def naive_convolve_3(np.ndarray[DTYPE_t, ndim=2] f, np.ndarray[DTYPE_t, ndim=2] g): if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1: raise ValueError(\"Only odd dimensions on filter supported\") assert f.dtype == DTYPE and g.dtype == DTYPE cdef int vmax = f.shape[0] cdef int wmax = f.shape[1] cdef int smax = g.shape[0] cdef int tmax = g.shape[1] cdef int smid = smax // 2 cdef int tmid = tmax // 2 cdef int xmax = vmax + 2*smid cdef int ymax = wmax + 2*tmid # “缓冲”语法 cdef np.ndarray[DTYPE_t, ndim=2] h = np.zeros([xmax, ymax], dtype=DTYPE) cdef int x, y, s, t, v, w cdef int s_from, s_to, t_from, t_to cdef DTYPE_t value for x in range(xmax): for y in range(ymax): s_from = max(smid - x, -smid) s_to = min((xmax - x) - smid, smid + 1) t_from = max(tmid - y, -tmid) t_to = min((ymax - y) - tmid, tmid + 1) value = 0 for s in range(s_from, s_to): for t in range(t_from, t_to): v = x - smid + s w = y - tmid + t value += g[smid - s, tmid - t] * f[v, w] h[x, y] = value return h Writing convolve3.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from distutils.extension import Extension from Cython.Distutils import build_ext import numpy extension = Extension( \"convolve3\", sources=[\"convolve3.pyx\"], include_dirs=[numpy.get_include()], # 如果用到numpy language=\"c++\" ) setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(extension), ) Overwriting setup.py !python setup.py build_ext --inplace Compiling convolve3.pyx because it changed. [1/1] Cythonizing convolve3.pyx running build_ext building 'convolve3' extension gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/Users/huangsizhe/anaconda3/include/python3.6m -c convolve3.cpp -o build/temp.macosx-10.7-x86_64-3.6/convolve3.o In file included from convolve3.cpp:559: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: \u001b[1m/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001b[0m #warning \"Using deprecated NumPy API, disable it by \" \\ \u001b[0;1;32m ^ \u001b[0m\u001b[1mconvolve3.cpp:6531:26: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mcode will never be executed [-Wunreachable-code]\u001b[0m module = PyImport_ImportModuleLevelObject( \u001b[0;1;32m ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \u001b[0m2 warnings generated. g++ -bundle -undefined dynamic_lookup -L/Users/huangsizhe/anaconda3/lib -arch x86_64 -L/Users/huangsizhe/anaconda3/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.7-x86_64-3.6/convolve3.o -o /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/嵌入与扩展篇/使用Cython优化python程序的性能/使用Cython扩展numpy/convolve3.cpython-36m-darwin.so clang: \u001b[0;1;35mwarning: \u001b[0mlibstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]\u001b[0m from convolve3 import naive_convolve_3 naive_convolve_3(f,g) array([[ 0, 0, 1, ..., 2056, 1477, 792], [ 0, 109, 329, ..., 8858, 6227, 3275], [ 900, 2127, 3684, ..., 23106, 16050, 8349], ..., [1850400, 3730389, 5639970, ..., 6230334, 4183464, 2106687], [1329300, 2678435, 4047407, ..., 4445402, 2983649, 1501849], [ 712800, 1435572, 2168317, ..., 2369524, 1589761, 799920]]) %timeit -n10 naive_convolve_3(f,g) 1.86 ms ± 289 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) 提高了150倍的性能 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-28 21:36:29 "},"嵌入与扩展篇/用numba为python写高性能C扩展.html":{"url":"嵌入与扩展篇/用numba为python写高性能C扩展.html","title":"用numba为python写高性能C扩展","keywords":"","body":"*用numba为python写高性能C扩展 numba是利用llvm加速python的技术,虽然现在还在开发中,但已经基本可用了 numba有代码预热,如果迭代太少反而会减低效率 from numba import jit,int64,int32,float32,float64 基本用法:装饰符@jit 使用装饰符@jit可以延迟编译并进行优化 def f_org(x, y): # A somewhat trivial example return x + y from numba import jit @jit def f(x, y): # A somewhat trivial example return x + y f(1,2) 3 f(1j, 2) (2+1j) 使用@jit标注类型快速编译 @jit(int32(int32, int32)) def fint(x, y): # A somewhat trivial example return x + y fint(1,2) 3 fint(1j,2) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 fint(1j,2) ~/anaconda3/lib/python3.6/site-packages/numba/dispatcher.py in _explain_matching_error(self, *args, **kws) 397 msg = (\"No matching definition for argument type(s) %s\" 398 % ', '.join(map(str, args))) --> 399 raise TypeError(msg) 400 401 def _search_new_conversions(self, *args, **kws): TypeError: No matching definition for argument type(s) complex128, int64 numba必须为用到的所有函数加上@jit,否则会拖慢运算 import math @jit def square(x): return x ** 2 @jit def hypot(x, y): return math.sqrt(square(x) + square(y)) hypot(1,2) 2.23606797749979 我们来看看加速的效果怎么样 import time from numpy import random from numba import double from numba.decorators import jit as jit def sum2d(arr): M, N = arr.shape result = 0.0 for i in range(M): for j in range(N): result += arr[i,j] return result jitsum2d = jit(sum2d) csum2d = jitsum2d.compile(double(double[:,::1])) arr = random.randn(100, 100) start = time.time() res = sum2d(arr) duration = time.time() - start print(\"Result from python is %s in %s (msec)\" % (res, duration*1000)) csum2d(arr) # warm up start = time.time() res = csum2d(arr) duration2 = time.time() - start print(\"Result from compiled is %s in %s (msec)\" % (res, duration2*1000)) print(\"Speed up is %s\" % (duration / duration2)) Result from python is -68.045336031 in 2.89607048035 (msec) Result from compiled is -68.045336031 in 0.118970870972 (msec) Speed up is 24.3426853707 使用@generated_jit()编译时控制特殊化选项 虽然jit()装饰器在许多情况下是有用的，有时你想编写一个具有不同实现取决于其输入类型的函数。 generated_jit（）装饰器允许用户在编译时控制特殊化的选择，同时充满保留JIT函数的运行时执行速度。 假设你想编写一个函数，该函数根据某些约定返回一个给定值是否是一个\"丢失\"值。为了举例，让我们采用以下定义： 对于浮点参数，缺少的值是NaN Numpy datetime64和timedelta64参数，缺少的值是NaT 其他类型没有缺少值的概念。 编译时逻辑很容易使用generated_jit()装饰器实现： import numpy as np from numba import generated_jit, types @generated_jit(nopython=True) def is_missing(x): \"\"\" Return True if the value is missing, False otherwise. \"\"\" if isinstance(x, types.Float): return lambda x: np.isnan(x) elif isinstance(x, (types.NPDatetime, types.NPTimedelta)): # The corresponding Not-a-Time value missing = x('NaT') return lambda x: x == missing else: return lambda x: False 这里有几点要注意： 装饰函数使用参数的Numba类型调用，而不是它们的值。 装饰函数实际上不计算结果，它返回一个可调用的实现给定类型的函数的实际定义。 可以在编译时预先计算一些数据（上面缺少的变量），以便在编译的实现中重用它们。 函数定义使用与修饰函数中的参数相同的名称，这是必需的，以确保通过名称传递参数按预期工作。 编译可选项 除了基本用法,@jit()和@generated_jit()还可以带上一些参数 nopython 这个关键字表示编译时不使用python的对象,这是一种不太安全的编译方式,容易报错 @jit(nopython=True) def f_nopython(x, y): return x + y f_nopython(1,2) 3 nogil 我们知道python受gil限制,使用这个参数可以突破限制,但用了这个就相当于也用了nopython=True,但要注意解决线程冲突等问题. @jit(nogil=True) def f(x, y): return x + y import threading from timeit import repeat import numpy as np from numba import jit nthreads = 4 size = 1e6 def func_np(a, b): \"\"\" Control function using Numpy. \"\"\" return np.exp(2.1 * a + 3.2 * b) @jit('void(double[:], double[:], double[:])', nopython=True, nogil=True) def inner_func_nb(result, a, b): \"\"\" Function under test. \"\"\" for i in range(len(result)): result[i] = math.exp(2.1 * a[i] + 3.2 * b[i]) def timefunc(correct, s, func, *args, **kwargs): \"\"\" Benchmark *func* and print out its runtime. \"\"\" print(s.ljust(20)) # Make sure the function is compiled before we start the benchmark res = func(*args, **kwargs) if correct is not None: assert np.allclose(res, correct), (res, correct) # time it print('{:>5.0f} ms'.format(min(repeat(lambda: func(*args, **kwargs), number=5, repeat=2)) * 1000)) return res def make_singlethread(inner_func): \"\"\" Run the given function inside a single thread. \"\"\" def func(*args): length = len(args[0]) result = np.empty(length, dtype=np.float64) inner_func(result, *args) return result return func def make_multithread(inner_func, numthreads): \"\"\" Run the given function inside *numthreads* threads, splitting its arguments into equal-sized chunks. \"\"\" def func_mt(*args): length = len(args[0]) result = np.empty(length, dtype=np.float64) args = (result,) + args chunklen = (length + numthreads - 1) // numthreads # Create argument tuples for each input chunk chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args] for i in range(numthreads)] # Spawn one thread per chunk threads = [threading.Thread(target=inner_func, args=chunk) for chunk in chunks] for thread in threads: thread.start() for thread in threads: thread.join() return result return func_mt func_nb = make_singlethread(inner_func_nb) func_nb_mt = make_multithread(inner_func_nb, nthreads) a = np.random.rand(size) b = np.random.rand(size) correct = timefunc(None, \"numpy (1 thread)\", func_np, a, b) timefunc(correct, \"numba (1 thread)\", func_nb, a, b) timefunc(correct, \"numba (%d threads)\" % nthreads, func_nb_mt, a, b) /Users/huangsizhe/LIB/CONDA/anaconda/envs/py2/lib/python2.7/site-packages/ipykernel/__main__.py:76: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future /Users/huangsizhe/LIB/CONDA/anaconda/envs/py2/lib/python2.7/site-packages/ipykernel/__main__.py:77: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future numpy (1 thread) 118 ms numba (1 thread) 83 ms numba (4 threads) 46 ms array([ 90.34046635, 1.79903916, 33.98849279, ..., 9.11325173, 21.48394079, 11.4777402 ]) cache 我们也可以使用缓存来提高运行效率 @jit(cache=True) def f_cache(x, y): return x + y f_cache(1,2) 3 使用@jitclass编译python的类 这个装饰器比较新,目前容易出错.但用法应该不会有大变化,class可以静态编译的话还是相当可以 import numpy as np from numba import jitclass # import the decorator from numba import int32, float32 # import the types spec = [ ('value', int32), # a simple scalar field ('array', float32[:]), # an array field ] @jitclass(spec) class Bag(object): def __init__(self, value): self.value = value self.array = np.zeros(value, dtype=np.float32) @property def size(self): return self.array.size def increment(self, val): for i in range(self.size): self.array[i] = val return self.array mybag = Bag(21) print('isinstance(mybag, Bag)', isinstance(mybag, Bag)) print('mybag.value', mybag.value) print('mybag.array', mybag.array) print('mybag.size', mybag.size) print('mybag.increment(3)', mybag.increment(3)) print('mybag.increment(6)', mybag.increment(6)) ('isinstance(mybag, Bag)', True) ('mybag.value', 21) ('mybag.array', array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)) ('mybag.size', 21) ('mybag.increment(3)', array([ 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.], dtype=float32)) ('mybag.increment(6)', array([ 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.], dtype=float32)) 限制 一个jitclass类对象在numba编译函数中被当作一个函数（构造函数）。 isinstance()只在解释器中工作。但在解释器中操作jitclass实例尚未优化。 jitclasses目前仅在CPU上可用。 使用@vectorize和@guvectorize构建numpy的universal function vectorize(向量化计算)是指是一种特殊的并行计算的方式，相比于一般程序在同一时间只执行一个操作的方式，它可以在同一时间执行多次操作，通常是对不同的数据执行同样的一个或一批指令，或者说把指令应用于一个数组/向量。 python的numpy包以向量化作为其计算的基本特点.而@vectorize就是将函数作为向量化工具的装饰器 目前,vectorize装饰器支持编译后被下面的目标使用: Target Description cpu Single-threaded CPU parallel Multi-core CPU cuda CUDA GPU vectorize() 我们可以这样定义一个操作 from numba import vectorize, float64 @vectorize([float64(float64, float64)]) def f_u(x, y): return x + y 但这样就限制了通共性,我们可以这样写提高他的通用性 @vectorize([int32(int32, int32), int64(int64, int64), float32(float32, float32), float64(float64, float64)]) def f_u(x, y): return x + y a = np.arange(6) f_u(a, a) array([ 0, 2, 4, 6, 8, 10]) a = np.linspace(0, 1, 6) f_u(a, a) array([ 0. , 0.4, 0.8, 1.2, 1.6, 2. ]) a = np.linspace(0, 1+1j, 6) f_u(a, a) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 f_u(a, a) TypeError: ufunc 'f_u' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'' a = np.arange(12).reshape(3, 4) a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) f_u.reduce(a, axis=0) array([12, 15, 18, 21]) f_u.reduce(a, axis=1) array([ 6, 22, 38]) f_u.accumulate(a) array([[ 0, 1, 2, 3], [ 4, 6, 8, 10], [12, 15, 18, 21]]) f_u.accumulate(a, axis=1) array([[ 0, 1, 3, 6], [ 4, 9, 15, 22], [ 8, 17, 27, 38]]) guvectorize() vectorize()允许你编写一次在一个元素上工作的ufuncs 而guvectorize()装饰器将这个概念进一步提升一步，允许你编写ufuncs来处理输入为任意数量的元素的数组，并返回不同尺寸的阵列。典型的例子是运行中值或卷积滤波器。与vectorize()函数相反，guvectorize()函数不返回它们的结果值：它们将它作为数组参数，它必须由函数填充。这是因为数组实际上是由NumPy的dispa分配的 from numba import vectorize,guvectorize @guvectorize([(int64[:], int64[:], int64[:])], '(n),()->(n)') def g(x, y, res): for i in range(x.shape[0]): res[i] = x[i] + y[0] a = np.arange(5) print(g(a, 2)) [2 3 4 5 6] b = np.arange(6).reshape(2, 3) print(g(b, 10)) print(g(b, np.array([10, 20]))) [[10 11 12] [13 14 15]] [[10 11 12] [23 24 25]] Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 14:52:29 "},"嵌入与扩展篇/使用f2py用fortain给python写扩展.html":{"url":"嵌入与扩展篇/使用f2py用fortain给python写扩展.html","title":"使用f2py用fortain给python写扩展","keywords":"","body":"使用f2py用fortain给python写扩展 numpy许多算法实现是使用Fortran,f2py就是numpy中用于将Fortran代码编译为python可以使用的动态链接库的工具. 本文主要介绍如何使用f2py编译Fortran代码,使python可以调用. 是否有必要用Fortran写扩展 这个要看应用的领域,Fortran是专为计算设计的编程语言,多维数组是内置的数据类型,可以说在向量计算矩阵计算上它有天然的优势,而且语法相比C语言更加接近python,也没有复杂的语法和底层概念,用它写扩展可以专注于算法.因此如果一个模块完全是做计算的,那它就很适合用这门语言写扩展. 但同时它的劣势也就在于太过小众,如果一个人已经回C/C++,甚至不用是精通,他往往也没有动力再学一门新语言.同时Fortran除了写计算逻辑优秀以外几乎可以说一无是处.也没什么现代的编程技巧,因此除非是用作写算法模块,否则确实不值得专门学个这. 那为啥还要写这一节? 因为科学计算是python最重要的应用领域,几乎没有之一;数学家,物理学家往往都不关心怎么编程,只关心算法本身.如果是年级大点的数学家,物理学家,几乎都学过Fortran,而年轻的可能没学过,但Fortran好上手的特性非常适合作为第一门高性能计算编程语言.因此这个需求和这个用户群体非常契合.这就值得介绍一下了. 简单fortain语法 相对比价现代,支持面又比较广的是fortran95标准.其基本特点是: 完整的结构化和模块化 矩阵运算支持 简单的子程序接口,方便传递矩阵 功能强大而简单的Namelist输入输出 对并行计算提供特别支持 编译代码执行效率高 内置函数较少 基本规则 大小写不敏感 自由格式 &为换行连写 !为注释语句 程序中任何地方用stop可推出程序 建议每个域(program、module、function、 subrouting)第一行都写implicit none 使用f2py编译fortran的pyton扩展 此处给出一个简单的求平方和的例子用于演示demo.f95: subroutine sum_of_square(x, y, n) implicit none integer, intent(in) :: n integer :: i real(kind=8), intent(in) :: x(n) real(kind=8), intent(out) :: y y = 0 do i=1, n y = y + x(i)**2 end do end 使用命令f2py -c -m file_path就可以很简单的将其编译为python模块 !f2py -c -m demo demo.f95 --quiet In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpqavw1pmi/src.macosx-10.7-x86_64-3.6/demomodule.c:16: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpqavw1pmi/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpqavw1pmi/src.macosx-10.7-x86_64-3.6/demomodule.c:109:12: warning: unused function 'f2py_size' [-Wunused-function] static int f2py_size(PyArrayObject* var, ...) ^ 2 warnings generated. In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpqavw1pmi/src.macosx-10.7-x86_64-3.6/fortranobject.c:2: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpqavw1pmi/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpqavw1pmi/src.macosx-10.7-x86_64-3.6/fortranobject.c:138:18: warning: comparison of integers of different signs: 'Py_ssize_t' (aka 'long') and 'unsigned long' [-Wsign-compare] if (size from demo import sum_of_square sum_of_square([1,2,3,4]) 30.0 在python解释器中调用编译工具 如果有需要在python环境中编译Fortran代码,那需要使用numpy中的f2py子模块 编译Fortran代码需要使用f2py.compile(source, modulename='untitled', extra_args='', verbose=1, source_fn=None,extension=\".f\")方法, from numpy import f2py with open(\"demo.f95\",\"rb\") as f: source = f.read() f2py.compile(source, modulename='demo1',extension='.f95') running build running config_cc unifing config_cc, config, build_clib, build_ext, build commands --compiler options running config_fc unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options running build_src build_src building extension \"demo1\" sources f2py options: [] f2py:> /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 Reading fortran codes... Reading file '/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpwef1g0pz.f95' (format:free) Post-processing... Block: demo1 Block: sum_of_square Post-processing (stage 2)... Building modules... Building module \"demo1\"... Constructing wrapper function \"sum_of_square\"... y = sum_of_square(x,[n]) Wrote C/API module \"demo1\" to file \"/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c\" adding '/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c' to sources. adding '/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6' to include_dirs. copying /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/f2py/src/fortranobject.c -> /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 copying /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/f2py/src/fortranobject.h -> /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 build_src: building npy-pkg config files running build_ext customize UnixCCompiler customize UnixCCompiler using build_ext get_default_fcompiler: matching types: '['gnu95', 'nag', 'absoft', 'ibm', 'intel', 'gnu', 'g95', 'pg']' customize Gnu95FCompiler Found executable /usr/local/bin/gfortran customize Gnu95FCompiler customize Gnu95FCompiler using build_ext building 'demo1' extension compiling C sources C compiler: gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/include -arch x86_64 creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62 creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 compile options: '-I/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 -I/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/Users/huangsizhe/anaconda3/include/python3.6m -c' gcc: /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c:16: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c:109:12: warning: unused function 'f2py_size' [-Wunused-function] static int f2py_size(PyArrayObject* var, ...) ^ 2 warnings generated. gcc: /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c:2: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c:138:18: warning: comparison of integers of different signs: 'Py_ssize_t' (aka 'long') and 'unsigned long' [-Wsign-compare] if (size /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 Reading fortran codes... Reading file '/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpwef1g0pz.f95' (format:free) Post-processing... Block: demo1 Block: sum_of_square Post-processing (stage 2)... Building modules... Building module \"demo1\"... Constructing wrapper function \"sum_of_square\"... y = sum_of_square(x,[n]) Wrote C/API module \"demo1\" to file \"/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c\" adding '/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c' to sources. adding '/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6' to include_dirs. copying /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/f2py/src/fortranobject.c -> /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 copying /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/f2py/src/fortranobject.h -> /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 build_src: building npy-pkg config files running build_ext customize UnixCCompiler customize UnixCCompiler using build_ext get_default_fcompiler: matching types: '['gnu95', 'nag', 'absoft', 'ibm', 'intel', 'gnu', 'g95', 'pg']' customize Gnu95FCompiler Found executable /usr/local/bin/gfortran customize Gnu95FCompiler customize Gnu95FCompiler using build_ext building 'demo1' extension compiling C sources C compiler: gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/huangsizhe/anaconda3/include -arch x86_64 -I/Users/huangsizhe/anaconda3/include -arch x86_64 creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62 creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t creating /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 compile options: '-I/var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6 -I/Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include -I/Users/huangsizhe/anaconda3/include/python3.6m -c' gcc: /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c:16: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/demo1module.c:109:12: warning: unused function 'f2py_size' [-Wunused-function] static int f2py_size(PyArrayObject* var, ...) ^ 2 warnings generated. gcc: /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c:2: In file included from /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.h:13: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18: In file included from /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1816: /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings] #warning \"Using deprecated NumPy API, disable it by \" \\ ^ /var/folders/62/pwdyzlx51_j_3_0lr8zxzbx00000gn/T/tmpx4bqux1t/src.macosx-10.7-x86_64-3.6/fortranobject.c:138:18: warning: comparison of integers of different signs: 'Py_ssize_t' (aka 'long') and 'unsigned long' [-Wsign-compare] if (size from demo1 import sum_of_square sum_of_square([1,2,3,4]) 30.0 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-14 11:12:21 "},"基础应用篇/":{"url":"基础应用篇/","title":"基础应用篇","keywords":"","body":"基础应用 python结合标准库以及一些其他工具已经可以完成绝大多是的工作.本篇介绍使用python完成一些几乎在所有的应用,软件或服务中都会用到的基本功能.比如 国际化 让不同文化不同地理位置的用户都可以使用你写的服务 信息安全 通过数字签名以及加密等方式保证信息只被设计为希望其可以看懂的人看懂 压缩与归档 时间换空间,提高你的服务或数据的磁盘利用效率 数据库连接 连接数据库为你的应用或服务保存信息 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:20:15 "},"基础应用篇/国际化/":{"url":"基础应用篇/国际化/","title":"国际化","keywords":"","body":"国际化工具 国际化(internationalization)是设计和制造容易适应不同区域要求的产品的一种方式. 它要求从产品中抽离所有地域语言,国家/地区和文化相关的元素.换言之,应用程序的功能和代码设计考虑在 不同地区运行的需要,其代码简化了不同本地版本的生产.开发这样的程序的过程,就称为国际化. python标准库提供了针对文本翻译和时间的工具gettext,time,datetime和calendar 针对货币国际化的工具则可以使用money模块 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:03:40 "},"基础应用篇/国际化/字符编码判断.html":{"url":"基础应用篇/国际化/字符编码判断.html","title":"字符编码判断","keywords":"","body":"字符编码判断 计算机字符编码最初最原始的编码就是广为人知ascii编码了,不过它只能表示数字和英文字母和一些标点符号,数量非常有限,后来各个国家各种语言设定了各自的编码方式来对应自己的语言文字,而现在广泛使用utf-8或者utf-16来统一编码所有字符.因为种种历史原因,文本的编码格式非常混乱,这种时候就可以使用chardet工具来判别使用的是何种字符编码,这个工具我们已经在前文提及 chardet可以使用pip安装.安装后可以使用命令行工具 chardetect 来辨别文件的字符编码类型. 作为模块使用 import requests rawdata = requests.get('http://www.baike.com/wiki/%E6%9C%9F%E6%9C%9B').content import chardet chardet.detect(rawdata) {'confidence': 0.99, 'encoding': 'utf-8'} 结果的encoding表示判断是哪种编码,confidence表示确信度 复杂情况的辨别 如果处理大量文本，您可以逐步调用检测器，当有足够的信心报告其结果，它就会停止。 import requests from chardet.universaldetector import UniversalDetector usock = requests.get('http://yahoo.co.jp/') detector = UniversalDetector() for line in usock.iter_lines(): detector.feed(line) if detector.done: break detector.close() usock.close() print(detector.result) {'encoding': 'utf-8', 'confidence': 0.99} 如此一来我们就不需要把整个文本用于辨别,这就减少了时间 如果要检测多个文本（例如单独文件）的编码，可以重复使用单个UniversalDetector对象。 只需在每个文件的开头调用detect.reset(),调用detect.feed多次，然后调用detect.close()并检查检测器.result字典为文件的结果。 import glob from chardet.universaldetector import UniversalDetector detector = UniversalDetector() for filename in glob.glob('src/*.py'): print(filename.ljust(60),end=\"\") detector.reset() for line in open(filename, 'rb'): detector.feed(line) if detector.done: break detector.close() print(detector.result) src/gettext_te.py {'encoding': 'ascii', 'confidence': 1.0} src/international.py {'encoding': 'ascii', 'confidence': 1.0} src/pygettext.py {'encoding': 'ISO-8859-2', 'confidence': 0.8550385660653095} src/srcgettext_te.py {'encoding': 'ascii', 'confidence': 1.0} src/transfer.py {'encoding': 'ascii', 'confidence': 1.0} Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:04:25 "},"基础应用篇/国际化/国际化文本翻译.html":{"url":"基础应用篇/国际化/国际化文本翻译.html","title":"国际化文本翻译","keywords":"","body":"国际化文本翻译 我们写app希望可以适应本地化需求,也就是当换一种语言的时候可以自动转成翻译好的对应文本.我们当然可以每个语言些一个版本,代码相同只是修改其中的文本. 一个简单的解决方案是使用一个函数包裹字符串,让函数负责找到对应翻译.比如 spanishStrings = {'Hello world!': 'Hola Mundo!'} frenchStrings = {'Hello world!': 'Bonjour le monde!'} germanStrings = {'Hello world!': 'Hallo Welt!'} def trans(s): if LANGUAGE == 'English': return s if LANGUAGE == 'Spanish': return spanishStrings.get(s) if LANGUAGE == 'French': return frenchStrings.get(s) if LANGUAGE == 'German': return germanStrings.get(s) LANGUAGE = 'French' print(trans(\"Hello world!\")) Bonjour le monde! 但是很明显,一旦文本量变大了就会无法管理了~ Python提供了gettext模块用于解决这类问题 gettext的使用 创建国际化文档的文件夹目录 ----| |-src-| |-locale-| |-en-| | |-LC_MESSAGES | |-cn-| | |-LC_MESSAGES | |-fr-| |-LC_MESSAGES gettext初始化 使用脚本工具pygettext初始化gettext设置(如果安装的python中没有的话可以来这里下载) !src/pygettext.py -p src/ File \"src/pygettext.py\", line 516 except getopt.error, msg: ^ SyntaxError: invalid syntax !cat src/messages.pot # SOME DESCRIPTIVE TITLE. # Copyright (C) YEAR ORGANIZATION # FIRST AUTHOR , YEAR. # msgid \"\" msgstr \"\" \"Project-Id-Version: PACKAGE VERSION\\n\" \"POT-Creation-Date: 2016-12-08 20:34+CST\\n\" \"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\\n\" \"Last-Translator: FULL NAME \\n\" \"Language-Team: LANGUAGE \\n\" \"MIME-Version: 1.0\\n\" \"Content-Type: text/plain; charset=CHARSET\\n\" \"Content-Transfer-Encoding: ENCODING\\n\" \"Generated-By: pygettext.py 1.5\\n\" 我们修改它的 \"Content-Type: text/plain; charset=CHARSET\\n\" \"Content-Transfer-Encoding: ENCODING\\n\" 两个字段,并为其添加要翻译的内容 %%writefile src/transfor.pot # SOME DESCRIPTIVE TITLE. # Copyright (C) YEAR ORGANIZATION # FIRST AUTHOR , YEAR. # msgid \"\" msgstr \"\" \"Project-Id-Version: PACKAGE VERSION\\n\" \"POT-Creation-Date: 2016-12-08 20:34+CST\\n\" \"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\\n\" \"Last-Translator: FULL NAME \\n\" \"Language-Team: LANGUAGE \\n\" \"MIME-Version: 1.0\\n\" \"Content-Type: text/plain; charset=gb2312\\n\" \"Content-Transfer-Encoding: utf-8\\n\" \"Generated-By: pygettext.py 1.5\\n\" msgid \"hello\" msgstr \"\" msgid \"Python now\" msgstr \"\" Overwriting src/transfor.pot 接着我们就可以使用poedit来逐条翻译了这边有一个基本教程操作 我们用poedit为写一份中文的翻译,放在locale/cn/LC_MESSAGES中,其中包含两份文件,zh_CN.po和zh_CN.mo,同样的也弄一份英文的 !cat src/locale/cn/zh_CN.po cat: src/locale/cn/zh_CN.po: No such file or directory 注册国际化文本 %%writefile src/transfer.py #!/usr/bin/env python # -*- coding: utf-8 -*- import gettext langen = gettext.translation('en', './src/locale', languages=['en']) langcn = gettext.translation('zh_CN', './src/locale', languages=['cn']) Overwriting src/transfer.py 其中: gettext_te.py是要翻译模块或app名 ./locale是存放翻译文件的路径, languages参数指定要使用的语言存放的子目录,这里cn表示使用./locale/cn/LC_MESSAGES/路径下的翻译文件. 这样我们就有了一个_()方法来翻译文本 编辑主模块 %%writefile src/gettext_te.py #!/usr/bin/env python # -*- coding: utf-8 -*- from __future__ import print_function from transfer import * langcn.install() print(_(\"Hello world!\")) langen.install() print(_(\"Hello world!\")) Overwriting src/gettext_te.py %run src/gettext_te.py Hello world! Hello world! 这样每次只要修改对应文件夹的mo文件就可以实现本地化翻译了 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:04:15 "},"基础应用篇/国际化/时间日期处理.html":{"url":"基础应用篇/国际化/时间日期处理.html","title":"时间日期处理","keywords":"","body":"时间日期处理 python和时间有关的标准库模块常用的主要有3个 基本时间模块time 日历模块calendar 时间日历模块datetime 一图流时间日期处理的方法介绍 基本时间模块time time 模块中一般有三种表示时间的方式: 第一种是时间戳(timestamp)的方式(相对于1970.1.1 00:00:00以秒计算的偏移量),时间戳是惟一的,也是各种语言通用的.有的语言如java,js时间以ms记,所以处理的时候注意下,适当的时候/1000 第二种以数组的形式表示即(struct_time,结构化时间),共有九个元素，分别表示，同一个时间戳的struct_time会因为时区不同而不同 元素属性 范围及说明 year (four digits, e.g. 1998) month (1-12) day (1-31) hours (0-23) minutes (0-59) seconds (0-59) weekday (0-6, Monday is 0) Julian day (一年中的第几天, 1-366) DST (-1, 0 or 1) 是否是夏令时,0说明是不是,1说明是,-1说明不确定 第三种是字符串表述,也就我们可以直接看懂的形式 可以用如下的符号格式化字符串输出: 符号 意思及取值范围 %y 两位数的年份表示（00-99） %Y 四位数的年份表示（000-9999） %m 月份（01-12） %d 月内中的一天（0-31） %H 24小时制小时数（0-23） %I 12小时制小时数（01-12） %M 分钟数（00=59） %S 秒（00-59） %a 本地简化星期名称 %A 本地完整星期名称 %b 本地简化的月份名称 %B 本地完整的月份名称 %c 本地相应的日期表示和时间表示 %j 年内的一天（001-366） %p 本地A.M.或P.M.的等价符 %U 一年中的星期数（00-53）星期天为星期的开始 %w 星期（0-6），星期天为星期的开始 %W 一年中的星期数（00-53）星期一为星期的开始 %x 本地相应的日期表示 %X 本地相应的时间表示 %Z 当前时区的名称 %% %号本身 import time 时间获取 获取当前时间戳 time() now_timestamp = time.time() now_timestamp 1498831412.6540039 获取当前结构化时间 localtime() now_struct = time.localtime() now_struct time.struct_time(tm_year=2017, tm_mon=6, tm_mday=30, tm_hour=22, tm_min=3, tm_sec=33, tm_wday=4, tm_yday=181, tm_isdst=0) 直接获取当前时间字符串 asctime() time.asctime() 'Fri Jun 30 22:03:33 2017' 时间表现形式转化 时间戳=>结构化时间 localtime() gmtime() # 当前时区 time.localtime(now_timestamp) time.struct_time(tm_year=2017, tm_mon=6, tm_mday=30, tm_hour=22, tm_min=3, tm_sec=32, tm_wday=4, tm_yday=181, tm_isdst=0) # UTC时区(0时区) time.gmtime(now_timestamp) time.struct_time(tm_year=2017, tm_mon=6, tm_mday=30, tm_hour=14, tm_min=3, tm_sec=32, tm_wday=4, tm_yday=181, tm_isdst=0) 结构化时间=>时间戳 mktime() time.mktime(now_struct) 1498831413.0 结构化时间=>字符串 asctime() strftime() time.asctime(now_struct) 'Fri Jun 30 22:03:33 2017' time.strftime(\"%Y-%m-%d %H:%M:%S\", now_struct) '2017-06-30 22:03:33' 时间戳=>字符串 ctime() time.ctime(now_timestamp) 'Fri Jun 30 22:03:32 2017' 将格式化字符串转化为时间戳 a = \"Sat Sep 24 22:22:22 2015\" b = time.mktime(time.strptime(a,\"%a %b %d %H:%M:%S %Y\")) b 1443104542.0 将格式化字符串转化为结构化时间 c = time.strptime(a,\"%a %b %d %H:%M:%S %Y\") c time.struct_time(tm_year=2015, tm_mon=9, tm_mday=24, tm_hour=22, tm_min=22, tm_sec=22, tm_wday=5, tm_yday=267, tm_isdst=-1) 特殊函数 线程推迟指点时间 sleep(sec) time.sleep(1) 基本的日历模块calendar calendar模块，即日历模块，提供了对日期的一些操作方法，和生成日历的方法。 主要提供的常量(用list查看): 常量 说明 calendar.day_name 一周的星期几名字 calendar.day_abbr 一周的星期几名字的简写 calendar.month_name 月份名字 calendar.month_abbr 月份名字的简写 主要的方法有: 方法 说明 calendar.setfirstweekday(weekday) 设置日历中星期的的第一天是周几 calendar.firstweekday() 查看日历中一星期的第一天是周几(在列表中的位置) calendar.isleap(year) 判断是否是闰年 calendar.leapdays(y1, y2) 获取两个年份之间闰年数 calendar.weekday(year, month, day) 查看某一天是星期几(在列表中的位置) calendar.weekheader(n) 返回星期几的英文缩写,n表示用几位字母 calendar.monthrange(year, month) 返回第一天是周几(列表中位置和月的长度) calendar.monthcalendar(year, month) 返回一个表示日历的二维数组 calendar.prmonth(theyear, themonth, w=0, l=0) 直接打印日历 calendar.month(theyear, themonth, w=0, l=0) 返回某月的日历文本 calendar.prcal(year, w=0, l=0, c=6, m=3) 打印一年的日历 calendar.calendar(year, w=2, l=1, c=6, m=3) 返回一年日历的字符串 calendar.timegm(tuple) 把一个 UTC 的 struct_time 转化为 POSIX 时间戳 其中有三个主要的类型可以实例化: calendar.Calendar(firstweekday=0) 该类提供了许多生成器，如星期的生成器，某月日历生成器. 主要有: iterweekdays() 返回一周几天的生成器 itermonthdates(year, month) 返回某月的每一天的datetime构成的生成器 itermonthdays2(year, month) 返回某月的每一天的(日期,星期)构成的生成器 itermonthdays(year, month) 返回某月的每一天的日期构成的生成器 monthdatescalendar(year, month) 返回某月的每一天的datetime构成的list(每周是一个list) monthdays2calendar(year, month) 返回某月的每一天的(日期,星期)构成的list(每周是一个list) monthdayscalendar(year, month) 返回某月的每一天的日期构成的list(每周是一个list) yeardatescalendar(year, width=3) 返回某年的每一天的datetime构成的list(每月一个list,每周是一个list) yeardays2calendar(year, width=3) 返回某年的每一天的(日期,星期)构成的list(每月一个list,每周是一个list) yeardayscalendar(year, width=3) 返回某年的每一天的日期构成的list(每月一个list,每周是一个list) calendar.TextCalendar(firstweekday=0) 该类提供了按月、按年生成日历字符串的方法。 主要有: 方法 说明 formatmonth(theyear, themonth, w=0, l=0) 返回某月的日历字符串 prmonth(theyear, themonth, w=0, l=0) 打印某月的日历字符串 formatyear(theyear, w=2, l=1, c=6, m=3) 返回某年的日历字符串 pryear(theyear, w=2, l=1, c=6, m=3) 打印某年的日历字符串 子类有: calendar.LocaleTextCalendar(firstweekday=0, locale=None) 用来生成本地日历,主要就是月份和星期的本地语言化,locale默认是计算机的locale calendar.HTMLCalendar(firstweekday=0) 类似TextCalendar，不过生成的是HTML格式日历 主要有: formatmonth(theyear, themonth, withyear=True) 返回某月的日历的html字符串 formatyear(theyear, width=3) 返回某年的日历的html字符串 formatyearpage(theyear, width=3, css='calendar.css', encoding=None) 返回完整的页面代码的字符串 子类有: calendar.LocaleHTMLCalendar(firstweekday=0, locale=None) 用来生成本地日历,主要就是月份和星期的本地语言化,locale默认是计算机的locale import calendar cal = calendar.HTMLCalendar(calendar.MONDAY) with open('calendar.html',\"wb\") as f: f.write(cal.formatyearpage(2016)) 最常用的时间日历模块 datetime datetime同样是python标准库,不过它看起来就很OO很现代了~它用一个叫datetime的类型来表示时间,一般来说,做时间的计算会用它而不是time模块 from datetime import datetime 获取datetime 时间 获取当前日期和时间 datetime.now() now = datetime.now() now datetime.datetime(2017, 6, 30, 22, 3, 39, 535750) now.__str__() '2017-06-30 22:03:39.535750' 获取某一时间datetime() yesterday = datetime(2015,9,23,17,2,4,220475) yesterday datetime.datetime(2015, 9, 23, 17, 2, 4, 220475) datetime => 时间戳 .timestamp() now.timestamp() 1498831419.53575 时间戳 => datetime 本地时间 before_now = datetime.fromtimestamp(now_timestamp) before_now.__str__() '2017-06-30 22:03:32.654004' UTC标准时间 before_now_UTC = datetime.utcfromtimestamp(now_timestamp) before_now_UTC.__str__() '2017-06-30 14:03:32.654004' 格式化字符串 => datetime cday = datetime.strptime('2015-6-1 18:19:59', '%Y-%m-%d %H:%M:%S') cday datetime.datetime(2015, 6, 1, 18, 19, 59) datetime => 格式化字符串 now.strftime('%a, %b %d %H:%M') 'Fri, Jun 30 22:03' 时间计算 from datetime import datetime, timedelta now = datetime.now() print(now) print(now + timedelta(hours=10)) print(now - timedelta(days=1)) print(now + timedelta(days=2, hours=12)) 2017-06-30 22:03:46.561364 2017-07-01 08:03:46.561364 2017-06-29 22:03:46.561364 2017-07-03 10:03:46.561364 tenten = datetime(2015, 10, 1, 0, 0, 0, 0) (tenten - now).__str__() '-639 days, 1:56:13.438636' from datetime import datetime, timedelta now = datetime.now() now datetime.datetime(2017, 6, 30, 22, 3, 47, 327346) now + timedelta(seconds=10) datetime.datetime(2017, 6, 30, 22, 3, 57, 327346) nowonow = datetime.now() nowonow datetime.datetime(2017, 6, 30, 22, 3, 47, 917878) nowonow False 支持链式表达式和时区转换的时间处理模块 moment是一个开源,接口仿照js库moment的时间处理模块,支持链式表达式 他的好处是用链式表达式可以写起来很顺畅 可以使用pip安装,以下是官方的例子,要用的话可以对着例子找接口 import moment from datetime import datetime # Create a moment from a string moment.date(\"12-18-2012\", \"M-D-YYYY\") # Create a moment with strftime format moment.date(\"12-18-2012\", \"%m-%d-%Y\") # By default, the \"%Y-%m-%d\" strftime format is used moment.date(\"2012-12-18\") # Create a moment from the current datetime moment.now() # The moment can also be UTC-based moment.utcnow() # Create a moment with the UTC time zone moment.utc(\"2012-12-18\", \"YYYY-M-D\") # Create a moment from a Unix timestamp moment.unix(13558751536) # Create a moment from a Unix UTC timestamp moment.unix(13558751536, utc=True) # Return a datetime instance moment.date(2012, 12, 18).date # We can do the same thing with the UTC method moment.utc(2012, 12, 18).date # Create and format a moment using Moment.js semantics moment.now().format(\"YYYY-M-D\") # Create and format a moment with strftime semantics moment.date(2012, 12, 18).strftime(\"%Y-%m-%d\") # Update your moment's time zone moment.date(datetime(2012, 12, 18)).locale(\"US/Central\").date # Alter the moment's UTC time zone to a different time zone moment.utcnow().timezone(\"US/Eastern\").date # Set and update your moment's time zone. For instance, I'm on the # west coast, but want NYC's current time. moment.now().locale(\"US/Pacific\").timezone(\"US/Eastern\") # In order to manipulate time zones, a locale must always be set or # you must be using UTC. moment.utcnow().timezone(\"US/Eastern\").date # You can also clone a moment, so the original stays unaltered now = moment.utcnow().timezone(\"US/Pacific\") future = now.clone().add(weeks=2) # Customize your moment by chaining commands moment.date(2012, 12, 18).add(days=2).subtract(weeks=3).date # Imagine trying to do this with datetime, right? moment.utcnow().add(years=3, months=2).format(\"YYYY-M-D h:m A\") # You can use multiple keyword arguments moment.date(2012, 12, 19).add(hours=1, minutes=2, seconds=3) # And, a similar subtract example... moment.date(2012, 12, 19, 1, 2, 3).subtract(hours=1, minutes=2, seconds=3) # In addition to adding/subtracting, we can also replace values moment.now().replace(hours=5, minutes=15, seconds=0).epoch() # And, if you'd prefer to keep the microseconds on your epoch value moment.now().replace(hours=5, minutes=15, seconds=0).epoch(rounding=False) # Years, months, and days can also be set moment.now().replace(years=1984, months=1, days=1, hours=0, minutes=0, seconds=0) # Also, datetime properties are available moment.utc(2012, 12, 19).year == 2012 # Including plural ones (since I'm bad at remembering) moment.now().seconds # We can also manipulate to preferred weekdays, such as Monday moment.date(2012, 12, 19).replace(weekday=1).strftime(\"%Y-%m-%d\") # Or, this upcoming Sunday moment.date(\"2012-12-19\").replace(weekday=7).date # We can even go back to two Sundays ago moment.date(2012, 12, 19).replace(weekday=-7).format(\"YYYY-MM-DD\") # It's also available as a property moment.utcnow().weekday # And, there's an easy way to zero out the hours, minutes, and seconds moment.utcnow().zero Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:04:33 "},"基础应用篇/国际化/货币处理模块.html":{"url":"基础应用篇/国际化/货币处理模块.html","title":"货币处理模块","keywords":"","body":"货币处理模块 各国所用货币不同,实时汇率也不同,因此货币处理在国际化上是一个比较麻烦的事儿. python模块money提供了一个相对好的解决方案,可以通过pip安装它,如果想要本地化的显示功能,比如打印出￥ xxx这种,那还需要安装babel作为依赖 单一货币结算 money提供了一个类Money来作为定义货币种类的基类,它很适合用作单货币间的运算工具,它支持的运算有 和同一货币 支持+,-,/ 和比较操作 和常数 支持使用* from money import Money m = Money(amount='2.22', currency='EUR') m EUR 2.22 m.amount Decimal('2.22') m.currency 'EUR' print(m.format('en_US')) €2.22 币种间换算 对不同货币间的运算,我们需要确定比例,这需要使用其中的xrates类 xrates类需要先install一个抽象类来作为后端,常用的是money.exchange.SimpleBackend 之后需要确定以哪种货币作为基准,一般都是以美元为基准 然后就是已定义各种货币对美元的比例了 from decimal import Decimal from money import xrates xrates.install('money.exchange.SimpleBackend') xrates.base = 'USD' #注意是1美元兑换目标货币的值 xrates.setrate('EUR', Decimal('0.9279')) xrates.setrate('CNY', Decimal('6.8785')) a = Money(1, 'EUR') b = Money(1, 'CNY') a.to('CNY') CNY 7.412975536156913460502209290 更灵活的换算 在前面已经定义好了换算比例的情况下,可以使用XMoney类来直接计算不同货币种类 from money import XMoney xrates.install('money.exchange.SimpleBackend') xrates.base = 'USD' #注意是1美元兑换目标货币的值 xrates.setrate('EUR', Decimal('0.9279')) xrates.setrate('CNY', Decimal('6.8785')) a = XMoney(1, 'EUR') b = XMoney(1, 'CNY') a+b EUR 1.134898597077851275714181871 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:04:42 "},"基础应用篇/国际化/结语.html":{"url":"基础应用篇/国际化/结语.html","title":"结语","keywords":"","body":"结语 python标准库对于国际化的支持可以说是比较浅的,时间日期的接口也比较落伍,然而基本上还是够用的.当然了按照惯例,社区提供了很多更加优雅的工具来做同样的事情. 相关的扩展和模块 arrow 一个更优雅的时间日期处理工具 jieba 知名的中文分词工具. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:04:00 "},"基础应用篇/数据压缩与归档/":{"url":"基础应用篇/数据压缩与归档/","title":"数据压缩与归档","keywords":"","body":"数据压缩 python标准库可以提供简单的压缩解压功能.主要是使用zlib,zipfile和tarfile. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:06:54 "},"基础应用篇/数据压缩与归档/数据压缩解压.html":{"url":"基础应用篇/数据压缩与归档/数据压缩解压.html","title":"数据压缩解压","keywords":"","body":"数据压缩解压 压缩和解压说白了就是时间换空间,运算换存储的一种解决方案,标准库中的zlib和bz2模块都是数据压缩解压工具,他们的主要应用场景是数据传输. 注意压缩只能是bytes类型 在python3.4中新增了对lzma的支持,也就是说支持zx格式了,它除了有压缩字节序列的接口,也提供了直接从文本读取数据进行压缩的接口.同时bz2也新增了从对文件的压缩解压接口. zlib import zlib exa_str=u\"\"\"\\ 网易体育1月5日报道： 国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，\\ 巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友\\ “小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，\\ 排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。 \"\"\" 压缩compress(data[, level]) level是压缩等级(范围0~9),默认是6,1是最快单压缩最少的,9是最慢但压缩最多得,0表示不压缩 z_str=zlib.compress(exa_str.encode()) len(z_str)/len(exa_str.encode()) 0.7527910685805422 可以看到默认level时压缩率在75%的样子 解压 zlib.decompress(z_str).decode(\"utf-8\") '网易体育1月5日报道：\\n\\n国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友“小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。\\n' 自定义压缩和解压器 压缩器compressobj([level[, method[, wbits[, memLevel[, strategy]]]]]) level 压缩等级,范围1~9,默认6 method 压缩方法,目前只支持默认方法 wbits 确定窗口缓冲区的大小,范围是8~15,越高效果越好,但占用内存越多 memLevel 内部压缩状态存储等级,范围1~9,数值越大消耗内存越多,但更快压缩率更高 strategy 压缩算法相关,可选值有Z_DEFAULT_STRATEGY, Z_FILTERED,Z_HUFFMAN_ONLY 解压器decompressobj(wbits=15) bz2 bz2和zlib接口差不多,只是使用的不同的算法 import bz2 压缩compress(data[, level]) level是压缩等级(范围1~9),默认是9,1是最快单压缩最少的,9是最慢但压缩最多得 b_str = bz2.compress(exa_str.encode()) len(b_str)/len(exa_str.encode()) 0.8309409888357256 解压decompress(data) bz2.decompress(b_str).decode(\"utf-8\") '网易体育1月5日报道：\\n\\n国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友“小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。\\n' 文件接口bz2.open(filename, mode='r', compresslevel=9, encoding=None, errors=None, newline=None) 在py3.3中新提供的压缩文件接口,通常用于处理.bz格式的文件,在3.4中又进行了完善,目前支持的mode为: 字节序列可以使用'r', 'rb', 'w', 'wb', 'x', 'xb', 'a'或者'ab' 文本可以使用'rt', 'wt', 'xt' 或者 'at' with bz2.open(\"test.bz2\",'wt') as f: f.write(exa_str) with bz2.open(\"test.bz2\",'rt') as f: print(f.read()) 网易体育1月5日报道： 国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友“小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。 lzma(py3.4) python3.4中提供了对lzma压缩算法的支持,现在它可以用于解压.xz格式的文件或者压缩/解压字节序列 压缩字节序列(compress) import lzma data_out = lzma.compress(exa_str.encode()) len(data_out)/len(exa_str.encode()) 0.8803827751196173 解压字节序列(decompress) lzma.decompress(data_out).decode(\"utf-8\") '网易体育1月5日报道：\\n\\n国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友“小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。\\n' 增量压缩 lzc = lzma.LZMACompressor() out1 = lzc.compress(b\"Some data\\n\") out2 = lzc.compress(b\"Another piece of data\\n\") out3 = lzc.compress(b\"Even more data\\n\") out4 = lzc.flush() result = b\"\".join([out1, out2, out3, out4]) result b'\\xfd7zXZ\\x00\\x00\\x04\\xe6\\xd6\\xb4F\\x02\\x00!\\x01\\x16\\x00\\x00\\x00t/\\xe5\\xa3\\xe0\\x00.\\x00+]\\x00)\\x9b\\xc9\\xa6gB-8\\xa2k\\x95V\\x1b\\xc7\\xccb\\x8f\\xf2\\xe7\\xe0\\x13\\x12\\xc8\\xdc\\xaf(\\x10\\xdf\\xb0\\xc1\\x1a\\x95$\\xf4\\xde\\x0f\\xc1~l\\x1d\\xa6 \\x00\\x00\\x00,\\xdc\\xbd\\xb54c,$\\x00\\x01G/\\xb0Qo4\\x1f\\xb6\\xf3}\\x01\\x00\\x00\\x00\\x00\\x04YZ' lzma.decompress(result) b'Some data\\nAnother piece of data\\nEven more data\\n' 文件接口lzma.open(filename, mode=\"rb\", *, format=None, check=-1, preset=None, filters=None, encoding=None, errors=None, newline=None) 与bz2类似,lzma也提供了一个处理文件的接口,用法也大同小异 with lzma.open(\"test.xz\",'wt') as f: f.write(exa_str) with lzma.open(\"test.xz\",'rt') as f: print(f.read()) 网易体育1月5日报道： 国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友“小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:07:24 "},"基础应用篇/数据压缩与归档/压缩归档.html":{"url":"基础应用篇/数据压缩与归档/压缩归档.html","title":"压缩归档","keywords":"","body":"压缩归档 如果是用于归档文件,那我们最好的选择就是使用压缩工具,python的标准库自带zipfile和tarfile用来压缩归档文件,还有gzip用来为单一文件进行压缩,另外github上还有一个归档为rar的工具rarfile. zipfile zip文件格式由三个部分组成：压缩源文件数据区+压缩源文件目录区+压缩源文件目录结束标志 压缩源文件数据区 在这个数据区中每一个压缩的源文件/目录都是一条记录，记录的格式如下： [文件头+ 文件数据 + 数据描述符] 文件头结构 组成 长度 文件头标记 4 bytes (0x04034b50) 解压文件所需 pkware 版本 2 bytes 全局方式位标记 2 bytes 压缩方式 2 bytes 最后修改文件时间 2 bytes 最后修改文件日期 2 bytes CRC-32校验 4 bytes 压缩后尺寸 4 bytes 未压缩尺寸 4 bytes 文件名长度 2 bytes 扩展记录长度 2 bytes 文件名 （不定长度） 扩展字段 （不定长度） 文件数据 数据描述符 组成 长度 CRC-32校验 4 bytes 压缩后尺寸 4 bytes 未压缩尺寸 4 bytes 这个数据描述符只在全局方式位标记的第３位设为１时才存在，紧接在压缩数据的最后一个字节后。这个数据描述符只用在不能对输出的 ZIP 文件进行检索时使用。例如：在一个不能检索的驱动器（如：磁带机上）上的 ZIP 文件中。如果是磁盘上的ZIP文件一般没有这个数据描述符。 压缩源文件目录区 在这个数据区中每一条纪录对应在压缩源文件数据区中的一条数据 组成 长度 目录中文件文件头标记 4 bytes (0x02014b50) 压缩使用的pkware 版本 2 bytes 解压文件所需 pkware 版本 2 bytes 全局方式位标记 2 bytes 压缩方式 2 bytes 最后修改文件时间 2 bytes 最后修改文件日期 2 bytes ＣＲＣ－３２校验 4 bytes 压缩后尺寸 4 bytes 未压缩尺寸 4 bytes 文件名长度 2 bytes 扩展字段长度 2 bytes 文件注释长度 2 bytes 磁盘开始号 2 bytes 内部文件属性 2 bytes 外部文件属性 4 bytes 局部头部偏移量 4 bytes 文件名 （不定长度） 扩展字段 （不定长度） 文件注释 （不定长度） 压缩源文件目录结束标志 组成 长度 目录结束标记 4 bytes (0x02014b50) 当前磁盘编号 2 bytes 目录区开始磁盘编号 2 bytes 本磁盘上纪录总数 2 bytes 目录区中纪录总数 2 bytes 目录区尺寸大小 4 bytes 目录区对第一张磁盘的偏移量 4 bytes ZIP 文件注释长度 2 bytes ZIP 文件注释 （不定长度） import zipfile 创建归档 创建一个文件的zip归档 with zipfile.ZipFile('source/output/笑傲江湖.zip', 'w',zipfile.ZIP_DEFLATED) as f: f.write(\"source/input/笑傲江湖.txt\") 创建字符串的归档 with open(\"source/input/iris.csv\",\"r\") as f: content = f.read() with zipfile.ZipFile('source/output/iris_str.zip', 'w',zipfile.ZIP_DEFLATED) as f: f.writestr( 'iris_str.csv',content) 创建一个多文件归档 在归档大量文件时,我们可以用allowZip64=True来指定支持超过2Gb的归档 with zipfile.ZipFile('source/output/all_input.zip', 'w',zipfile.ZIP_DEFLATED,allowZip64=True) as f: f.write(\"source/input/笑傲江湖.txt\") f.write(\"source/input/iris.csv\") f.write(\"source/input/people.json\") 查看压缩文件信息 #查看是不是zip压缩文件 zipfile.is_zipfile(\"source/output/all_input.zip\") True # 查看zip中的文件列表 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.namelist()) ['source/input/笑傲江湖.txt', 'source/input/iris.csv', 'source/input/people.json'] # 打开zip中某个文件 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.open('source/input/people.json').read().decode(\"utf-8\")) [{\"name\":\"Michael\"},{\"name\":\"Andy\", \"age\":30},{\"name\":\"Justin\", \"age\":19}] # 查看zip文件的信息列表 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.infolist()) [, , ] # 查看压缩信息 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.printdir()) File Name Modified Size source/input/笑傲江湖.txt 2016-12-23 23:17:44 2989594 source/input/iris.csv 2016-12-23 23:17:44 4606 source/input/people.json 2016-12-23 23:17:44 75 None # 查看zip中某文件的信息 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: info = f.getinfo('source/input/people.json') print(info) # 查看创建时间 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: info = f.getinfo('source/input/people.json') print(info.date_time) (2016, 12, 23, 23, 17, 44) # 检查zip中每个文件的CRC,有错误会返回对应文件作为列表成员 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.testzip()) None 解压文件 全部解压 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: f.extractall(\"source/extract\") 单独解压一个 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: f.extract(\"source/input/iris.csv\",\"source/exone\") 密码处理 zipfile只能解压带密码的zip包,并不支持创建加密的zip归档,要使用密码只要像这个样: with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: f.setpassword() f.extract(\"source/input/iris.csv\",\"source/exone\") 即可 tarfile tar是linux下是常见的归档格式,常见的后缀有tar,tar.bz,tar.gz三种后缀,分别对应三种不同的压缩算法, tarfile的归档用法也与zipfile类似,只是接口有些变化 import tarfile with tarfile.TarFile('source/output/all_input.tar', 'w') as f: f.add(\"source/input/笑傲江湖.txt\") f.add(\"source/input/iris.csv\") f.add(\"source/input/people.json\") #查看是不是zip压缩文件 tarfile.is_tarfile(\"source/output/all_input.tar\") True #查看压缩信息 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.list()) ?rwxr-xr-x huangsizhe/staff 2989594 2016-12-23 23:17:44 source/input/笑傲江湖.txt ?rwxr-xr-x huangsizhe/staff 4606 2016-12-23 23:17:44 source/input/iris.csv ?rwxr-xr-x huangsizhe/staff 75 2016-12-23 23:17:44 source/input/people.json None # 查看zip中的文件列表 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.getnames()) ['source/input/笑傲江湖.txt', 'source/input/iris.csv', 'source/input/people.json'] # 查看zip文件的信息列表 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.getmembers()) [, , ] # 查看zip中某文件的信息,比如修改时间戳 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.getmember(\"source/input/iris.csv\").mtime) 1482506264 如果要结合gz或者bz压缩,那么就不能使用这个类,而要使用tarfile.open(name=None, mode='r', fileobj=None, bufsize=10240, **kwargs)函数 其中mode=可选的有: mode 说明 'r' or 'r:*' 使用透明压缩读打开 'r:' 无压缩读打开 'r:gz' gzip压缩读打开 'r:bz2' bzip2压缩读打开 'a' or 'a:' 无需压缩append写打开。如果文件不存在，则创建该文件。 'w' or 'w:' 无压缩写 'w:gz' gzip写打开 'w:bz2' bzip2写打开 创建压缩归档 import os with tarfile.open(\"source/output/all_input.tar.gz\",\"w:gz\") as tar: for root,dir,files in os.walk(\"source/input\"): for file in files: fullpath = os.path.join(root,file) tar.add(fullpath) 解压压缩归档 with tarfile.open(\"source/output/all_input.tar.gz\",\"r:gz\") as tar: names = tar.getnames() for name in names: tar.extract(name,path=\"source/ex_tar\") rarfile python标准库并不支持rar格式的归档,但有个rarfile可以通过pip安装,他的接口与zipfile一样,只是不能写只能读 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:07:15 "},"基础应用篇/数据压缩与归档/结语.html":{"url":"基础应用篇/数据压缩与归档/结语.html","title":"结语","keywords":"","body":"结语 python标准库只给出了最基本的人机交互工具当然了python有意思的人机交互工具远不止这些 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:07:02 "},"基础应用篇/信息安全/":{"url":"基础应用篇/信息安全/","title":"信息安全","keywords":"","body":"摘要加密与数字签名 python标准库hashlib和hmac提供了基本的摘要算法.在python3.6中还新增了一个标准库secrets用于生成用于加密的随机数据. 而加密和签名算法则需要第三方工具如PyCrypto,itsdangerous支持. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:01:42 "},"基础应用篇/信息安全/摘要算法.html":{"url":"基础应用篇/信息安全/摘要算法.html","title":"摘要算法","keywords":"","body":"摘要算法 摘要算法是将信息压缩提取以作为数据指纹的算法,我们下载东西要确认下的东西有没有下错下漏常用这种算法来做验证,在密码学中这是很多算法的基础 具体摘要算法是怎么样的？摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示） 还有一种应用场景是用来存储用户的密码,大家都知道明文密码存储在数据库里很不安全,之前爆出很多知名网站将用户密码以明文存储,导致信息泄露.可以通过摘要算法给密码加个密存储进去.这样要破解密码除了要知道密码本身,还得知道生成最终摘要文本的算法才可以.也就相对安全多了. 有没有可能两个不同的数据通过某个摘要算法得到了相同的摘要？完全有可能，因为任何摘要算法都是把无限多的数据集合映射到一个有限的集合中。这种情况称为碰撞，比如Bob试图根据你的摘要反推出一篇文章'how to learn hashlib in python - by Bob'，并且这篇文章的摘要恰好和你的文章完全一致，这种情况也并非不可能出现，但是非常非常困难。 hashlib Python的hashlib提供了常见的摘要算法，如MD5，SHA1等等。 import hashlib md5 psw=\"haolaoshixihuandadota2\" md5 = hashlib.md5() #初始化摘要对象 md5.update(psw.encode('utf-8')) #使用md5算法计算这段摘要 print(md5.hexdigest())#输出16进制字符串 acc5d43185d33c88def863ac18704561 SHA1 sha1 = hashlib.sha1() sha1.update(psw.encode(\"utf-8\")) print(sha1.hexdigest()) e53754d171a425b1dbb4a215cd86d568050055c5 sha224, sha256, sha384, sha512 一样的操作,只是时间花费不同而已 sha224 = hashlib.sha224() sha224.update(psw.encode(\"utf-8\")) print(sha224.hexdigest()) 660b6249c5213d05e1df371cf7cae75fd9369a467684bc631c44d0f4 长字符串操作 长字符串或者一个分段的字符串要作摘要可以分段的进行update,结果是一样的 x_md5 = hashlib.md5() x_md5.update('how to use md5 in '.encode('utf-8')) x_md5.update('python hashlib?'.encode('utf-8')) print(x_md5.hexdigest()) d26a53750bc40b38b65a520292f69306 hmac 和hashlib中的算法不同,hmac算法需要一个key作为seed才可以得到散列点.这样的好处是黑客除了要知道密码,算法,还得知道这个key才能够攻破密码,我们完全可以为不同时间注册的用户使用不同的key,这样破解的难度就更大了 具体用法如下: import hmac myhmac = hmac.new(b'key') myhmac.update(u\"我得密码\".encode(\"utf-8\")) myhmac.hexdigest() 'd63cd3fbde648491d690927a7e13fc58' 参数 hamc的new方法可以带参数 hmac.new(key[, msg[, digestmod]]) key 秘钥 msg 需要散列的信息 digestmod 摘要算法,默认为md5,可以是任何hashlib中的算法 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:02:11 "},"基础应用篇/信息安全/数字签名.html":{"url":"基础应用篇/信息安全/数字签名.html","title":"数字签名","keywords":"","body":"数字签名 关于什么是数字签名,可以看阮一峰的这篇博客 说简单些就是一个为了确保信息完整性和正确性的技术,他的原理就是在要传输的数据上附带一个经过发件人私钥加密的原文摘要数据,这个摘要可以用发件人的公钥解密,之后与接收到数据的摘要核对就可以验证准确性了. 使用PyCryto创建简单签名 from Crypto.PublicKey import RSA from Crypto.Hash import SHA from Crypto.Signature import PKCS1_v1_5 as Signature_pkcs1_v1_5 import base64 创建签名 #使用自己的秘钥对内容进行签名 message = 'hello , this is a test text' with open('source/private.pem') as f: key = f.read() rsakey = RSA.importKey(key) signer = Signature_pkcs1_v1_5.new(rsakey)# 构建签名 digest = SHA.new() digest.update(message) # 使用SHA算法获得摘要 sign = signer.sign(digest) # 使用摘要签名 signature = base64.b64encode(sign) #序列化 signature 'JrnG0TzTCe+K/VhyiFrmfwmiDDQqSkL5ai7PbBsOfTLee+/XIcPLi906WGYb9pRvLtx5EGa6OStuzomC1mqie96nc/81TjhCq61WUJ6Agg6MZplxhai1eKpN/iOW2jCjrRELfIiuoCgT7IYQ5L0va9C6NeHjURFaDYoR/9Rd88xyYaSFGFA3z4eLDntmI5totWRNUszmL9cWfCC7TRgdTZp5O9eDuoylLkkKVABKSzAtDc2+LJ8Hx1cj+zfT40L2e9RDGYKxvMA5A9mTGh7C4w3r1nlR9nzzEOlnUNTmxQNOnRjfs1vtcDsXAMs8s3RmZosz8WL1/1jKF6P/EuAadQ==' 解码签名 #使用公钥解码签名 with open('source/public_pem') as f: key = f.read() rsakey = RSA.importKey(key) verifier = Signature_pkcs1_v1_5.new(rsakey) digest = SHA.new() # Assumes the data is base64 encoded to begin with digest.update(message) is_verify = signer.verify(digest, base64.b64decode(signature))#对比解码后的签名和原文的摘要已确认 print is_verify True 使用itsdangerous建立签名 itsdangerous是一个序列化数据生成签名的工具,它内部使用hmac和sha1来签名,支持jsonweb签名 一个基本的签名 from itsdangerous import Signer s = Signer('secret-key') l=s.sign('my string') l 'my string.wh6tMHxLgJqB6oY1uT73iMlyrOA' 签名会被加在字符串尾部，中间由句号 (.)分隔。验证字符串，使用 unsign() 方法： s.unsign(l) 'my string' 如果被签名的是一个unicode字符串，那么它将隐式地被转换成utf-8。然而，在反签名时，你没法知道它原来是unicode还是字节串。因此一个好习惯是用统一的字符串形式 使用时间戳 如果你想要可以过期的签名，可以使用 TimestampSigner 类，它会加入时间戳信息并签名。在反签名时，你可以验证时间戳有没有过期： from itsdangerous import TimestampSigner s = TimestampSigner('secret-key') string = s.sign('foo') s.unsign(string, max_age=5) 'foo' s.unsign(string, max_age=5) 'foo' 盐 所有的类都接受一个盐的参数。这名字可能会误导你，因为通常你会认为，密码学中的盐会是一个和被签名的字符串储存在一起的东西，用来防止彩虹表查找。这种盐是公开的。 与Django中的原始实现类似，itsdangerous中的盐，是为了一个截然不同的目的而产生的。你可以将它视为成命名空间。就算你泄露了它，也不是很严重的问题，因为没有密钥的话，它对攻击者没什么帮助。 假设你想签名两个链接。你的系统有个激活链接，用来激活一个用户账户，并且你有一个升级链接，可以让一个用户账户升级为付费用户，这两个链接使用email发送。在这两种情况下，如果你签名的都是用户ID，那么该用户可以在激活账户和升级账户时，复用URL的可变部分。现在你可以在你签名的地方加上更多信息（如升级或激活的意图），但是你也可以用不同的盐： from itsdangerous import URLSafeSerializer s1 = URLSafeSerializer('secret-key', salt='activate-salt') s1.dumps(42) 'NDI.kubVFOOugP5PAIfEqLJbXQbfTxs' s2 = URLSafeSerializer('secret-key', salt='upgrade-salt') s2.dumps(42) 'NDI.7lx-N1P-z2veJ7nT1_2bnTkjGTE' s2.loads(s1.dumps(42)) --------------------------------------------------------------------------- BadSignature Traceback (most recent call last) in () ----> 1 s2.loads(s1.dumps(42)) /Users/huangsizhe/LIB/CONDA/anaconda/envs/py2/lib/python2.7/site-packages/itsdangerous.pyc in loads(self, s, salt) 580 \"\"\" 581 s = want_bytes(s) --> 582 return self.load_payload(self.make_signer(salt).unsign(s)) 583 584 def load(self, f, salt=None): /Users/huangsizhe/LIB/CONDA/anaconda/envs/py2/lib/python2.7/site-packages/itsdangerous.pyc in unsign(self, signed_value) 372 return value 373 raise BadSignature('Signature %r does not match' % sig, --> 374 payload=value) 375 376 def validate(self, signed_value): BadSignature: Signature 'kubVFOOugP5PAIfEqLJbXQbfTxs' does not match 最常用的生成会过期的用户信息token(序列化) from itsdangerous import TimedJSONWebSignatureSerializer as Serializer s = Serializer('SECRET_KEY', 30) token = s.dumps({'confirm': \"hsz\"}) token 'eyJhbGciOiJIUzI1NiIsImV4cCI6MTQ5ODgzMDU5NiwiaWF0IjoxNDk4ODMwNTY2fQ.eyJjb25maXJtIjoiaHN6In0.4Rrx-XF5XH2fEWitw9eQjEeffcKhNWcSE8s81FYtw1g' data = s.loads(token) data {u'confirm': u'hsz'} data = s.loads(token) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:02:23 "},"基础应用篇/信息安全/加密算法.html":{"url":"基础应用篇/信息安全/加密算法.html","title":"加密算法","keywords":"","body":"加密算法 加密算法基本可以分为两种: 对称加密 非对称加密 非对称加密有很高的安全性,但是和对称加密比起来,它非常的慢,所以我们还是要用对称加密来传送消息. 但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去. PyCrypto是一个python的密码学工具,它提供了多种加密算法,我们可以直接使用.它有以下这些模块: Crypto.Hash 摘要算法 Crypto.Random 随机模块 Crypto.Cipher 对称加密算法 Crypto.PublicKey 非对称加密 下文为最常见的对称加密和非对称加密算法的例子 对称加密(Symmetric Cryptography) 对称加密是最快速、最简单的一种加密方式，加密（encryption）与解密（decryption）用的是同样的密钥（secret key）对称加密有很多种算法，由于它效率很高，所以被广泛使用在很多加密协议的核心当中。 对称加密通常使用的是相对较小的密钥，一般小于256 bit。因为密钥越大，加密越强，但加密与解密的过程越慢。如果你只用1 bit来做这个密钥，那黑客们可以先试着用0来解密，不行的话就再用1解；但如果你的密钥有1 MB大，黑客们可能永远也无法破解，但加密和解密的过程要花费很长的时间。密钥的大小既要照顾到安全性，也要照顾到效率，是一个trade-off。 最常见的对称加密算法就是AES算法了 一般对称加密有如下几种模式 MODE_ECB 电码本模式(Electronic Codebook) 这种模式是将整个明文分成若干段相同的小段，然后对每一小段进行加密 优点: 简单； 有利于并行计算； 误差不会被传送； 缺点: 1. 不能隐藏明文的模式； 2. 可能对明文进行主动攻击； MODE_CBC = 2 密码分组链接模式（Cipher Block Chaining) 这种模式是先将明文切分成若干小段，然后每一小段与初始块或者上一段的密文段进行异或运算后，再与密钥进行加密。 优点： 不容易主动攻击,安全性好于ECB,适合传输长度长的报文,是SSL、IPSec的标准。 　　 缺点： 不利于并行计算； 误差传递； 需要初始化向量IV MODE_CFB = 3 密码反馈模式（Cipher FeedBack) 优点： 1. 隐藏了明文模式; 2. 分组密码转化为流模式; 3. 可以及时加密传送小于分组的数据; 缺点: 1. 不利于并行计算; 2. 误差传送：一个明文单元损坏影响多个单元; 3. 唯一的IV; MODE_OFB = 5 输出反馈模式(Output FeedBack) 优点: 隐藏了明文模式; 分组密码转化为流模式; 可以及时加密传送小于分组的数据; 缺点: 1. 不利于并行计算; 2. 对明文的主动攻击是可能的; 3. 误差传送：一个明文单元损坏影响多个单元; MODE_CTR = 6 计数器模式（Counter) 计算器模式不常见，在CTR模式中， 有一个自增的算子，这个算子用密钥加密之后的输出和明文异或的结果得到密文，相当于一次一密。这种加密方式简单快速，安全可靠，而且可以并行加密，但是 在计算器不能维持很长的情况下，密钥只能使用一次 MODE_OPENPGP = 7 OpenPGP 模式 AES AES算法,即高级加密标准（英语：Advanced Encryption Standard，缩写：AES），在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。经过五年的甄选流程，高级加密标准由美国国家标准与技术研究院（NIST）于2001年11月26日发布于FIPS PUB 197，并在2002年5月26日成为有效的标准。2006年，高级加密标准已然成为对称密钥加密中最流行的算法之一 from Crypto.Cipher import AES from Crypto import Random key = 'This is a key123' iv = Random.new().read(AES.block_size)#iv,AES需要block_size = 16位的随机bytes iv b'H\\t\\x80X\\xbe|\\x7f\\x1e\\xace8~\\x91?\\xc0P' obj = AES.new(key, AES.MODE_CBC, iv) message = \"The answer is no\" ciphertext = obj.encrypt(message) ciphertext b'\\xf3\\x80L\\x1cV9D\\x17L\\xe1Igb\\xda\\x9c\\xee' obj2 = AES.new(key, AES.MODE_CBC, iv) obj2.decrypt(ciphertext) b'The answer is no' DES DES全称为Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法，1977年被美国联邦政府的国家标准局确定为联邦资料处理标准（FIPS），并授权在非密级政府通信中使用，随后该算法在国际上广泛流传开来。需要注意的是，在某些文献中，作为算法的DES称为数据加密算法（Data Encryption Algorithm,DEA），已与作为标准的DES区分开来 from Crypto.Cipher import DES key = 'abcdefgh' obj=DES.new(key, DES.MODE_ECB) message=\"Guido van Rossum is a space alien.\" len(message) 34 DES的加密数据长度必须是8的整数倍 ciph=obj.encrypt(message+'XXXXXX')# 加密 ciph b'\\x11,\\xe3Nq\\x8cDY\\xdfT\\xe2pA\\xfa\\xad\\xc9s\\x88\\xf3,\\xc0j\\xd8\\xa8\\xca\\xe7\\xe2I\\xd15w\\x1d61\\xc3dgb/\\x06' obj.decrypt(ciph) b'Guido van Rossum is a space alien.XXXXXX' 非对称加密 非对称加密是当今世界用的最多的一种加密形式,它使用一对秘钥而不是一个秘钥来实现加密解密, 这两个秘钥是公开密钥（public key，简称公钥）和私有密钥（private key，简称私钥） 他们的用法如下图 简单说就是发送方用接收方的公钥加密数据,接收方再用自己的私钥解码数据,因此两个人要加密交流必须各自都有公钥私钥,然后相互交换过公钥才行 RSA 常见的非对称加密算法是RSA RSA算法基于一个十分简单的数论事实：将两个大质数相乘十分容易，但是想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥.具体的算法介绍可以看阮一峰的这篇介绍文 生成秘钥 from Crypto.PublicKey import RSA from Crypto import Random random_generator = Random.new().read random_generator > key = RSA.generate(2048,random_generator)# rsa算法生成实例 # 秘钥对的生成 private_pem = key.exportKey() private_pem b'-----BEGIN RSA PRIVATE KEY-----\\nMIIEpQIBAAKCAQEA4CfM+MJLzygGFes8BtnH6Vu8rYRbWbFQQSTq5v4qU9LNi0bG\\nFHxfKjHleA9i+lwZcPRfvQtv89TC4RN8uudZ4UCKEpYwEli6x+7Bu4xYa1x3PHSg\\nv/YL7yoaeXHl5wrXPE9UoTvgiP4JWJ9+4+FuXRUMApkcKhSckgJXM5yyfFB/Gt9K\\nWbsa29zbKWdI5Q3TklVUaid147rUcQen0yfJ1t5LptcHSnndCYBOfGwttDzv5yAs\\nfaa0q0xq5hDqFlxJvXWx68eqhia24wImpqWu9JzGLZxOgmUwtEzN7x7NdWXTPHql\\ny/bVLu8GqFGdB9D5/MKz4Wku6CpEGCM/duH15wIDAQABAoIBAQDWucnEUnvEihaq\\nUJlEBsNWbCamIbBQj2bNwMu1U6zAd6Om07lUTn/rL7kd9b9fDXLhnXdI5Pftn9a/\\nPaeyc4TKHsUlYPHT4WOruq+jNaJN1lnyc9a5jL2J8c9CnzUYym28vFHZ0j4ZfSD+\\n4GrxaTYLvOmwY3NzbCNASzW1n1nrcnV+OeiG0Lb3lZUJ0TiHXAI1ZMn47ov0LEdP\\nbFxeR3Up7LguKveUc6PLH6b4lviy4Qbf96f8ZdiNJSkHjPm0rL0j3ZPWaE/cZzvE\\nawk+nMZQ/DJq1in1oQvzRQQgsGl81Ix3xpu/ni46uUjMur7Vb5Kev39xmUzMNiVz\\nDpsUOp5BAoGBAONtYqlYmoJkpp4Mhv+ZxhZ4zUaaPwCKIVhli+U/Q/MvWKtiIN5U\\nzpzTrXDdcwPyVolF/tbmgcPKZ+M16h3oWuBDHMds0uMnHpWxodrD0TLH3038hiE7\\nxtZ19ETALn6vGHQihtf4jKEyWn2ECrjxD5+hQGF4dT4XKlriDDJ8UO5vAoGBAPxR\\nL4xu8Zi1iJ9npwqsjnCtZOPi05wDGgykdwffP0eicQykiq8rFyWH1lkDHU2JOpMO\\na16s5UaIAenYJ3HkWgnHfKeKJRUfW4sFA+u+I3VyjpP5I0VzEeSGutP2RbgbA0xb\\n2i51gUaHSlKr2u5EI4c4J5dzHI+6RDsN+zMBGawJAoGAP+6E+KP+sz8GE5Hj9UBO\\nDg0hb4J2yXkLDKVnISeau2cI3wyzvqxKdI2QyRSHe4mJSAeULucXfWmNsLJ8QLIL\\nsdVL5sextMdPcrc/j5bSXRsQrASb1AXQzILWCumXaGdiUWtPSrEFH19fTr9qoDir\\nsq0Kwxuwoaazcl7vHNYTjiMCgYEA7m4hiolEUFQrOMcQOKv7JksULayo3qKnuQ6p\\nVI0IFT9RqOrMCt+jTdnhGdgxlpV4/oH/wEWNm2rms/2IuL1awCb8iq2mgSFStjoV\\nDG5uv4tzZC1nwTcNz2/pmGb+Vw1fvoaF1KVBdk5eU2UGy2UkVaEg+KLUeJVB6LQ7\\njmUZx1ECgYEAxJpbacrbNjEHazmMDmNwqBsqF2qvC+jnPD8QbwqefTUENiJeOzwd\\nQPwvAQAI3GD5FlUF2EjjRR/cNoAnU3UBk3csCvIu/XD40cZABdF+hn3EGQyqko3n\\ntZlgjrxAKu6Pq4eClxqaYuTSNk7dvU0rLmbdZx8C8svfLlLZMeyCvME=\\n-----END RSA PRIVATE KEY-----' public_pem = key.publickey().exportKey() public_pem b'-----BEGIN PUBLIC KEY-----\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4CfM+MJLzygGFes8BtnH\\n6Vu8rYRbWbFQQSTq5v4qU9LNi0bGFHxfKjHleA9i+lwZcPRfvQtv89TC4RN8uudZ\\n4UCKEpYwEli6x+7Bu4xYa1x3PHSgv/YL7yoaeXHl5wrXPE9UoTvgiP4JWJ9+4+Fu\\nXRUMApkcKhSckgJXM5yyfFB/Gt9KWbsa29zbKWdI5Q3TklVUaid147rUcQen0yfJ\\n1t5LptcHSnndCYBOfGwttDzv5yAsfaa0q0xq5hDqFlxJvXWx68eqhia24wImpqWu\\n9JzGLZxOgmUwtEzN7x7NdWXTPHqly/bVLu8GqFGdB9D5/MKz4Wku6CpEGCM/duH1\\n5wIDAQAB\\n-----END PUBLIC KEY-----' 加密 from Crypto.Cipher import PKCS1_v1_5 as Cipher_pkcs1_v1_5 import base64 message = 'hello , this is a test text' rsakey = RSA.importKey(public_pem) cipher = Cipher_pkcs1_v1_5.new(rsakey)#加密 cipher_text = base64.b64encode(cipher.encrypt(message.encode(\"utf-8\")))#序列化 cipher_text b'BXD6hPYLRHFZPRKS8k+BLM7MdhVJd95H81AAHOlpDtoiNVY0kx9M6+bovp2lJNnCQQW7SdXgUa3jU3tc75x7lhKWw/+ZqdPZLa7u4lD+cvz4gsT3XzTxvjd7mB0KFnoUrsR/x+3/R1X0IuBksZoQfXhtEd4Mtadikj2NSLEFxYxxfS8iZz0Ds4Cq8/nY2bw9a8o70hXJPyiLTlt2e2sIWQpBUq/lgA6zDrtgt92TQFAAWG+iy9DM8Jmj5O5lEiL47XO2rD5h5GWtTG+mkhUfLkmdw01ekf541AZAPEaGjvkkuju56r77vgVELw9pWbfIriu0BaAXXLk7q+2dnGzPpA==' 解密 rsakey = RSA.importKey(private_pem) cipher = Cipher_pkcs1_v1_5.new(rsakey) text = cipher.decrypt(base64.b64decode(cipher_text), random_generator)#解密 text b'hello , this is a test text' 我们将这对钥匙保存起来 with open('source/private.pem', 'wb') as f: f.write(private_pem) with open('source/public_pem', 'wb') as f: f.write(public_pem) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:01:57 "},"基础应用篇/信息安全/结语.html":{"url":"基础应用篇/信息安全/结语.html","title":"结语","keywords":"","body":"结语 python标准库提供了最最基本的信息安全工具,虽然提供的md5,SHA1已经被破解了,但忽悠忽悠外行还是可以. 相关扩展和模块 itsdangerous 用于将信息传入未知渠道时的加盐序列化算法,web应用中比较常用 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 15:02:54 "},"人机交互篇/":{"url":"人机交互篇/","title":"人机交互篇","keywords":"","body":"人机交互篇 人机交互历史发展概览 自人类发明计算机以来,人机交互就是一个课题,在”远古时期”,人机交互靠打孔纸片,因此只有专业人员才能利用计算机做各种各样的事儿. 再后来有了通用计算机,有了unix,大家通过terminal在shell里用命令行工具与计算机交互.再到后来mac,windows的出现以及鼠标的诞生带来了交互的革命, 人们可以通过点击屏幕上的对应位置来与计算机交互了,这就是gui,再到后来互联网革命,机器交互成了人与人交互的一个媒介,在交互设计思路上产生了很大的变革, 而现如今的移动端交互革命又带来了新的挑战,小屏幕以及各种传感器的引入大大增加了交互的可用维度,降低了交互成本,现在前沿的VR,AR,MR技术也同样无疑的会带来更低的交互成本和更好的交互体验. 但更加明显的是,人机交互的革命既是一个交互成本降低的过程,又是一个程序复杂度和计算机硬件要求指数级增加的过程. 越是人易于使用的交互方式越是需要复杂的程序结构和高性能的硬件支撑.而设计和美学也在人机交互中占有越来越大的比例. 以至于不懂计算机的小白往往把人机交互作为设计,美工的研究课题.学计算机科学的同学们表示相当无奈. 可以看到人机交互的发展历史就是一个机器迁就用户,程序员迁就机器的发展过程. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:37:23 "},"人机交互篇/使用python编写命令行工具.html":{"url":"人机交互篇/使用python编写命令行工具.html","title":"使用python编写命令行工具","keywords":"","body":"命令行工具 计算机最基础的应用就是命令行工具了,众所周知的linux便是因为拥有shell和一众方便好用的命令行工具而备受程序员和geek喜欢. 这种交互方式优缺点都很显而易见,因此喜欢的人非常喜欢,不喜欢的人非常不喜欢. 优点 功能简单单一,使用灵活 一般命令行工具都是很小巧简单,专注只做一件事 形式统一,对开发人员更友好 命令行工具只接收固定的参数运作,以一问一答的形式或者指派开始进程,指派结束进程的方式与人交互,几乎可以说没有太多的交互可言,因此便于开发 便于自动化 可以通过脚本将多个工具串联实现复杂功能 缺点 交互不友好 命令行工具几乎没有交互可言,因此看起来比较丑陋而且不连贯 选择困难 对于一般不熟悉的用户,众多的工具会让人无从下手 跨平台学习成本高 linux,windows都有各自的系统接口和语言环境,他们往往并不通用,因此工具可移植性比较差,不同平台要记不同的命令增加了学习成本. 使用脚本语言编写命令行工具 静态语言编写命令行工具虽然便于分发,但写起来太过费事因此往往不是快速开发最好的选择 现在的很多工具都是用脚本语言写的,为了让脚本语言写的工具用起来像静态语言编写的那样,不用声明使用的是什么解释器, 在unix和它的衍生平台上,我们常在脚本开头写上比如: #!/usr/bin/env python 这样的标识,这叫Shebang (Unix), 之后再使用chmod +x 为全局赋予执行权限,或者使用chmod u+x 为当前用户提供执行权限. 而在windows上,我们可以通过后缀选择运行的工具. 使用python编写命令行工具 python的简易语法和很多很\"魔法\"的语言工具,非常适合编写命令行工具.其标准库就已经提供了足够好用的命令行参数解析工具,而社区很多有才的开发者又设计了许多对开发人员更加友好的同类工具,本文将对几个典型的工具做说明. 标准库中的命令行解析工具(argparse) python标准库中的argparse模块是官方推荐的命令行工具.它可以解析命令行参数,可以生成次级菜单等 基本命令 argparse模块的命令可以归结为就3条 parser = argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True) 创建命令行解析对象 其中的参数: prog - 程序的名字（默认：sys.argv[0]） usage - 描述程序用法的字符串（默认：从解析器的参数生成） description - 参数帮助信息之前的文本（默认：空） epilog - 参数帮助信息之后的文本（默认：空） parents - ArgumentParser 对象的一个列表，这些对象的参数应该包括进去 像有时候需要解析非常复杂的关键字参数,比如像git那样的, import argparse parent_parser = argparse.ArgumentParser(add_help=False) parent_parser.add_argument('--parent', type=int) foo_parser = argparse.ArgumentParser(parents=[parent_parser]) foo_parser.add_argument('foo') foo_parser.parse_args(['--parent', '2', 'XXX']) Namespace(foo='XXX', parent=2) bar_parser = argparse.ArgumentParser(parents=[parent_parser]) bar_parser.add_argument('--bar') bar_parser.parse_args(['--bar', 'YYY']) Namespace(bar='YYY', parent=None) formatter_class - 定制化帮助信息的类 prefix_chars - 可选参数的前缀字符集（默认：‘-‘） fromfile_prefix_chars - 额外的参数应该读取的文件的前缀字符集（默认：None） argument_default - 参数的全局默认值（默认：None） conflict_handler - 解决冲突的可选参数的策略（通常没有必要） add_help - 给解析器添加-h/–help 选项（默认：True） parser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest]) 增加命令行参数,方法的参数说明如下: name or flags 命令行参数名或者选项，如上面的address或者-p,--port.其中命令行参数如果没给定，且没有设置defualt，则出错。但是如果是选项的话，则设置为None,add_argument() 方法必须知道期望的是可选参数，比如-f 或者--foo，还是位置参数，比如一个文件列表。传递给add_argument() 的第一个参数因此必须是一个标记序列或者一个简单的参数名字。例如，一个可选的参数可以像这样创建： action action 关键字参数指出应该如何处理命令行参数。支持的动作有: 'store' - 只是保存参数的值。这是默认的动作 'store_const' - 保存由const关键字参数指出的值。（注意const关键字参数默认是几乎没有帮助的None。）'store_const'动作最常用于指定某种标记的可选参数 'store_true'和'store_false' - 它们是'store_const' 的特殊情形，分别用于保存值True和False。另外，它们分别会创建默认值False 和True。 'append' - 保存一个列表，并将每个参数值附加在列表的后面。这对于允许指定多次的选项很有帮助。示例用法： 'append_const' - 保存一个列表，并将const关键字参数指出的值附加在列表的后面。（注意const关键字参数默认是None。）'append_const' 动作在多个参数需要保存常量到相同的列表时特别有用。例如： 'count' - 计算关键字参数出现的次数。例如，这可用于增加详细的级别： 'help' - 打印当前解析器中所有选项的完整的帮助信息然后退出。默认情况下，help动作会自动添加到解析器中。参见ArgumentParser以得到如何生成输出信息。 'version' - 它期待version=参数出现在add_argument()调用中，在调用时打印出版本信息并退出： nargs 命令行参数的个数，一般使用通配符表示，其中，'?'表示只用一个，'*'表示0到多个，'+'表示至少一个 default 默认值 type 参数的类型，默认是字符串string类型，还有float、int,file等类型 choices 可以看做是default的扩展,参数的值必须在choices的范围内 required 一般情况下，argparse模块假定-f和--bar标记表示可选参数，它们在命令行中可以省略。如果要使得选项是必需的，可以指定True作为required=关键字参数的值给add_argument() help 和ArgumentParser方法中的参数作用相似，出现的场合也一致 parser.parse_args() 执行解析命令行参数 一个简单的例子 我们来写一个实现求整数开根的命令行工具,它有--help(-h)和--version(-v)两个参数信息 代码如下: %%writefile src/python/std/sqrt_std.py #!/usr/bin/env python # -*- coding:utf-8 -*- from __future__ import print_function import argparse from math import sqrt __version__=\"0.1.0\" def sqrtarg(number): return sqrt(number) def version(): return \"version:\"+__version__ def main(): parser = argparse.ArgumentParser() parser.add_argument(\"number\", type=int, help=u\"求开根的参数\") parser.add_argument(\"-v\",\"--version\", help=u\"查看版本号\",action=\"store_true\") args = parser.parse_args() if args.version: print(version()) if args.number: print(sqrtarg(args.number)) if __name__ == '__main__': main() Writing src/python/std/sqrt_std.py !python src/python/std/sqrt_std.py usage: sqrt_std.py [-h] [-v] number sqrt_std.py: error: the following arguments are required: number !python src/python/std/sqrt_std.py -h usage: sqrt_std.py [-h] [-v] number positional arguments: number 求开根的参数 optional arguments: -h, --help show this help message and exit -v, --version 查看版本号 !python src/python/std/sqrt_std.py 36 6.0 运行细节 type参数只是类型检验,传入的参数还是字符串 不需要写usage 有nargs参数的话获取的对应是一个list 参数传入实际上是被存入了一个namespace的空间中这个空间有俩参数,其中一个是方法名命名的一个list,要调用使用即可: args.方法名 如果参数中有只能接受一个的情况,可以加入判断 if args.methodname1 == args.methodname1: print 'usage: ' + __file__ + ' --help' sys.exit(2) 来判断两个参数,要么都存在， 要么都不存在， 即可满足要求 子解析 如果要写一个类似git那样复杂的有子命令如add,push pull等的工具,单单用上面的解析工具是不够的,需要使用add_subparsers([title][, description][, prog][, parser_class][, action][, option_string][, dest][, help][, metavar])命令 其中: title - 在输出的帮助中子解析器组的标题；默认情况下，如果提供description参数则为“subcommands”，否则使用位置参数的标题 description - 在输出的帮助中子解析器组的描述，默认为None prog - 与子命令的帮助一起显示的使用帮助信息，默认为程序的名字和子解析器参数之前的所有位置参数 parser_class - 用于创建子解析器实例的类，默认为当前的解析器（例如ArgumentParser） dest - 子命令的名字应该存储的属性名称；默认为None且不存储任何值 help - 在输出的帮助中子解析器中的帮助信息，默认为None metavar - 在帮助中表示可用的子命令的字符串；默认为None并以{cmd1, cmd2, ..}的形式表示子命令 parser = argparse.ArgumentParser() parser.add_argument('--foo', action='store_true', help='foo help') subparsers = parser.add_subparsers(help='sub-command help') parser_a = subparsers.add_parser('a', help='a help') parser_a.add_argument('bar', type=int, help='bar help') parser_b = subparsers.add_parser('b', help='b help') parser_b.add_argument('--baz', choices='XYZ', help='baz help') parser.parse_args(['a', '12']) Namespace(bar=12, foo=False) parser.parse_args(['--foo', 'b', '--baz', 'Z']) Namespace(baz='Z', foo=True) 处理子命令的一个特别有效的方法是将add_subparsers()方法和set_defaults() 调用绑在一起使用，这样每个子命令就可以知道它应该执行哪个Python 函数。例如： def foo(args): print(args.x * args.y) def bar(args): print('((%s))' % args.z) parser = argparse.ArgumentParser() subparsers = parser.add_subparsers() parser_foo = subparsers.add_parser('foo') parser_foo.add_argument('-x', type=int, default=1) parser_foo.add_argument('y', type=float) parser_foo.set_defaults(func=foo) parser_bar = subparsers.add_parser('bar') parser_bar.add_argument('z') parser_bar.set_defaults(func=bar) args = parser.parse_args('foo 1 -x 2'.split()) args Namespace(func=, x=2, y=1.0) args.func(args) 2.0 args = parser.parse_args('bar XYZYX'.split()) args Namespace(func=, z='XYZYX') args.func(args) ((XYZYX)) 这样的话，你可以让parse_args()在参数解析完成之后去做调用适当的函数的工作。像这种方式将函数和动作关联起来是最简单的方法来处理你每个子命令的不同动作。然而，如果需要检查调用的子命令的名字，用dest关键字参数调用add_subparsers()就行 parser = argparse.ArgumentParser() subparsers = parser.add_subparsers(dest='subparser_name') subparser1 = subparsers.add_parser('1') subparser1.add_argument('-x') subparser2 = subparsers.add_parser('2') subparser2.add_argument('y') parser.parse_args(['2', 'frobble']) Namespace(subparser_name='2', y='frobble') 参数分组 很多时候参数是相互配合使用的,这就可以用add_argument_group(title=None, description=None)分组 parser = argparse.ArgumentParser(prog='PROG', add_help=False) group1 = parser.add_argument_group('group1', 'group1 description') group1.add_argument('foo', help='foo help') group2 = parser.add_argument_group('group2', 'group2 description') group2.add_argument('--bar', help='bar help') _StoreAction(option_strings=['--bar'], dest='bar', nargs=None, const=None, default=None, type=None, choices=None, help='bar help', metavar=None) parser.print_help() usage: PROG [--bar BAR] foo group1: group1 description foo foo help group2: group2 description --bar BAR bar help 要一组参数互斥,可以使用add_mutually_exclusive_group(required=False) required 参数，用于指示互斥分组中至少有一个参数是必需的 parser = argparse.ArgumentParser(prog='PROG') group = parser.add_mutually_exclusive_group(required=True) group.add_argument('--foo', action='store_true') group.add_argument('--bar', action='store_false') parser.parse_args([\"--foo\",\"--bar\"]) usage: PROG [-h] (--foo | --bar) PROG: error: argument --bar: not allowed with argument --foo An exception has occurred, use %tb to see the full traceback. SystemExit: 2 /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D. warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1) parser.parse_args([]) usage: PROG [-h] (--foo | --bar) PROG: error: one of the arguments --foo --bar is required An exception has occurred, use %tb to see the full traceback. SystemExit: 2 /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D. warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1) parser.parse_args([\"--foo\"]) Namespace(bar=True, foo=True) 多级子命令 如果我们的命令行工具有更加复杂的子命令解析需求,那么我们可以使用如下的方式做扩展: class Command: def __init__(self, argv): parser = argparse.ArgumentParser( description='xxxxxx', usage='''xxxx [] The most commonly used xxx commands are: clean clean a project install install a package ''') parser.add_argument('command', help='Subcommand to run') # parse_args defaults to [1:] for args, but you need to # exclude the rest of the args too, or validation will fail self.argv = argv args = parser.parse_args(argv[0:1]) if not hasattr(self, args.command): print('Unrecognized command') parser.print_help() exit(1) # use dispatch pattern to invoke method with same name getattr(self, args.command)() def clean(self): parser = argparse.ArgumentParser( description='clean a project') parser.add_argument( '-A', '--all', action='store_true') parser.set_defaults(func=clean) args = parser.parse_args(self.argv[1:]) args.func(args) def install(self): parser = argparse.ArgumentParser( description='install a package for this project') parser.add_argument('packages', nargs='?', type=str, default=\"DEFAULT\") parser.add_argument( '-D', '--dev', action='store_true') parser.add_argument( '-T', '--test', action='store_true') parser.add_argument( '-A', '--all', action='store_true') parser.set_defaults(func=install) args = parser.parse_args(self.argv[1:]) args.func(args) print(\"install done!\") def main(argv: Sequence[str]=sys.argv[1:]): Command(argv) 更加pythonic的替代品 实话说python的标准库还是比较有C/C++语言的风格残留的,而现如今的python代码风格会更加'魔法'一些,会用到比较多的装饰器工具. click就是一个比较符合现在python编程风格的工具.它是一个比较重的命令行解析工具,它还包括了参数类型检验等复杂的功能,很适合构建复杂的命令行工具.不过命令行工具做的太复杂就不太符合它的定位了,因此这边不多讲. 他的用法也不复杂,使用python的装饰器声明参数,并自动构建帮助文档,具体的细节可以看官方文档. 所见即所得的命令行的工具(docopt) docopt的特色是利用文件的__doc__,解析命令行参数构建参数组成的字典来自动识别.它可以使用pip安装,并完全支持pypy 我们用docopt改写上面的开方工具 %%writefile src/python/doc/sqrt_doc.py #!/usr/bin/env python # coding:utf-8 u\"\"\" Usage: test1.py [option] ... test1.py (-v|--version) test1.py (-a|--all) test1.py (-h|--help) Options: -h --help 帮助 -v --version 显示版本号. -a --all 显示全部参数 \"\"\" from docopt import docopt from math import sqrt __version__=\"0.1.0\" def version(): return \"version:\"+__version__ def main(): args = docopt(__doc__) if args.get(\"-h\") or args.get(\"-help\"): print(__doc__) elif args.get(\"-v\") or args.get(\"--version\"): print(__version__) elif args.get(\"-a\") or args.get(\"--all\"): print(args) elif args.get(\"\"): print(\" \".join(map(lambda x :str(sqrt(float(x))),args.get(\"\")))) else: print(\"wrong args!\") print(__doc__) if __name__ == '__main__': main() Writing src/python/doc/sqrt_doc.py !python src/python/doc/sqrt_doc.py Usage: test1.py [option] ... test1.py (-v|--version) test1.py (-a|--all) test1.py (-h|--help) !python src/python/doc/sqrt_doc.py -a {'--all': True, '--help': False, '--version': False, '': [], 'option': False} !python src/python/doc/sqrt_doc.py -v 0.1.0 !python src/python/doc/sqrt_doc.py -h Usage: test1.py [option] ... test1.py (-v|--version) test1.py (-a|--all) test1.py (-h|--help) Options: -h --help 帮助 -v --version 显示版本号. -a --all 显示全部参数 !python src/python/doc/sqrt_doc.py 36 6.0 细节 用<>包裹表示参数,如果参数后面有...则表示参数是列表 用[]包裹选项 用()包裹必选内容 用|区分选项 这边有一个详细的匹配细节和测试工具 docopt写起来并不会省代码,但它所见即所得,更加直观,当你写完注释的时候你的命令行解析也实现了. 补充1:命令行显示循环美化 tqdm是一个进度条工具,除了可以给命令行工具增加进度条看出进度外,还可以用于jupyter-notebook tqdm模块的tqdm类是这个包的核心,所有功能都是在它上面衍生而来 tqdm类 可以包装可迭代对象,它的实例化参数有: desc : str, optional 放在bar前面的描述字符串 total : int, optional 显示多长 leave : bool, optional 结束时时保留进度条的所有痕迹。 file : io.TextIOWrapper or io.StringIO, optional 输出到文件 ncols : int, optional 自定义宽度 mininterval : float, optional 更新最短时间 maxinterval : float, optional 更新最大时间 miniters : int, optional 每次更新最小值 ascii : bool, optional 使用ascii碼显示 disable : bool, optional 是否禁用整个progressbar unit : str, optional 显示的更新单位 unit_scale : bool, optional 根据单位换算进度 dynamic_ncols : bool, optional 可以不断梗概ncols的环境 smoothing : float, optional 用于速度估计的指数移动平均平滑因子（在GUI模式中忽略）。范围从0（平均速度）到1（当前/瞬时速度）[默认值：0.3]。 bar_format : str, optional 指定自定义栏字符串格式。可能会影响性能 initial : int, optional 初始计数器值。重新启动进度条时有用[默认值：0]。 position : int, optional 指定打印此条的线偏移（从0开始）如果未指定，则为自动。用于一次管理多个条 基础的循环 from tqdm import tqdm for i in tqdm(range(int(9e6)),desc=\"test:\"): pass test:: 100%|██████████| 9000000/9000000 [00:02for i in tqdm(range(int(9e6)),desc=\"test\",dynamic_ncols=True): pass test: 100%|██████████| 9000000/9000000 [00:02使用with语句手工更新 with tqdm(total=100) as bar: for i in range(10): bar.update(10) 100%|██████████| 100/100 [00:00补充2: 为命令行工具自动创建gui Gooey是一个可以将python命令行自动转成gui的工具,它依赖wxpython,废话不多说,看例子.我们来将之前的命令行工具转化一下 %%writefile src/python/std/sqrt_std_gui.py #!/usr/bin/env python3 import argparse from math import sqrt from gooey import Gooey, GooeyParser __version__=\"0.1.0\" def sqrtarg(number): return sqrt(number) def version(): return \"version:\"+__version__ @Gooey(language='chinese') def main(): parser = argparse.ArgumentParser() parser.add_argument(\"number\", type=int, help=u\"求开根的参数\") parser.add_argument(\"-v\",\"--version\", help=u\"查看版本号\",action=\"store_true\") args = parser.parse_args() if args.version: print(version()) if args.number: print(sqrtarg(args.number)) if __name__ == '__main__': main() Writing src/python/std/sqrt_std_gui.py !python src/python/std/sqrt_std_gui.py Traceback (most recent call last): File \"src/python/std/sqrt_std_gui.py\", line 4, in from gooey import Gooey, GooeyParser ModuleNotFoundError: No module named 'gooey' 补充: python3命令行工具的发布 我的用python写的脚本直接运行当然是可以,用Shebang结合权限设定也可以在一般的情况下使用,但如果我们的希望它成为可以随时使用的工具,更好的方式是将它用setuptool安装到python的脚本位置(当然也可以上传到pyp上供大家使用), 这边给出两个的setup.py文件作为参考 %%writefile src/python/doc/setup.py from distutils.core import setup import os pathroot = os.path.split(os.path.realpath(__file__))[0] setup( name='sqrt_doc', version='0.1.0', scripts=[pathroot+'/sqrt_doc.py'] ) Writing src/python/doc/setup.py !python src/python/doc/setup.py install running install running build running build_scripts copying and adjusting /Users/huangsizhe/WORKSPACE/github/hsz1273327/TutorialForPython/ipynbs/人机交互篇/src/python/doc/sqrt_doc.py -> build/scripts-3.6 running install_scripts copying build/scripts-3.6/sqrt_doc.py -> /Users/huangsizhe/anaconda3/bin changing mode of /Users/huangsizhe/anaconda3/bin/sqrt_doc.py to 755 running install_egg_info Writing /Users/huangsizhe/anaconda3/lib/python3.6/site-packages/sqrt_doc-0.1.0-py3.6.egg-info !sqrt_doc.py 48 6.928203230275509 将std文件夹中文件结构改成 |-lib\\ | |-__init__.py | |-sqrt_std.py |-setup.py %%writefile src/python/std/setup.py from setuptools import setup,find_packages import os pathroot = os.path.split(os.path.realpath(__file__))[0] setup( name='sqrt_std', version='0.1.0', packages = find_packages(), entry_points = { 'console_scripts': ['sqrt_std=lib.sqrt_std:main'], } ) Writing src/python/std/setup.py 之后到目录下开始编译 python setup.py install Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:36:59 "},"人机交互篇/自定义交互式界面.html":{"url":"人机交互篇/自定义交互式界面.html","title":"自定义交互式界面","keywords":"","body":"自定义交互式界面(cmd) 有时候我们希望我们的服务有一个可交互的客户端,就像数据库操作. Python提供了交互界面的自定义功能,通过cmd模块我们可以将一些指令放入交互界面中,便于直接调用 我们制作一个python自带的绘图工具turtle的交互界面作为例子: %%writefile src/turtleshell.py #!/usr/bin/env python # --*-- coding:utf-8 --*-- from __future__ import print_function import cmd, sys from turtle import * class TurtleShell(cmd.Cmd): intro = 'Welcome to the turtle shell. Type help or ? to list commands.\\n' prompt = '(turtle) ' file = None # ----- basic turtle commands ----- def do_forward(self, arg): 'Move the turtle forward by the specified distance: FORWARD 10' forward(*parse(arg)) def do_right(self, arg): 'Turn turtle right by given number of degrees: RIGHT 20' right(*parse(arg)) def do_left(self, arg): 'Turn turtle left by given number of degrees: LEFT 90' left(*parse(arg)) def do_goto(self, arg): 'Move turtle to an absolute position with changing orientation. GOTO 100 200' goto(*parse(arg)) def do_home(self, arg): 'Return turtle to the home position: HOME' home() def do_circle(self, arg): 'Draw circle with given radius an options extent and steps: CIRCLE 50' circle(*parse(arg)) def do_position(self, arg): 'Print the current turle position: POSITION' print('Current position is %d %d\\n' % position()) def do_heading(self, arg): 'Print the current turle heading in degrees: HEADING' print('Current heading is %d\\n' % (heading(),)) def do_color(self, arg): 'Set the color: COLOR BLUE' color(arg.lower()) def do_undo(self, arg): 'Undo (repeatedly) the last turtle action(s): UNDO' def do_reset(self, arg): 'Clear the screen and return turtle to center: RESET' reset() def do_bye(self, arg): 'Stop recording, close the turtle window, and exit: BYE' print('Thank you for using Turtle') self.close() bye() return True # ----- record and playback ----- def do_record(self, arg): 'Save future commands to filename: RECORD rose.cmd' self.file = open(arg, 'w') def do_playback(self, arg): 'Playback commands from a file: PLAYBACK rose.cmd' self.close() with open(arg) as f: self.cmdqueue.extend(f.read().splitlines()) def precmd(self, line): line = line.lower() if self.file and 'playback' not in line: print(line, file=self.file) return line def close(self): if self.file: self.file.close() self.file = None def parse(arg): 'Convert a series of zero or more numbers to an argument tuple' return tuple(map(int, arg.split())) if __name__ == '__main__': TurtleShell().cmdloop() Writing src/turtleshell.py 在命令行运行下试试 (turtle) CIRCLE 50 (turtle) bye 接着是一个支持sqlite,mysql,pg的命令行客户端 %%writefile src/sqlshell.py #!/usr/bin/env python3 import argparse import cmd, sys import pandas as pd import readline from playhouse.db_url import connect class SqlShell(cmd.Cmd): def __init__(self,completekey='tab', stdin=None, stdout=None,sql_uri=None): super().__init__(completekey=completekey, stdin=stdin, stdout=stdout) self.uri = sql_uri or \"sqlite:///:memory:\" self.db = connect(self.uri) self.db.connect() self.intro = 'Welcome to the sql shell. Type help or ? to list commands.\\n' self.prompt = \"(\"+self.uri.split(\"://\")[0]+\" Writing src/sqlshell.py Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:36:52 "},"人机交互篇/GUI/":{"url":"人机交互篇/GUI/","title":"GUI","keywords":"","body":"GUI 鼠标和微软苹带来了GUI这种交互方式,它的最大特点是图像化,依靠点击来选择指令,而且一般除了主页面外,还会有多层的子页面.交互模式开始复杂了起来. 从GUI诞生开始,设计和美学开始进入这个领域,而对用户的友好程度成为了一个软件的衡量标准之一. 本文的执行环境需要自己为ipython notebook编写的子进程执行魔术命令%exec_py,可以参考这篇文章自行实现和配置. GUI的设计原则 GUI的图形化特点带了了用户学习难度的降低,因此GUI包括后来的各种交互模式的设计最重要的就是以人为本,关注用户体验 必须考虑目标用户群体是个什么样的群像 必须考虑用户的学习成本,突出简化最主要的需求的操作,并尽量让用户用更少的步骤完成需求 设计应该符合常识习惯 避免频繁的切换界面,界面间应该风格统一和谐 本文的GUI编程攻略是针对python标准库Tkinter,网络上相关的资料比较少,因此很多人对其有\"难用\"的映像,实际上Tkinter可以说是最符合Python风格的gui框架了--极少的组件通过简单组合就可以构造一个简洁够用的GUI界面. 本文的执行环境需要自己为ipython notebook编写的子进程执行魔术命令%exec_py,可以参考这篇文章自行实现和配置. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:40:17 "},"人机交互篇/GUI/TK框架GUI编程的基本思路.html":{"url":"人机交互篇/GUI/TK框架GUI编程的基本思路.html","title":"TK框架GUI编程的基本思路","keywords":"","body":"TK框架GUI编程的基本思路 首先我们来明确几个单词以明确Gui编程语境下的基本上下文环境. 窗口(window) 就是在屏幕上打开一个窗口,GUI的最上层单元,实际上GUI程序就是一个循环,平时一直空转等待事件,当发生事件后就由回调函数执行对应操作. 窗口打开程序执行,窗口关闭程序退出. 框架(Frame) 就是屏幕上的一块矩形区域,多是用来作为容器(container)来布局窗口 控件(widget) 就是具体的可操作可交互块,比如按钮,文本框,包括窗口,帧等都是. 事件(event) 指的是一个用于改变控件/帧/窗口等对象状态的触发信号 回调函数(callback) 指的是在外部定义好的控件/帧/窗口等在接收到事件后处理事件的方法. 网格(grid) 指的是堆放控件的一种常用方式,控件可摆放的位置按从上到下,从左到右的顺序获得一个二维的编号,组件按照编号放置在网格对应的位置上. 像素(pixel) 显示设备上用于显示图像的最小单位,每个像素就是一个发光点,GUI的图形本质上就是这些点的组合. GUI编程的基本架构模式 通常gui编程就是将模块的接口使用gui组合包装起来,在不同的情况下调用不同的接口从而达到方便用户使用的目的.因此GUI编程基本可以使用mvc结构进行分解,即: Model 模型,也就是业务模型,实际业务的内容 View 视图,也就是GUI中的图形组合 Controller 控制器,也就是连接视图与模型的组件,通常使用事件模型传递控制信息. 这3层相互独立,同常通过接口进行交互,但通常使用Tk的时候Controller作为application的住体,model和view则是作为主体的嵌入.model部分本文不会多做描述,而gui编程更加关心的是视图和控制器部分. 对MVC结构更多的理解可以看一些其他的书籍,推荐阮一峰先生的这篇博客,讲的浅显易懂,每次看都可以有新的收获. 视图部分 视图部分主要是管用户实际看到的内容,因此除了堆砌组件外,设计也是一门技术活.视图也就基本可以分为组件和布局两个部分. 像C#,QT这种库一个最方便的地方是可以通过工具所见即所得的组织组件,python自带的Tkinter并没有提供这个工具.但其实是有一个类似工具的http://page.sourceforge.net/#Download, 它的安装需要先安装了TCL环境(需翻墙)activetcl,不过使用工具生成的代码会比较难以维护,还是更加推荐手动编写,毕竟很简单. 视图的组件 在python标准库中有3个库提供了tk的控件,分别是 tkinter tk的基本库,提供的控件包括: 控件名类型 意义 Toplevel 顶层帧 Frame 框架 LabelFrame 标签框架 Button 按钮 Canvas 画板 Checkbutton 复选框 Entry 输入框 Label 标签 Listbox 列表框 Menu 菜单栏 Menubutton 菜单按钮 Message 信息栏 OptionMenu 选项菜单 PanedWindow 中分栏窗口 Radiobutton 单选框 Scale 滑块 Scrollbar 滚动条 Spinbox 指定输入范围值的输入框 Text 文本框 tkinter.ttk 一个tk的扩展库,提供了更多的样式和控件以及一些控件的美化版本. 优化控件包括: 控件名 说明 Button 按钮 Checkbutton 复选框 Entry 输入框 Frame 框架 Label 标签 LabelFrame 标签框架 Menubutton 菜单按钮 PanedWindow 中分栏窗口 Radiobutton 单选框 Scale 滑块 Scrollbar 滚动条 新增的控件包括: 控件名 说明 Combobox 组合框,包含文本字段和一个包含可选值的下拉列表 Notebook 标签页,形式参见chrome中的标签页 Progressbar 进度条 Separator 分离器,显示一个水平或垂直分隔条 Sizegrip 控制TopLevel的窗口大小 Treeview TreeView控件显示一个项目的树状分层集合 tkinter.scrolledtext 单独的带滚动条的文本框,集成了文本框和滚动条,调用更加方便些 另外还有两个第三方库可以使用,不过由于tk模块年深日久,第三方扩展也历史久远,现在只能直接下载源码使用python setup.py install安装. Python megawidgets提供了更多组件的第三方库 pandastable提供了对表格的支持. 各个控件的接口可以查看这份文档 控件的基本设置方式 在tkinter中每个控件都有一个configure()方法用于设置,设置configure的参数可能各不相同,但其设置方式都是一致的,就是 使用关键字在初始化控件时设置 调用控件对象的configure()方法设置 ttk的控件使用方式和tkinter一致,但设置方式使用ttk.Style()进行全局设置,而非直接在单独的控件中设置. 比如同样是设置label,tkinter中设置方式如下: l1 = tkinter.Label(text=\"Test\", fg=\"black\", bg=\"white\") l2 = tkinter.Label(text=\"Test\", fg=\"black\", bg=\"white\") 而ttk中如下: style = ttk.Style() style.configure(\"BW.TLabel\", foreground=\"black\", background=\"white\") l1 = ttk.Label(text=\"Test\", style=\"BW.TLabel\") l2 = ttk.Label(text=\"Test\", style=\"BW.TLabel\") 控件的组合方式 用过图像编辑软件的读者一定知道图层这一概念,图片是一个一个的图层堆叠组合而成.我们的GUI也是一层一层堆叠而成,最底层必须是TopLevel这个有点类似于画板,通常在其上我们会放上一个帧,这有点像刷个底色图层,之后就是在这个帧上放置其他组件了.最终的gui就是由所有这些组件构成的一颗组件树. 每个组件初始化的第一参数都是它的父级组件,我们可以使用 第一个tkinter程序 %%writefile src/first.py import tkinter tkinter._test() Overwriting src/first.py %exec_py src/first.py 布局思路 有3种方式可以为控件布局: pack() grid() place() pack() pack()默认会一个一个从上往下堆叠,但同样也可以接受几个参数 side (left,top,right,bottom) fill ( X,Y,BOTH 和 NONE)水平方向填充,竖直方向填充,水平和竖直方向填充和不填充。 expand 参数可以是 YES 和 NO anchor (n, ne, e, se, s, sw, w, nw, or center)NESW 表示上右下左以及他们的组合或者是 CENTER(表示中 间)。 ipadx 表示的是内边距的 x 方向 ipady 表示 的是内边距的 y 方向 padx 表示的是外边距的 x 方向 pady 表示的是外边距的 y 方向 %%writefile src/pack.py from tkinter import Frame,Label,Button class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.LabelL = Label(self, text='左边') self.LabelL.pack(side=\"left\") self.LabelR = Label(self, text='右边') self.LabelR.pack(side=\"right\") self.LabelT = Label(self, text='顶') self.LabelT.pack(side=\"top\") self.LabelB = Label(self, text='底') self.LabelB.pack(side=\"bottom\") self.LabelN = Label(self, text='N') self.LabelN.pack(anchor=\"n\") self.LabelE = Label(self, text='E') self.LabelE.pack(anchor=\"e\") self.LabelS = Label(self, text='S') self.LabelS.pack(anchor=\"s\") self.LabelW= Label(self, text='W') self.LabelW.pack(anchor=\"w\") self.LabelCENTER= Label(self, text='CENTER') self.LabelCENTER.pack(anchor=\"center\") self.quitButton = Button(self, text='Quit',background=\"red\", command=self.quit) self.quitButton.pack(side=\"bottom\") if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('pack布局测试') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/pack.py %exec_py src/pack.py grid() 最常用布局 grid()里的参数: row 表示行(从0开始) column 表示列(从0开始) sticky (N,E,S,W) 表 示上右下左,它决定了这个组件是从哪个方向开始的 ipadx,ipady,padx,pady,它们 的意思和 pack 函数是一样的,默认边距是 0。 rowspan 表示跨越的行数 columnspan 表示跨越的列数。 %%writefile src/grid.py from tkinter import Frame,Label,Button class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.Label00 = Label(self, text='00') self.Label00.grid(row=0,column=0) self.Label10 = Label(self, text='10') self.Label10.grid(row=1,column=0) self.Label11 = Label(self, text='11') self.Label11.grid(row=1,column=1) self.Label30 = Label(self, text='30') self.Label30.grid(row=3,column=0) self.quitButton = Button(self, text='Quit',background=\"red\", command=self.quit) self.quitButton.grid(row=2,column=2) if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('grid布局测试') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/grid.py %exec_py src/grid.py 控制部分 Tkinter的控制部分是依靠为控件绑定事件和回调函数来实现的 事件 事件绑定和解绑 bind() unbind() 绑定bind() bind 函数的调用规则: 控件对象.bind(事件类型,回调函数) 事件类型: 事件类型是一组字符串,它采用的描述方式是这样的: MODIFIER 即修饰符,它的全部取值如下: Control Mod1, M1, Command Alt Mod2, M2, Option Shift Mod3, M3 Lock Mod4, M4 Extended Mod5, M5 Button1, B1 Meta, M Button2, B2 Double Button3, B3 Triple Button4, B4 Quadruple Button5, B5 --- TYPE 表示类型,它的全部取值如下: Activate Destroy Map ButtonPress, Button Enter MapRequest ButtonRelease Expose Motion Circulate FocusIn MouseWheel CirculateRequest FocusOut Property Colormap Gravity Reparent Configure KeyPress, Key ResizeRequest ConfigureRequest KeyRelease Unmap Create Leave Visibility Deactivate --- --- DETAIL 表示细节,其实也就是对第二个参数的一些辅助说明。 常用事件类型: 表示鼠标左键单击,其中的 1 换成 3 表示右 键被单击,为 2 的时候表示鼠标中键 表示 A 键被按下,其中的 A 可以换成其他的键位。 表示按下的是 Ctrl 和 V 键,V 可以换成其他 键位。 表示按下的是 F1 键,对于 Fn 系列的,都可以随便 换。 更加具体的可以看http://www.tcl.tk/man/tcl8.5/TkCmd/bind.htm#M23 bind()可以绑定所有继承自Misc类的组件,也就是说即便是标签也可以绑定动作. bind()有两个扩展 窗体对象.bind_all(事件类型,回调函数)全程序级别绑定事件 窗体对象.bind_class(类名,事件类型,回调函数)类级别绑定事件,比如所有标签这样 解绑 unbind() 窗体对象.unbind(事件类型) 我们看一个相对全面一些的例子:记事本 %%writefile src/editer.py import os from tkinter import * from tkinter.messagebox import * from tkinter.filedialog import * class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.filename = \"\" self.creatMenu() self.createWidgets() def creatMenu(self): #主菜单 menubar = Menu(self) #子菜单 menufile = Menu(menubar) menufile.add_command(label = \"打开\",accelerator = \"Ctrl + O\",command = self.myopen) menufile.add_command(label = \"新建\",accelerator = \"Ctrl + N\",command = self.new) menufile.add_command(label = \"保存\",accelerator = \"Ctrl + S\",command = self.save) menufile.add_command(label = \"另存为\",accelerator = \"Ctrl + Shift + S\",command = self.saveas) menuedit = Menu(menubar) menuedit.add_command(label = \"剪切\",accelerator = \"Ctrl + X\",command = self.cut) menuedit.add_command(label = \"复制\",accelerator = \"Ctrl + C\",command = self.copy) menuedit.add_command(label = \"黏贴\",accelerator = \"Ctrl + V\",command = self.paste) menuedit.add_separator() menuedit.add_command(label = \"全选\",accelerator = \"Ctrl + A\", command = lambda :self.textPad.tag_add('sel',1.0,\"end\")) menuaboutme = Menu(menubar) menuaboutme.add_command(label = \"作者\",command = self.author) menuaboutme.add_command(label = \"版权\",command = self.power) #子菜单与主菜单关联 for name,submenu in zip([\"文件\",\"编辑\",\"关于\"],[menufile,menuedit,menuaboutme]): menubar.add_cascade(label=name,menu=submenu) #最关键的一步,主菜单与app关联 self.master.config(menu=menubar) #右键菜单 menu = Menu(self.master) menu.add_command(label = \"剪切\",command = self.cut) menu.add_command(label = \"复制\",command = self.copy) menu.add_command(label = \"黏贴\",command = self.paste) #绑定鼠标右键呼出 if (self.master.tk.call('tk', 'windowingsystem')=='aqua'): self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) else: self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) def createWidgets(self): self.shortcutbar = Frame(self,height = 25,bg = \"light sea green\") self.shortcutbar.pack(expand = NO,fill =X) self.lnlabel = Label(self,width = 2,bg = \"antique white\") self.lnlabel.pack(side = LEFT,anchor = 'nw',fill = Y) self.textPad = Text(self,bg = \"antique white\") self.textPad.pack() self.textPad.insert(INSERT,\"Hello\") self.textPad.insert(END,\"world\") self.textPad.bind(\"\",self.new) self.textPad.bind(\"\",self.new) self.textPad.bind(\"\",self.myopen) self.textPad.bind(\"\",self.myopen) self.textPad.bind(\"\",self.save) self.textPad.bind(\"\",self.save) self.textPad.bind(\"\",lambda : self.textPad.tag_add('sel',1.0,\"end\")) self.textPad.bind(\"\",lambda : self.textPad.tag_add('sel',1.0,\"end\")) def myopen(self): self.filename = askopenfilename(defaultextension = \".txt\") if self.filename == \"\": self.filename = None else: self.master.title(\"一个记事本\"+os.path.basename(self.filename)) self.textPad.delete(\"1.0\",\"end\") with open(self.filename,\"r\") as f: s = f.read() self.textPad.insert(\"1.0\",s) def new(self): self.master.title(\"未命名文件\") self.filename = None self.textPad.delete(\"1.0\",END) def save(self): try: with open(self.filename,\"w\") as f: msg = self.textPad.get(1.0,\"end\") f.write(msg) except : self.saveas() def saveas(self): f = asksaveasfilename(initialfile = \"未命名. txt\",defaultextension = \".txt\") self.filename = f with open(f,\"w\") as fh: msg = self.textPad.get(1.0,\"end\") fh.write(msg) self.master.title(\"一个记事本\"+os.path.basename(f)) def cut(self): self.textPad.event_generate(\">\") def copy(self): self.textPad.event_generate(\">\") def paste(self): self.textPad.event_generate(\">\") def author(self): self.shouinfo(\"作者黄思喆\") def power(self): self.showinfo(\"本软件使用BSD许可证\") if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('一个记事本') #app.master.geometry(\"300x300+100+100\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/editer.py %exec_py src/editer.py 使用xxxcommand设置绑定默认事件的回调 另一种方式是使用xxxcommand绑定默认事件,这个可以看作是官方给的语法糖,多数时候不同的控件会用到的事件也就一两种,官方为其提供了通过简单设置config就可以绑定好回调的方法.比如按钮就可以直接设置Button(self, text='Quit',fg=\"red\", command=self.quit)绑定退出方法. 事件循环 从tk的执行方式上就可以很容易的看出,TK使用的是事件循环来执行GUI行为.在前文中我们介绍过事件循环的原理,TK太老了,到现在依然还没有支持异步协程的写法,倒是有个第三方演示项目asyncio-tkinter.但无论怎么样,事件循环不可以被阻塞,因此通常gui会结合多线程/多进程来执行model部分的逻辑. 在前文中我们也已经介绍过python的多进程/多线程工具,本人还是更加推荐使用concurrent.futures中的执行器,通过池来执行,由于submit后返回的是Future对象,可以使用这个对象的各种接口获取其状态,在执行出结果后有两种方式刷新gui 使用Future对象的add_done_callback(fn)接口在执行完后直接进行更新 通过root.after(time,callback)接口每隔一段时间检测下Future的状态. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:38:34 "},"人机交互篇/GUI/Tkinter的组件介绍.html":{"url":"人机交互篇/GUI/Tkinter的组件介绍.html","title":"Tkinter的组件介绍","keywords":"","body":"Tkinter的标准组件介绍 上文中我们已经罗列过tk支持的所有组件,本文将详细介绍这些组件和常用的组合方式. 控件名类型 意义 Toplevel 顶层框架 Frame 框架 LabelFrame 标签框架 Menu 菜单栏 Menubutton 菜单按钮 OptionMenu 弹出菜单 Label 标签 Button 按钮 Entry 输入框 Radiobutton 单选框 Checkbutton 复选框 Scale 滑块 Text 文本框 Canvas 画板 Listbox 列表框 Message 信息栏 PanedWindow 中分栏窗口 Scrollbar 滚动条 Spinbox 指定输入范围值的输入框 Combobox 组合框,包含文本字段和一个包含可选值的下拉列表 Notebook 标签页,形式参见chrome中的标签页 Progressbar 进度条 Separator 分离器,显示一个水平或垂直分隔条 Sizegrip 控制TopLevel的窗口大小 Treeview TreeView控件显示一个项目的树状分层集合 本文只是略微介绍标准库的组件,让大家对各个组件有个映像,对应接口还是要去http://effbot.org/tkinterbook/查看 窗口的构建,Toplevel和常用操作 使用tkinter中窗口是一个隐含的对象,最低一层实际上是toplevel.构建窗口就是实例化一个Tk对象,一个Tk对象,一个Tk对象会实例化一个Toplevel控件,也就是一个包含窗口的帧. Tk实例可以有如下常用的属性和方法 title(str) 窗口的标题 iconbitmap(path_str) 设置窗口的标题图标 geometry 定义窗口的长宽和出现位置,单位是像素,使用形如\"600x400+100+400\"的字符串设定表示长x宽+左上角x像素位+左上角y像素位 wm_maxsize(width=800, height=600) 设置窗口最大长宽值 wm_minsize(width=400, height=300) 设置窗口最小长宽值 mainloop() 主循环,执行则相当于启动窗口 attributes()设置window,这个参数的调用方式略奇葩,使用的是形如attributes('-alpha',0.5)的键值对式的格式,可选的参数包括 字段 平台 意义 alpha win,mac 透明度,范围是0~1之间,0代表完全透明年 disabled win 如果设置,则禁用这个窗口 modified mac 标记窗口为已修改 titlepath mac 窗口代理图标的路径 toolwindow win 设置窗口样式为工具窗口 topmost win 设置窗口总是在其他窗口前 configure() 设置Toplevel控件,可以设置的内容主要包括 字段 意义 bd/borderwidth 边框宽,默认是o menu 设置菜单Menu对象 relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT background/bg 背景色,可以是这里定义的字符串,也可以是#FFFFFF这样的RGB colormap 设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 height 高度 width 宽度 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding takefocus 指示用户可以使用tab键移动到这个部件 %%writefile src/first_toplevel.py from tkinter import Tk win = Tk() win.title(\"first window\") win.iconbitmap(r\"C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\人机交互\\GUI\\src\\myredis.ico\") win.geometry(\"600x400+100+400\") win.configure(background=\"Blue\") win.attributes('-alpha',0.5) win.mainloop() Overwriting src/first_toplevel.py %exec_py src/first_toplevel.py 通常我们并不会直接实例化Tk()来显示地创建窗口,而是通过继承的方式来构建应用. 多窗口 像gimp这种工具,一起动就是几个窗口各司其职,这种就需要利用toplevel构造多窗口了. 虽然是构造了多个窗口,但主循环还是只执行主窗口的.其他窗口则更多的是作为辅助. %%writefile src/toplevel.py from tkinter import Frame,Label,Button,Toplevel class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world1!') self.helloLabel.pack() class App2(Toplevel): def __init__(self, master=None): Toplevel.__init__(self, master) self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world2!') self.helloLabel.pack() if __name__ ==\"__main__\": app1 = Application() # 设置窗口标题: app1.master.title('Hello World1') app1.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app2 = App2() app2.title(\"helloword2\") app2.geometry(\"200x200+0+0\")#长x宽+x+y app1.mainloop() Overwriting src/toplevel.py %exec_py src/toplevel.py 框架的构建和常用操作 tk中的帧有两种: Frame 最基本的框架 LabelFrame 基本的框架的变体,它在它的子窗口周围绘制一个边框，并且它也可以显示标题 而ttk中也有Frame对象. 框架可以设置的内容包括 字段 意义 background/bg 背景色 bd/borderwidth 边框宽,默认是o colormap 调色板,设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT takefocus 指示用户可以使用tab键移动到这个部件 height 高度 width 宽度 Frame对象实例化需要传入一个master参数,这master可以是None或者一个它的父组件(通常是一个Toplevel对象).如果是空它则会自己实例化一个Toplevel作为其父组件.访问这个父组件可以使用frame.master. 通常我们的app主体会继承一个Frame并以其为基本容器构建应用. 框架的例子 我们来自己写个例子,体会下框架的用法. %%writefile src/firstGUI.py #coding:utf-8 from tkinter import Frame,Label,Button class Application(Frame): def __init__(self, master=None): super().__init__(master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/firstGUI.py %exec_py src/firstGUI.py 运行后出现如图小对话框 可以看出,应用类继承自Frame基类 每个Button、Label、输入框等，都是一个Widget.Frame则是可以容纳其他Widget的Widget,所有的Widget组合起来就是一棵树. pack()方法把Widget加入到父容器中,并实现布局.pack()是最简单的布局,grid()可以实现更复杂的布局. 在createWidgets()方法中，我们创建一个Label和一个Button,当Button被点击时，触发self.quit()使程序退出 ttk中的框架 使用ttk中的框架和在tk中差别不大 %%writefile src/ttk_frame.py #coding:utf-8 from tkinter.ttk import Frame,Label,Button,Style style = Style() style.configure(\"RW.TLabel\", foreground=\"red\", background=\"white\") class Application(Frame): def __init__(self, master=None): super().__init__(master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel.pack() self.quitButton = Button(self,text='Quit',style=\"RW.TLabel\",command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/ttk_frame.py %exec_py src/ttk_frame.py LabelFrame labelFrame是frame的子类,区别在于这个的意思似乎更加接近框架它提供的是一个有边界的框,并且这个框可以使用text设置付名,其他额外的设置还有: 字段 意义 background/bg 背景色 bd/borderwidth 边框宽,默认是o colormap 调色板,设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT takefocus 指示用户可以使用tab键移动到这个部件 height 高度 width 宽度 foreground/fg 前景 font 字体 labelanchor 标签位置(e:右侧横置,en:右测偏上横置,es:右测偏下横置,n:,ne,nw,s,se,sw,w,wn,ws) labelwidget 标签使用的组件,如果省略,框架使用Text文本组件 text 标签文本 labelanchor可选的参数为: 标志 说明 e 右侧 en 右侧偏上 es 右侧偏下 n 顶部 ne 顶部偏右 nw 顶部偏左 s 下侧 se 下侧偏右 sw 下侧偏左 w 左侧 wn 左侧偏上 ws 左侧偏下 文本要竖排只能通过插入回车了 %%writefile src/tklf.py #coding:utf-8 from tkinter import LabelFrame,Label,Button class Application(LabelFrame): def __init__(self, master=None): super().__init__(master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() self.config(text=\"test_text\",labelanchor=\"w\") def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/tklf.py %exec_py src/tklf.py ttk中的labelframe 在ttk中labelframe的设置方式略有改变 %%writefile src/ttklf.py #coding:utf-8 from tkinter.ttk import LabelFrame,Label,Button,Style style = Style() style.configure(\"RW.TLabel\", foreground=\"red\", background=\"white\") class Application(LabelFrame): def __init__(self, master=None): super().__init__(master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() self.config(text=\"test_text\",labelanchor=\"w\") def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel.pack() self.quitButton = Button(self,text='Quit',style=\"RW.TLabel\",command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/ttklf.py %exec_py src/ttklf.py 菜单 Menu Menu 和其他的组件一样,第一个是 parent,这里通常都是TopLevel,同时还需要给win对象设置menu. 然后我们可以用add(type, **options)或者addxxxx接口为其添加组件.支持的菜单类型有: 菜单命令commmand 子菜单cascade 分割线separator 复选菜单checkbutton 单选菜单radiobutton options则是对各个项进行的设置,包括 字段 意义 activebackground 激活状态的背景色 activeforeground 激活状态的前景色 accelerator 指定快捷键 background 背景色 bitmap 位图 columnbreak 分栏符 command 选中后执行的回调 font 字体 foreground 前景色 hidemargin 隐藏边缘 image 图片 indicatoron 指示器开启 label 标签 menu 菜单对象 offvalue off状态下的值 onvalue on状态下的值 selectcolor 选中后的颜色 selectimage 选中后的图片 state 状态 underline 下划线 value 值 variable 变量 这些设置可以在添加是加上,也可以使用entryconfig(index, **options)接口后设置.注意index是最开始设置的label 另一个菜单相关的对象Menubutton现在基本已经不再使用了,因为菜单相关的都可以使用menu实现. 菜单命令 add_commmand方法来为它添加菜单项. 如果该菜单是顶层菜单,则添加的菜单项依次向右添加; 如果该菜单是顶层菜单的一个子菜单项(配合add_cascade),则它添加的是子菜单的菜单项. add_command中的参数常用的有: label 属性,用来指定的是菜单项的名称 command 属性用来指定被点击的时候调用的方法 acceletor 属性指定的是快捷键 underline 属性 是是否拥有下划线。 最后可以用窗口的menu属性指定我们使用哪一个作为它的顶层菜单. %%writefile src/menu_command.py from tkinter import Frame,Label,Button,Menu class Application(Frame): def __init__(self, master=None,): Frame.__init__(self, master) #窗口大小位置 self.pack() self.createWidgets() menu = self.creatMenu() self.master.config(menu=menu) menu.entryconfig(\"新建\",label=234) help(menu) def creatMenu(self): #主菜单 menubar = Menu(self.master) #子菜单 menufile = Menu(menubar) for item in [\"新建\",\"打开\",\"保存\",\"另存为\"]: menubar.add_command(label = item) for item in [\"1\",\"2\",\"3\",\"4\"]: menufile.add_command(label = item) menufile.add_separator() menubar.add_cascade(label = \"子菜单\",menu=menufile) return menubar def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel[\"background\"] =\"green\" self.helloLabel.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/menu_command.py %exec_py src/menu_command.py 子菜单 如果有子菜单,我们需则需要使用add_cascade cascade 可以理解为“级联”,即它 的作用只是为了引出后面的菜单。 add_cascade属性: menu 属性,它指明了要把那个菜单级联到该菜单项上 label 属性,用于指定该菜单项的名称。 分割线 本身没有什么功能,只是为了美观,使用add_separator() 单选菜单和复选菜单 单选菜单类型为radiobutton可以使用接口add_radiobutton; 复选菜单类型为checkbutton可以使用接口add_checkbutton 这两个的添加方式和command的添加方式一样,不同之处在于他们通常是作为顶层菜单的一个子菜单存在的. %%writefile src/menu_othercommand.py from tkinter import Frame,Label,Button,Menu class Application(Frame): def __init__(self, master=None,): Frame.__init__(self, master) #窗口大小位置 self.pack() self.createWidgets() menu = self.creatMenu() self.master.config(menu=menu) def creatMenu(self): #主菜单 menubar = Menu(self.master) #子菜单 menufile = Menu(menubar) #多选菜单 menuradio = Menu(menubar) #单选菜单 menucheck = Menu(menubar) for item in [\"1\",\"2\",\"3\",\"4\"]: menufile.add_command(label = item) menubar.add_cascade(label = \"子菜单\",menu=menufile) for i in [\"a\",\"b\",\"c\"]: menuradio.add_radiobutton(label = i) menubar.add_cascade(label = \"多选菜单\",menu=menuradio) for i in [\"a1\",\"b2\",\"c3\"]: menucheck.add_checkbutton(label = i) menubar.add_cascade(label = \"单选菜单\",menu=menucheck) return menubar def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel[\"background\"] =\"green\" self.helloLabel.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/menu_othercommand.py %exec_py src/menu_othercommand.py 右键弹出菜单 一般弹出菜单是右键点击后出现的菜单,tk中的弹出菜单比较原始的,具体思路是这样: 我们先新建一个菜单, 然后向菜单项中添加各种功能, 最后我们监听鼠标右键消息,如果是鼠标 右键被单击, 此时可以根据需要判断下鼠标位置来确定是哪个弹出菜单被弹出, 然后使用 Menu 类的 pop 方法来弹出 菜单。 Menu 类里面有一个post方法,它接收两个参数,即 x 和 y 坐标,它会在相应的位置弹出菜单 例子: 一个菜单栏 %%writefile src/menu.py from tkinter import Frame,Label,Button,Menu class Application(Frame): def __init__(self, master=None,): Frame.__init__(self, master) #窗口大小位置 self.pack() self.createWidgets() menu = self.creatMenu() def creatMenu(self): #主菜单 menubar = Menu(self.master) #子菜单 menufile = Menu(menubar) for item in [\"新建\",\"打开\",\"保存\",\"另存为\"]: menufile.add_radiobutton(label = item) menuedit = Menu(menubar) for item in [\"复制\",\"黏贴\",\"剪切\"]: menuedit.add_checkbutton(label = item) #子菜单与主菜单关联 for name,submenu in zip([\"文件\",\"编辑\"],[menufile,menuedit]): menubar.add_cascade(label=name,menu=submenu) #最关键的一步,主菜单与app关联 self.master.config(menu=menubar) #右键菜单 menu = Menu(self.master) for i in ('One', 'Two', 'Three'): menu.add_command(label=i) #插入分割线 menu.add_separator() for i in ('1', '2', '3'): menu.add_command(label=i) #绑定鼠标右键呼出 if (self.master.tk.call('tk', 'windowingsystem')=='aqua'): self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) else: self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel[\"background\"] =\"green\" self.helloLabel.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/menu.py %exec_py src/menu.py OptionMenu 弹出菜单,通常用于点击某个对象后选择值 %%writefile src/option_menu.py from tkinter import * master = Tk() variable = StringVar(master) variable.set(\"one\") # default value w = OptionMenu(master, variable, \"one\", \"two\", \"three\") w.pack() mainloop() Overwriting src/option_menu.py %exec_py src/option_menu.py 其他组件用法 tkinter的控件上文中已有介绍,下面详细介绍各个组件的功能和设置方式. 标签 Label 标签可以定义的属性主要有: 字段 意义 background/bg 背景色 bd/borderwidth 边框宽,默认是o colormap 调色板,设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT takefocus 指示用户可以使用tab键移动到这个部件 height 高度 width 宽度 foreground/fg 前景 font 字体 text 标签文本 activebackground 激活状态的背景色 activeforeground 激活状态的前景色 anchor 文本的对齐位置,可选的有N, NE, E, SE, S, SW, W, NW,CENTER image 是否使用图标 bitmap 按钮的图标 compound 图片和文字的围绕方式,可选的有BOTTOM, LEFT, RIGHT, TOP,CENTER justify 多行文本如何排版,可选项包括LEFT, RIGHT, CENTER state 按钮状态,可选的有NORMAL, ACTIVE, DISABLED.默认NORMAL. textvariable 使用Tkinter variable设置按钮文本 underline 下划线 wraplength 确定按钮的文本应何时被包装成多行 按钮 Button 按钮算是最常用的控件之一了,它的属性主要有: 字段 意义 background/bg 背景色 bd/borderwidth 边框宽,默认是o colormap 调色板,设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT takefocus 指示用户可以使用tab键移动到这个部件 height 高度 width 宽度 foreground/fg 前景 font 字体 text 标签文本 activebackground 激活状态的背景色 activeforeground 激活状态的前景色 anchor 文本的对齐位置,可选的有N, NE, E, SE, S, SW, W, NW,CENTER image 是否使用图标 bitmap 按钮的图标 command 点击按钮的回调函数 compound 图片和文字的围绕方式,可选的有BOTTOM, LEFT, RIGHT, TOP,CENTER disabledforeground 无效前景色 justify 多行文本如何排版,可选项包括LEFT, RIGHT, CENTER overrelief 鼠标移动到上面时显示的内容 repeatdelay 重复延迟 repeatinterval 重复间隔 state 按钮状态,可选的有NORMAL, ACTIVE, DISABLED.默认NORMAL. textvariable 使用Tkinter variable设置按钮文本 underline 下划线 wraplength 确定按钮的文本应何时被包装成多行 最值得注意的是command参数,注意它的回调函数没有参数 输入框 Entry 字段 意义 background/bg 背景色 bd/borderwidth 边框宽,默认是o colormap 调色板,设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT takefocus 指示用户可以使用tab键移动到这个部件 height 高度 width 宽度 foreground/fg 前景 font 字体 text 标签文本 justify 多行文本如何排版,可选项包括LEFT, RIGHT, CENTER state 按钮状态,可选的有NORMAL, ACTIVE, DISABLED.默认NORMAL. textvariable 使用Tkinter variable设置按钮文本 wraplength 确定按钮的文本应何时被包装成多行 disabledbackground 无效背景 disabledforeground 无效前景 exportselection 选中的文本是否自动保存到剪切板 insertbackground 光标颜色 insertborderwidth 光标边框宽度 insertofftime 光标闪烁间隔 insertontime 光标闪烁单次亮起的时间 insertwidth 光标宽度 readonlybackground 当状态为readonly时的背景色 selectbackground 选中区域的背景色 selectborderwidth 选中区域的宽度 selectforeground 选中区域的前景色 show 常用在密码这种,覆盖显示文本 validate 指定validate vcmd/validatecommand validate时执行的回调 xscrollcommand 水平滚动条 属性: get() 获取输入(返回一个str) 例:一个用户登录界面 %%writefile src/entry.py from tkinter import Frame,Label,Button,Entry class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.userLabel = Label(self, text='用户名:') self.userLabel.grid(row = 0,column = 0,sticky=\"w\") self.userEntry = Entry(self) self.userEntry.grid(row = 0,column = 1,sticky=\"e\") self.pwLabel = Label(self, text='密码:') self.pwLabel.grid(row = 1,column = 0,sticky=\"w\") self.pwEntry = Entry(self) self.pwEntry.grid(row = 1,column = 1,sticky=\"e\") self.enterButton = Button(self,text = \"登录\",command = self.reg) self.enterButton.grid(row = 2,column = 1,sticky = \"e\") self.logLabel = Label(self, text='') self.logLabel.grid(row = 3) def reg(self): s1 = self.userEntry.get() s2 = self.pwEntry.get() if s1 == \"www.google.com\" and s2 == \"www.bing.com\": self.logLabel[\"text\"]=\"登录成功\" else: self.logLabel[\"text\"]=\"用户名或密码错误\" self.userEntry.delete(0,len(s1)) self.pwEntry.delete(0,len(s1)) if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('登录界面') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/entry.py %exec_py src/entry.py 单选按钮 Radiobutton 一般是几个里面选一个用 可选的设置有: 字段 意义 background/bg 背景色 bd/borderwidth 边框宽,默认是o colormap 调色板,设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT takefocus 指示用户可以使用tab键移动到这个部件 height 高度 width 宽度 foreground/fg 前景 font 字体 text 标签文本 activebackground 激活状态的背景色 activeforeground 激活状态的前景色 anchor 文本的对齐位置,可选的有N, NE, E, SE, S, SW, W, NW,CENTER image 是否使用图标 bitmap 按钮的图标 command 点击按钮的回调函数 compound 图片和文字的围绕方式,可选的有BOTTOM, LEFT, RIGHT, TOP,CENTER disabledforeground 无效前景色 justify 多行文本如何排版,可选项包括LEFT, RIGHT, CENTER overrelief 鼠标移动到上面时显示的内容 repeatdelay 重复延迟 repeatinterval 重复间隔 state 按钮状态,可选的有NORMAL, ACTIVE, DISABLED.默认NORMAL. textvariable 使用Tkinter variable设置按钮文本 underline 下划线 wraplength 确定按钮的文本应何时被包装成多行 indicatoron 是否使用标准的单选样式,默认为Ture,否则样式为SUNKEN offrelief 按钮默认是否被按下 value 选项对应的值 variable 与此按钮关联的变量 直接看代码: 单选框和复选框往往会需要用到一个变量用于保存选择的内容,一般的变量无法起到效果,需要使用tk提供的变量类型: BooleanVar, DoubleVar, IntVar, StringVar 要使用的话set方法就是赋值,get方法就是取值. %%writefile src/radiobutton.py from tkinter import Frame,Label,Button,Radiobutton, IntVar class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.var = IntVar() self.helloLabel = Label(self, text='Hello, world!\\n') self.helloLabel.pack() self.rbframe=Frame(self) self.rbframe.pack() self.c1 = Radiobutton( self.rbframe, indicatoron=False, text = \"1\", value=1, variable=self.var, command = self._callback ) self.c1.pack() self.c2 = Radiobutton( self.rbframe, indicatoron=False, text = \"2\", value=2, variable=self.var, command = self._callback ) self.c2.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() def _callback(self): self.helloLabel.config(text = \"值为{}\".format(self.var.get())) if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/radiobutton.py %exec_py src/radiobutton.py 复选框 Checkbutton 复选框通常是用来选择信息的时候的一种选择,它前面 有个小正方形的方块,如果选中则有一个对号,也可以再 次点击以取消该对号来取消选中。 字段 意义 background/bg 背景色 bd/borderwidth 边框宽,默认是o colormap 调色板,设置需要是Colormap的实例, container 设置需要是Container的实例 cursor 鼠标光标在其中的位置 highlightbackground 要高亮的背景色 highlightcolor 要高亮的颜色 highlightthickness 高亮的宽度 padx 水平padding pady 垂直padding relief 边框样式,可选的FLAT,SUNKEN,RAISED,GROOVE,RIDGE默认为FLAT takefocus 指示用户可以使用tab键移动到这个部件 height 高度 width 宽度 foreground/fg 前景 font 字体 text 标签文本 activebackground 激活状态的背景色 activeforeground 激活状态的前景色 anchor 文本的对齐位置,可选的有N, NE, E, SE, S, SW, W, NW,CENTER image 是否使用图标 bitmap 按钮的图标 command 点击按钮的回调函数 compound 图片和文字的围绕方式,可选的有BOTTOM, LEFT, RIGHT, TOP,CENTER disabledforeground 无效前景色 justify 多行文本如何排版,可选项包括LEFT, RIGHT, CENTER overrelief 鼠标移动到上面时显示的内容 repeatdelay 重复延迟 repeatinterval 重复间隔 state 按钮状态,可选的有NORMAL, ACTIVE, DISABLED.默认NORMAL. textvariable 使用Tkinter variable设置按钮文本 underline 下划线 wraplength 确定按钮的文本应何时被包装成多行 indicatoron 是否使用标准的单选样式,默认为Ture,否则样式为SUNKEN offrelief 按钮默认是否被按下 value 选项对应的值 variable 与此按钮关联的变量 indicatoron 是否画上指示器,状态有SUNKEN和RAISED offvalue 未被选中的值 onvalue 选中的值 看个例子: %%writefile src/checkbutton.py from tkinter import Frame,Label,Button,Checkbutton class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!\\n') self.helloLabel.pack() self.c1 = Checkbutton(self, text = \"1\", command = lambda : self.helloLabel.config( text = self.helloLabel[\"text\"]+\"1被选中了奇数次\\n\")) self.c1.pack() self.c2 = Checkbutton(self, text = \"2\", command = lambda : self.helloLabel.config( text = self.helloLabel[\"text\"]+\"2被选中了奇数次\\n\")) self.c2.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/checkbutton.py %exec_py src/checkbutton.py 文本域 Text 也就是用来存放字符串的大空间 基本的定义也就是宽度width和高度height了,但由于有类编辑的需求,因此需要引入标签来定位光标.可以用的定位标签包括 \",\" 行号,列号组成的坐标字符串 \".end\" 行号对应行的末尾 INSERT 光标的当前位置 CURRENT 光标最近的字符 END 文末 另外还有一些复杂的用法一般用不到 %%writefile src/text.py from tkinter import * root = Tk() text = Text(root) text.pack() # INSERT 索引表示插入光标当前的位置 text.insert(INSERT, \"I love \") text.insert(END, \"Python!\") mainloop() Overwriting src/text.py %exec_py src/text.py 画布 Canvas 和html5中的画布一样,tk中的画布也是用来绘图的,直接看代码吧: %%writefile src/canvas.py from tkinter import Frame,Canvas class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.can = Canvas(self,width = 400,height=300,bg = \"#233333\") self.can.create_line((0,0),(200,200),width = 8) self.can.create_text(300,30,text = \"一个画板\") self.can.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') # 主消息循环: app.mainloop() Overwriting src/canvas.py %exec_py src/canvas.py Listbox 列表框 文本按列表的形式排列,列表框是用来从一组文本项目选择。根据ListBox的配置，用户可以选择从列表中一个或多个项目,通常,这个任务可以由多选实现 %%writefile src/listbox.py from tkinter import Frame,Listbox,END class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.list = Listbox(self) self.list.pack() self.list.insert(END, \"a list entry\") for item in [\"one\", \"two\", \"three\", \"four\"]: self.list.insert(END, item) if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') # 主消息循环: app.mainloop() Overwriting src/listbox.py %exec_py src/listbox.py Message 信息栏 使用单字体显示短文本消息.通常可以使用普通标签代替. %%writefile src/message.py from tkinter import Tk,Message master = Tk() w = Message(master, text=\"this is a message\") w.pack() master.mainloop() Overwriting src/message.py %exec_py src/message.py PanedWindow 中分栏窗口 可用于实现2-pane和3-pane的布局 %%writefile src/panewindow.py from tkinter import Tk,Label,PanedWindow,BOTH,VERTICAL master = Tk() m1 = PanedWindow(master) m1.pack(fill=BOTH, expand=1) left = Label(m1, text=\"left pane\") m1.add(left) m2 = PanedWindow(m1, orient=VERTICAL) m1.add(m2) top = Label(m2, text=\"top pane\") m2.add(top) bottom = Label(m2, text=\"bottom pane\") m2.add(bottom) master.mainloop() Overwriting src/panewindow.py %exec_py src/panewindow.py Scale 滑块 通常如果是有界输入,那么就可以使用滑块 %%writefile src/scale.py from tkinter import Tk,Scale,HORIZONTAL master = Tk() w = Scale(master, from_=0, to=100) w.pack() w = Scale(master, from_=0, to=200, orient=HORIZONTAL) w.pack() master.mainloop() Writing src/scale.py %exec_py src/scale.py Scrollbar 滚动条 滚动条通常不会单独使用,而是配合文本,列表框,画板使用. %%writefile src/scrollbar.py from tkinter import Tk,Scrollbar,Listbox master = Tk() scrollbar = Scrollbar(master) scrollbar.pack(side='right', fill='y') listbox = Listbox(master, yscrollcommand=scrollbar.set) for i in range(1000): listbox.insert('end', str(i)) listbox.pack(side='left', fill='both') scrollbar.config(command=listbox.yview) master.mainloop() Overwriting src/scrollbar.py %exec_py src/scrollbar.py Spinbox 指定输入范围值的输入框 Spinbox可以用来代替只有有限数量的命令值的输入框. %%writefile src/spinbox.py from tkinter import Tk,Spinbox master = Tk() w = Spinbox(master, from_=0, to=10) w.pack() master.mainloop() Writing src/spinbox.py %exec_py src/spinbox.py Combobox 组合框 ttk提供的控件,包含文本字段和一个包含可选值的下拉列表https://docs.python.org/3/library/tkinter.ttk.html#tkinter.ttk.Combobox 这个控件和单选框功能类似,一般也会借助tk中的变量类型. %%writefile src/combobox.py from tkinter import Tk,StringVar from tkinter.ttk import Combobox master = Tk() number = StringVar() w = Combobox(master,textvariable=number) w['values'] = (1, 2, 4, 42, 100) # 设置下拉列表的值 w.grid(column=1, row=1) # 设置其在界面中出现的位置 column代表列 row 代表行 w.current(0) w.pack() master.mainloop() Overwriting src/combobox.py %exec_py src/combobox.py Notebook标签页 标签页是ttk中的控件通常用在同时管理多个资源的情况下,形式参见chrome中的标签页. %%writefile src/notebook.py from tkinter import Tk,PhotoImage from tkinter.ttk import Notebook,Frame,Button root = Tk() scheduledimage=PhotoImage(\"source/canvas.png\") note = Notebook(root) tab1 = Frame(note) tab2 = Frame(note) tab3 = Frame(note) Button(tab1, text='Exit', command=root.destroy).pack(padx=100, pady=100) note.add(tab1, text = \"Tab One\",image=scheduledimage, compound=\"top\") note.add(tab2, text = \"Tab Two\") note.add(tab3, text = \"Tab Three\") note.pack() root.mainloop() Overwriting src/notebook.py %exec_py src/notebook.py Progressbar 进度条 ttk的独有控件显示,一个长期运行的操作状态指示.它可以在两种模式下运行: 确定模式,显示完成的工作量与完成工作的总量; 不确定模式,提供动画显示,让用户知道工作正在进行中 下面的例子中还用到了ttk中的Separator用于做分割,Sizegrip用于缩放窗口 %%writefile src/progressbar.py from tkinter import * from tkinter import ttk import time def manu_increment(*args): for i in range(100): p1[\"value\"] = i+1 root.update() time.sleep(0.1) def auto_increment(*args): global flag,value flag = not flag if flag: btn2[\"text\"] = \"暂停动画\" p2.start(10) else: btn2[\"text\"] = \"开始动画\" value = p2[\"value\"] p2.stop() p2[\"value\"] = value root = Tk() root.title(\"Progressbar组件\") sg = ttk.Sizegrip(root).grid(row=99,column=99,sticky=\"se\") # 定量进度条 p1 = ttk.Progressbar(root, length=200, mode=\"determinate\", orient=HORIZONTAL) p1.grid(row=1,column=1) p1[\"maximum\"] = 100 p1[\"value\"] = 0 # 通过指定变量，改变进度条位置 # n = IntVar() # p1[\"variable\"] = n # 通过指定步长，改变进度条位置 # p1.step(2) btn = ttk.Button(root,text=\"开始动画\",command=manu_increment) btn.grid(row=1,column=0) # 非定量进度条 flag = False # 标志位 value = 0 # 进度条位置 # 分隔 sep = ttk.Separator(root) sep.grid(sticky = \"ew\") p2 = ttk.Progressbar(root, length=200,orient = HORIZONTAL) p2.grid(row=3,column=1) btn2 = ttk.Button(root,text=\"自动动画\",command=auto_increment) btn2.grid(row=3,column=0) root.mainloop() Overwriting src/progressbar.py %exec_py src/progressbar.py Treeview TreeView控件显示一个项目的树状分层集合,通常这用来展示数据或者文件系统等结构. %%writefile src/treeview.py from tkinter import * from tkinter import ttk root = Tk() tree = ttk.Treeview(root) tree[\"columns\"]=(\"one\",\"two\") tree.column(\"one\", width=100 ) tree.column(\"two\", width=100) tree.heading(\"one\", text=\"coulmn A\") tree.heading(\"two\", text=\"column B\") tree.insert(\"\" , 0, text=\"Line 1\", values=(\"1A\",\"1b\")) id2 = tree.insert(\"\", 1, \"dir2\", text=\"Dir 2\") tree.insert(id2, \"end\", \"dir 2\", text=\"sub dir 2\", values=(\"2A\",\"2B\")) ##alternatively: tree.insert(\"\", 3, \"dir3\", text=\"Dir 3\") tree.insert(\"dir3\", 3, text=\" sub dir 3\",values=(\"3A\",\" 3B\")) tree.pack() root.mainloop() Writing src/treeview.py %exec_py src/treeview.py ScrolledText 带滚动条的文本框,这个组件在tkinter.scrolledtext下 %%writefile src/scrolled_text.py from tkinter import Tk,END from tkinter.scrolledtext import ScrolledText root = Tk() stext = ScrolledText(root,bg='white', height=10) stext.pack(fill=\"both\", side=\"left\", expand=True) stext.focus_set() root.mainloop() Overwriting src/scrolled_text.py %exec_py src/scrolled_text.py 对话框 Dialog和消息弹窗 messagebox 对话框和消息弹窗也是常见的控件,在,但他们独立于其他控件,而是放在tkinter.filedialog,tkinter.simpledialog和tkinter.messagebox下. 在tkinter下提供了如下几种常见的对话框形式: messagebox下的方法都是继承自messagebox.dialog.Dialog 只有一个按钮(确定)的消息弹窗 tkinter.messagebox.showinfo(title,message) 信息弹窗 tkinter.messagebox.showwarning(title,message) 警告弹窗 tkinter.messagebox.showerror(title,message) 错误弹窗 有两个按钮的消息弹窗 tkinter.messagebox.askokcancel(title,message)(确定,取消)点击确定返回Ture取消返回False tkinter.messagebox.askquestion(title,message)(确定,取消)点击确定返回\"yes\"取消返回\"no\" tkinter.messagebox.askyesno(title,message)(是,否)点击是返回Ture;否返回False tkinter.messagebox.askretrycancel(title,message)(重试,取消)点击重试返回 Ture;取消返回False 有三个按钮的消息弹窗 tkinter.messagebox.askyesnocancel(title,message)是：True;否：False;取消：None 输入值的消息弹窗 tkinter.simpledialog.askinteger(title, prompt)问询整数的消息弹窗 tkinter.simpledialog.askfloat(title, prompt)问询浮点数的消息弹窗 tkinter.simpledialog.askstring(title, prompt)询问字符创的消息弹窗 选择文件弹窗 tkinter.filedialog.askopenfilename()打开一个文件的弹窗,返回文件名列表 tkinter.filedialog.asksaveasfilename()保存一个文件的弹窗 tkinter.filedialog.askopenfile()打开一个文件的弹窗,返回文件对象 tkinter.filedialog.askopenfiles()打开多个文件的弹窗,返回文件对象的列表 tkinter.filedialog.asksaveasfile()保存一个文件的弹窗,返回文件对象 tkinter.filedialog.askdirectory()打开一个文件夹的弹窗,返回文件地址 %%writefile src/messagebox.py from tkinter import Frame,Label,Button,Entry from tkinter.messagebox import showinfo class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.userLabel = Label(self, text='用户名:') self.userLabel.grid(row = 0,column = 0,sticky=\"w\") self.userEntry = Entry(self) self.userEntry.grid(row = 0,column = 1,sticky=\"e\") self.pwLabel = Label(self, text='密码:') self.pwLabel.grid(row = 1,column = 0,sticky=\"w\") self.pwEntry = Entry(self) self.pwEntry.grid(row = 1,column = 1,sticky=\"e\") self.enterButton = Button(self,text = \"登录\",command = self.reg) self.enterButton.grid(row = 2,column = 1,sticky = \"e\") self.logLabel = Label(self, text='') self.logLabel.grid(row = 3) def reg(self): s1 = self.userEntry.get() s2 = self.pwEntry.get() if s1 == \"www.google.com\" and s2 == \"www.bing.com\": self.logLabel[\"text\"]=\"登录成功\" else: self.logLabel[\"text\"]=\"用户名或密码错误\" self.userEntry.delete(0,len(s1)) self.pwEntry.delete(0,len(s1)) showinfo(title = \"错误\",message=\"用户名或密码错误\") if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('登录界面') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/messagebox.py %exec_py src/messagebox.py %%writefile src/simpledialog.py import tkinter from tkinter import simpledialog def inputStr(): r = simpledialog.askstring('Python Tkinter', 'Input String', initialvalue = 'Python Tkinter') print(r) def inputInt(): r = simpledialog.askinteger('Python Tkinter', 'Input Integer') print(r) def inputFloat(): r = simpledialog.askfloat('Python Tkinter', 'Input Float') print(r) root = tkinter.Tk() btn1 = tkinter.Button(root, text='Input String', command=inputStr) btn2 = tkinter.Button(root, text='Input Integer', command=inputInt) btn3 = tkinter.Button(root, text='Input Float', command=inputFloat) btn1.pack(side='left') btn2.pack(side='left') btn3.pack(side='left') root.mainloop() Writing src/simpledialog.py %exec_py src/simpledialog.py %%writefile src/filedialog.py import tkinter from tkinter import filedialog def openfile(): r = filedialog.askopenfilename(title='打开文件', filetypes=[('Python', '*.py *.pyw'), ('All Files', '*')]) print(r) def savefile(): r = filedialog.asksaveasfilename(title='保存文件', initialdir='d:\\mywork', initialfile='hello.py') print(r) root = tkinter.Tk() btn1 = tkinter.Button(root, text='File Open', command=openfile) btn2 = tkinter.Button(root, text='File Save', command=savefile) btn1.pack(side='left') btn2.pack(side='left') root.mainloop() Overwriting src/filedialog.py %exec_py src/filedialog.py Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:38:25 "},"人机交互篇/GUI/结合pandas和matplotlib制作数据科学GUI工具/结合pandas和matplotlib制作数据科学GUI工具.html":{"url":"人机交互篇/GUI/结合pandas和matplotlib制作数据科学GUI工具/结合pandas和matplotlib制作数据科学GUI工具.html","title":"结合pandas和matplotlib制作数据科学GUI工具","keywords":"","body":"结合pandas和matplotlib制作数据科学GUI工具 python的一大作用就是做数据分析,如果使用tkinter构建数据科学工具,那么难免会使用到表格和图表,第三方工具pandastable提供了对表格和数据图片的支持.多数时候这个工具可以满足数据分析的一般需求. pandastable 这个包的使用方式和标准库基本一样. TableModel类似tkinter中的XxxxVar,用于维护表格数据,而TableCanvas就是控件类了. TableModel TableModel初始化可以使用TableModel(dataframe=None, rows=20, columns=5)如果初始化的时候已经有pandas的dataframe对象,那么后两个参数就没必要写上,同时TableModel的实例中dataframe也是可以访问的,可以对其直接操作以修改其内容.其他的接口可以看它的api文档 Table Table和一般的控件使用方法差不多,都需要以个父级控件作为初始化的参数,它的设置中多出了一个model参数用于指定TableModel的实例.同时Table的实例中也有model对象可以直接访问到对应的model实例. 其他的设置项包括: dataframe=None指定要显示的dataframe showtoolbar=False是否显示工具条 showstatusbar=False是否显示状态条 TableCanvas常用的方法有: table.show()将图表渲染到gui table.updateModel(model)更新图表数据 table.redraw()重新画图表 table.importCSV(path)从csv中导入数据 table.columncolors['mycol'] = '#dcf1fc'为指定列设置显示颜色 table.setRowColors(rows, color)为指定行设置颜色 table.clearFormatting() 清空格式设置 table.sortTable(columnIndex=None, ascending=1, index=False)排序表格 table.showPlotViewer(parent=None, layout='horizontal')开启作图页面 其他的接口可以查看接口文档http://pandastable.readthedocs.io/en/latest/pandastable.html#module-pandastable.core %%writefile src/table_canvas.py from tkinter import Tk,Frame from pandastable import Table, TableModel root = Tk() f = Frame(root) f.pack(fill=\"both\",expand=1) model = TableModel.getSampleData() table = Table(f, dataframe=model,showtoolbar=True, showstatusbar=True) table.show() table.showPlotViewer() #table.showPlot() root.mainloop() Overwriting src/table_canvas.py %exec_py src/table_canvas.py 直接使用matplotlib作图 上面的pandastable工具更多的是通用的静态数据可视化工具,但更多的时候可能还是需要使用matplotlib直接作图. 要让matplotlib绘制的图片可以在tk中展示需要使用组件matplotlib.backends.backend_tkagg.FigureCanvasTkAgg和matplotlib.backends.backend_tkagg.NavigationToolbar2TkAgg FigureCanvasTkAgg(f, master=root)是绘图的画板(注意不是tk组件),第一位是要绘制的图片对象matplotlib.figure.Figure的实例,使用.show()方法展示渲染出来的图,.get_tk_widget()用于从这个绘图板上获取tk的对应组件. NavigationToolbar2TkAgg(canvas, root)是画板的工具栏,第一位是FigureCanvasTkAgg组件的实例,第二位是父组件,.update()方法用于更新组件的状态 同时需要在绘图时指定好backend:matplotlib.use('TkAgg') 我们来绘制一个k线图 %matplotlib inline import datetime import matplotlib as mpl import matplotlib.pyplot as plt import matplotlib.finance as mpf from matplotlib.pylab import date2num import tushare as ts wdyx = ts.get_k_data('002739','2017-01-01') wdyx.info() Int64Index: 120 entries, 0 to 119 Data columns (total 7 columns): date 120 non-null object open 120 non-null float64 close 120 non-null float64 high 120 non-null float64 low 120 non-null float64 volume 120 non-null float64 code 120 non-null object dtypes: float64(5), object(2) memory usage: 7.5+ KB wdyx[:3] date open close high low volume code 0 2017-01-03 54.010 54.070 54.110 53.711 30518.0 002739 1 2017-01-04 54.090 56.691 56.771 53.831 103953.0 002739 2 2017-01-05 56.302 56.591 57.080 55.924 65414.0 002739 def date_to_num(dates): num_time = [] for date in dates: date_time = datetime.datetime.strptime(date,'%Y-%m-%d') num_date = date2num(date_time) num_time.append(num_date) return num_time mat_wdyx = wdyx.as_matrix() num_time = date_to_num(mat_wdyx[:,0]) mat_wdyx[:,0] = num_time mat_wdyx[:3] array([[736332.0, 54.01, 54.07, 54.11, 53.711, 30518.0, '002739'], [736333.0, 54.09, 56.691, 56.771, 53.831, 103953.0, '002739'], [736334.0, 56.302, 56.591, 57.08, 55.924, 65414.0, '002739']], dtype=object) fig, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(15,8)) mpf.candlestick_ochl(ax1, mat_wdyx, width=1.0, colorup = 'g', colordown = 'r') ax1.set_title('wandayuanxian') ax1.set_ylabel('Price') ax1.grid(True) ax1.xaxis_date() plt.bar(mat_wdyx[:,0]-0.25, mat_wdyx[:,5], width= 0.5) ax2.set_ylabel('Volume') ax2.grid(True) 接下来我们把它画在tk上 %%writefile src/matplotlib_draw.py import datetime from tkinter import Tk,Button import matplotlib as mpl import matplotlib.pyplot as plt import matplotlib.finance as mpf from matplotlib.pylab import date2num from matplotlib.backend_bases import key_press_handler from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg,NavigationToolbar2TkAgg import tushare as ts mpl.use('TkAgg') def date_to_num(dates): num_time = [] for date in dates: date_time = datetime.datetime.strptime(date,'%Y-%m-%d') num_date = date2num(date_time) num_time.append(num_date) return num_time def plot(mat_wdyx): fig, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(15,8)) mpf.candlestick_ochl(ax1, mat_wdyx, width=1.0, colorup = 'g', colordown = 'r') ax1.set_title('wandayuanxian') ax1.set_ylabel('Price') ax1.grid(True) ax1.xaxis_date() plt.bar(mat_wdyx[:,0]-0.25, mat_wdyx[:,5], width= 0.5) ax2.set_ylabel('Volume') ax2.grid(True) return fig def main(): wdyx = ts.get_k_data('002739','2017-01-01') mat_wdyx = wdyx.as_matrix() num_time = date_to_num(mat_wdyx[:,0]) mat_wdyx[:,0] = num_time f = plot(mat_wdyx) root = Tk() canvas =FigureCanvasTkAgg(f, master=root) canvas.show() canvas.get_tk_widget().pack(side=\"top\", fill=\"both\", expand=1) toolbar =NavigationToolbar2TkAgg(canvas, root) toolbar.update() canvas._tkcanvas.pack(side=\"top\", fill=\"both\", expand=1) #定义并绑定键盘事件处理函数 def on_key_event(event): print('you pressed %s'% event.key) key_press_handler(event, canvas, toolbar) canvas.mpl_connect('key_press_event', on_key_event) def _quit(): #结束事件主循环，并销毁应用程序窗口 root.quit() root.destroy() button =Button(master=root, text='Quit', command=_quit) button.pack(side=\"bottom\") root.mainloop() if __name__==\"__main__\": main() Overwriting src/matplotlib_draw.py %exec_py src/matplotlib_draw.py 创建及时刷新的图片 使用root.after(time,callback)方法我们来制作一个动画 %%writefile src/matplotlib_draw_an.py import datetime from tkinter import Tk,Button,IntVar import numpy as np import matplotlib as mpl mpl.use('TkAgg') import matplotlib.pyplot as plt import matplotlib.finance as mpf from matplotlib.pylab import date2num from matplotlib.backend_bases import key_press_handler from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg,NavigationToolbar2TkAgg def plot(i): fig, ax = plt.subplots() x = np.arange(0, 2*np.pi, 0.01) line, = ax.plot(x, np.sin(x+ i/10.0)) return fig,ax def main(): root = Tk() I = 0 f,ax = plot(I) canvas =FigureCanvasTkAgg(f, master=root) canvas.show() canvas.get_tk_widget().pack(side=\"top\", fill=\"both\", expand=1) toolbar =NavigationToolbar2TkAgg(canvas, root) toolbar.update() canvas._tkcanvas.pack(side=\"top\", fill=\"both\", expand=1) def callback(): nonlocal I ax.clear() x = np.arange(0, 2*np.pi, 0.01) line, = ax.plot(x, np.sin(x+ I/10.0)) I+=1 canvas.draw() root.after(200,callback) #canvas.new_timer(interval=200,callbacks=callback) #定义并绑定键盘事件处理函数 def on_key_event(event): print('you pressed %s'% event.key) key_press_handler(event, canvas, toolbar) canvas.mpl_connect('key_press_event', on_key_event) def _quit(): #结束事件主循环，并销毁应用程序窗口 root.quit() root.destroy() button =Button(master=root, text='Quit', command=_quit) button.pack(side=\"bottom\") root.after(200,callback) root.mainloop() if __name__==\"__main__\": main() Overwriting src/matplotlib_draw_an.py %exec_py src/matplotlib_draw_an.py Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:38:42 "},"人机交互篇/使用matplotlib做数据可视化/":{"url":"人机交互篇/使用matplotlib做数据可视化/","title":"使用matplotlib做数据可视化","keywords":"","body":"使用matplotlib做数据可视化 matplotlib和numpy一样,是事实上的python\"标准库\",是被使用最多的二维绘图Python包.它不仅提供一个非常快捷的用python可视化数据的方法,而且提供了出版质量的多种格式图像.不过遗憾的是pypy目前并不支持.matplotlib主要是一个绘图工具,大多数的数据科学工具都对他支持良好. 它体系庞大复杂,可以绘制各种常规图形,也可以绘制点线构成自定义的图形,可以是2d图形也可以画3d图形,可以绘制图片也可以构建简单动画,甚至于还有个模块爬取美股信息 本文将从多个角度介绍matplotlib Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 16:08:57 "},"人机交互篇/使用matplotlib做数据可视化/matplotlib的基本设置/matplotlib的基本设置.html":{"url":"人机交互篇/使用matplotlib做数据可视化/matplotlib的基本设置/matplotlib的基本设置.html","title":"matplotlib的基本设置","keywords":"","body":"matplotlib的基本设置 绘图从来就是个很复杂的东西,各种样式各种设置非常复杂,不信的同学可以拿latex类比下. matplotlib设置方式可以分为三种: 使用内置的配置主题 临时设置 使用配置文件matplotlibrc import matplotlib.pyplot as plt import matplotlib import numpy as np %matplotlib inline 通常matplotlib在linux下的设置文件放在~/.config/matplotlib/下但也会有特殊,我们可以用下面的代码查看配置文件的位置 matplotlib.get_configdir() '/Users/huangsizhe/.matplotlib' 使用内置的配置主题 matplotlib内置了许多基本的设置主题可以通过matplotlib.pyplot.style.available查看 plt.style.available ['bmh', 'classic', 'dark_background', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark-palette', 'seaborn-dark', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'seaborn', 'animation_support', 'chinese_support'] 样式的用法有两种, 一种是全局使用,plt.style.use('seaborn-darkgrid') 设定好之后所有下面的图将都是这一样式 另一种是临时使用样式,可以使用plt.style.context结合with语句,构建上下文环境 我们来看看他们的效果大约是啥样 x=[1,2,3,4,5,6,7,8] y=[2,1,3,5,2,6,12,7] with plt.style.context(('seaborn-darkgrid')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-notebook')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('classic')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-ticks')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('grayscale')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('bmh')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-talk')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('dark_background')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('ggplot')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('fivethirtyeight')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-colorblind')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-deep')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-whitegrid')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-bright')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-poster')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-muted')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-paper')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-white')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-pastel')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-dark')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-dark-palette')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() 这些主题都是可以组合使用的 with plt.style.context(('fivethirtyeight','seaborn-whitegrid','seaborn-pastel')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-whitegrid','seaborn-pastel','fivethirtyeight')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() 可以看出,如果有冲突,后定义的会覆盖先定义的. 临时修改配置 matplotlib允许临时修改配置,使用的是matplotlib.rcParams matplotlib.rcParams['lines.linewidth'] = 2 matplotlib.rcParams['lines.color'] = 'r' 或者使用matplotlib.rc(group, **kwargs)来快速的为分组做设定 matplotlib.rc('lines', linewidth=2, color='r') 使用matplotlibrc文件全局的设置 matplotlib会以 本地->环境变量MATPLOTLIBRC/matplotlibrc指定位置->用户配置位置(linux:.config/matplotlib/matplotlibrc,other:.matplotlib/matplotlibrc),->matplotlib安装根目录/matplotlib/mpl-data/matplotlibrc 的顺序查找matplotlibrc,用它就可以配置需要的设置了,这个方法是全局默认加载的. 一份设置文档大约是这个样子,和python规则一样,#代表注释 ### MATPLOTLIBRC FORMAT # This is a sample matplotlib configuration file - you can find a copy # of it on your system in # site-packages/matplotlib/mpl-data/matplotlibrc. If you edit it # there, please note that it will be overwritten in your next install. # If you want to keep a permanent local copy that will not be # overwritten, place it in the following location: # unix/linux: # $HOME/.config/matplotlib/matplotlibrc or # $XDG_CONFIG_HOME/matplotlib/matplotlibrc (if $XDG_CONFIG_HOME is set) # other platforms: # $HOME/.matplotlib/matplotlibrc # # See http://matplotlib.org/users/customizing.html#the-matplotlibrc-file for # more details on the paths which are checked for the configuration file. # # This file is best viewed in a editor which supports python mode # syntax highlighting. Blank lines, or lines starting with a comment # symbol, are ignored, as are trailing comments. Other lines must # have the format # key : val # optional comment # # Colors: for the color values below, you can either use - a # matplotlib color string, such as r, k, or b - an rgb tuple, such as # (1.0, 0.5, 0.0) - a hex string, such as ff00ff - a scalar # grayscale intensity such as 0.75 - a legal html color name, e.g., red, # blue, darkslategray #### CONFIGURATION BEGINS HERE # The default backend; one of GTK GTKAgg GTKCairo GTK3Agg GTK3Cairo # MacOSX Qt4Agg Qt5Agg TkAgg WX WXAgg Agg Cairo GDK PS PDF SVG # Template. # You can also deploy your own backend outside of matplotlib by # referring to the module name (which must be in the PYTHONPATH) as # 'module://my_backend'. backend : tkagg # If you are using the Qt4Agg backend, you can choose here # to use the PyQt4 bindings or the newer PySide bindings to # the underlying Qt4 toolkit. #backend.qt4 : PyQt4 # PyQt4 | PySide # Note that this can be overridden by the environment variable # QT_API used by Enthought Tool Suite (ETS); valid values are # \"pyqt\" and \"pyside\". The \"pyqt\" setting has the side effect of # forcing the use of Version 2 API for QString and QVariant. # The port to use for the web server in the WebAgg backend. # webagg.port : 8888 # If webagg.port is unavailable, a number of other random ports will # be tried until one that is available is found. # webagg.port_retries : 50 # When True, open the webbrowser to the plot that is shown # webagg.open_in_browser : True # When True, the figures rendered in the nbagg backend are created with # a transparent background. # nbagg.transparent : False # if you are running pyplot inside a GUI and your backend choice # conflicts, we will automatically try to find a compatible one for # you if backend_fallback is True #backend_fallback: True #interactive : False #toolbar : toolbar2 # None | toolbar2 (\"classic\" is deprecated) #timezone : UTC # a pytz timezone string, e.g., US/Central or Europe/Paris # Where your matplotlib data lives if you installed to a non-default # location. This is where the matplotlib fonts, bitmaps, etc reside #datapath : /home/jdhunter/mpldata ### LINES # See http://matplotlib.org/api/artist_api.html#module-matplotlib.lines for more # information on line properties. #lines.linewidth : 1.5 # line width in points #lines.linestyle : - # solid line #lines.color : C0 # has no affect on plot(); see axes.prop_cycle #lines.marker : None # the default marker #lines.markeredgewidth : 1.0 # the line width around the marker symbol #lines.markersize : 6 # markersize, in points #lines.dash_joinstyle : miter # miter|round|bevel #lines.dash_capstyle : butt # butt|round|projecting #lines.solid_joinstyle : miter # miter|round|bevel #lines.solid_capstyle : projecting # butt|round|projecting #lines.antialiased : True # render lines in antialiased (no jaggies) # The three standard dash patterns. These are scaled by the linewidth. #lines.dashed_pattern : 2.8, 1.2 #lines.dashdot_pattern : 4.8, 1.2, 0.8, 1.2 #lines.dotted_pattern : 1.1, 1.1 #lines.scale_dashes : True #markers.fillstyle: full # full|left|right|bottom|top|none ### PATCHES # Patches are graphical objects that fill 2D space, like polygons or # circles. See # http://matplotlib.org/api/artist_api.html#module-matplotlib.patches # information on patch properties #patch.linewidth : 1 # edge width in points. #patch.facecolor : C0 #patch.edgecolor : black # if forced, or patch is not filled #patch.force_edgecolor : False # True to always use edgecolor #patch.antialiased : True # render patches in antialiased (no jaggies) ### HATCHES #hatch.color : k #hatch.linewidth : 1.0 ### Boxplot #boxplot.notch : False #boxplot.vertical : True #boxplot.whiskers : 1.5 #boxplot.bootstrap : None #boxplot.patchartist : False #boxplot.showmeans : False #boxplot.showcaps : True #boxplot.showbox : True #boxplot.showfliers : True #boxplot.meanline : False #boxplot.flierprops.color : 'k' #boxplot.flierprops.marker : 'o' #boxplot.flierprops.markerfacecolor : 'none' #boxplot.flierprops.markeredgecolor : 'k' #boxplot.flierprops.markersize : 6 #boxplot.flierprops.linestyle : 'none' #boxplot.flierprops.linewidth : 1.0 #boxplot.boxprops.color : 'k' #boxplot.boxprops.linewidth : 1.0 #boxplot.boxprops.linestyle : '-' #boxplot.whiskerprops.color : 'k' #boxplot.whiskerprops.linewidth : 1.0 #boxplot.whiskerprops.linestyle : '-' #boxplot.capprops.color : 'k' #boxplot.capprops.linewidth : 1.0 #boxplot.capprops.linestyle : '-' #boxplot.medianprops.color : 'C1' #boxplot.medianprops.linewidth : 1.0 #boxplot.medianprops.linestyle : '-' #boxplot.meanprops.color : 'C2' #boxplot.meanprops.marker : '^' #boxplot.meanprops.markerfacecolor : 'C2' #boxplot.meanprops.markeredgecolor : 'C2' #boxplot.meanprops.markersize : 6 #boxplot.meanprops.linestyle : 'none' #boxplot.meanprops.linewidth : 1.0 ### FONT # # font properties used by text.Text. See # http://matplotlib.org/api/font_manager_api.html for more # information on font properties. The 6 font properties used for font # matching are given below with their default values. # # The font.family property has five values: 'serif' (e.g., Times), # 'sans-serif' (e.g., Helvetica), 'cursive' (e.g., Zapf-Chancery), # 'fantasy' (e.g., Western), and 'monospace' (e.g., Courier). Each of # these font families has a default list of font names in decreasing # order of priority associated with them. When text.usetex is False, # font.family may also be one or more concrete font names. # # The font.style property has three values: normal (or roman), italic # or oblique. The oblique style will be used for italic, if it is not # present. # # The font.variant property has two values: normal or small-caps. For # TrueType fonts, which are scalable fonts, small-caps is equivalent # to using a font size of 'smaller', or about 83%% of the current font # size. # # The font.weight property has effectively 13 values: normal, bold, # bolder, lighter, 100, 200, 300, ..., 900. Normal is the same as # 400, and bold is 700. bolder and lighter are relative values with # respect to the current weight. # # The font.stretch property has 11 values: ultra-condensed, # extra-condensed, condensed, semi-condensed, normal, semi-expanded, # expanded, extra-expanded, ultra-expanded, wider, and narrower. This # property is not currently implemented. # # The font.size property is the default font size for text, given in pts. # 10 pt is the standard value. # #font.family : sans-serif #font.style : normal #font.variant : normal #font.weight : medium #font.stretch : normal # note that font.size controls default text sizes. To configure # special text sizes tick labels, axes, labels, title, etc, see the rc # settings for axes and ticks. Special text sizes can be defined # relative to font.size, using the following values: xx-small, x-small, # small, medium, large, x-large, xx-large, larger, or smaller #font.size : 10.0 #font.serif : DejaVu Serif, Bitstream Vera Serif, New Century Schoolbook, Century Schoolbook L, Utopia, ITC Bookman, Bookman, Nimbus Roman No9 L, Times New Roman, Times, Palatino, Charter, serif #font.sans-serif : DejaVu Sans, Bitstream Vera Sans, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif #font.cursive : Apple Chancery, Textile, Zapf Chancery, Sand, Script MT, Felipa, cursive #font.fantasy : Comic Sans MS, Chicago, Charcoal, Impact, Western, Humor Sans, xkcd, fantasy #font.monospace : DejaVu Sans Mono, Bitstream Vera Sans Mono, Andale Mono, Nimbus Mono L, Courier New, Courier, Fixed, Terminal, monospace ### TEXT # text properties used by text.Text. See # http://matplotlib.org/api/artist_api.html#module-matplotlib.text for more # information on text properties #text.color : black ### LaTeX customizations. See http://wiki.scipy.org/Cookbook/Matplotlib/UsingTex #text.usetex : False # use latex for all text handling. The following fonts # are supported through the usual rc parameter settings: # new century schoolbook, bookman, times, palatino, # zapf chancery, charter, serif, sans-serif, helvetica, # avant garde, courier, monospace, computer modern roman, # computer modern sans serif, computer modern typewriter # If another font is desired which can loaded using the # LaTeX \\usepackage command, please inquire at the # matplotlib mailing list #text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling # unicode strings. #text.latex.preamble : # IMPROPER USE OF THIS FEATURE WILL LEAD TO LATEX FAILURES # AND IS THEREFORE UNSUPPORTED. PLEASE DO NOT ASK FOR HELP # IF THIS FEATURE DOES NOT DO WHAT YOU EXPECT IT TO. # preamble is a comma separated list of LaTeX statements # that are included in the LaTeX document preamble. # An example: # text.latex.preamble : \\usepackage{bm},\\usepackage{euler} # The following packages are always loaded with usetex, so # beware of package collisions: color, geometry, graphicx, # type1cm, textcomp. Adobe Postscript (PSSNFS) font packages # may also be loaded, depending on your font settings #text.dvipnghack : None # some versions of dvipng don't handle alpha # channel properly. Use True to correct # and flush ~/.matplotlib/tex.cache # before testing and False to force # correction off. None will try and # guess based on your dvipng version #text.hinting : auto # May be one of the following: # 'none': Perform no hinting # 'auto': Use FreeType's autohinter # 'native': Use the hinting information in the # font file, if available, and if your # FreeType library supports it # 'either': Use the native hinting information, # or the autohinter if none is available. # For backward compatibility, this value may also be # True === 'auto' or False === 'none'. #text.hinting_factor : 8 # Specifies the amount of softness for hinting in the # horizontal direction. A value of 1 will hint to full # pixels. A value of 2 will hint to half pixels etc. #text.antialiased : True # If True (default), the text will be antialiased. # This only affects the Agg backend. # The following settings allow you to select the fonts in math mode. # They map from a TeX font name to a fontconfig font pattern. # These settings are only used if mathtext.fontset is 'custom'. # Note that this \"custom\" mode is unsupported and may go away in the # future. #mathtext.cal : cursive #mathtext.rm : serif #mathtext.tt : monospace #mathtext.it : serif:italic #mathtext.bf : serif:bold #mathtext.sf : sans #mathtext.fontset : dejavusans # Should be 'dejavusans' (default), # 'dejavuserif', 'cm' (Computer Modern), 'stix', # 'stixsans' or 'custom' #mathtext.fallback_to_cm : True # When True, use symbols from the Computer Modern # fonts when a symbol can not be found in one of # the custom math fonts. #mathtext.default : it # The default font to use for math. # Can be any of the LaTeX font names, including # the special name \"regular\" for the same font # used in regular text. ### AXES # default face and edge color, default tick sizes, # default fontsizes for ticklabels, and so on. See # http://matplotlib.org/api/axes_api.html#module-matplotlib.axes #axes.facecolor : white # axes background color #axes.edgecolor : black # axes edge color #axes.linewidth : 0.8 # edge linewidth #axes.grid : False # display grid or not #axes.titlesize : large # fontsize of the axes title #axes.titlepad : 4.0 # pad between axes and title in points #axes.labelsize : medium # fontsize of the x any y labels #axes.labelpad : 4.0 # space between label and axis #axes.labelweight : normal # weight of the x and y labels #axes.labelcolor : black #axes.axisbelow : 'line' # draw axis gridlines and ticks below # patches (True); above patches but below # lines ('line'); or above all (False) #axes.formatter.limits : -7, 7 # use scientific notation if log10 # of the axis range is smaller than the # first or larger than the second #axes.formatter.use_locale : False # When True, format tick labels # according to the user's locale. # For example, use ',' as a decimal # separator in the fr_FR locale. #axes.formatter.use_mathtext : False # When True, use mathtext for scientific # notation. #axes.formatter.useoffset : True # If True, the tick label formatter # will default to labeling ticks relative # to an offset when the data range is # small compared to the minimum absolute # value of the data. #axes.formatter.offset_threshold : 4 # When useoffset is True, the offset # will be used when it can remove # at least this number of significant # digits from tick labels. # axes.spines.left : True # display axis spines # axes.spines.bottom : True # axes.spines.top : True # axes.spines.right : True #axes.unicode_minus : True # use unicode for the minus symbol # rather than hyphen. See # http://en.wikipedia.org/wiki/Plus_and_minus_signs#Character_codes #axes.prop_cycle : cycler('color', # ['1f77b4', 'ff7f0e', '2ca02c', 'd62728', # '9467bd', '8c564b', 'e377c2', '7f7f7f', # 'bcbd22', '17becf']) # color cycle for plot lines # as list of string colorspecs: # single letter, long name, or # web-style hex #axes.autolimit_mode : data # How to scale axes limits to the data. # Use \"data\" to use data limits, plus some margin # Use \"round_number\" move to the nearest \"round\" number #axes.xmargin : .05 # x margin. See `axes.Axes.margins` #axes.ymargin : .05 # y margin See `axes.Axes.margins` #polaraxes.grid : True # display grid on polar axes #axes3d.grid : True # display grid on 3d axes ### DATES # These control the default format strings used in AutoDateFormatter. # Any valid format datetime format string can be used (see the python # `datetime` for details). For example using '%%x' will use the locale date representation # '%%X' will use the locale time representation and '%%c' will use the full locale datetime # representation. # These values map to the scales: # {'year': 365, 'month': 30, 'day': 1, 'hour': 1/24, 'minute': 1 / (24 * 60)} # date.autoformatter.year : %Y # date.autoformatter.month : %Y-%m # date.autoformatter.day : %Y-%m-%d # date.autoformatter.hour : %H:%M # date.autoformatter.minute : %H:%M:%S # date.autoformatter.second : %H:%M:%S # date.autoformatter.microsecond : %H:%M:%S.%f ### TICKS # see http://matplotlib.org/api/axis_api.html#matplotlib.axis.Tick #xtick.top : False # draw ticks on the top side #xtick.bottom : True # draw ticks on the bottom side #xtick.major.size : 3.5 # major tick size in points #xtick.minor.size : 2 # minor tick size in points #xtick.major.width : 0.8 # major tick width in points #xtick.minor.width : 0.6 # minor tick width in points #xtick.major.pad : 3.5 # distance to major tick label in points #xtick.minor.pad : 3.4 # distance to the minor tick label in points #xtick.color : k # color of the tick labels #xtick.labelsize : medium # fontsize of the tick labels #xtick.direction : out # direction: in, out, or inout #xtick.minor.visible : False # visibility of minor ticks on x-axis #xtick.major.top : True # draw x axis top major ticks #xtick.major.bottom : True # draw x axis bottom major ticks #xtick.minor.top : True # draw x axis top minor ticks #xtick.minor.bottom : True # draw x axis bottom minor ticks #ytick.left : True # draw ticks on the left side #ytick.right : False # draw ticks on the right side #ytick.major.size : 3.5 # major tick size in points #ytick.minor.size : 2 # minor tick size in points #ytick.major.width : 0.8 # major tick width in points #ytick.minor.width : 0.6 # minor tick width in points #ytick.major.pad : 3.5 # distance to major tick label in points #ytick.minor.pad : 3.4 # distance to the minor tick label in points #ytick.color : k # color of the tick labels #ytick.labelsize : medium # fontsize of the tick labels #ytick.direction : out # direction: in, out, or inout #ytick.minor.visible : False # visibility of minor ticks on y-axis #xtick.major.left : True # draw y axis left major ticks #xtick.major.right : True # draw y axis right major ticks #xtick.minor.left : True # draw y axis left minor ticks #xtick.minor.right : True # draw y axis right minor ticks ### GRIDS #grid.color : b0b0b0 # grid color #grid.linestyle : - # solid #grid.linewidth : 0.8 # in points #grid.alpha : 1.0 # transparency, between 0.0 and 1.0 ### Legend #legend.loc : best #legend.frameon : True # if True, draw the legend on a background patch #legend.framealpha : 0.8 # legend patch transparency #legend.facecolor : inherit # inherit from axes.facecolor; or color spec #legend.edgecolor : 0.8 # background patch boundary color #legend.fancybox : True # if True, use a rounded box for the # legend background, else a rectangle #legend.shadow : False # if True, give background a shadow effect #legend.numpoints : 1 # the number of marker points in the legend line #legend.scatterpoints : 1 # number of scatter points #legend.markerscale : 1.0 # the relative size of legend markers vs. original #legend.fontsize : medium # Dimensions as fraction of fontsize: #legend.borderpad : 0.4 # border whitespace #legend.labelspacing : 0.5 # the vertical space between the legend entries #legend.handlelength : 2.0 # the length of the legend lines #legend.handleheight : 0.7 # the height of the legend handle #legend.handletextpad : 0.8 # the space between the legend line and legend text #legend.borderaxespad : 0.5 # the border between the axes and legend edge #legend.columnspacing : 2.0 # column separation ### FIGURE # See http://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure #figure.titlesize : large # size of the figure title (Figure.suptitle()) #figure.titleweight : normal # weight of the figure title #figure.figsize : 6.4, 4.8 # figure size in inches #figure.dpi : 100 # figure dots per inch #figure.facecolor : white # figure facecolor; 0.75 is scalar gray #figure.edgecolor : white # figure edgecolor #figure.autolayout : False # When True, automatically adjust subplot # parameters to make the plot fit the figure #figure.max_open_warning : 20 # The maximum number of figures to open through # the pyplot interface before emitting a warning. # If less than one this feature is disabled. # The figure subplot parameters. All dimensions are a fraction of the #figure.subplot.left : 0.125 # the left side of the subplots of the figure #figure.subplot.right : 0.9 # the right side of the subplots of the figure #figure.subplot.bottom : 0.11 # the bottom of the subplots of the figure #figure.subplot.top : 0.88 # the top of the subplots of the figure #figure.subplot.wspace : 0.2 # the amount of width reserved for blank space between subplots, # expressed as a fraction of the average axis width #figure.subplot.hspace : 0.2 # the amount of height reserved for white space between subplots, # expressed as a fraction of the average axis height ### IMAGES #image.aspect : equal # equal | auto | a number #image.interpolation : nearest # see help(imshow) for options #image.cmap : viridis # A colormap name, gray etc... #image.lut : 256 # the size of the colormap lookup table #image.origin : upper # lower | upper #image.resample : True #image.composite_image : True # When True, all the images on a set of axes are # combined into a single composite image before # saving a figure as a vector graphics file, # such as a PDF. ### CONTOUR PLOTS #contour.negative_linestyle : dashed # dashed | solid #contour.corner_mask : True # True | False | legacy ### ERRORBAR PLOTS #errorbar.capsize : 0 # length of end cap on error bars in pixels ### HISTOGRAM PLOTS #hist.bins : 10 # The default number of histogram bins. # If Numpy 1.11 or later is # installed, may also be `auto` ### SCATTER PLOTS #scatter.marker : o # The default marker type for scatter plots. ### Agg rendering ### Warning: experimental, 2008/10/10 #agg.path.chunksize : 0 # 0 to disable; values in the range # 10000 to 100000 can improve speed slightly # and prevent an Agg rendering failure # when plotting very large data sets, # especially if they are very gappy. # It may cause minor artifacts, though. # A value of 20000 is probably a good # starting point. ### SAVING FIGURES #path.simplify : True # When True, simplify paths by removing \"invisible\" # points to reduce file size and increase rendering # speed #path.simplify_threshold : 0.1 # The threshold of similarity below which # vertices will be removed in the simplification # process #path.snap : True # When True, rectilinear axis-aligned paths will be snapped to # the nearest pixel when certain criteria are met. When False, # paths will never be snapped. #path.sketch : None # May be none, or a 3-tuple of the form (scale, length, # randomness). # *scale* is the amplitude of the wiggle # perpendicular to the line (in pixels). *length* # is the length of the wiggle along the line (in # pixels). *randomness* is the factor by which # the length is randomly scaled. # the default savefig params can be different from the display params # e.g., you may want a higher resolution, or to make the figure # background white #savefig.dpi : figure # figure dots per inch or 'figure' #savefig.facecolor : white # figure facecolor when saving #savefig.edgecolor : white # figure edgecolor when saving #savefig.format : png # png, ps, pdf, svg #savefig.bbox : standard # 'tight' or 'standard'. # 'tight' is incompatible with pipe-based animation # backends but will workd with temporary file based ones: # e.g. setting animation.writer to ffmpeg will not work, # use ffmpeg_file instead #savefig.pad_inches : 0.1 # Padding to be used when bbox is set to 'tight' #savefig.jpeg_quality: 95 # when a jpeg is saved, the default quality parameter. #savefig.directory : ~ # default directory in savefig dialog box, # leave empty to always use current working directory #savefig.transparent : False # setting that controls whether figures are saved with a # transparent background by default # tk backend params #tk.window_focus : False # Maintain shell focus for TkAgg # ps backend params #ps.papersize : letter # auto, letter, legal, ledger, A0-A10, B0-B10 #ps.useafm : False # use of afm fonts, results in small files #ps.usedistiller : False # can be: None, ghostscript or xpdf # Experimental: may produce smaller files. # xpdf intended for production of publication quality files, # but requires ghostscript, xpdf and ps2eps #ps.distiller.res : 6000 # dpi #ps.fonttype : 3 # Output Type 3 (Type3) or Type 42 (TrueType) # pdf backend params #pdf.compression : 6 # integer from 0 to 9 # 0 disables compression (good for debugging) #pdf.fonttype : 3 # Output Type 3 (Type3) or Type 42 (TrueType) # svg backend params #svg.image_inline : True # write raster image data directly into the svg file #svg.fonttype : 'path' # How to handle SVG fonts: # 'none': Assume fonts are installed on the machine where the SVG will be viewed. # 'path': Embed characters as paths -- supported by most SVG renderers # 'svgfont': Embed characters as SVG fonts -- supported only by Chrome, # Opera and Safari #svg.hashsalt : None # if not None, use this string as hash salt # instead of uuid4 # docstring params #docstring.hardcopy = False # set this when you want to generate hardcopy docstring # Set the verbose flags. This controls how much information # matplotlib gives you at runtime and where it goes. The verbosity # levels are: silent, helpful, debug, debug-annoying. Any level is # inclusive of all the levels below it. If your setting is \"debug\", # you'll get all the debug and helpful messages. When submitting # problems to the mailing-list, please set verbose to \"helpful\" or \"debug\" # and paste the output into your report. # # The \"fileo\" gives the destination for any calls to verbose.report. # These objects can a filename, or a filehandle like sys.stdout. # # You can override the rc default verbosity from the command line by # giving the flags --verbose-LEVEL where LEVEL is one of the legal # levels, e.g., --verbose-helpful. # # You can access the verbose instance in your code # from matplotlib import verbose. #verbose.level : silent # one of silent, helpful, debug, debug-annoying #verbose.fileo : sys.stdout # a log filename, sys.stdout or sys.stderr # Event keys to interact with figures/plots via keyboard. # Customize these settings according to your needs. # Leave the field(s) empty if you don't need a key-map. (i.e., fullscreen : '') #keymap.fullscreen : f # toggling #keymap.home : h, r, home # home or reset mnemonic #keymap.back : left, c, backspace # forward / backward keys to enable #keymap.forward : right, v # left handed quick navigation #keymap.pan : p # pan mnemonic #keymap.zoom : o # zoom mnemonic #keymap.save : s # saving current figure #keymap.quit : ctrl+w, cmd+w # close the current figure #keymap.grid : g # switching on/off a grid in current axes #keymap.yscale : l # toggle scaling of y-axes ('log'/'linear') #keymap.xscale : L, k # toggle scaling of x-axes ('log'/'linear') #keymap.all_axes : a # enable all axes # Control location of examples data files #examples.directory : '' # directory to look in for custom installation ###ANIMATION settings #animation.html : 'none' # How to display the animation as HTML in # the IPython notebook. 'html5' uses # HTML5 video tag. #animation.writer : ffmpeg # MovieWriter 'backend' to use #animation.codec : h264 # Codec to use for writing movie #animation.bitrate: -1 # Controls size/quality tradeoff for movie. # -1 implies let utility auto-determine #animation.frame_format: 'png' # Controls frame format used by temp files #animation.ffmpeg_path: 'ffmpeg' # Path to ffmpeg binary. Without full path # $PATH is searched #animation.ffmpeg_args: '' # Additional arguments to pass to ffmpeg #animation.avconv_path: 'avconv' # Path to avconv binary. Without full path # $PATH is searched #animation.avconv_args: '' # Additional arguments to pass to avconv #animation.mencoder_path: 'mencoder' # Path to mencoder binary. Without full path # $PATH is searched #animation.mencoder_args: '' # Additional arguments to pass to mencoder #animation.convert_path: 'convert' # Path to ImageMagick's convert binary. # On Windows use the full path since convert # is also the name of a system tool. 自定义主题(支持中文字体) 我们当然可以自己定义自己的主题,他的内容和matplotlibrc一样,但以.mplstyle作为后缀,自定义的主题放在mpl_configdir/stylelib下就可以被识别,比如我们定义一个专用于可以显示中文的主题chinese_support.mplstyle 第一步,下载字体,我们使用[微软雅黑],下载好后放在自己的设置文件夹matplotlib安装根目录/matplotlib/mpl-data/下的fonts/ttf文件夹中(这步如果已经有字体文件可以省略) 第二步,在你的设置文件夹下的stylelib文件夹下(没有就自己创建)写下 font.family : LiHei ProLi,Song Pro,Microsoft YaHei, sans-serif 为了跨平台,可以把Microsoft YaHei放到前面,但个人觉得没苹果的字体好看,就算了 第三步,删除fontList.cache文件然后重启即可 查看自己有哪些字体可以使用如下命令 from matplotlib.font_manager import FontManager import subprocess fm = FontManager() mat_fonts = set(f.name for f in fm.ttflist) mat_fonts {'.Keyboard', '.LastResort', 'Andale Mono', 'Apple Braille', 'Apple Chancery', 'AppleGothic', 'AppleMyungjo', 'Arial', 'Arial Black', 'Arial Narrow', 'Arial Rounded MT Bold', 'Arial Unicode MS', 'Ayuthaya', 'Big Caslon', 'Bodoni 72 Smallcaps', 'Bodoni Ornaments', 'Bradley Hand', 'Brush Script MT', 'Chalkduster', 'Comic Sans MS', 'Courier New', 'DIN Alternate', 'DIN Condensed', 'DejaVu Sans', 'DejaVu Sans Display', 'DejaVu Sans Mono', 'DejaVu Serif', 'DejaVu Serif Display', 'Diwan Thuluth', 'Farisi', 'Georgia', 'GungSeo', 'Gurmukhi MT', 'HeadLineA', 'Herculanum', 'Hoefler Text', 'Impact', 'InaiMathi', 'Khmer Sangam MN', 'Kokonor', 'Krungthep', 'Lao Sangam MN', 'LiHei Pro', 'LiSong Pro', 'Luminari', 'Microsoft Sans Serif', 'Mishafi', 'Mishafi Gold', 'Osaka', 'PCMyungjo', 'PilGi', 'Plantagenet Cherokee', 'STFangsong', 'STHeiti', 'STIXGeneral', 'STIXIntegralsD', 'STIXIntegralsSm', 'STIXIntegralsUp', 'STIXIntegralsUpD', 'STIXIntegralsUpSm', 'STIXNonUnicode', 'STIXSizeFiveSym', 'STIXSizeFourSym', 'STIXSizeOneSym', 'STIXSizeThreeSym', 'STIXSizeTwoSym', 'STIXVariants', 'Sathu', 'SignPainter', 'Silom', 'Skia', 'Symbol', 'System Font', 'Tahoma', 'Times New Roman', 'Trattatello', 'Trebuchet MS', 'Verdana', 'Wawati SC', 'Wawati TC', 'Webdings', 'Weibei SC', 'Weibei TC', 'Wingdings', 'Wingdings 2', 'Wingdings 3', 'YuGothic', 'Yuppy SC', 'Yuppy TC', 'Zapf Dingbats', 'Zapfino', 'cmb10', 'cmex10', 'cmmi10', 'cmr10', 'cmss10', 'cmsy10', 'cmtt10'} X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=u\"余弦\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=u\"正弦\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() plt.style.use('chinese_support') X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=u\"余弦\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=u\"正弦\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() matplotlib 对notebook的特殊支持 matplotlib提供了一个backend为jupyter notebook 提供了控件支持 from __future__ import print_function from imp import reload import matplotlib reload(matplotlib) matplotlib.use('nbagg') import matplotlib.backends.backend_nbagg reload(matplotlib.backends.backend_nbagg) 非交互模式 import matplotlib.backends.backend_webagg_core reload(matplotlib.backends.backend_webagg_core) import matplotlib.pyplot as plt plt.interactive(False) fig1 = plt.figure() plt.plot(range(10)) plt.show() 定义了第一张图后,后面的定义就可以不再使用plt.figure() plt.plot([3, 2, 1]) plt.show() 我们可以用connection_info()查看每张图片的ui状态 print(matplotlib.backends.backend_nbagg.connection_info()) Figure 1 - Figure 1 Figure 2 - Figure 2 Figures pending show: 0 也可以关闭一副图的ui plt.close(fig1) 在非交互模式下没有plt.show就不会显示 plt.plot(range(10)) [] 显示以前创建的图 plt.show() plt.figure() plt.plot(range(5)) plt.show() 交互模式 使用plt.interactive(True)开启交互模式,交互模式下不需要show就可以显示图片 plt.interactive(True) plt.figure() plt.plot([3, 2, 1]) [] 后续行应添加到现有图形，而不是创建一个新的图形。 plt.plot(range(3)) [] 在交互模式下调用connection_info不应显示任何未决数字 print(matplotlib.backends.backend_nbagg.connection_info()) Figure 2 - Figure 2 Figure 3 - Figure 3 Figure 4 - Figure 4 Figure 5 - Figure 5 这种模式用来调试不错,并不适合用来做图 plt.interactive(False) 多个显示 plt.gcf().canvas.manager.reshow() 动画 import matplotlib.animation as animation import numpy as np fig, ax = plt.subplots() x = np.arange(0, 2*np.pi, 0.01) # x-array line, = ax.plot(x, np.sin(x)) def animate(i): line.set_ydata(np.sin(x+i/10.0)) # update the data return line, #Init only required for blitting to give a clean slate. def init(): line.set_ydata(np.ma.array(x, mask=True)) return line, ani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init, interval=32., blit=True) plt.show() 绑定事件动作 按任何键盘键或鼠标按钮（或滚动）应该在图形有焦点时循环线条线。该图在创建时应默认具有焦点，并通过单击画布重新获得。单击图形外的任何位置都应该释放焦点，但将鼠标移出图形不应该释放焦点。 import itertools fig, ax = plt.subplots() x = np.linspace(0,10,10000) y = np.sin(x) ln, = ax.plot(x,y) evt = [] colors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c'])) def on_event(event): if event.name.startswith('key'): fig.suptitle('%s: %s' % (event.name, event.key)) elif event.name == 'scroll_event': fig.suptitle('%s: %s' % (event.name, event.step)) else: fig.suptitle('%s: %s' % (event.name, event.button)) evt.append(event) ln.set_color(next(colors)) fig.canvas.draw() fig.canvas.draw_idle() fig.canvas.mpl_connect('button_press_event', on_event) fig.canvas.mpl_connect('button_release_event', on_event) fig.canvas.mpl_connect('scroll_event', on_event) fig.canvas.mpl_connect('key_press_event', on_event) fig.canvas.mpl_connect('key_release_event', on_event) plt.show() 计时器 import time fig, ax = plt.subplots() text = ax.text(0.5, 0.5, '', ha='center') def update(text): text.set(text=time.ctime()) text.axes.figure.canvas.draw() timer = fig.canvas.new_timer(500, [(update, [text], {})]) timer.start() plt.show() Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:39:32 "},"人机交互篇/使用matplotlib做数据可视化/绘图工具pyplot/绘图工具pyplot.html":{"url":"人机交互篇/使用matplotlib做数据可视化/绘图工具pyplot/绘图工具pyplot.html","title":"绘图工具pyplot","keywords":"","body":"绘图工具pyplot matplotlib.pylot是matplotlib的绘图工具 我们将会由一个绘制sin(x)曲线的例子开始,由简单到复杂的学习这个库 最简单的实现 最基本的函数就是plt.plot()了,它会产生一个图形, import matplotlib.pyplot as plt import pylab %matplotlib inline import numpy as np plt.style.use('chinese_support') X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plt.plot(X,C);plt.plot(X,S) [] 修改一些设置 plot接收参数,可以使用color指定线的颜色,用linewidth指定线条粗细,linestyle指定线条形状 plt.figure(figsize=(10,6), dpi=80)#设置图片大小和dpi plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\");plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"--\") [] 边界扩大 我们可以i为plt对象绑定xlim和ylim来指定坐标轴的范围 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\") plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.show() 设置y轴记号标签 xtick和ytick则是可以接收一个序列来确定刻度 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\") plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 plt.show() 移动脊柱 实际上每幅图有四条脊柱（上下左右），为了将脊柱放在图的中间，我们必须将其中的两条（上和右）设置为无色，然后调整剩下的两条到合适的位置——数据空间的 0 点。 脊柱使用对象gca来操作 它有 .spines选择'right','top','bottom','left'来确定要操作的是哪条脊柱 .set_color设置颜色 .set_position设定位置 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\") plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() 图例 plt.legend(loc=)可以用来初始化图例位置 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=\"cosine\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=\"sine\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() 给一些特殊点做注释 我们希望在 $2\\pi/3$ 的位置给两条函数曲线加上一个注释。首先，我们在对应的函数图像位置上画一个点；然后，向横轴引一条垂线，以虚线标记；最后，写上标签。 plt.text可以在图上指定位置配上文字 plt.annotate可以用来画出图片上的说明文字 plt.plot用来画直线 plt.scatter 可以用来画交点 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.text(0.25, 0.75, r'$cos(x)$') plt.text(1.25, 0.75, r'$sin(x)$') plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=\"cosine\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=\"sine\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) t = 2*np.pi/3 #特殊点x轴位置 plt.plot([t,t],[0,np.cos(t)], color ='blue', linewidth=2.5, linestyle=\"--\")#竖线从0到与cos(t)交点,蓝色虚线 plt.scatter([t,],[np.cos(t),], 50, color ='blue')# 画交点 plt.annotate(r'$\\sin(\\frac{2\\pi}{3})=\\frac{\\sqrt{3}}{2}$', xy=(t, np.sin(t)), xycoords='data', xytext=(+10, +30), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.plot([t,t],[0,np.sin(t)], color ='red', linewidth=2.5, linestyle=\"--\")#竖线从0到与sin(t)交点,红色虚线 plt.scatter([t,],[np.sin(t),], 50, color ='red')# 画交点 plt.annotate(r'$\\cos(\\frac{2\\pi}{3})=-\\frac{1}{2}$', xy=(t, np.cos(t)), xycoords='data', xytext=(-90, -50), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.show() 精益求精 坐标轴上的记号标签被曲线挡住了，作为强迫症患者这是不能忍的。我们可以把它们放大，然后添加一个白色的半透明底色。这样可以保证标签和曲线同时可见。 并且我们给图片加上格子 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=\"cosine\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=\"sine\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) # 添加一个白色的半透明底色 for label in ax.get_xticklabels() + ax.get_yticklabels(): label.set_fontsize(16) label.set_bbox(dict(facecolor='white', edgecolor='None', alpha=0.65 )) t = 2*np.pi/3 #特殊点x轴位置 plt.plot([t,t],[0,np.cos(t)], color ='blue', linewidth=2.5, linestyle=\"--\")#竖线从0到与cos(t)交点,蓝色虚线 plt.scatter([t,],[np.cos(t),], 50, color ='blue')# 画交点 plt.annotate(r'$\\sin(\\frac{2\\pi}{3})=\\frac{\\sqrt{3}}{2}$', xy=(t, np.sin(t)), xycoords='data', xytext=(+10, +30), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.plot([t,t],[0,np.sin(t)], color ='red', linewidth=2.5, linestyle=\"--\")#竖线从0到与sin(t)交点,红色虚线 plt.scatter([t,],[np.sin(t),], 50, color ='red')# 画交点 plt.annotate(r'$\\cos(\\frac{2\\pi}{3})=-\\frac{1}{2}$', xy=(t, np.cos(t)), xycoords='data', xytext=(-90, -50), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.grid(True) plt.show() 填充颜色 fill_between方法来填充两个线条间的内容 n = 256 X = np.linspace(-np.pi,np.pi,n,endpoint=True) Y = np.sin(2*X) plt.axes([0.025,0.025,0.95,0.95]) plt.plot (X, Y+1, color='blue', alpha=1.00) plt.fill_between(X, 1, Y+1, color='blue', alpha=.25) plt.plot (X, Y-1, color='blue', alpha=1.00) plt.fill_between(X, -1, Y-1, (Y-1) > -1, color='blue', alpha=.25) plt.fill_between(X, -1, Y-1, (Y-1) 图像、子图、坐标轴和记号 到目前为止，我们都用隐式的方法来绘制图像和坐标轴。快速绘图中，这是很方便的。我们也可以显式地控制图像、子图、坐标轴。Matplotlib 中的「图像」指的是用户界面看到的整个窗口内容。在图像里面有所谓「子图」。子图的位置是由坐标网格确定的，而「坐标轴」却不受此限制，可以放在图像的任意位置。我们已经隐式地使用过图像和子图：当我们调用 plot 函数的时候，matplotlib 调用 gca() 函数以及 gcf() 函数来获取当前的坐标轴和图像；如果无法获取图像，则会调用 figure() 函数来创建一个——严格地说，是用 subplot(1,1,1) 创建一个只有一个子图的图像。 子图像 你可以用子图来将图样（plot）放在均匀的坐标网格中。用 subplot 函数的时候，你需要指明网格的行列数量，以及你希望将图样放在哪一个网格区域中。此外，gridspec 的功能更强大，你也可以选择它来实现这个功能。 plt.subplot(2,2,1) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,1)',ha='center',va='center',size=20,alpha=.5) plt.subplot(2,2,2) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,2)',ha='center',va='center',size=20,alpha=.5) plt.subplot(2,2,3) plt.xticks([]),plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,3)',ha='center',va='center',size=20,alpha=.5) plt.subplot(2,2,4) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,4)',ha='center',va='center',size=20,alpha=.5) # savefig('../figures/subplot-grid.png', dpi=64) plt.show() 格子grid ax = plt.axes([0.025,0.025,0.95,0.95]) ax.set_xlim(0,4) ax.set_ylim(0,3) ax.xaxis.set_major_locator(plt.MultipleLocator(1.0)) ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1)) ax.yaxis.set_major_locator(plt.MultipleLocator(1.0)) ax.yaxis.set_minor_locator(plt.MultipleLocator(0.1)) ax.grid(which='major', axis='x', linewidth=0.75, linestyle='-', color='0.75') ax.grid(which='minor', axis='x', linewidth=0.25, linestyle='-', color='0.75') ax.grid(which='major', axis='y', linewidth=0.75, linestyle='-', color='0.75') ax.grid(which='minor', axis='y', linewidth=0.25, linestyle='-', color='0.75') ax.set_xticklabels([]) ax.set_yticklabels([]) plt.show() 多重网格 plt.subplot(2,2,1) plt.subplot(2,2,3) plt.subplot(2,2,4) plt.show() fig = plt.figure() fig.subplots_adjust(bottom=0.025, left=0.025, top = 0.975, right=0.975) plt.subplot(2,1,1) plt.xticks([]), plt.yticks([]) plt.subplot(2,3,4) plt.xticks([]), plt.yticks([]) plt.subplot(2,3,5) plt.xticks([]), plt.yticks([]) plt.subplot(2,3,6) plt.xticks([]), plt.yticks([]) plt.show() 坐标轴 坐标轴和子图功能类似，不过它可以放在图像的任意位置。因此，如果你希望在一副图中绘制一个小图，就可以用这个功能。 plt.axes([0.1,0.1,.8,.8]) plt.xticks([]), plt.yticks([]) plt.text(0.6,0.6, 'axes([0.1,0.1,.8,.8])',ha='center',va='center',size=20,alpha=.5) plt.axes([0.2,0.2,.3,.3]) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'axes([0.2,0.2,.3,.3])',ha='center',va='center',size=16,alpha=.5) #plt.savefig(\"../figures/axes.png\",dpi=64) plt.show() plt.axes([0.1,0.1,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.1,0.1,.8,.8])',ha='left',va='center',size=16,alpha=.5) plt.axes([0.2,0.2,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.2,0.2,.5,.5])',ha='left',va='center',size=16,alpha=.5) plt.axes([0.3,0.3,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.3,0.3,.5,.5])',ha='left',va='center',size=16,alpha=.5) plt.axes([0.4,0.4,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.4,0.4,.5,.5])',ha='left',va='center',size=16,alpha=.5) # plt.savefig(\"../figures/axes-2.png\",dpi=64) plt.show() 记号 良好的记号是图像的重要组成部分。Matplotlib 里的记号系统里的各个细节都是可以由用户个性化配置的。你可以用 Tick Locators 来指定在那些位置放置记号，用 Tick Formatters 来调整记号的样式。主要和次要的记号可以以不同的方式呈现。默认情况下，每一个次要的记号都是隐藏的，也就是说，默认情况下的次要记号列表是空的——NullLocator。 下面有为不同需求设计的一些 Locators: NullLocatorNo ticks. IndexLocatorPlace a tick on every multiple of some base number of points plotted. FixedLocatorTick locations are fixed. LinearLocatorDetermine the tick locations. MultipleLocatorSet a tick on every integer that is multiple of some base. AutoLocatorSelect no more than n intervals at nice locations. LogLocatorDetermine the tick locations for log axes. 特殊图形 除了点线等基本工具,还可以直接使用设置好的类型画一些基本图形 散点图scatter n = 1024 X = np.random.normal(0,1,n) Y = np.random.normal(0,1,n) plt.scatter(X,Y) plt.show() n = 1024 X = np.random.normal(0,1,n) Y = np.random.normal(0,1,n) T = np.arctan2(Y,X) # 计算出象限 plt.axes([0.025,0.025,0.95,0.95]) plt.scatter(X,Y, s=75, c=T, alpha=.5) plt.xlim(-1.5,1.5), plt.xticks([]) plt.ylim(-1.5,1.5), plt.yticks([]) plt.show() 栅栏图bar n = 12 X = np.arange(n) Y1 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) Y2 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) plt.bar(X, +Y1, facecolor='#9999ff', edgecolor='white') plt.bar(X, -Y2, facecolor='#ff9999', edgecolor='white') for x,y in zip(X,Y1): plt.text(x+0.4, y+0.05, '%.2f' % y, ha='center', va= 'bottom') plt.ylim(-1.25,+1.25) plt.show() n = 12 X = np.arange(n) Y1 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) Y2 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) plt.axes([0.025,0.025,0.95,0.95]) plt.bar(X, +Y1, facecolor='#9999ff', edgecolor='white') plt.bar(X, -Y2, facecolor='#ff9999', edgecolor='white') for x,y in zip(X,Y1): plt.text(x+0.4, y+0.05, '%.2f' % y, ha='center', va= 'bottom') for x,y in zip(X,Y2): plt.text(x+0.4, -y-0.05, '%.2f' % y, ha='center', va= 'top') plt.xlim(-.5,n), plt.xticks([]) plt.ylim(-1.25,+1.25), plt.yticks([]) plt.show() 等高线图meshgrid def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 256 x = np.linspace(-3,3,n) y = np.linspace(-3,3,n) X,Y = np.meshgrid(x,y) plt.contourf(X, Y, f(X,Y), 8, alpha=.75, cmap='jet') C = plt.contour(X, Y, f(X,Y), 8, colors='black', linewidth=.5) plt.show() def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 256 x = np.linspace(-3,3,n) y = np.linspace(-3,3,n) X,Y = np.meshgrid(x,y) plt.axes([0.025,0.025,0.95,0.95]) plt.contourf(X, Y, f(X,Y), 8, alpha=.75, cmap=plt.cm.hot) C = plt.contour(X, Y, f(X,Y), 8, colors='black', linewidth=.5) plt.clabel(C, inline=1, fontsize=10) plt.xticks([]), plt.yticks([]) plt.show() 灰度图（Imshow） def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 10 x = np.linspace(-3,3,4*n) y = np.linspace(-3,3,3*n) X,Y = np.meshgrid(x,y) plt.imshow(f(X,Y)) plt.show() def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 10 x = np.linspace(-3,3,3.5*n) y = np.linspace(-3,3,3.0*n) X,Y = np.meshgrid(x,y) Z = f(X,Y) plt.axes([0.025,0.025,0.95,0.95]) plt.imshow(Z,interpolation='nearest', cmap='bone', origin='lower') plt.colorbar(shrink=.92) plt.xticks([]), plt.yticks([]) plt.show() 饼状图 n = 20 Z = np.random.uniform(0,1,n) plt.pie(Z) plt.show() n = 20 Z = np.ones(n) Z[-1] *= 2 plt.axes([0.025,0.025,0.95,0.95]) plt.pie(Z, explode=Z*.05, colors = ['%f' % (i/float(n)) for i in range(n)]) plt.gca().set_aspect('equal') plt.xticks([]), plt.yticks([]) plt.show() 柱状图hist mu, sigma = 100, 15 x = mu + sigma * np.random.randn(10000) plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75) plt.xlabel('Smarts') plt.ylabel('Probability') plt.title('Histogram of IQ') plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$') plt.axis([40, 160, 0, 0.03]) plt.grid(True) 量场图--箭头（Quiver Plots） n = 8 X,Y = np.mgrid[0:n,0:n] plt.quiver(X,Y) plt.show() n = 8 X,Y = np.mgrid[0:n,0:n] T = np.arctan2(Y-n/2.0, X-n/2.0) R = 10+np.sqrt((Y-n/2.0)**2+(X-n/2.0)**2) U,V = R*np.cos(T), R*np.sin(T) plt.axes([0.025,0.025,0.95,0.95]) plt.quiver(X,Y,U,V,R, alpha=.5) plt.quiver(X,Y,U,V, edgecolor='k', facecolor='None', linewidth=.5) plt.xlim(-1,n), plt.xticks([]) plt.ylim(-1,n), plt.yticks([]) plt.show() 极轴图 plt.axes([0,0,1,1]) N = 20 theta = np.arange(0.0, 2*np.pi, 2*np.pi/N) radii = 10*np.random.rand(N) width = np.pi/4*np.random.rand(N) bars = plt.bar(theta, radii, width=width, bottom=0.0) for r,bar in zip(radii, bars): bar.set_facecolor( plt.cm.jet(r/10.)) bar.set_alpha(0.5) plt.show() ax = plt.axes([0.025,0.025,0.95,0.95], polar=True) N = 20 theta = np.arange(0.0, 2*np.pi, 2*np.pi/N) radii = 10*np.random.rand(N) width = np.pi/4*np.random.rand(N) bars = plt.bar(theta, radii, width=width, bottom=0.0) for r,bar in zip(radii, bars): bar.set_facecolor( plt.cm.jet(r/10.)) bar.set_alpha(0.5) ax.set_xticklabels([]) ax.set_yticklabels([]) plt.show() 3D 图 from mpl_toolkits.mplot3d import Axes3D fig = plt.figure() ax = Axes3D(fig) X = np.arange(-4, 4, 0.25) Y = np.arange(-4, 4, 0.25) X, Y = np.meshgrid(X, Y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R) ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='hot') plt.show() fig = plt.figure() ax = Axes3D(fig) X = np.arange(-4, 4, 0.25) Y = np.arange(-4, 4, 0.25) X, Y = np.meshgrid(X, Y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R) ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.cm.hot) ax.contourf(X, Y, Z, zdir='z', offset=-2, cmap=plt.cm.hot) ax.set_zlim(-2,2) plt.show() 手稿 eqs = [] eqs.append((r\"$W^{3\\beta}_{\\delta_1 \\rho_1 \\sigma_2} = U^{3\\beta}_{\\delta_1 \\rho_1} + \\frac{1}{8 \\pi 2} \\int^{\\alpha_2}_{\\alpha_2} d \\alpha^\\prime_2 \\left[\\frac{ U^{2\\beta}_{\\delta_1 \\rho_1} - \\alpha^\\prime_2U^{1\\beta}_{\\rho_1 \\sigma_2} }{U^{0\\beta}_{\\rho_1 \\sigma_2}}\\right]$\")) eqs.append((r\"$\\frac{d\\rho}{d t} + \\rho \\vec{v}\\cdot\\nabla\\vec{v} = -\\nabla p + \\mu\\nabla^2 \\vec{v} + \\rho \\vec{g}$\")) eqs.append((r\"$\\int_{-\\infty}^\\infty e^{-x^2}dx=\\sqrt{\\pi}$\")) eqs.append((r\"$E = mc^2$\")) eqs.append((r\"$F_G = G\\frac{m_1m_2}{r^2}$\")) plt.axes([0.025,0.025,0.95,0.95]) for i in range(24): index = np.random.randint(0,len(eqs)) eq = eqs[index] size = np.random.uniform(12,32) x,y = np.random.uniform(0,1,2) alpha = np.random.uniform(0.25,.75) plt.text(x, y, eq, ha='center', va='center', color=\"#11557c\", alpha=alpha, transform=plt.gca().transAxes, fontsize=size, clip_on=True) plt.xticks([]), plt.yticks([]) # savefig('../figures/text_ex.png',dpi=48) plt.show() 箱形图 箱形图可以用来集中化的体现数据的特点 np.random.seed(937) data = np.random.lognormal(size=(37, 4), mean=1.5, sigma=1.75) labels = list('ABCD') fs = 10 # fontsize # demonstrate how to toggle the display of different elements: fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6, 6)) axes[0, 0].boxplot(data, labels=labels) axes[0, 0].set_title('Default', fontsize=fs) axes[0, 1].boxplot(data, labels=labels, showmeans=True) axes[0, 1].set_title('showmeans=True', fontsize=fs) axes[0, 2].boxplot(data, labels=labels, showmeans=True, meanline=True) axes[0, 2].set_title('showmeans=True,\\nmeanline=True', fontsize=fs) axes[1, 0].boxplot(data, labels=labels, showbox=False, showcaps=False) axes[1, 0].set_title('Tufte Style \\n(showbox=False,\\nshowcaps=False)', fontsize=fs) axes[1, 1].boxplot(data, labels=labels, notch=True, bootstrap=10000) axes[1, 1].set_title('notch=True,\\nbootstrap=10000', fontsize=fs) axes[1, 2].boxplot(data, labels=labels, showfliers=False) axes[1, 2].set_title('showfliers=False', fontsize=fs) for ax in axes.flatten(): ax.set_yscale('log') ax.set_yticklabels([]) fig.subplots_adjust(hspace=0.4) plt.show() # demonstrate how to customize the display different elements: boxprops = dict(linestyle='--', linewidth=3, color='darkgoldenrod') flierprops = dict(marker='o', markerfacecolor='green', markersize=12, linestyle='none') medianprops = dict(linestyle='-.', linewidth=2.5, color='firebrick') meanpointprops = dict(marker='D', markeredgecolor='black', markerfacecolor='firebrick') meanlineprops = dict(linestyle='--', linewidth=2.5, color='purple') fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6, 6)) axes[0, 0].boxplot(data, boxprops=boxprops) axes[0, 0].set_title('Custom boxprops', fontsize=fs) axes[0, 1].boxplot(data, flierprops=flierprops, medianprops=medianprops) axes[0, 1].set_title('Custom medianprops\\nand flierprops', fontsize=fs) axes[0, 2].boxplot(data, whis='range') axes[0, 2].set_title('whis=\"range\"', fontsize=fs) axes[1, 0].boxplot(data, meanprops=meanpointprops, meanline=False, showmeans=True) axes[1, 0].set_title('Custom mean\\nas point', fontsize=fs) axes[1, 1].boxplot(data, meanprops=meanlineprops, meanline=True, showmeans=True) axes[1, 1].set_title('Custom mean\\nas line', fontsize=fs) axes[1, 2].boxplot(data, whis=[15, 85]) axes[1, 2].set_title('whis=[15, 85]\\n#percentiles', fontsize=fs) for ax in axes.flatten(): ax.set_yscale('log') ax.set_yticklabels([]) fig.suptitle(\"I never said they'd be pretty\") fig.subplots_adjust(hspace=0.4) plt.show() 更多的图形可以在http://matplotlib.org/api/pyplot_summary.html中查看 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:40:38 "},"人机交互篇/使用matplotlib做数据可视化/非结构网络/非结构网络.html":{"url":"人机交互篇/使用matplotlib做数据可视化/非结构网络/非结构网络.html","title":"非结构网络","keywords":"","body":"非结构网络 非结构网格是没有规则拓扑关系的网格，它通常由多边形三角形组成。 网格中的每个每个元素都可以是二维的多边形或者三维多面体，其中最常见的是二维的三角形以及三维的四面体。 在每个元素之间没有隐含的连通性。 由于结构网格面对复杂几何外形时生成困难，以及耗费大量人工，自动化程度不高等缺点，非结构网格逐渐发展起来.使用它的技术主要有流体分析,空气动力学,有限元分析等细分领域. matplotlib中有针对它的作图工具matplotlib.tri模块 核心类class matplotlib.tri.Triangulation(x, y, triangles=None, mask=None) 由n个point点和n个三角形组成的非结构化三角形网格。三角形可以由用户指定或使用Delaunay三角测量自动生成。 x,y对应网格点的坐标 triangles 对于每个三角形，组成三角形的三个点的索引以逆时针方式排序。如果未指定，则计算Delaunay三角剖分。 mask 指定哪些三角形的屏蔽数组 它的方法有: calculate_plane_coefficients(z) 从点（x，y）坐标和指定的z形阵列（n points）计算所有未屏蔽三角形的平面方程系数。返回的数组具有形状（n points，3）并且允许使用 z = array [tri，0] x array [tri，1] y array [tri，2] edges 返回包含非屏蔽三角形的所有边的整型数组形状（nedges，2）。每个边是起点索引和终点索引。每个边（开始，结束和结束，开始）只出现一次。 get_masked_triangles() 返回未屏蔽的三角形数组。 get_trifinder() 返回此三角剖分的默认matplotlib.tri.TriFinder,如果需要,创建它.这允许轻松共享相同的TriFinder对象。 neighbors 邻点 set_mask(mask) 设置或清除屏蔽数组. 寻找是三角形算法 matplotlib.tri.TriFinder(triangulation) TriFinder类使用来自M.de Berg，M.van Kreveld，M.Overmars和O. Schwarzkopf的书“Computational Geometry，Algorithms and Applications”，第二版中的梯形映射算法来实现。三角测量必须有效，即它不能具有重复的点，由共线点形成的三角形或重叠的三角形。该算法对于由共线点形成的三角形具有一些公差，但是这不应被依赖。 这个类的实例可以被调用 trifinder(x,y),调用后会 返回包含指定x，y点所在的三角形的索引的数组，或者对于不在三角形内的点返回-1。 x，y是相同形状和任意数量维度的类阵列x和y坐标。 返回具有相同形状和x和y的整数数组。 三角形网格线性插值 matplotlib.tri.LinearTriInterpolator(triangulation, z, trifinder=None) LinearTriInterpolator对三角形网格执行线性插值。每个三角形由平面表示，使得点（x，y）处的内插值位于包含（x，y）的三角形的平面上。因此，内插值在三角形上是连续的，但是它们的一阶导数在三角形之间的边缘处是不连续的。 他的实例有方法gradient(x, y),可以返回在指定的x，y点包含插值导数的2个包含屏蔽数组的列表。 而实例被调用会返回在指定的x，y点包含插值的屏蔽数组。 三角形网格执行三次插值 matplotlib.tri.CubicTriInterpolator(triangulation, z, kind='min_E', trifinder=None, dz=None) CubicTriInterpolator对三角形网格执行三次插值。在一维, 一段上 做三次插值,函数由函数的值和其两端的导数定义。这在三角形内的2-d中几乎相同，除了函数的值及其2导数必须在每个三角形节点处定义。CubicTriInterpolator获取每个节点（由用户提供）的函数值，并在内部计算导数的值，从而实现平滑插值。 （作为一个特殊功能，用户还可以在每个节点强加导数的值，但这不应该是常见的用法。） kind 选择平滑算法，以便计算内插导数（默认为“min_E”）：如果'min_E'：（默认）计算每个节点处的导数以最小化弯曲能量。如果'geom'：每个节点的导数被计算为相关三角形法线的加权平均值。用于速度优化（大网格）。如果'user'：用户提供参数dz，因此不需要计算。 trifinder 如果未指定，Triangulation的默认TriFinder将通过调用matplotlib.tri.Triangulation.get_trifinder（）来使用。 dz 仅在kind ='user'时使用。在这种情况下，dz必须提供为（dzdx，dzdy），其中dzdx，dzdy是与z相同形状的数组，并且是三角点处的内插一阶导数。 内插基于三角网格的Clough-Tocher细分方案（为了使其更清楚，网格的每个三角形将被划分为3个子三角形，并且在每个子三角形上，内插函数是2的三次多项式坐标）。这种技术源自FEM（有限元方法）分析;使用的元件是还原的Hsieh-Clough-Tocher（HCT）元件。其形状函数在[R1]中描述。组合函数保证是C1平滑的，即它是连续的，并且其一阶导数也是连续的（这在三角形内容中是容易显示的，但当穿过边缘时也是如此）。 在默认情况下（种类='min_E'），内插器使由HCT元素形状函数生成的函数空间上的曲率能量最小化 - 利用施加的值，但在每个节点处的任意导数。最小化的函数是所谓的总曲率的积分（基于来自[R2] -PCG稀疏求解器的算法的实现）： $ E(z) = {\\frac 1 2 } \\int_\\Omega ((\\frac {\\partial^2 z} {\\partial x^2} )^2 + (\\frac {\\partial^2 z} {\\partial y^2} )^2 +2(\\frac {\\partial^2 z} {\\partial y \\partial x} )^2)dxdy $ 如果用户选择case type ='geom'，则使用简单的几何近似（三角形法线向量的加权平均），这可以在非常大的网格上提高速度。 例子: from matplotlib.tri import Triangulation, UniformTriRefiner,\\ CubicTriInterpolator import matplotlib.pyplot as plt import matplotlib.cm as cm import numpy as np import math # 计算偶极子的电位 def dipole_potential(x, y): \"\"\" The electric dipole potential V \"\"\" r_sq = x**2 + y**2 theta = np.arctan2(y, x) z = np.cos(theta)/r_sq return (np.max(z) - z) / (np.max(z) - np.min(z)) # 创建三角网格 #----------------------------------------------------------------------------- # 首先创建点的x和y坐标 n_angles = 30 n_radii = 10 min_radius = 0.2 radii = np.linspace(min_radius, 0.95, n_radii) angles = np.linspace(0, 2*math.pi, n_angles, endpoint=False) angles = np.repeat(angles[..., np.newaxis], n_radii, axis=1) angles[:, 1::2] += math.pi/n_angles x = (radii*np.cos(angles)).flatten() y = (radii*np.sin(angles)).flatten() V = dipole_potential(x, y) V[:5] array([ 0. , 0.25222984, 0.35123967, 0.40177562, 0.4296875 ]) triang = Triangulation(x, y) # 屏蔽掉不需要的值 xmid = x[triang.triangles].mean(axis=1) ymid = y[triang.triangles].mean(axis=1) mask = np.where(xmid*xmid + ymid*ymid # 精细化数据 - 内插电位V refiner = UniformTriRefiner(triang) tri_refi, z_test_refi = refiner.refine_field(V, subdiv=3) # 计算电场（Ex，Ey）作为电位梯度 tci = CubicTriInterpolator(triang, -V) # 这里,gradient()需要 网格节点，但可以在其他任何地方 (Ex, Ey) = tci.gradient(triang.x, triang.y) E_norm = np.sqrt(Ex**2 + Ey**2) #作图 plt.figure() plt.gca().set_aspect('equal') plt.triplot(triang, color='0.8') levels = np.arange(0., 1., 0.01) cmap = cm.get_cmap(name='hot', lut=None) # 三角等高线 plt.tricontour(tri_refi, z_test_refi, levels=levels, cmap=cmap, linewidths=[2.0, 1.0, 1.0, 1.0]) # 用quiver绘制电矢量场的方向 plt.quiver(triang.x, triang.y, Ex/E_norm, Ey/E_norm, units='xy', scale=10., zorder=3, color='blue', width=0.007, headwidth=3., headlength=4.) plt.title('Gradient plot: an electrical dipole') plt.show() 通过递归细分的均匀网格细化 matplotlib.tri.UniformTriRefiner(triangulation)类 通过递归细分的均匀网格细化。 它有方法 refine_field(z, triinterpolator=None, subdiv=3) 用来优化在封装三角定义上定义的字段 triinterpolator插值器用于场插值。如果未指定，将使用CubicTriInterpolator。 subdiv细分的递归级别。默认为3.每个三角形将被划分为4个**子细分三角形。 refine_triangulation(return_tri_index=False, subdiv=3) 计算封装三角测量的均匀精细三角测量refi_triangulation。此函数通过将每个父三角形递归地（递归细分的水平）分割成在边中间节点上构建的4个子子三角形，来细化封装的三角形。最后，每个三角形因此被划分为4 **个子三角形。 subdiv的默认值为3，从而为初始三角形的每个三角形产生64个精细子三角形。 return_tri_index布尔值，指示是否将返回指示每个点的父三角形索引的索引表。默认值False。 例子:在粗糙的三角形网格（例如，由相对稀疏的测试数据构建的三角测量）上绘制高质量等高线： # 在用户定义的三角网格上演示高分辨率三轴定位用matplotlib.tri.UniformTriRefiner import matplotlib.tri as tri # 要分析测试的function def function_z(x, y): \"\"\" A function of 2 variables \"\"\" r1 = np.sqrt((0.5 - x)**2 + (0.5 - y)**2) theta1 = np.arctan2(0.5 - x, 0.5 - y) r2 = np.sqrt((-x - 0.2)**2 + (-y - 0.2)**2) theta2 = np.arctan2(-x - 0.2, -y - 0.2) z = -(2*(np.exp((r1/10)**2) - 1)*30. * np.cos(7.*theta1) + (np.exp((r2/10)**2) - 1)*30. * np.cos(11.*theta2) + 0.7*(x**2 + y**2)) return (np.max(z) - z)/(np.max(z) - np.min(z)) # 构建三角网络中的点 n_angles = 20 n_radii = 10 min_radius = 0.15 radii = np.linspace(min_radius, 0.95, n_radii) angles = np.linspace(0, 2*math.pi, n_angles, endpoint=False) angles = np.repeat(angles[..., np.newaxis], n_radii, axis=1) angles[:, 1::2] += math.pi/n_angles x = (radii*np.cos(angles)).flatten() y = (radii*np.sin(angles)).flatten() z = function_z(x, y) #开始构建三角网络 triang = tri.Triangulation(x, y) # 屏蔽不要的店 xmid = x[triang.triangles].mean(axis=1) ymid = y[triang.triangles].mean(axis=1) mask = np.where(xmid*xmid + ymid*ymid # 精细化数据 refiner = tri.UniformTriRefiner(triang) tri_refi, z_test_refi = refiner.refine_field(z, subdiv=3) plt.figure() plt.gca().set_aspect('equal') plt.triplot(triang, lw=0.5, color='white') levels = np.arange(0., 1., 0.025) cmap = cm.get_cmap(name='terrain', lut=None) plt.tricontourf(tri_refi, z_test_refi, levels=levels, cmap=cmap) plt.tricontour(tri_refi, z_test_refi, levels=levels, colors=['0.25', '0.5', '0.5', '0.5', '0.5'], linewidths=[1.0, 0.5, 0.5, 0.5, 0.5]) plt.title(\"High-resolution tricontouring\") plt.show() 三角网格分析和改进的基本工具 matplotlib.tri.TriAnalyzer(triangulation) 定义三角网格分析和改进的基本工具。TriAnalizer封装了一个Triangulation对象，并提供了用于网格分析和网格改进的基本工具。 它有三个方法 circle_ratios(rescale=True) 返回三角形的三角形平坦度的度量。 圆周半径与外接圆半径的比率是广泛使用的三角形平坦度的指标。对于等边三角形，它总是 get_flat_tri_mask(min_circle_ratio=0.01, rescale=True) 消除三角测量中过分平坦的边界三角形。返回一个屏蔽数组new_mask(布尔值)，它允许从边界定位的平面三角形（根据他们的circle_ratios（））清除封装的三角剖分。这个屏蔽数组意味着随后应用于使用matplotlib.tri.Triangulation.set_mask（）的三角测量。 new_mask是初始三角形掩模的扩展，在初始掩模的三角形将保持掩蔽的意义上。new_mask数组是递归计算的;在每个步骤，只有当它们与当前网格边界共享一侧时，才移除平面三角形。因此，在三角域中将不产生新的空穴。 + min_circle_ratio 如果内圆/外圆半径比r/R 这个函数的基本原理是Delaunay三角形(一个非结构化的点集合,有时在边界处包含几乎平坦的三角形)，导致绘图中的伪像（特别是对于高分辨率轮廓化）。用计算的new_mask掩蔽，封装的三角剖分将不包含具有低于min_circle_ratio的圆比率的更多未掩蔽的边界三角形，从而改进后续绘图或插值的网格质量。 例子:随机集合的高分辨率定向 本演示的初始数据点和三角网格为： 在[-1,1]×[-1,1]正方形内部实例化一组随机点 然后计算这些点的Delaunay三角剖分，其中a 随机子集的三角形被用户掩盖（基于 init_mask_frac 参数）。 这将模拟无效的数据。 提出的通用程序获得高分辨率轮廓的这种 数据集如下： 使用matplotlib.tri.TriAnalyzer计算扩展屏蔽,从边框中排除形状不好（平）的三角形三角测量。 将屏蔽应用于三角剖分（使用set_mask）。 使用a来细化和内插数据matplotlib.tri.UniformTriRefiner。 用tricontour绘制精制数据。 from matplotlib.tri import Triangulation, TriAnalyzer, UniformTriRefiner #----------------------------------------------------------------------------- # 用于测试的函数 #----------------------------------------------------------------------------- def experiment_res(x, y): \"\"\" 表实验结果的分析函数\"\"\" x = 2.*x r1 = np.sqrt((0.5 - x)**2 + (0.5 - y)**2) theta1 = np.arctan2(0.5 - x, 0.5 - y) r2 = np.sqrt((-x - 0.2)**2 + (-y - 0.2)**2) theta2 = np.arctan2(-x - 0.2, -y - 0.2) z = (4*(np.exp((r1/10)**2) - 1)*30. * np.cos(3*theta1) + (np.exp((r2/10)**2) - 1)*30. * np.cos(5*theta2) + 2*(x**2 + y**2)) return (np.max(z) - z)/(np.max(z) - np.min(z)) #----------------------------------------------------------------------------- # 生成初始数据测试点和演示的三角测量 #----------------------------------------------------------------------------- n_test = 200 # 测试数据点数，对于subdiv = 3从3到5000进行测试 subdiv = 3 # 平滑图的初始网格的递归细分数。 #值> 3可能导致精细网格的三角形数量非常多：new triangles numbering =（4 ** subdiv）* ntri init_mask_frac = 0.0 min_circle_ratio = .01 # 随机点 random_gen = np.random.mtrand.RandomState(seed=127260) x_test = random_gen.uniform(-1., 1., size=n_test) y_test = random_gen.uniform(-1., 1., size=n_test) z_test = experiment_res(x_test, y_test) # 使用Delaunay三角网格划分 tri = Triangulation(x_test, y_test) ntri = tri.triangles.shape[0] # 剔除一些要屏蔽的点 mask_init = np.zeros(ntri, dtype=np.bool) masked_tri = random_gen.randint(0, ntri, int(ntri*init_mask_frac)) mask_init[masked_tri] = True tri.set_mask(mask_init) #----------------------------------------------------------------------------- # 在高分辨率绘图之前改进三角测量：删除平面三角形 #----------------------------------------------------------------------------- # 掩蔽在三角形网格的边界处的不良形状的三角形 mask = TriAnalyzer(tri).get_flat_tri_mask(min_circle_ratio) tri.set_mask(mask) # 精细化数据 refiner = UniformTriRefiner(tri) tri_refi, z_test_refi = refiner.refine_field(z_test, subdiv=subdiv) # 用于与分析进行比较 z_expected = experiment_res(tri_refi.x, tri_refi.y) flat_tri = Triangulation(x_test, y_test) flat_tri.set_mask(~mask) #开始画图 plot_tri = True # plot of base triangulation plot_masked_tri = True # plot of excessively flat excluded triangles plot_refi_tri = False # plot of refined triangulation plot_expected = False # plot of analytical function values for comparison # Graphical options for tricontouring levels = np.arange(0., 1., 0.025) cmap = cm.get_cmap(name='Blues', lut=None) plt.figure() plt.gca().set_aspect('equal') plt.title(\"Filtering a Delaunay mesh\\n\" + \"(application to high-resolution tricontouring)\") # 1) 精确（计算）数据轮廓的图： plt.tricontour(tri_refi, z_test_refi, levels=levels, cmap=cmap, linewidths=[2.0, 0.5, 1.0, 0.5]) # 2) 预期（分析）数据轮廓（虚线）的图： if plot_expected: plt.tricontour(tri_refi, z_expected, levels=levels, cmap=cmap, linestyles='--') # 3) 进行内插的细网格的图： if plot_refi_tri: plt.triplot(tri_refi, color='0.97') # 4) 初始“粗糙”网格的图： if plot_tri: plt.triplot(tri, color='0.7') # 4) 从原生的Delaunay三角形而来的未经验证的三角形的图： if plot_masked_tri: plt.triplot(flat_tri, color='red') plt.show() scale_factors 将三角划分为以平方为单位。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:40:46 "},"人机交互篇/使用matplotlib做数据可视化/桑基图/桑基图.html":{"url":"人机交互篇/使用matplotlib做数据可视化/桑基图/桑基图.html","title":"桑基图","keywords":"","body":"桑基图 桑基图（Sankey diagram），即桑基能量分流图，也叫桑基能量平衡图。一种特定类型的流程图，图中延伸的分支的宽度对应数据流量的大小, 通常应用于能源、材料成分、金融等数据的可视化分析。 因1898年Matthew Henry Phineas Riall Sankey绘制的\"蒸汽机的能源效率图\"而闻名，此后便以其名字命名为“桑基图”。 桑基图最明显的特征就是，始末端的分支宽度总和相等，即所有主支宽度的总和应与所有分出去的分支宽度的总和相等，保持能量的平衡。 import numpy as np import matplotlib.pyplot as plt from matplotlib.sankey import Sankey %matplotlib inline matplotlib.sankey.Sankey(ax=None, scale=1.0, unit='', format='%G', gap=0.25, radius=0.1, shoulder=0.03, offset=0.15, head_angle=100, margin=0.4, tolerance=1e-06, **kwargs)是matplotlib构建桑基图的工具 他有两个方法来构造图形 .add(patchlabel='', flows=None, orientations=None, labels='', trunklength=1.0, pathlengths=0.25, prior=None, connect=(0, 0), rotation=0, **kwargs) flows就是流入的百分比了负数表示为流出 labels是每个流的标签 orientations 的取值范围为[-1,0,1]有效值为1（从顶部到顶部），0（从左到右）或-1（从底部到底部）.如果orientation = 0，输入将从左边突入，输出将向右边突破。 add()返回的还是一个Sankey对象,因此链式操作一直add() .finish()构造结束 S=Sankey() S.add(flows=[0.25, 0.15, 0.60, -0.20, -0.15, -0.05, -0.50, -0.10], labels=['', '', '', 'First', 'Second', 'Third', 'Fourth', 'Fifth'], orientations=[-1, 1, 0, 1, 1, 1, 0, -1]).finish() S 我们也可以直接在构造函数里定义流 Sankey(flows=[0.25, 0.15, 0.60, -0.20, -0.15, -0.05, -0.50, -0.10], labels=['', '', '', 'First', 'Second', 'Third', 'Fourth', 'Fifth'], orientations=[-1, 1, 0, 1, 1, 1, 0, -1]).finish() plt.title(\"The default settings produce a diagram like this.\") 我们可以在finish()之后通过一些针对其中元素的操作做特殊化处理 fig = plt.figure() ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[], title=\"Flow Diagram of a Widget\") sankey = Sankey(ax=ax, scale=0.01, offset=0.2, head_angle=180, format='%.0f', unit='%')# 单位unit定义 sankey.add(flows=[25, 0, 60, -10, -20, -5, -15, -10, -40], labels=['', '', '', 'First', 'Second', 'Third', 'Fourth', 'Fifth', 'Hurray!'], orientations=[-1, 1, 0, 1, 1, 1, -1, -1, 0], pathlengths=[0.25, 0.25, 0.25, 0.25, 0.25, 0.6, 0.25, 0.25, 0.25], patchlabel=\"Widget\\nA\", alpha=0.2, lw=2.0) # Arguments to matplotlib.patches.PathPatch() diagrams = sankey.finish() diagrams[0].patch.set_facecolor('#37c959') diagrams[0].texts[-1].set_color('r') diagrams[0].text.set_fontweight('bold') 如果有两张图用来表现两个系统的关系,可以像下面这么做 fig = plt.figure() ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[], title=\"Two Systems\") flows = [0.25, 0.15, 0.60, -0.10, -0.05, -0.25, -0.15, -0.10, -0.35] sankey = Sankey(ax=ax, unit=None) sankey.add(flows=flows, label='one', orientations=[-1, 1, 0, 1, 1, 1, -1, -1, 0]) sankey.add(flows=[-0.25, 0.15, 0.1], fc='#37c959', label='two', orientations=[-1, -1, -1], prior=0, connect=(0, 0)) diagrams = sankey.finish() diagrams[-1].patch.set_hatch('/') plt.legend(loc='best') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:40:28 "},"人机交互篇/使用matplotlib做数据可视化/图片加载/图片加载.html":{"url":"人机交互篇/使用matplotlib做数据可视化/图片加载/图片加载.html","title":"图片加载","keywords":"","body":"图片加载 matplotlib.image模块提供了读取图片和进行简单处理的能力,他的底层是pillow import numpy as np import matplotlib.pyplot as plt import matplotlib.image as mpimg img=mpimg.imread('./source/cat.jpg') 通过imread()方法读取的图片会被转换成像素矩阵(numpy的narray对象),其shape与图像分辨率有关,比如: 上图是342x220的图片,那么 img.shape (220, 342, 3) 其中的3为每个像素表现为一个RGB的三位数组 img array([[[254, 254, 254], [254, 254, 254], [254, 254, 254], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[254, 254, 254], [254, 254, 254], [254, 254, 254], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[254, 254, 254], [254, 254, 254], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], ..., [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]]], dtype=uint8) 我们可以通过plt.imshow(img)将这个数组初始化为一个plot对象 imgplot = plt.imshow(img) plt.show() 当然了只要是相同格式的数组都可以通过这个方式初始化为一个plot对象 将假彩色方案应用于图像绘图 伪彩色可以是一个有用的工具，用于增强对比度和更容易地可视化数据。这在使用投影仪对数据进行演示时尤其有用(它们的对比度通常很差)。假彩色仅与单通道，灰度，光度图像相关。我们目前有一个RGB图像。由于R，G和B都是相似的（见上面或在你的数据中的自己），我们可以只选择一个通道的数据： lum_img_r = img[:,:,0] lum_img_r array([[254, 254, 254, ..., 255, 255, 255], [254, 254, 254, ..., 255, 255, 255], [254, 254, 255, ..., 255, 255, 255], ..., [255, 255, 255, ..., 255, 255, 255], [255, 255, 255, ..., 255, 255, 255], [255, 255, 255, ..., 255, 255, 255]], dtype=uint8) lum_img_r.shape (220, 342) plt.imshow(lum_img_r) plt.show() lum_img_g = img[:,:,1] plt.imshow(lum_img_g) plt.show() lum_img_g = img[:,:,2] plt.imshow(lum_img_g) plt.show() 现在我们以使用R为通道的图片,使用亮度（2D，无颜色）图像，应用默认色彩映射（也称为查找表，LUT）。默认值称为jet。有很多其他的也可以选择。 plt.imshow(lum_img_r, cmap=\"hot\") plt.show() 也还可以使用set_cmap()方法更改现有绘图对象上的颜色 imgplot = plt.imshow(lum_img_r) imgplot.set_cmap('spectral') plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The spectral and spectral_r colormap was deprecated in version 2.0. Use nipy_spectral and nipy_spectral_r instead. warnings.warn(message, mplDeprecation, stacklevel=1) 色标参考 它有助于了解颜色代表什么值。我们可以通过添加颜色条来做到这一点。 imgplot = plt.imshow(lum_img_r) plt.colorbar() plt.show() 检查特定数据范围 有时，您想要增强图像的对比度，或者在特定区域中扩大对比度，同时牺牲不会变化很大的颜色的细节，或者无关紧要。找到感兴趣区域的好工具是直方图。要创建我们的图像数据的直方图，我们使用hist（）函数。 plt.hist(lum_img_r.ravel(), bins=256,fc='k', ec='k') plt.show() 下图就显示出了各个色值的分布状态,看打出来25x为值的是大多数中的大多数 通常，图像的“有趣”部分在峰值附近，您可以通过剪切峰值上方和/或下方的区域获得额外的对比度。在我们的直方图中，看起来在高端没有太多有用的信息（图像中不是很多白色的东西）。让我们调整上限，以便我们有效地“放大”直方图的一部分。我们通过将clim参数传递给imshow来实现。你也可以通过调用图像绘图对象的set_clim（）方法来做到这一点，但是要确保你在使用IPython Notebook时在plot命令的同一个单元格中这样做 - 它不会改变以前单元格的绘图。 imgplot = plt.imshow(lum_img_r, clim=(0, 200)) plt.show() 阵列插值方案 插值根据不同的数学方案计算像素的“应该”的颜色或值。这种情况发生的一个常见的地方是当你调整图像的大小。像素的数量变化，但你想要相同的信息。由于像素是离散的，因此缺少空间。插值是如何填补这个空间。这就是为什么你的图像有时拉伸会出来看起来像素化。当原始图像和扩展图像之间的差异较大时，效果更加明显。比如windows显示像素如果过分低于你的屏幕像素,那么你拉伸到屏幕那么大,看起来就都是马赛克,就是这个效果. 而插值算法就是拉伸时如何模拟的去显示出缺失信息的技术 from PIL import Image img = Image.open('./source/cat.jpg') img.thumbnail((64, 64), Image.ANTIALIAS) # 将图片压缩到64x64像素 img.height,img.width#41是因为图片比例 (41, 64) imgplot = plt.imshow(img) plt.show() 内置的插值算法有 'nearest', 最近值,也就是马赛克块 'bilinear', 双线性插值 'bicubic',双三次插值 'spline16'/'spline36', 样条插值 'hanning'/'hamming'/'gaussian'/'kaiser'/'bessel'/'sinc' 窗插值算法 'hermite',埃尔米特插值 'quadric',二次曲面插值 'catrom',[Catmull-Rom插值算法]https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline 'mitchell' 'lanczos'Lanczos算法 imgplot = plt.imshow(img, interpolation=\"nearest\") plt.show() 使用双三次插值(bicubic)模糊处理 imgplot = plt.imshow(img, interpolation=\"bicubic\") plt.show() 图片修改分辨率 img模块还提供了一个缩略图的工具 matplotlib.image.thumbnail(infile, thumbfile, scale=0.1, interpolation='bilinear', preview=False) 它可以直接修改文件并保存为另一文件,只是类型限制在png,svg和pdf三种 mpimg.thumbnail(\"./source/cat.jpg\", \"./source/cat_min.png\", scale=0.15, interpolation='bicubic') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:40:06 "},"人机交互篇/使用matplotlib做数据可视化/保存图片/保存图片.html":{"url":"人机交互篇/使用matplotlib做数据可视化/保存图片/保存图片.html","title":"保存图片","keywords":"","body":"保存图片 保存图片可以使用matplotlib.pyplot.savefig来实现 from matplotlib import pyplot as plt import numpy as np %matplotlib inline fig = plt.figure(figsize=(40,40)) x=np.linspace(-4,4,30) y=np.sin(x) plt.plot(x,y,'--*b') fig.savefig(\"./source/sin_ex.png\", dpi=15) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:39:48 "},"人机交互篇/使用matplotlib做数据可视化/控件.html":{"url":"人机交互篇/使用matplotlib做数据可视化/控件.html","title":"控件","keywords":"","body":"控件 很神奇的,matplot还提供了简单的可供交互的控件包括 buttons 按钮 check_buttons 选择按钮 radio_buttons 多选按钮 menu 目录 from __future__ import print_function from imp import reload import matplotlib reload(matplotlib) matplotlib.use('nbagg') import matplotlib.backends.backend_nbagg reload(matplotlib.backends.backend_nbagg) import matplotlib.backends.backend_webagg_core reload(matplotlib.backends.backend_webagg_core) import numpy as np import matplotlib.pyplot as plt plt.interactive(False) 按钮bottom 添加按钮可以使用plt.subplots_adjust(bottom=xx)为其在底部留下足够空间 用plt.axes([0.7, 0.05, 0.1, 0.075])为按钮划定大小和位置 添加按钮可以使用Button(ax, label, image=None, color='0.85', hovercolor='0.95') 而为其添加回调函数,则可以用为其绑定on_clicked方法 bnext = Button(axnext, 'Next') bnext.on_clicked(callback.next) 这种形式 from matplotlib.widgets import Button freqs = np.arange(2, 20, 3) fig, ax = plt.subplots() plt.subplots_adjust(bottom=0.2) t = np.arange(0.0, 1.0, 0.001) s = np.sin(2*np.pi*freqs[0]*t) l, = plt.plot(t, s, lw=2) class Index(object): ind = 0 def next(self, event): self.ind += 1 i = self.ind % len(freqs) ydata = np.sin(2*np.pi*freqs[i]*t) l.set_ydata(ydata) plt.draw() def prev(self, event): self.ind -= 1 i = self.ind % len(freqs) ydata = np.sin(2*np.pi*freqs[i]*t) l.set_ydata(ydata) plt.draw() callback = Index() axprev = plt.axes([0.7, 0.05, 0.1, 0.075]) axnext = plt.axes([0.81, 0.05, 0.1, 0.075]) bnext = Button(axnext, 'Next') bnext.on_clicked(callback.next) bprev = Button(axprev, 'Previous') bprev.on_clicked(callback.prev) plt.show() 选择按钮CheckButtons from matplotlib.widgets import CheckButtons t = np.arange(0.0, 2.0, 0.01) s0 = np.sin(2*np.pi*t) s1 = np.sin(4*np.pi*t) s2 = np.sin(6*np.pi*t) fig, ax = plt.subplots() l0, = ax.plot(t, s0, visible=False, lw=2) l1, = ax.plot(t, s1, lw=2) l2, = ax.plot(t, s2, lw=2) plt.subplots_adjust(left=0.2) rax = plt.axes([0.05, 0.4, 0.1, 0.15]) check = CheckButtons(rax, ('2 Hz', '4 Hz', '6 Hz'), (False, True, True)) def func(label): if label == '2 Hz': l0.set_visible(not l0.get_visible()) elif label == '4 Hz': l1.set_visible(not l1.get_visible()) elif label == '6 Hz': l2.set_visible(not l2.get_visible()) plt.draw() check.on_clicked(func) plt.show() 单选框RadioButtons from matplotlib.widgets import RadioButtons t = np.arange(0.0, 2.0, 0.01) s0 = np.sin(2*np.pi*t) s1 = np.sin(4*np.pi*t) s2 = np.sin(8*np.pi*t) fig, ax = plt.subplots() l, = ax.plot(t, s0, lw=2, color='red') plt.subplots_adjust(left=0.3) axcolor = 'lightgoldenrodyellow' rax = plt.axes([0.05, 0.7, 0.15, 0.15], axisbg=axcolor) radio = RadioButtons(rax, ('2 Hz', '4 Hz', '8 Hz')) def hzfunc(label): hzdict = {'2 Hz': s0, '4 Hz': s1, '8 Hz': s2} ydata = hzdict[label] l.set_ydata(ydata) plt.draw() radio.on_clicked(hzfunc) rax = plt.axes([0.05, 0.4, 0.15, 0.15], axisbg=axcolor) radio2 = RadioButtons(rax, ('red', 'blue', 'green')) def colorfunc(label): l.set_color(label) plt.draw() radio2.on_clicked(colorfunc) rax = plt.axes([0.05, 0.1, 0.15, 0.15], axisbg=axcolor) radio3 = RadioButtons(rax, ('-', '--', '-.', 'steps', ':')) def stylefunc(label): l.set_linestyle(label) plt.draw() radio3.on_clicked(stylefunc) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) 滑块Slider from matplotlib.widgets import Slider, Button, RadioButtons fig, ax = plt.subplots() plt.subplots_adjust(left=0.25, bottom=0.25) t = np.arange(0.0, 1.0, 0.001) a0 = 5 f0 = 3 s = a0*np.sin(2*np.pi*f0*t) l, = plt.plot(t, s, lw=2, color='red') plt.axis([0, 1, -10, 10]) axcolor = 'lightgoldenrodyellow' axfreq = plt.axes([0.25, 0.1, 0.65, 0.03], axisbg=axcolor) axamp = plt.axes([0.25, 0.15, 0.65, 0.03], axisbg=axcolor) sfreq = Slider(axfreq, 'Freq', 0.1, 30.0, valinit=f0) samp = Slider(axamp, 'Amp', 0.1, 10.0, valinit=a0) def update(val): amp = samp.val freq = sfreq.val l.set_ydata(amp*np.sin(2*np.pi*freq*t)) fig.canvas.draw_idle() sfreq.on_changed(update) samp.on_changed(update) resetax = plt.axes([0.8, 0.025, 0.1, 0.04]) button = Button(resetax, 'Reset', color=axcolor, hovercolor='0.975') def reset(event): sfreq.reset() samp.reset() button.on_clicked(reset) rax = plt.axes([0.025, 0.5, 0.15, 0.15], axisbg=axcolor) radio = RadioButtons(rax, ('red', 'blue', 'green'), active=0) def colorfunc(label): l.set_color(label) fig.canvas.draw_idle() radio.on_clicked(colorfunc) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) 光标Cursor from matplotlib.widgets import Cursor fig = plt.figure(figsize=(8, 6)) ax = fig.add_subplot(111, axisbg='#FFFFCC') x, y = 4*(np.random.rand(2, 100) - .5) ax.plot(x, y, 'o') ax.set_xlim(-2, 2) ax.set_ylim(-2, 2) # set useblit = True on gtkagg for enhanced performance cursor = Cursor(ax, useblit=True, color='red', linewidth=2) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) 多路光标 from matplotlib.widgets import MultiCursor t = np.arange(0.0, 2.0, 0.01) s1 = np.sin(2*np.pi*t) s2 = np.sin(4*np.pi*t) fig = plt.figure() ax1 = fig.add_subplot(211) ax1.plot(t, s1) ax2 = fig.add_subplot(212, sharex=ax1) ax2.plot(t, s2) multi = MultiCursor(fig.canvas, (ax1, ax2), color='r', lw=1) plt.show() 矩形框 from matplotlib.widgets import RectangleSelector def line_select_callback(eclick, erelease): 'eclick and erelease are the press and release events' x1, y1 = eclick.xdata, eclick.ydata x2, y2 = erelease.xdata, erelease.ydata print(\"(%3.2f, %3.2f) --> (%3.2f, %3.2f)\" % (x1, y1, x2, y2)) print(\" The button you used were: %s %s\" % (eclick.button, erelease.button)) def toggle_selector(event): print(' Key pressed.') if event.key in ['Q', 'q'] and toggle_selector.RS.active: print(' RectangleSelector deactivated.') toggle_selector.RS.set_active(False) if event.key in ['A', 'a'] and not toggle_selector.RS.active: print(' RectangleSelector activated.') toggle_selector.RS.set_active(True) fig, current_ax = plt.subplots() # make a new plotingrange N = 100000 # If N is large one can see x = np.linspace(0.0, 10.0, N) # improvement by use blitting! plt.plot(x, +np.sin(.2*np.pi*x), lw=3.5, c='b', alpha=.7) # plot something plt.plot(x, +np.cos(.2*np.pi*x), lw=3.5, c='r', alpha=.5) plt.plot(x, -np.sin(.2*np.pi*x), lw=3.5, c='g', alpha=.3) print(\"\\n click --> release\") # drawtype is 'box' or 'line' or 'none' toggle_selector.RS = RectangleSelector(current_ax, line_select_callback, drawtype='box', useblit=True, button=[1, 3], # don't use middle button minspanx=5, minspany=5, spancoords='pixels', interactive=True) plt.connect('key_press_event', toggle_selector) plt.show() click --> release 选定区域SpanSelector from matplotlib.widgets import SpanSelector fig = plt.figure(figsize=(8, 6)) ax = fig.add_subplot(211, axisbg='#FFFFCC') x = np.arange(0.0, 5.0, 0.01) y = np.sin(2*np.pi*x) + 0.5*np.random.randn(len(x)) ax.plot(x, y, '-') ax.set_ylim(-2, 2) ax.set_title('Press left mouse button and drag to test') ax2 = fig.add_subplot(212, axisbg='#FFFFCC') line2, = ax2.plot(x, y, '-') def onselect(xmin, xmax): indmin, indmax = np.searchsorted(x, (xmin, xmax)) indmax = min(len(x) - 1, indmax) thisx = x[indmin:indmax] thisy = y[indmin:indmax] line2.set_data(thisx, thisy) ax2.set_xlim(thisx[0], thisx[-1]) ax2.set_ylim(thisy.min(), thisy.max()) fig.canvas.draw() # set useblit True on gtkagg for enhanced performance span = SpanSelector(ax, onselect, 'horizontal', useblit=True, rectprops=dict(alpha=0.5, facecolor='red')) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:40:20 "},"人机交互篇/使用matplotlib做数据可视化/动画/动画.html":{"url":"人机交互篇/使用matplotlib做数据可视化/动画/动画.html","title":"动画","keywords":"","body":"动画 动画说白了就是隔段时间刷新一下画面,matplotlib.animation提供了构建动画的工具主要是这几个方法: 通过函数构建 通过作品构建 通过继承matplotlib.animation.TimedAnimation类制作动画 动画需要后渲染后端,一般使用ffmpeg,安装方法可以看]这里 无论哪种方式构建的动画都可以通过.save方法保存为希望的格式,也可以用.to_html5_video方法输出一份html5可以读取的文件. from __future__ import print_function from imp import reload import matplotlib reload(matplotlib) matplotlib.use('nbagg') import matplotlib.backends.backend_nbagg reload(matplotlib.backends.backend_nbagg) import matplotlib.backends.backend_webagg_core reload(matplotlib.backends.backend_webagg_core) import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation plt.interactive(False) 通过函数构建动画 matplotlib.animation.FuncAnimation(fig, func, frames=None, init_func=None, fargs=None, save_count=None, **kwargs) FuncAnimation类是最常用的构建函数. 他的构造函数有这样一些参数 fig 一个figure对象,图像都是基于这个对象相当于一个画板 func(frame)->tuple(axes.plot) 一个构建动画函数,参数是frames传入的每一帧,而返回的是一个由参数构建的plot对象构成的tuple frames 一个可迭代对象,可以是生成器,可以是一个序列,也可以是数字,数字相当于传入一个xrange(n) init_func(frame)->tuple(axes.plot) 初始化函数,第0帧时候调用它构建图形 如果blit = True，func和init_func必须返回一个可迭代的作品对象来重绘 kwargs包括repeat，repeat_delay和interval： interval每隔interval毫秒绘制一个新帧。 repeat控制动画是否应在帧序列完成时重复。 repeat_delay可选地在重复动画之前添加以毫秒为单位的延迟。 from IPython.display import HTML %matplotlib inline plt.style.use(\"animation_support\") 使用数字定义帧 fig, ax = plt.subplots() x = np.arange(0, 2*np.pi, 0.01) line, = ax.plot(x, np.sin(x)) def animate(i): line.set_ydata(np.sin(x + i/10.0)) # update the data return line, # Init only required for blitting to give a clean slate. def init(): line.set_ydata(np.ma.array(x, mask=True)) return line, ani = animation.FuncAnimation(fig, animate, 200, init_func=init, interval=25, blit=True) ani Your browser does not support the video tag. 使用生成器定义帧 # 使用生成器构建每一帧的传入数据 def data_gen(t=0): cnt = 0 while cnt = xmax: ax.set_xlim(xmin, 2*xmax) ax.figure.canvas.draw() line.set_data(xdata, ydata) return line, ani = animation.FuncAnimation(fig, run, data_gen, blit=False, interval=10, repeat=False, init_func=init) ani Your browser does not support the video tag. 通过作品组合构建动画 matplotlib.animation.ArtistAnimation(fig, artists, *args, **kwargs) 这种方式和上面类似,只是先画好每一幅图,之后按顺序和指定的帧率制作动画 fig2 = plt.figure() x = np.arange(-9, 10) y = np.arange(-9, 10).reshape(-1, 1) base = np.hypot(x, y) ims = [] for add in np.arange(15): ims.append((plt.pcolor(x, y, base + add, norm=plt.Normalize(0, 30)),)) im_ani = animation.ArtistAnimation(fig2, ims, interval=50, repeat_delay=3000, blit=True) im_ani Your browser does not support the video tag. 通过继承构建 matplotlib.animation.TimedAnimation是上面俩的基类,我们也可以直接继承它来构造动画,主要要重载的是 __init__()方法 _draw_frame方法,对应func new_frame_seq对应frames _init_draw对应init_func from matplotlib.lines import Line2D class SubplotAnimation(animation.TimedAnimation): def __init__(self): fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(2, 2, 2) ax3 = fig.add_subplot(2, 2, 4) self.t = np.linspace(0, 80, 400) self.x = np.cos(2 * np.pi * self.t / 10.) self.y = np.sin(2 * np.pi * self.t / 10.) self.z = 10 * self.t ax1.set_xlabel('x') ax1.set_ylabel('y') self.line1 = Line2D([], [], color='black') self.line1a = Line2D([], [], color='red', linewidth=2) self.line1e = Line2D( [], [], color='red', marker='o', markeredgecolor='r') ax1.add_line(self.line1) ax1.add_line(self.line1a) ax1.add_line(self.line1e) ax1.set_xlim(-1, 1) ax1.set_ylim(-2, 2) ax1.set_aspect('equal', 'datalim') ax2.set_xlabel('y') ax2.set_ylabel('z') self.line2 = Line2D([], [], color='black') self.line2a = Line2D([], [], color='red', linewidth=2) self.line2e = Line2D( [], [], color='red', marker='o', markeredgecolor='r') ax2.add_line(self.line2) ax2.add_line(self.line2a) ax2.add_line(self.line2e) ax2.set_xlim(-1, 1) ax2.set_ylim(0, 800) ax3.set_xlabel('x') ax3.set_ylabel('z') self.line3 = Line2D([], [], color='black') self.line3a = Line2D([], [], color='red', linewidth=2) self.line3e = Line2D( [], [], color='red', marker='o', markeredgecolor='r') ax3.add_line(self.line3) ax3.add_line(self.line3a) ax3.add_line(self.line3e) ax3.set_xlim(-1, 1) ax3.set_ylim(0, 800) animation.TimedAnimation.__init__(self, fig, interval=50, blit=True) def _draw_frame(self, framedata): i = framedata head = i - 1 head_len = 10 head_slice = (self.t > self.t[i] - 1.0) & (self.t ani = SubplotAnimation() ani Your browser does not support the video tag. 动画的输出 最简单的输出就是直接通过matplotlib输出,直接plt.show()即可,注意这种方式jupyter notebook并不支持.只能在脚本中使用 输出为html5可读的视屏 使用.to_html5_video()方法可以直接输出一段浏览器可以识别的带标签的html5字符串这种可以直接嵌入到网页前端 保存动画 动画保存是通过.save(filename, writer=None, fps=None, dpi=None, codec=None, bitrate=None, extra_args=None, metadata=None, extra_anim=None, savefig_kwargs=None)方法 writer可以自己定义转码工具,默认为ffmpeg fps为帧率 dpi控制动画每帧中的每英寸点数. codec指定保存的格式,默认使用filename的后缀作为格式 bitrate指定压缩影片每秒使用的位数，以千位/秒为单位。更高的数字意味着更高质量的电影，但是以增加的文件大小为代价。如果未指定值，则默认值为rcparam animation.bitrate给出的值。 metadata元数据包括在输出文件中的元数据的键和值的字典。可能有用的一些键包括：标题，艺术家，流派，主题，版权，srcform，注释。 动画生成和转码工具的设置 matplotlib本身就是个作图的工具,本身无法制作动画,但他可以通过其他工具提供了几个参数用来转码和设置,我们可以定义一个主题来实现需要的时候加载 animation.ffmpeg_path : /bin/ffmpeg animation.convert_path: /imagemagick/6.9.7-0/bin/convert animation.html: html5 通过这样的设置可以使用ffmpeg工具转码为常见的格式如MP4,也可以通过指定writer参数来使用imagemagick构建gif动画图片. 第三个参数是为了让jupyter notebook可以直接显示动画,如果不设置也可以使用 from IPython.display import HTML 然后HTML(ani.to_html5())来输出动画 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:39:58 "},"人机交互篇/使用matplotlib做数据可视化/matplitlib结合web技术.html":{"url":"人机交互篇/使用matplotlib做数据可视化/matplitlib结合web技术.html","title":"matplitlib结合web技术","keywords":"","body":"matplitlib结合web技术 现今的数据可视化早已不再局限于文章或者出个图就算了,更多的需要使用web技术动态的构建图像,使用web技术做数据可视化当然可以在前端做,比如结合d3.js实现,但如果要从后端生成,我们也可以使用matplotlib来实现. matplotlib的web端使用的绘图技术有两种 基于svg图像标签的图像技术 基于websocket的图像技术 根据实现也分为展示型和交互型,一般来说,交互型就会用到ajax技术,轮询,或者websocket了 当然了,对于生成的动画,也是可以结合web技术实现展示的 我们这次的来以股票数据作为例子来绘制图形,用来查看上证50股的历史k线图 上证50成分股内容如下 symbol_dict = { \"600000\": \"浦发银行\", \"600010\": \"包钢股份\", \"600015\": \"华夏银行\", \"600016\": \"民生银行\", \"600018\": \"上港集团\", \"600028\": \"中国石化\", \"600030\": \"中信证券\", \"600036\": \"招商银行\", \"600048\": \"保利地产\", \"600050\": \"中国联通\", \"600089\": \"特变电工\", \"600104\": \"上汽集团\", \"600109\": \"国金证券\", \"600111\": \"北方稀土\", \"600150\": \"中国船舶\", \"600256\": \"广汇能源\", \"600406\": \"国电南瑞\", \"600518\": \"康美药业\", \"600519\": \"贵州茅台\", \"600583\": \"海油工程\", \"600585\": \"海螺水泥\", \"600637\": \"东方明珠\", \"600690\": \"青岛海尔\", \"600837\": \"海通证券\", \"600887\": \"伊利股份\", \"600893\": \"中航动力\", \"600958\": \"东方证券\", \"600999\": \"招商证券\", \"601006\": \"大秦铁路\", \"601088\": \"中国神华\", \"601166\": \"兴业银行\", \"601169\": \"北京银行\", \"601186\": \"中国铁建\", \"601288\": \"农业银行\", \"601318\": \"中国平安\", \"601328\": \"交通银行\", \"601390\": \"中国中铁\", \"601398\": \"工商银行\", \"601601\": \"中国太保\", \"601628\": \"中国人寿\", \"601668\": \"中国建筑\", \"601688\": \"华泰证券\", \"601766\": \"中国中车\", \"601800\": \"中国交建\", \"601818\": \"光大银行\", \"601857\": \"中国石油\", \"601901\": \"方正证券\", \"601988\": \"中国银行\", \"601989\": \"中国重工\", \"601998\": \"中信银行\"} 我们通过输入编号和日期来进行查找 下面是基本的函数 from __future__ import print_function from imp import reload import matplotlib reload(matplotlib) matplotlib.use('nbagg') import matplotlib.backends.backend_nbagg reload(matplotlib.backends.backend_nbagg) import matplotlib.backends.backend_webagg_core reload(matplotlib.backends.backend_webagg_core) import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation plt.interactive(False) from matplotlib.finance import quotes_historical_yahoo_ochl from matplotlib.finance import candlestick_ochl from matplotlib.dates import YearLocator, MonthLocator, DateFormatter ,WeekdayLocator,MONDAY,DayLocator import datetime import numpy as np /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The finance module has been deprecated in mpl 2.0 and will be removed in mpl 2.2. Please use the module mpl_finance instead. warnings.warn(message, mplDeprecation, stacklevel=1) symbol_dict = { \"600000\": u\"浦发银行\", \"600010\": u\"包钢股份\", \"600015\": u\"华夏银行\", \"600016\": u\"民生银行\", \"600018\": u\"上港集团\", \"600028\": u\"中国石化\", \"600030\": u\"中信证券\", \"600036\": u\"招商银行\", \"600048\": u\"保利地产\", \"600050\": u\"中国联通\", \"600089\": u\"特变电工\", \"600104\": u\"上汽集团\", \"600109\": u\"国金证券\", \"600111\": u\"北方稀土\", \"600150\": u\"中国船舶\", \"600256\": u\"广汇能源\", \"600406\": u\"国电南瑞\", \"600518\": u\"康美药业\", \"600519\": u\"贵州茅台\", \"600583\": u\"海油工程\", \"600585\": u\"海螺水泥\", \"600637\": u\"东方明珠\", \"600690\": u\"青岛海尔\", \"600837\": u\"海通证券\", \"600887\": u\"伊利股份\", \"600893\": u\"中航动力\", \"600958\": u\"东方证券\", \"600999\": u\"招商证券\", \"601006\": u\"大秦铁路\", \"601088\": u\"中国神华\", \"601166\": u\"兴业银行\", \"601169\": u\"北京银行\", \"601186\": u\"中国铁建\", \"601288\": u\"农业银行\", \"601318\": u\"中国平安\", \"601328\": u\"交通银行\", \"601390\": u\"中国中铁\", \"601398\": u\"工商银行\", \"601601\": u\"中国太保\", \"601628\": u\"中国人寿\", \"601668\": u\"中国建筑\", \"601688\": u\"华泰证券\", \"601766\": u\"中国中车\", \"601800\": u\"中国交建\", \"601818\": u\"光大银行\", \"601857\": u\"中国石油\", \"601901\": u\"方正证券\", \"601988\": u\"中国银行\", \"601989\": u\"中国重工\", \"601998\": u\"中信银行\" } plt.style.use('chinese_support') def draw_k(id_str,from_date_str,to_date_str): #设置x轴坐标刻度 mondays = WeekdayLocator(MONDAY) # 主要刻度 alldays = DayLocator() # 次要刻度 mondayFormatter = DateFormatter('%m-%d-%Y') # 如：2-29-2015 dayFormatter = DateFormatter('%d') from_date = tuple((int(i) for i in from_date_str.strip().split(\"-\"))) to_date = tuple((int(i) for i in to_date_str.strip().split(\"-\"))) quotes_ochl = quotes_historical_yahoo_ochl(id_str+'.ss', from_date ,to_date) fig, ax = plt.subplots() fig.subplots_adjust(bottom=0.2) ax.xaxis.set_major_locator(mondays) ax.xaxis.set_minor_locator(alldays) ax.xaxis.set_major_formatter(mondayFormatter) candlestick_ochl(ax, quotes_ochl, width=0.6, colorup='r', colordown='g') ax.xaxis_date() ax.autoscale_view() plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right') ax.grid(True) plt.title(symbol_dict.get(id_str,u\"未知\")) plt.show() draw_k('600000','2016-6-20','2016-7-20') 基于SVG的展示型图像 一种方式是将svg图像写入一个伪造的文件,然后将其取出,把头部修改了,这样就可以直接用了 from pyquery import PyQuery as Q from io import BytesIO import json def deal_with_svg(f): # Create XML tree from the SVG file. value = f.getvalue() # Add attributes to the patch objects. # Add a transition effect result = Q(value) return result.__str__() def draw_k_svg(id_str,from_date_str,to_date_str): #设置x轴坐标刻度 mondays = WeekdayLocator(MONDAY) # 主要刻度 alldays = DayLocator() # 次要刻度 mondayFormatter = DateFormatter('%m-%d-%Y') # 如：2-29-2015 dayFormatter = DateFormatter('%d') from_date = tuple((int(i) for i in from_date_str.strip().split(\"-\"))) to_date = tuple((int(i) for i in to_date_str.strip().split(\"-\"))) quotes_ochl = quotes_historical_yahoo_ochl(id_str+'.ss', from_date ,to_date) fig, ax = plt.subplots() fig.subplots_adjust(bottom=0.2) ax.xaxis.set_major_locator(mondays) ax.xaxis.set_minor_locator(alldays) ax.xaxis.set_major_formatter(mondayFormatter) candlestick_ochl(ax, quotes_ochl, width=0.6, colorup='r', colordown='g') ax.xaxis_date() ax.autoscale_view() plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right') ax.grid(True) plt.title(symbol_dict.get(id_str,u\"未知\")) f = BytesIO() plt.savefig(f, format=\"svg\") return deal_with_svg(f) from IPython.display import HTML HTML(draw_k_svg('600000','2016-6-20','2016-7-20')) *{stroke-linecap:butt;stroke-linejoin:round;} 样例代码可以在这里看到 基于websocket的绘图技术 通过这种方式可以提供交互,把图片连同工具栏一起发送到客户端,具体的方法可以看样例代码,这边提供了2种样例代码,分别使用: tornado flask+gevent-websocket 使用.to_html5_video()直接输出动画 在支持html5的的浏览器上完全可以直接用.to_html5_video()来获得可以输出视频 from matplotlib.animation import FuncAnimation def rain(): fig = plt.figure(figsize=(7, 7)) ax = fig.add_axes([0, 0, 1, 1], frameon=False) ax.set_xlim(0, 1), ax.set_xticks([]) ax.set_ylim(0, 1), ax.set_yticks([]) # Create rain data n_drops = 50 rain_drops = np.zeros(n_drops, dtype=[('position', float, 2), ('size', float, 1), ('growth', float, 1), ('color', float, 4)]) # Initialize the raindrops in random positions and with # random growth rates. rain_drops['position'] = np.random.uniform(0, 1, (n_drops, 2)) rain_drops['growth'] = np.random.uniform(50, 200, n_drops) # Construct the scatter which we will update during animation # as the raindrops develop. scat = ax.scatter(rain_drops['position'][:, 0], rain_drops['position'][:, 1], s=rain_drops['size'], lw=0.5, edgecolors=rain_drops['color'], facecolors='none') def update(frame_number): # Get an index which we can use to re-spawn the oldest raindrop. current_index = frame_number % n_drops # Make all colors more transparent as time progresses. rain_drops['color'][:, 3] -= 1.0/len(rain_drops) rain_drops['color'][:, 3] = np.clip(rain_drops['color'][:, 3], 0, 1) # Make all circles bigger. rain_drops['size'] += rain_drops['growth'] # Pick a new position for oldest rain drop, resetting its size, # color and growth factor. rain_drops['position'][current_index] = np.random.uniform(0, 1, 2) rain_drops['size'][current_index] = 5 rain_drops['color'][current_index] = (0, 0, 0, 1) rain_drops['growth'][current_index] = np.random.uniform(50, 200) # Update the scatter collection, with the new colors, sizes and positions. scat.set_edgecolors(rain_drops['color']) scat.set_sizes(rain_drops['size']) scat.set_offsets(rain_drops['position']) # Construct the animation, using the update function as the animation # director. animation = FuncAnimation(fig, update, interval=10) return animation.to_html5_video() HTML(rain()) Your browser does not support the video tag. 使用gif图片嵌入img输出动画 我们也可以用类似svg嵌入网页的方式嵌入gif from numpy import sin, cos import scipy.integrate as integrate import matplotlib.animation as animation plt.style.use(\"animation_support\") import os import base64 import time def double_pendulum(): G = 9.8 # acceleration due to gravity, in m/s^2 L1 = 1.0 # length of pendulum 1 in m L2 = 1.0 # length of pendulum 2 in m M1 = 1.0 # mass of pendulum 1 in kg M2 = 1.0 # mass of pendul def derivs(state, t): dydx = np.zeros_like(state) dydx[0] = state[1] del_ = state[2] - state[0] den1 = (M1 + M2)*L1 - M2*L1*cos(del_)*cos(del_) dydx[1] = (M2*L1*state[1]*state[1]*sin(del_)*cos(del_) + M2*G*sin(state[2])*cos(del_) + M2*L2*state[3]*state[3]*sin(del_) - (M1 + M2)*G*sin(state[0]))/den1 dydx[2] = state[3] den2 = (L2/L1)*den1 dydx[3] = (-M2*L2*state[3]*state[3]*sin(del_)*cos(del_) + (M1 + M2)*G*sin(state[0])*cos(del_) - (M1 + M2)*L1*state[1]*state[1]*sin(del_) - (M1 + M2)*G*sin(state[2]))/den2 return dydx # create a time array from 0..100 sampled at 0.05 second steps dt = 0.05 t = np.arange(0.0, 20, dt) # th1 and th2 are the initial angles (degrees) # w10 and w20 are the initial angular velocities (degrees per second) th1 = 120.0 w1 = 0.0 th2 = -10.0 w2 = 0.0 # initial state state = np.radians([th1, w1, th2, w2]) # integrate your ODE using scipy.integrate. y = integrate.odeint(derivs, state, t) x1 = L1*sin(y[:, 0]) y1 = -L1*cos(y[:, 0]) x2 = L2*sin(y[:, 2]) + x1 y2 = -L2*cos(y[:, 2]) + y1 fig = plt.figure() ax = fig.add_subplot(111, autoscale_on=False, xlim=(-2, 2), ylim=(-2, 2)) ax.grid() line, = ax.plot([], [], 'o-', lw=2) time_template = 'time = %.1fs' time_text = ax.text(0.05, 0.9, '', transform=ax.transAxes) def init(): line.set_data([], []) time_text.set_text('') return line, time_text def animate(i): thisx = [0, x1[i], x2[i]] thisy = [0, y1[i], y2[i]] line.set_data(thisx, thisy) time_text.set_text(time_template % (i*dt)) return line, time_text ani = animation.FuncAnimation(fig, animate, np.arange(1, len(y)), interval=25, blit=True, init_func=init) timestmp = time.time() ani.save(\"{stmp}_temp.gif\".format(stmp=timestmp), writer='imagemagick',codec=\"gif\",fps=15) with open(\"{stmp}_temp.gif\".format(stmp=timestmp),\"rb\") as f: value = base64.b64encode(f.read()).decode() os.remove(\"{stmp}_temp.gif\".format(stmp=timestmp)) result = ''.format(value=value) return result HTML(double_pendulum()) IOPub data rate exceeded. The notebook server will temporarily stop sending output to the client in order to avoid crashing it. To change this limit, set the config variable `--NotebookApp.iopub_data_rate_limit`. 这种方式最好不要用,很慢 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 15:39:13 "},"人机交互篇/使用matplotlib做数据可视化/结语.html":{"url":"人机交互篇/使用matplotlib做数据可视化/结语.html","title":"结语","keywords":"","body":"结语 数据可视化也算是人机交互的一种,当然更多的是展示,交互并不是重点.通常数据可视化用于辅助分析和辅助决策,且面向的用户通常是非技术人员,本身并不是什么关键性技术.但越是靠近人一端,应用就越是复杂.所以更多的时候数据可视化是体力活不是脑力活. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 16:11:47 "},"人机交互篇/结语.html":{"url":"人机交互篇/结语.html","title":"结语","keywords":"","body":"结语 python标准库只给出了最基本的人机交互工具当然了python的人机交互工具远不止这些.像web编程这些由于涉及到更多的是http协议和一些其他python无关的知识,本文就不多描述了. 人机交互软件的主要痛点是: 交互逻辑设计不能满足人们习惯 软件难以跨平台 第一点是设计师要解决的,而第二点目前都还没有一个靠谱的解决方案.对于python来说,比较合适的方案也就是: 使用标准库,利用python跨平台的特性.但python无法在移动端使用,因此局限比较大. 使用web技术,优点是真正的跨平台,因为前端通用都是浏览器,缺点是需要学习额外的前端技术比如js,html这类 相关扩展和模块 pygame 知名的python游戏开发工具.简单好用. tqdm 上面已经有简单介绍,用于美化循环的模块 colorama 为文本输出提供颜色 kivy 一个旨在跨平台的pythongui库,目前移动端对python3的支持还不完善,但可以持续关注中文文档 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-17 14:37:35 "},"数学与统计应用篇/":{"url":"数学与统计应用篇/","title":"数学与统计应用篇","keywords":"","body":"数学与统计应用篇 python是一门应用领域非常广泛的编程语言,但现今最为人所知的应用领域应该就是科学计算和机器学习了. 本篇就是介绍相应工具的篇章.本文不是讲数学,统计,算法的文章,因此不会太过具体的介绍这些工具的理论基础,更多的是会在实现角度和应用角度做出介绍. 常见的相关工具包括: 专用数据结构和类型 主要是由numpy和pandas提供,也因此这两个工具从成了python数据科学的基石.这两个工具除了实现了数据类型外也实现了一些算法,在多数时候也已经够用. 同构定长多维数组工具numpy.dnarry 结构化数据表DataFrame实现pandas.DataFrame 序列对象pandas.Series 计算框架 通常这类框架是某种理论框架的延续,也就是说算出结果只是附带的事情,这些框架关心的其实更多的是如何实现计算这一过程,虽然未必应用广泛但通常也没有替代品 符号计算框架Sympy 贝叶斯推断框架Pymc3 基于计算图的符号计算框架TensorFlow 算法封装 通用科学计算算法包scipy 机器学习算法包sklearn 专业统计工具包Statsmodels 复杂网络计算框架networkx以及C/C++实现的igraph 深度学习算法封装keras 本文会着重介绍Numpy和Pandas,并附带着介绍Sympy,Pymc3和TensorFlow.Numpy和Pandas以介绍其数据结构为主,而其他则更多的是介绍其来自的理论框架.当然,更重要的,本文还会介绍python标准库中的数学计算工具.其他的内容以后有机会会在其他文章中介绍 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 17:18:10 "},"数学与统计应用篇/使用标准库处理基本数学问题/使用标准库处理基本数学问题.html":{"url":"数学与统计应用篇/使用标准库处理基本数学问题/使用标准库处理基本数学问题.html","title":"使用标准库处理基本数学问题","keywords":"","body":"使用标准库处理基本数学问题 python内置了多数情况下足够用的数学工具用于做一些简单计算,主要包括几个部分: 专用的数据类型 包括有标准库中的理数,高精度数类型以及默认支持的复数类型 常用计算算法 包括针对自然数和复数的log,三角函数等计算 统计学工具 包括常用的统计计算算法和随机数模块 默认数的形式 python中的数分为 整数 0 浮点数 1.1 复数,而且大数计算是内置的被优化的相当好. 1+2j 数的进制 默认的数是10进制的,但python中也支持其他几种进制 16进制 0x10 16 8进制 0O10 8 2进制 0b10 2 而十进制转换成别的进制就会麻烦一些,需要使用bin(dec),oct(dec),hex(dec)这样的内置函数 bin(2) '0b10' oct(8) '0o10' hex(16) '0x10' 可以看到转换后得到的其实是字符串,这个需要注意. 大数的表示[3.6] 从python3.6起,大数可以使用每三位加一格下划线的表述方式输入了 12_234 12234 内置的计算操作 python内置的合法计算符号包括: 符号 操作名 + 加 - 减 * 乘 / 除 // 整除 ** 求幂 abs 取绝对值 另外还有一个符号@表示矩阵乘法,这个官方的数据结构没有实现但numpy和pandas倒是实现了 高精度数(decimal) 高精度数模块(decimal)提供了一种可用于代替float的数据类型,这种数据类型并不适合常用计算,因为高精度意味着更耗时;但在需要高精度浮点运算时比较好用,适合用在财务上. 这种数据类型可以由整数,浮点数,数字字符串转化得来 获得当前精度环境 from decimal import getcontext getcontext() Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999, capitals=1, clamp=0, flags=[], traps=[InvalidOperation, DivisionByZero, Overflow]) 设定精度 getcontext().prec = 10 转化为decimal数据类型 from decimal import Decimal Decimal(1) / Decimal(7) Decimal('0.1428571429') 有理数(fractions) 有理数(fractions)模块提供了一种用来表示有理数的数据类型,它可以用整数,浮点数,高精度数或者数字和除号字符串创建 from fractions import Fraction Fraction(16, -10) Fraction(-8, 5) Fraction(123) Fraction(123, 1) Fraction() Fraction(0, 1) Fraction('3/7') Fraction(3, 7) Fraction('1.414213 \\t\\n') Fraction(1414213, 1000000) Fraction('-.125') Fraction(-1, 8) Fraction('7e-6') Fraction(7, 1000000) Fraction(2.25) Fraction(9, 4) Fraction(1.1) Fraction(2476979795053773, 2251799813685248) from decimal import Decimal Fraction(Decimal('1.1')) Fraction(11, 10) 数学运算模块math python自带的math模块提供了一些常用的数学运算和常数 常数 常数 说明 math.e 自然常数e math.pi 圆周率pi 数值计算 函数 说明 例子 math.ceil(x) 返回大于x的整数上限的浮点数,x为整数则返回自己的浮点形式 math.ceil(1)->1.0,math.ceil(1.1)->2.0,math.ceil(-1.5)->-1.0 math.copysign(x, y) 返回绝对值为x,符号为y的符号的数 math.copysign(1.0, -0.0)->-1.0 math.fabs(x) 相当于abs(x),返回绝对值 math.fabs(-3.4)->3.4 math.factorial(x) 数学上的x!,阶乘 math.factorial(3)->6 math.floor(x) 与ceil相反,得到上限 math.floor(-0.5)->-1.0 math.fmod(x, y) 求模运算,适合用在浮点数,注意和%的不同 math.fmod(3.5, -2)->1.53.5%-2->-0.5 math.frexp(x) 将x拆成分(m,e),x== m 2*e math.frexp(2.43)->(0.6075, 2) math.fsum(iterable) 求序列中所有数的和的精确值 fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])->1.0 math.isinf(x) 判断x是不是float(\"inf\") --- math.isnan(x) 判断x是不是float(\"NaN\") --- math.ldexp(m,e) 求m 2*e math.ldexp(3, 1)->6.0 math.modf(x) 拆分整数小数部分 math.modf(-3.5)->(-0.5, -3.0) math.trunc(x) 返回整数部分 math.trunc(3.5)->3 平方和对数 函数 说明 例子 math.exp(x) 自然数的幂 e**x math.exp(2)->7.38905609893065 math.expm1(x) 返回e的x次方减1 math.expm1(2)->6.38905609893065 math.log(x[, base]) 返回x的以base为底的对数，base默认为e math.log(math.e)->1.0math.log(10,2)->3.3219280948873626 math.log10(x) 返回x的以10为底的对数 math.log10(2)->0.30102999566398114 math.log1p(x) 返回1+x的自然对数（以e为底) math.log1p(math.e-1)->1.0 math.pow(x, y) 返回x的y次方 math.pow(5,3)->125.0 math.sqrt(x) 返回x的平方根 math.sqrt(3)->1.7320508075688772 三角函数 弧度 函数 说明 math.acos(x) acos(x) math.asin(x) asin(x) math.atan(x) atan(x) math.atan2(y, x) atan(y / x) math.cos(x) cos(x) math.hypot(x, y) sqrt(xx + yy) math.sin(x) sin(x) math.tan(x) tan(x) 角度,弧度转换 函数 说明 math.degrees(x) 弧度转度 math.radians(x) 度转弧度 双曲函数 函数 说明 math.sinh(x) 双曲正弦 $ \\sinh x = {\\frac {e^x - e^{ - x} } 2} $ math.cosh(x) 双曲余弦 $ \\cosh x = {\\frac {e^x + e^{ - x} } 2} $ math.tanh(x) 双曲正切 $ \\tanh x = {\\frac {\\sinh x} {\\cosh x}} $ math.acosh(x) 反双曲余弦 math.asinh(x) 反双曲正弦 math.atanh(x) 反双曲正切 特殊函数: 函数 说明 math.erf(x) 误差函数: $\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-t^2}\\,\\mathrm dt.$ math.erfc(x) 互补误差函数:$\\mbox{erfc}(x) = 1-\\mbox{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_x^{\\infty} e^{-t^2}\\,\\mathrm dt\\,.$ math.gamma(x) 伽玛函数 $\\Gamma(z) = \\int_{0}^{\\infty} \\frac{t^{z-1}}{\\mathrm{e}^t} \\,{\\rm{d}}t$ math.lgamma(x) 伽马函数绝对值的自然对数 复数运算(cmath) 这个模块和math很像,只是面向的操作对象是复数.它独有的接口有 from cmath import phase,polar,rect 极坐标转换 phase()求相(相当于求atan2(x.imag, x.real)) phase(-1.0+0.0j) 3.141592653589793 phase(complex(-1.0,-0.0)) -3.141592653589793 polar(x)转换为极坐标 polar(x) 相当于 (abs(x), phase(x)). polar(complex(-1.0,-0.0)) (1.0, -3.141592653589793) rect(r,phi)已知半径和度数求以两边长为值的复数 r∗(math.cos(phi)+math.sin(phi)∗1j) r * (math.cos(phi) + math.sin(phi)*1j) r∗(math.cos(phi)+math.sin(phi)∗1j) from math import pi rect(1,pi/4) (0.7071067811865476+0.7071067811865475j) 统计模块(statistics) 该模块是3.4后新增的模块,这个模块提供一些统计学方法 均值中心性 函数 说明 mean() 均值 median() 中位数 median_low() Low median of data. median_high() High median of data. median_grouped() Median, or 50th percentile, of grouped data. mode() 众数 Mode (most common value) of discrete data. L = range(10000) from statistics import mean,median,median_low,median_high,median_grouped,mode mean(L) 4999.5 median(L) 4999.5 median_low(L) 4999 median_low(L) 4999 median_high(L) 5000 median_high(L) 5000 median_grouped(L) 4999.5 median_grouped(L, interval=2) 4999.0 from random import randint XL = [randint(1,10) for i in range(10000)] mode(XL) 3 分布统计 函数 说明 pstdev() 总体标准差 pvariance() 总体方差 stdev() 样本标准差 variance() 样本方差 from statistics import pstdev,pvariance,stdev,variance pstdev(L) 2886.751331514372 pvariance(L) 8333333.25 stdev(L) 2886.8956799071675 variance(L) 8334166.666666667 随机模块random 常规用法 无论在做测试中还是在做模拟中,随机都是必须的模块,具体这样用: import random random.random() # [0,1)内随机浮点数 0.5316010639901497 random.uniform(1, 10) # [1,10)内随机浮点数 3.585529954803634 random.randint(1, 10) # [1,10]范围内的随机整数 10 random.randrange(0, 101, 2) # 从等差数列中随机挑一个数 92 random.choice('abcdefghij') # 随机选一个 'g' items = [1, 2, 3, 4, 5, 6, 7] random.shuffle(items)#随机排序 random.sample([1, 2, 3, 4, 5], 3) # 随机选3个元素 [2, 5, 3] 随机种子 学过C的都知道伪随机,python也是伪随机,所以可以通过设定seed值来改变随机状态 from matplotlib import pyplot as plt %matplotlib inline 数学上的一些特殊随机 三角分布 三角分布式是连续概率分布,可以看做是在一个范围中有一个数(众数)它附近有最高的概率密度即最有可能出现在该众数上 random.triangular(low, high, mode)#三角形分布,默认众数(mode)是中值 hight,low,mode = 0,2,0.5 random.triangular(hight,low,mode) 0.07300503184109307 from collections import Counter c = Counter() for nbr in [round(random.triangular(0,2,0.5),2) for i in range(10000)]: c[nbr] = c[nbr] + 1 plt.plot([float(i) for i in c.keys()],[float(i) for i in c.values()],\".\") plt.show() β分布 β分布是在0到1上的特殊分布, 做硬币试验的假定分布，即做伯努利试验的假定分布在确定伯努利试验的分布之前，我们利用试验的少量数据来估计试验的概率（作为先验概率）beta分布涉及两个参数：1、试验成功的次数2、试验失败的次数. 概率密度函数为: $\\begin{align} f(x)=& x^{\\alpha-1}(1-x)^{\\beta-1} \\over \\int_0^1 u^{\\alpha-1}(1-u)^{\\beta-1}du\\ =&{\\frac {\\Gamma(\\alpha+\\beta)} {\\Gamma(\\alpha)\\Gamma(\\beta)}}x^{\\alpha-1}(1-x)^{\\beta-1}\\ =&{\\frac {1} {B(\\alpha-\\beta)}}x^{\\alpha-1}(1-x)^{\\beta-1} \\end{align} $ 累积分布函数: $\\begin{align} F(x;\\alpha,\\beta)=& \\frac {B_x(\\alpha,\\beta)} {B(\\alpha,\\beta)}&=I_x(\\alpha,\\beta) \\end{align} $ 其中${B_x(\\alpha,\\beta)}$是不完全Β函数,${I_x(\\alpha,\\beta)}$ 是正则不完全贝塔函数 是不完全Β函数，$I_x (\\alpha,\\beta)$ 是正则不完全贝塔函数 random.betavariate(alpha, beta)#beta分布 l0=[random.betavariate(0.5,1) for i in range(100000)] l1=[random.betavariate(2,3) for i in range(100000)] l2=[random.betavariate(3,4) for i in range(100000)] l3=[random.betavariate(2,5) for i in range(100000)] r0=[len([1 for j in l0 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r1=[len([1 for j in l1 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r2=[len([1 for j in l2 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r3=[len([1 for j in l3 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r0,color=\"red\") plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r1,color=\"blue\") plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r2,color=\"green\") plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r3,color=\"yellow\") plt.show() 指数分布 概率密度函数: 指数分布可以用来表示独立随机事件发生的时间间隔，比如旅客进机场的时间间隔、中文维基百科新条目出现的时间间隔等等。 许多电子产品的寿命分布一般服从指数分布。有的系统的寿命分布也可用指数分布来近似。它在可靠性研究中是最常用的一种分布形式。指数分布是伽玛分布和威布尔分布的特殊情况，产品的失效是偶然失效时，其寿命服从指数分布。 指数分布可以看作当威布尔分布中的形状系数等于1的特殊分布，指数分布的失效率是与时间t无关的常数，所以分布函数简单。 概率密度函数: $ f(x)=\\begin{cases} \\lambda e^{-\\lambda x}&\\text{$x>0$},\\ 0&\\text{$x\\le0$}. \\end{cases} $ 累积分布函数: $ F(x;\\lambda)=\\begin{cases} 1- e^{-\\lambda x}&\\text{$x\\ge0$},\\ 0&\\text{$x 期望值: $ EX=\\lambda^{-1} $ 方差: $D(X)=Var(X)=\\lambda ^{-2}$ random.expovariate(lambd) random.expovariate(3) 0.11719755325435312 c_e3 = Counter() for nbr in [round(random.expovariate(3),2 ) for i in range(10000)]: c_e3[nbr] = c_e3[nbr] + 1 plt.plot([float(i) for i in c_e3.keys()], [float(i) for i in c_e3.values()],\".\") plt.show() 伽玛分布 概率密度函数: 令 $X\\sim \\Gamma(\\alpha,\\beta)$ ; 则有: $f(x)={\\frac {x^{(\\alpha-1)} e^{(-\\lambda x)}} {\\Gamma(\\alpha)\\beta^\\alpha}} ,x>0 $ random.gammavariate(alpha, beta) c_gamma = Counter() for nbr in [round(random.gammavariate(5,0.5),2 ) for i in range(10000)]: c_gamma [nbr] = c_gamma [nbr] + 1 plt.plot([float(i) for i in c_gamma.keys()], [float(i) for i in c_gamma.values()],\".\") plt.show() 高斯分布(正态分布) 概率密度函数: $ f(x)={\\frac 1 {\\sqrt {2\\pi}\\sigma}} e^{-{\\frac {(x-\\mu)^2} {2\\sigma^2}}} $ 其中 $\\mu$ 与 $\\sigma$ 分别是变量对数的平均值与标准差 random.gauss(mu, sigma)#略快于下面的方法 random.normalvariate(mu, sigma) c_gauss = Counter() for nbr in [round(random.gauss(0,1),2 ) for i in range(10000)]: c_gauss[nbr] = c_gauss[nbr] + 1 plt.plot([float(i) for i in c_gauss.keys()], [float(i) for i in c_gauss.values()],\".\") plt.show() 对数正态分布 如果 X 是正态分布的随机变量，则 exp(X) 为对数正态分布；同样，如果 Y 是对数正态分布，则 ln(Y) 为正态分布。 如果一个变量可以看作是许多很小独立因子的乘积，则这个变量可以看作是对数正态分布。 概率密度函数: $ f(x;\\mu,\\sigma) = \\frac{1}{ \\sigma \\sqrt{2 \\pi}} e^{-(\\ln x - \\mu)^2/2\\sigma^2} $ 其中 $\\mu$ 与 $\\sigma$ 分别是变量对数的平均值与标准差 random.lognormvariate(mu, sigma) c_log = Counter() for nbr in [round(random.lognormvariate(0.5,0.5),2 ) for i in range(10000)]: c_log[nbr] = c_log[nbr] + 1 plt.plot([float(i) for i in c_log.keys()],[float(i) for i in c_log.values()],\".\") plt.show() 冯·米塞斯分布 冯·米塞斯分布（von Mises distribution）指一种圆上连续概率分布模型，它也被称作循环正态分布 概率密度函数: $ f(x|\\mu,\\kappa)=\\frac{e^{\\kappa\\cos(x-\\mu)}}{2\\pi I_0(\\kappa)} $ 参数μ和1/κ是μ和σ^2（对应正态分布中的均值和方差）的模拟量 μ是位置的度量（分布将围绕μ成簇） κ是集中度的度量（分散度的倒数，所以1/κ是σ^2的模拟量） 如果κ为0，分布是均匀分布，对于κ很小的情形，分布近似均匀分布 如果κ很大，分布紧紧围绕μ集中分布。实际上，随着κ增加，分布将趋于x以μ为均值1/κ为方差的正态分布 random.vonmisesvariate(mu, kappa) c_von = Counter() for nbr in [round(random.vonmisesvariate(10,1),2 ) for i in range(10000)]: c_von[nbr] = c_von[nbr] + 1 plt.plot([float(i) for i in c_von.keys()], [float(i) for i in c_von.values()],\".\") plt.show() 帕累托分布 帕累托法则(2,8定律) 帕累托分布是以意大利经济学家维弗雷多·帕雷托命名的。 是从大量真实世界的现象中发现的幂定律分布。这个分布在经济学以外，也被称为布拉德福分布。 概率密度函数: $ p(x) = \\left { \\begin{matrix} 0, & \\mbox{if }x {\\min}; \\ \\ {\\frac{k \\; x{\\min}^k} {x^{k+1}}}, & \\mbox{if }x > x_{\\min}. \\end{matrix} \\right. $ k是形状参数(shape parameter) random.paretovariate(k) c_par = Counter() for nbr in [round(random.paretovariate(10),2 ) for i in range(10000)]: c_par[nbr] = c_par[nbr] + 1 plt.plot([float(i) for i in c_par.keys()], [float(i) for i in c_par.values()],\".\") plt.show() 韦伯分布 韦伯分布（Weibull distribution），又称韦氏分布或威布尔分布，是可靠性分析和寿命检验的理论基础。 概率密度函数: $ f(x;\\lambda,k) = \\begin{cases} \\frac{k}{\\lambda}\\left(\\frac{x}{\\lambda}\\right)^{k-1}e^{-(x/\\lambda)^{k}} & x\\geq0\\ 0 & x λ＞0是比例参数（scale parameter），k＞0是形状参数（shape parameter） random.weibullvariate(lambda, k) c_wei = Counter() for nbr in [round(random.weibullvariate(2,1),2 ) for i in range(10000)]: c_wei[nbr] = c_wei[nbr] + 1 plt.plot([float(i) for i in c_wei.keys()], [float(i) for i in c_wei.values()],\".\") plt.show() Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 16:30:24 "},"数学与统计应用篇/numpy的高性能同构定长多维数组ndarray/numpy的高性能同构定长多维数组ndarray.html":{"url":"数学与统计应用篇/numpy的高性能同构定长多维数组ndarray/numpy的高性能同构定长多维数组ndarray.html","title":"numpy的高性能同构定长多维数组ndarray","keywords":"","body":"numpy的高性能同构定长数组ndarray numpy最大的意义在于它构建了这个高性能同构定长多维数组数组类型numpy.ndarray它是由C写的数据类型因此具有非常强的性能.同时 ndarray实现了Collection,Container和Iterable协议.因此python的序列操作也都可以使用. numpy.ndarray是几乎所有python科学计算工具的基石,包括pandas也是在其上构建的. import numpy as np ndarray数组的基本操作 ndarray本质上是一段连续内存.它支持基本的构造,切片,访问,和修改操作,并且也支持合并操作. 构建ndarray数组 numpy的数组需要由序列构建而来.通常我们使用构造函数numpy.array(obj:sequence,dtype:str,copy:bool=True,order:str,subok:bool=False,ndmin:int) 在数学上我们定义一个如下的矩阵: [012345] \\left [ \\begin{matrix} 0 & 1 &2\\\\ 3 & 4 &5 \\end{matrix} \\right ] [​0​3​​​1​4​​​2​5​​] 我们以它为例子介绍数组的构建 obj是用于转化的序列对象,要求必须是同一种数据类型 X = np.array([[0,1,2],[1,0,3]]) print(X) [[0 1 2] [1 0 3]] dtype可以用于指定数据类型 可用的数据类型下面\"元素的数据类型\"部分会列出,如果不指定则会自动使用可以存放数据的最小内存的数据类型. numpy可以特化其中元素的类型来获得更高的效率 类型 类型代码 说明 int8/uint8 i1/u1 有符号/无符号8位整型 int16/uint16 i2/u2 有符号/无符号16位整型 int32/uint32 i4/u4 有符号/无符号32位整型 int64/uint64 i8/u8 有符号/无符号64位整型 float16 f2 半精度浮点数 float32 f4或f 标准单精度浮点数 float64 f8或d 标准双精度浮点数 float128 f16或g 扩展精度浮点数 complex64 c8 32为浮点数表示的复数 complex128 c16 64为浮点数表示的复数 complex256 c32 128为浮点数表示的复数 bool ? 布尔值 object O python对象类型 string_ SX 固定长度字符串,比如长度为10,则S10 unicode_ UX 固定长度unicode,比如长度为10,则U10 X = np.array([[0,1,2],[1,0,3]],dtype=\"f2\") print(X) [[0. 1. 2.] [1. 0. 3.]] X.dtype dtype('float16') 结构体数组 在numpy中可以定义结构数组来表现结构化数据,虽然这个功能现在有pandas这个更好的实现,但如果只是轻量级的使用,numpy的结构数组或许更有效率 构造结构体使用np.dtype(obj,align:bool=False,copy:bool=True)类. 要自己构建结构体,其中obj需为一个字典,包含两个字段: names 用于指明字段名 formats 用于指明字段的类型 同时指明align=True用于指明数据要对齐(通过补齐让每个字段自动与最长的字段长度一致). copy则意味着类型是新对象还是只是原来标准类型的映射. persontype=np.dtype({'names':['name','age','weight'],'formats':['S32','i','f']},align=True)#先创建一个人物类型 People = np.array([ [(\"Huang\",27,75),(\"Hao\",25,55),(\"Li\",26,80)], [(\"Hu\",28,65),(\"Hua\",23,75),(\"Liu\",26,85)] ],dtype=persontype) print(People) [[(b'Huang', 27, 75.) (b'Hao', 25, 55.) (b'Li', 26, 80.)] [(b'Hu', 28, 65.) (b'Hua', 23, 75.) (b'Liu', 26, 85.)]] 访问某个数据的字段可以使用[]运算符 People[0,0]['name'] b'Huang' 也可以直接以字段为索引直接获取切片或全局的字段数组 People[0,:]['name']# 取行 array([b'Huang', b'Hao', b'Li'], dtype='|S32') People[:,0]['name']# 取列 array([b'Huang', b'Hu'], dtype='|S32') People['name'] # 全局 array([[b'Huang', b'Hao', b'Li'], [b'Hu', b'Hua', b'Liu']], dtype='|S32') copy,默认值为True,如果为True,构造出的数组为新建的,否则如果参数obj也是ndarray数组,则只是修改这个数组. X = np.array([[0,1,2],[1,0,3]],dtype=\"f2\") X_copy = np.array(X,copy=True) X is X_copy False X_self = np.array(X,copy=False) X is X_self True order用于标明下标的表现方式,可选的参数有'K', 'A', 'C', 'F',默认为\"K\" 在数学上我们定义一个如下的矩阵: [012345] \\left [ \\begin{matrix} 0 & 1 &2\\\\ 3 & 4 &5 \\end{matrix} \\right ] [​0​3​​​1​4​​​2​5​​] 在C语言中,中其存储方式是以行为主轴的,也就是会这么存. 0,1,2,3,4,5 而在Fortran中会以列为主轴存储,也就是这样 0,3,1,4,2,5 内部存储的样子比较难以观察,我们可以通过reshape来查看 X = np.array([[0,1,2],[3,4,5]],order=\"C\") print(X) X.reshape(1,6,order=\"C\") [[0 1 2] [3 4 5]] array([[0, 1, 2, 3, 4, 5]]) Y = np.array([[0,1,2],[3,4,5]],order=\"F\") print(Y) Y.reshape(1,6,order='F') [[0 1 2] [3 4 5]] array([[0, 3, 1, 4, 2, 5]]) 如果参数指明为\"C\",则表示使用C语言的规范存储,如果使用参数\"F\"则表示使用Fortran的规范存储. \"K\"和\"A\"在参数copy为False时表示继承obj数组的存储顺序,但copy为True时则表现不同,\"K\"在obj为数组时继承其顺序,非数组则会按C的格式存储.而\"A\"会在obj为数组时如果它的order为\"F\",\"A\",\"K\"时都是Fortran的存储顺序,否则为C的存储方式. subok如果为True,则子类将被传递;否则返回的数组将被强制为基类数组,False为默认. ndmin指定维度 这个参数更多的是用于将向量,矩阵等转化为更高维的张量,同样的功能也可以用reshape实现 X = np.array([[0,1,2],[3,4,5]],ndmin=2) print(X) [[0 1 2] [3 4 5]] Y = np.array([[0,1,2],[3,4,5]],ndmin=3) print(Y) [[[0 1 2] [3 4 5]]] Z = np.array([[0,1,2],[3,4,5]],ndmin=3) print(Z) [[[0 1 2] [3 4 5]]] 快速构建数组 numpy提供了很多方法快速构建一些特殊形式的数组 固定形状固定值的数组 全0数组np.zeros(shape) np.zeros((2,2)) array([[0., 0.], [0., 0.]]) 全1数组np.ones(shape) np.ones((2,2)) array([[1., 1.], [1., 1.]]) 空数组(只分配内存空间不赋值,也就是说里面可能是无意义数据)np.empty(shape) np.empty((2,2)) array([[1., 1.], [1., 1.]]) 特殊一维数组 一维等差数列数组np.arange(dow,up,step) np.arange(1,11,2) array([1, 3, 5, 7, 9]) 一维均分数组(可以看做等差数列的一种)np.linspace(start, stop, num=50, endpoint=True, retstep=False)->sample 其中endpoint如果为True表示stop为最后一个数. 如果retstep为True,则返回值为(sample,step),其中step就是均分的间隔 np.linspace(-np.pi, np.pi, 6,endpoint=True) array([-3.14159265, -1.88495559, -0.62831853, 0.62831853, 1.88495559, 3.14159265]) np.linspace(-np.pi, np.pi, 6,endpoint=True,retstep=True) (array([-3.14159265, -1.88495559, -0.62831853, 0.62831853, 1.88495559, 3.14159265]), 1.2566370614359172) 一维等比数列数组np.logspace(start, stop, num=num, endpoint=endpoint,base = base) 其中base参数可以用来固定底,这样就相当于做乘方了 np.logspace(0.1, 1, 10) array([ 1.25892541, 1.58489319, 1.99526231, 2.51188643, 3.16227766, 3.98107171, 5.01187234, 6.30957344, 7.94328235, 10. ]) np.logspace(0.1, 1, 10,base = 2) array([1.07177346, 1.14869835, 1.23114441, 1.31950791, 1.41421356, 1.51571657, 1.62450479, 1.74110113, 1.86606598, 2. ]) 特殊二维数组 单位矩阵数组np.eye(n) np.eye(3) array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) 对角矩阵数组np.diag(obj) 这个obj为一维序列时将会产生一个以其值为对角线其他都是0的对角矩阵;如果如一个方正则会取其对角线组成一个数组 np.diag((1,2,3)) array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]) np.diag( ( (1,2,3), (4,5,6), (7,8,9) ) ) array([1, 5, 9]) 构造随机数组 numpy有自己的随机数生成器,它可以作为标准库的补充,其接口基本和标准库的一致,用它可以方便的构造固定shape的随机数组. 像标准库random一样,numpy也可以设置随机种子np.random.seed(number) 洗牌 我们可以以一个一维序列作为输入,生成一个元素随机顺序的数组有两种方式 使用np.random.permutation生成一个新的一维序列 就地洗牌使用np.random.shuffle,改变原对象的排序 import matplotlib.pyplot as plt %matplotlib inline np.random.permutation([1,2,3,4,5,6]) array([1, 6, 5, 4, 2, 3]) a = np.array([1,2,3,4,5,6]) np.random.shuffle(a) a array([6, 2, 4, 1, 3, 5]) 均匀分布 numpy有3个均匀分布的函数 np.random.rand(d0,d1,...,dn)0~1返回内的均匀分布 np.random.uniform(low=0.0, high=1.0, size=None)low到high范围内的均匀分布 np.random.randint(low, high=None, size=None, dtype='l')low到high范围内整数的均匀分布 np.random.rand(2,3) array([[0.69799255, 0.7888051 , 0.66893797], [0.01018505, 0.93295118, 0.57403557]]) np.random.uniform(2,3,size=(3,4)) array([[2.27883779, 2.10539064, 2.6946143 , 2.99850912], [2.381377 , 2.33687032, 2.31932192, 2.96783378], [2.46179302, 2.72258605, 2.4427342 , 2.20615523]]) np.random.randint(1,9,size=(3,3)) array([[6, 7, 4], [4, 8, 1], [4, 3, 3]]) l=np.random.rand(1000) r1=[len(list(filter(lambda x:i+0.005>x>i-0.005,l))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r1) plt.show() 正态分布 正态分布又叫高斯分布,numpy中有两个方法实现: np.random.normal(loc=0.0, scale=1.0,size=None)loc为均值,scale为标准差size则为形状 np.random.randn(d0, d1, ..., dn)标准正态分布 np.random.normal(1,0.5,size=(3,3)) array([[1.14928514, 0.98874561, 1.08238708], [1.16838246, 1.08098035, 0.83320946], [2.2213291 , 1.10766759, 0.61062045]]) np.random.randn(3,3) array([[-0.74651304, -0.52009124, 0.10955316], [ 0.32689031, -1.44277601, 0.53329921], [ 1.21113617, -0.01221963, 0.88827929]]) l=np.random.randn(100000) r1=[len(list(filter(lambda x:i+0.05>x>i-0.05,l))) for i in map(lambda x:round(x*0.1,2),range(-40,40,1))] plt.plot(list(map(lambda x:round(x*0.1,2),range(-40,40,1))),r1) plt.show() 二项分布 二项分布是n个独立的是/非试验中成功的次数的离散概率分布,其中每次试验的成功概率为p.这样的单次成功/失败试验又称为伯努利试验.实际上当n = 1时,二项分布就是伯努利分布.二项分布是显著性差异的二项试验的基础. Poisson分布是二项分布n很大而P很小时的特殊形式,是两分类资料在n次实验中发生x次某种结果的概率分布.其概率密度函数为: P(x)=e−μ∗μxx!x=0,1,2...n P(x)=e-\\mu*\\frac {\\mu x} {x!} x=0,1,2...n P(x)=e−μ∗​x!​​μx​​x=0,1,2...n 其中e为自然对数的底,$\\mu$为总体均数,x为事件发生的阳性数. 二项分布在numpy中使用np.random.binomial(n, p, size=None),n为重复次数,p为True的概率,size为形状 sum(np.random.binomial(10,0.1,1000)==0)/1000.0# 10个样本成功率为0.1,验证1000次全部都失败的概率 0.363 Beta分布 使用函数np.random.beta(a, b, size=None)a为分布的参数$\\alpha$,b为参数$\\beta$ np.random.beta(0.5,0.3,[2,3]) array([[0.96751372, 0.89294397, 0.01424346], [0.32563002, 0.99996309, 0.69713176]]) l0=np.random.beta(0.5,1,100000) l1=np.random.beta(2,3,100000) l2=np.random.beta(3,4,100000) l3=np.random.beta(2,5,100000) r0=[len(list(filter(lambda x:i+0.005>x>i-0.005,l0))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r1=[len(list(filter(lambda x:i+0.005>x>i-0.005,l1))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r2=[len(list(filter(lambda x:i+0.005>x>i-0.005,l2))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r3=[len(list(filter(lambda x:i+0.005>x>i-0.005,l3))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r0,color=\"red\") plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r1,color=\"blue\") plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r2,color=\"green\") plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r3,color=\"yellow\") plt.show() 卡方分布 若k个随机变量$ Z_1、……、Z_k $是相互独立,符合标准正态分布的随机变量(数学期望为0,方差为1),则随机变量Z的平方和 X=∑i=1kZi2 X=\\sum_{i=1}^k Z_i^2 X=∑​i=1​k​​Z​i​2​​ 被称为服从自由度为k的卡方分布,记作 X∼χ2(k) X\\sim\\chi^2(k) X∼χ​2​​(k) X∼χk2 X\\sim\\chi^2_k X∼χ​k​2​​ numpy中使用接口np.random.chisquare(df, size=None)其中df为分布的参数,自由度$df$ np.random.chisquare(2,(2,3)) array([[1.2339406 , 2.84964228, 3.60035737], [0.33187465, 3.02932834, 4.39024623]]) 伽马分布 伽马分布使用接口np.random.gamma(shape, scale=1.0, size=None)shape表示形状参数$\\alpha$;scale为尺度参数$\\beta$ np.random.gamma(1,2,(2,3)) array([[3.17820824, 2.53817032, 1.49755265], [0.24098586, 1.61370319, 0.48898025]]) l0=np.random.gamma(0.5,1,100000) l1=np.random.gamma(9,0.5,100000) l2=np.random.gamma(7,1,100000) r0=[len(list(filter(lambda x:i+0.05>x>i-0.05,l0))) for i in map(lambda x:round(x*0.1,3),range(0,200,1))] r1=[len(list(filter(lambda x:i+0.05>x>i-0.05,l1))) for i in map(lambda x:round(x*0.1,3),range(0,200,1))] r2=[len(list(filter(lambda x:i+0.05>x>i-0.05,l2))) for i in map(lambda x:round(x*0.1,3),range(0,200,1))] plt.plot(list(map(lambda x:round(x*0.1,3),range(0,200,1))),r0,color=\"red\") plt.plot(list(map(lambda x:round(x*0.1,3),range(0,200,1))),r1,color=\"blue\") plt.plot(list(map(lambda x:round(x*0.1,3),range(0,200,1))),r2,color=\"green\") plt.show() 根据下标自定义数组构造过程 有的时候我们希望可以自定义的生成一个矩阵,比如我们希望生成一个各项值等于i+10j的矩阵(i为行号,j为列号)这时候可以使用np.fromfunction(func,shape,dtype) 其中的参数func的参数个数为shape的位数,而参数的值则是下标 np.fromfunction(lambda i,j: i+10*j,(3,4)) array([[ 0., 10., 20., 30.], [ 1., 11., 21., 31.], [ 2., 12., 22., 32.]]) 网格数组 np.ogrid可以用于快速构建用于构建网格的数组.他的参数是切片表达式,每有一个切片就会生成一个网格的一根轴,因此他的返回数据个数与参数个数一致. x,y = np.ogrid[:5,:10:2] print(x) print(y) [[0] [1] [2] [3] [4]] [[0 2 4 6 8]] 可以看到这两个数组一个行一个是列,且每位对称,这样做出来的数组就可以直接进行矩阵乘法了 x@y array([[ 0, 0, 0, 0, 0], [ 0, 2, 4, 6, 8], [ 0, 4, 8, 12, 16], [ 0, 6, 12, 18, 24], [ 0, 8, 16, 24, 32]]) 利用ogrid的返回值可以很容易的计算出二元函数在等间距网格上的值 例:画出 f(x,y)=xex2−y2f(x,y)=xe^{x^2-y^2}f(x,y)=xe​x​2​​−y​2​​​​ x,y = np.ogrid[-2:2:20j,-2:2:20j] z = x*np.exp(-x**2-y**2) from mpl_toolkits.mplot3d import Axes3D fig = plt.figure() ax = Axes3D(fig) ax.plot_surface(x, y, z, rstride=1, cstride=1, cmap='hot') plt.show() ndarray对象的常用属性 属性 含义 T 转置,与self.transpose()相同,如果维度小于2返回self size 数组中元素个数 itemsize 数组中单个元素的字节长度 dtype 数组元素的数据类型对象 ndim 数组的维度 shape 数组的形状 data 指向存放数组数据的memoryview对象 flat 返回数组的一维迭代器 imag 返回数组的虚部 real 返回数组的实部 nbytes 数组中所有元素的字节长度 ndarray也支持一些方法,这些方法与numpy对应函数重名.这边就不做详细介绍了 访问ndarray中的元素 访问某个元素可以像访问多维list对象中元素一样操作 X array([[0, 1, 2], [3, 4, 5]]) X[0][1] 1 也可以使用切片的方式,以,分隔每维来指定位置 X[0,1] 1 ndarray数组的切片 数字切片的规则和python中list一致, 以,分隔每维来指定位置. 以:代表范围,如果:之前或者之后缺省,则分别代表最初一位和最后一位.正整数数代表从头数到这位,复数代表从末位倒着数到这位 ,分隔的每一位都可以以一个list指定取某几位 X[:,1] array([1, 4]) X[:,:-1] array([[0, 1], [3, 4]]) X[:,[0,-1]] array([[0, 2], [3, 5]]) 按下表提取元素 numpy中是用np.take(a, indices, axis=None, out=None, mode='raise')从数组总提取对应的下标指示的元素构建一个新数组 x = np.arange(10) x array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) np.take(x,[1,2,3]) array([1, 2, 3]) 按条件查找下标对应的元素 numpy支持按条件查找下标对应的元素,使用的接口是np.choose(a, choices, out=None, mode='raise') 其中a为指定的下标组成的序列,choices为可被选择的内容, choices = [ [0, 1, 2, 3], [10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33] ] np.choose([2, 3, 1, 0], choices) array([20, 31, 12, 3]) 可以看到最后的结果是每列选择对应下标的值 按条件查找元素下标 numpy支持按条件查找元素所在下标,使用的接口是np.where,它有两种用法: np.where(condition, [x, y])来按条件查找元素并执行赋值. 其逻辑是:满足条件(condition),输出x,不满足输出y.condition是判断条件. aa = np.arange(10) np.where(aa,1,-1) # 0值也是False array([-1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) np.where(aa > 5,1,-1) # condition为一个bool值序列 array([-1, -1, -1, -1, -1, -1, 1, 1, 1, 1]) np.where( [ [True,False], [True,True] ], # 官网上的例子 [ [1,2], [3,4] ], [ [9,8], [7,6] ] ) ## 多维数组则是看对应下标位置判断取值 array([[1, 8], [3, 4]]) np.where(condition)返回满足条件的下标,即等价于condition.nonzero() np.where(aa>5) (array([6, 7, 8, 9]),) np.where(np.array([[0,1], [1,0]]) > 0) (array([0, 1]), array([1, 0])) 使用where实现三角波 T=1#定义周期T为1 x = np.linspace(0, 2,201,endpoint=True) C = 0.7#定义为0的部分 up = 0.5#定义上升的持续时间 top = 1.0#定义最大y值 #y=Kx+B K_up = lambda : top/up K_down = lambda : top/(up-C) B_down = top-K_down()*up y = np.where(np.modf(x)[0] >= C ,0,np.where(np.modf(x)[0] 按条件条件查找元素 numpy支持按条件查找元素,使用的是接口np.select(condlist, choicelist, default=0). 当满足多个条件时，将使用condlist中遇到的第一个条件.位置m处的输出是choicelist中数组的第m个元素，其中condlist中相应数组的第m个元素为True。 x = np.arange(10) x array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) condlist = [x5] condlist [array([ True, True, True, False, False, False, False, False, False, False]), array([False, False, False, False, False, False, True, True, True, True])] choicelist = [x, x**2] choicelist [array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([ 0, 1, 4, 9, 16, 25, 36, 49, 64, 81])] np.select(condlist, choicelist) array([ 0, 1, 2, 0, 0, 0, 36, 49, 64, 81]) 使用select实现三角波 T=1#定义周期T为1 x = np.linspace(0, 2,201,endpoint=True) C = 0.7#定义为0的部分 up = 0.5#定义上升的持续时间 top = 1.0#定义最大y值 #y=Kx+B K_up = lambda : top/up K_down = lambda : top/(up-C) B_down = top-K_down()*up y1 = np.select([np.modf(x)[0] >= C,np.modf(x)[0] 数组分段执行函数 np.piecewise(x, condlist, funclist, *args, **kw)可以按condlist将x拆成几段,每段分别执行funclist中对应的函数 使用piecewise实现三角波 y2 = np.piecewise( x, [np.modf(x)[0] >= C,np.modf(x)[0] 数组拼接 二维数组拼接分为横向拼接和纵向拼接 np.hstack(tup)横向拼接 np.vstack(tup)纵向拼接 其中tup为要拼接的对象组成的序列 更加通用的则是指定要拼接的轴np.concatenate(tup,axis=0,out=None)其中用axis指定以第几维为轴,out如果设置则必须为符合拼接后形状,元素类型的数组对象,这样拼接的结果会放入这个数组. A=np.arange(1,13).reshape(3,4) print(A) [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] B=np.arange(2,14).reshape(3,4) print(B) [[ 2 3 4 5] [ 6 7 8 9] [10 11 12 13]] np.hstack((A,B)) array([[ 1, 2, 3, 4, 2, 3, 4, 5], [ 5, 6, 7, 8, 6, 7, 8, 9], [ 9, 10, 11, 12, 10, 11, 12, 13]]) np.vstack((A,B)) array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [ 2, 3, 4, 5], [ 6, 7, 8, 9], [10, 11, 12, 13]]) np.concatenate((A,B),axis=0) array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [ 2, 3, 4, 5], [ 6, 7, 8, 9], [10, 11, 12, 13]]) np.concatenate((A,B),axis=1) array([[ 1, 2, 3, 4, 2, 3, 4, 5], [ 5, 6, 7, 8, 6, 7, 8, 9], [ 9, 10, 11, 12, 10, 11, 12, 13]]) 序列操作 作为一个序列,numpy也提供了很多序列专有操作,这些操作看起来有点函数式编程的意思.习惯这种思维的可以很方便的写出简洁的代码 真值判断 numpy使用any(a,axis=None)和all(a,axis=None)进行真值判断.,同时可以指定轴. x = np.array([0,1,2,3,4,5,6]) np.all(x) False np.any(x) True 迭代器 numpy使用np.nditer将数组转化为迭代器.它支持python的迭代器协议,可以使用next获取下一个元素.order参数可以直接影响它的迭代顺序. x = np.array([1,2,3,4,5,6]).reshape(2,3) print(x) x_i = np.nditer(x,order='C') [[1 2 3] [4 5 6]] for i in x_i: print(i) 1 2 3 4 5 6 x_j = np.nditer(x,order='F') for i in x_j: print(i) 1 4 2 5 3 6 排序 np.lexsort(keys, axis=-1) 使用一系列键执行间接排序,keys为要排序的复数序列.axis为以谁为轴,返回的是排序后的下标位置 X = np.array([ [9,4,0,4,0,2,1],# b [1,5,1,4,3,4,4] # a ]) # b在前，a在后，即是先按照a的元素进行比较 # 如a中的最小值为两个1，其索引分别为0,2，再计较b中相应索引上的值，即9,0 # 对应的最小应是：1,0，而其对应的索引为2，所以排序后返回的结果第一个值为索引2 # 下一个最小应是：1,9，而其对应的索引为0，所以排序后返回的结果第一个值为索引0 # 以此类推... ind = np.lexsort(X) # Sort by a, then by b print(ind) [2 0 4 6 5 3 1] np.argsort(a, axis=-1, kind='quicksort', order=None) 排序并返回下标 a ：所需排序的数组 axis：数组排序时的基准，axis=0，按行排列；axis=1，按列排列 kind：数组排序时使用的方法，其中:kind=′quicksort′为快排；kind=′mergesort′为混排；kind=′heapsort′为堆排； order：一个字符串或列表，可以设置按照某个属性进行排序 a=np.array([4,2,5,7,3]) b=np.argsort(a) print(b) # 列表b的元素表示的是原列表a中的元素的索引，5各元素的索引分别为0-4 # 返回的结果可以这样解读： # b[0]=1，表示原列表a的最小元素的索引为1，即原列表a中的第2个元素为最小值 # b[1]=4，表示原列表a的第二小元素的索引为4，即原列表a中的第5个元素为第二小元素 # ... # b[4]=3，表示原列表a中的最大元素的索引为3，即原列表a中的第4个元素为最大值 [1 4 0 2 3] c=np.array([ [3, 2], [5, 7] ]) d = np.argsort(c, axis=1) print(d) # axis=1，表明按照列进行排序，即是对[3, 2]进行排序，所以得到索引为[1, 0],其他同理 [[1 0] [0 1]] e = np.argsort(c, axis=0) print(e) # axis=0，表明按照行进行排序，即是对[3, 5]进行排序，所以得到索引为[0, 1],其他同理 [[0 0] [1 1]] np.sort(a, axis=-1, kind='quicksort', order=None) 这个接口与标准排序接口sorted类似功能 a ：所需排序的数组 axis：数组排序时的基准，axis=0，按行排列；axis=1，按列排列 kind：数组排序时使用的方法，其中:kind=′quicksort′为快排；kind=′mergesort′为混排；kind=′heapsort′为堆排； order：一个字符串或列表，可以设置按照某个属性进行排序,有点类似标准接口的key dtype = [('name', 'S10'), ('height', float), ('age', int)] values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38),('Galahad', 1.7, 38)] a = np.array(values, dtype=dtype) print(a) np.sort(a, order='height') [(b'Arthur', 1.8, 41) (b'Lancelot', 1.9, 38) (b'Galahad', 1.7, 38)] array([(b'Galahad', 1.7, 38), (b'Arthur', 1.8, 41), (b'Lancelot', 1.9, 38)], dtype=[('name', 'S10'), ('height', ' np.searchsorted(a, v, side='left', sorter=None) 排序后插入v时插入的索引位置 a：所需排序的数组 v：待查询索引的元素值 side：查询索引时的方向，其中:kind=′left′为从左至右；kind=′right′为从右至左 sorder：一个字符串或列表，可以设置按照某个属性进行排序 list3=[1,2,3,4,5] np.searchsorted(list3,2) # 如若要在list3中插入元素2，则应当将其插在原列表索引为1的地方，即是插在元素1的后面 1 np.searchsorted(list3,[-5,7,4,9]) # 如若要在list3中插入元素-5，则应当将其插在原列表索引为0的地方，即是插在元素1的前面 # 其他以此类推... array([0, 5, 3, 5]) np.partition(a, kth, axis=-1, kind='introselect', order=None) a:所需排序的数组 kth:以排序后第几个数为分界 axis: 以哪一维为轴 side:查询索引时的方向，其中:kind=′left′为从左至右；kind=′right′为从右至左 sorder:一个字符串或列表，可以设置按照某个属性进行排序 list4=[3,4,5,2,1] np.partition(list4,3) # 以排序后的第3个数，即3进行分区，分区后的结果即是： # 小于3的元素2,1位于3的前面，大于等于3的元素4,5位于3的后面 array([2, 1, 3, 4, 5]) 累积 其基本模式是延一条轴用一个函数计算到当前位的累积 求沿给定轴的元素的累积积np.cumprod(a, axis=None, dtype=None, out=None) a = np.array([1,2,3,4]) np.cumprod(a) # 结果每位是到这一位前各个的积 1, 1*2, 1*2*3 ,1*2*3*4 array([ 1, 2, 6, 24]) a = np.array([ [1, 2, 3], [4, 5, 6] ]) np.cumprod(a, axis=0) # 求各个列的累积积 # [ 1, 2, 3], # [ 1*4, 2*5, 3*6]] array([[ 1, 2, 3], [ 4, 10, 18]]) np.cumprod(a,axis=1) # 求各行的累积积 # [ 1, 1*2, 1*2*3], # [ 4, 4*5, 4*5*6] array([[ 1, 2, 6], [ 4, 20, 120]]) 沿给定轴的元素的累积和np.cumsum(a, axis=None, dtype=None, out=None) a = np.array([ [1, 2, 3], [4, 5, 6] ]) np.cumsum(a, axis=0) # 求各个列的累积和 # [ 1, 2, 3], # [ 1+4, 2+5, 3+6]] array([[1, 2, 3], [5, 7, 9]]) np.cumsum(a,axis=1) # 求各行的累积积 # [ 1, 1+2, 1+2+3], # [ 4, 4+5, 4+5+6] array([[ 1, 3, 6], [ 4, 9, 15]]) 差分diff 求沿给定轴axis的第n个离散差分diff(a, n=1, axis=-1)(常用在时间序列) x = np.array([1, 2, 4, 7, 0]) np.diff(x) # [2-1,4-2,7-4,0-7] array([ 1, 2, 3, -7]) x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]]) np.diff(x) # [[3-1,6-3,10-6], # [5-0,6-5,8-6]] array([[2, 3, 4], [5, 1, 2]]) universal function 除了通用的序列操作外,还支持ufunc ufunc是universal function的简写,它是一种对数组中每个元素做相同操作的函数,概念上类似原生python的map,但在实际的运算中又不同. 原生map实际上是运行迭代器一个一个操作,而universal function则是向量化的执行函数,即一个函数不同的数据一起运行,这样就大大提高了效率. 我们可以实际测试下python自带的迭代和universal function的性能差距 test = np.arange(int(1e5)) print(test) [ 0 1 2 ... 99997 99998 99999] %timeit -n 3 map(lambda x:x**2,test) 543 ns ± 276 ns per loop (mean ± std. dev. of 7 runs, 3 loops each) %timeit -n 3 test**2 The slowest run took 4.81 times longer than the fastest. This could mean that an intermediate result is being cached. 84.9 µs ± 68.9 µs per loop (mean ± std. dev. of 7 runs, 3 loops each) 广播 可见universal function的高效.universal function的另一个特性是两个ndarray对象可以对应项计算,这一特性被称作广播 当俩数组形状不同的时候,那就会进行广播处理 让所有数组向其中维数最多的数组看齐,shape不足的部分通过在前面加1补齐 输出数组的shape属性是输入数组shape属性在各轴上的最大值 如果输入数组的某个轴长度是1或输出数组对应数组对应轴的长度相同,这个数组就够用来计算,否则出错 当输入数组的某个轴长度为1时,沿着该轴运算时都用此轴上的额第一组值 看例子: 相同shape a = np.arange(12).reshape(3,4) a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) b = np.arange(3,15).reshape(3,4) b array([[ 3, 4, 5, 6], [ 7, 8, 9, 10], [11, 12, 13, 14]]) a+b array([[ 3, 5, 7, 9], [11, 13, 15, 17], [19, 21, 23, 25]]) 不同shape在对应轴上广播 a = np.arange(0,60,10).reshape(-1,1) print(a) a.shape [[ 0] [10] [20] [30] [40] [50]] (6, 1) b = np.arange(0,5) print(b) b.shape [0 1 2 3 4] (5,) c = a+b print(c) c.shape [[ 0 1 2 3 4] [10 11 12 13 14] [20 21 22 23 24] [30 31 32 33 34] [40 41 42 43 44] [50 51 52 53 54]] (6, 5) 与常量做四则运算 ndarray对象支持python支持的四则运算接口,包括幂运算,而且都是universal function X = np.arange(10).reshape(2,5) print(X) [[0 1 2 3 4] [5 6 7 8 9]] X+2 array([[ 2, 3, 4, 5, 6], [ 7, 8, 9, 10, 11]]) X-2 array([[-2, -1, 0, 1, 2], [ 3, 4, 5, 6, 7]]) X*2 array([[ 0, 2, 4, 6, 8], [10, 12, 14, 16, 18]]) X/2 array([[0. , 0.5, 1. , 1.5, 2. ], [2.5, 3. , 3.5, 4. , 4.5]]) X**2 array([[ 0, 1, 4, 9, 16], [25, 36, 49, 64, 81]]) Y = np.arange(2,12).reshape(2,5) Y array([[ 2, 3, 4, 5, 6], [ 7, 8, 9, 10, 11]]) X+Y array([[ 2, 4, 6, 8, 10], [12, 14, 16, 18, 20]]) X-Y array([[-2, -2, -2, -2, -2], [-2, -2, -2, -2, -2]]) X*Y array([[ 0, 3, 8, 15, 24], [35, 48, 63, 80, 99]]) X/Y array([[0. , 0.33333333, 0.5 , 0.6 , 0.66666667], [0.71428571, 0.75 , 0.77777778, 0.8 , 0.81818182]]) X**Y array([[ 0, 1, 16, 243, 4096], [ 78125, 1679616, 40353607, 1073741824, 31381059609]]) 比较运算 python的比较操作也都是universal function,只是返回的结果是bool值 X>5 array([[False, False, False, False, False], [False, True, True, True, True]]) X array([[ True, True, True, True, True], [False, False, False, False, False]]) X==5 array([[False, False, False, False, False], [ True, False, False, False, False]]) X>=5 array([[False, False, False, False, False], [ True, True, True, True, True]]) X array([[ True, True, True, True, True], [ True, False, False, False, False]]) 需要注意连续比较并不支持 2 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 2其他的函数 numpy中还定义了其他的常用universal function具体可以看官方https://docs.scipy.org/doc/numpy/reference/ufuncs.html#available-ufuncs 自定义ufunc 有的时候自带的ufunc不能满足需要,numpy允许自定义ufunc 使用接口np.frompyfunc(func, nin, nout) 例:用一个分段函数描述三角波 def triangle_wave(x,c,c0,hc): \"\"\"三角波\"\"\" x = x - int(x) if x >= c: r = 0.0 elif x x = np.linspace(0,2,1000) y1 = np.array([triangle_wave(t,0.6,0.4,1.0) for t in x]) triangl_ufunc1 = np.frompyfunc(triangle_wave,4,1) y2 = triangl_ufunc1(x,0.6,0.4,1.0) plt.plot(range(len(y2)),y2) plt.show() 使用接口np.vectorize(pyfunc, otypes=None, doc=None, excluded=None, cache=False, signature=None)直接将python函数转化为ufunc triangl_ufunc2 = np.vectorize(triangle_wave) triangl_ufunc2.__doc__ '三角波' y3 = triangl_ufunc2(x,0.6,0.4,1.0) plt.plot(range(len(y3)),y3) plt.show() ufunc的泛函 简单的可以理解为函数的函数就是泛函.numpy支持针对ufunc的泛函操作,具体的有如下几种: at(a, indices, b=None) at用于指定下标执行函数,未被指定的就不会执行函数,注意其返回值为None,但它会改变第一个参数数组中对应元素的值. a = np.array([1, 2, 3, 4]) np.negative.at(a, [0, 1]) print(a) [-1 -2 3 4] a = np.array([1, 2, 3, 4]) np.add.at(a,[0,1],1) print(a) [2 3 3 4] reduce reduce和原生python中的reduce差不多,就是rfold,折叠操作的特化 np.add.reduce([1,2,3]) # 相当于sum 6 np.add.reduce([[1,2,3],[6,7,8]],axis=1) #可以指定延哪条轴折叠 array([ 6, 21]) accumulate accumulate和python3中functiontools新增的累积函数accumulate一样 np.add.accumulate([1,2,3]) array([1, 3, 6]) outer outer,会对俩数组中每两对元素组合进行运算. np.add.outer([1,2,3,4,5],[2,3,4]) array([[3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9]]) reduceat(a, indices, axis=0, dtype=None, out=None) 指定范围执行reduce操作.相当于 ufunc.reduce(a[indices[i]:indices[i+1]]). 特殊情况是-- 如果i+1 最后一位时i+1 = a.shape[axis]. 在一维的情况下可以每两位组成一个范围对,然后通过切片操作隔位取值以过滤掉中间没有计算的部分 x=np.arange(8) print(x) [0 1 2 3 4 5 6 7] x.shape (8,) np.add.reduceat(x,[0,4, 1,5, 2,6, 3,7]) # 0+1+2+3 # 4 # 1+2+3+4 # 5 # 2+3+4+5 # 6 # 3+4+5+6 # 7 array([ 6, 4, 10, 5, 14, 6, 18, 7]) 在多维的情况下,可以用axis指定延哪条轴计算 x = np.linspace(0, 15, 16).reshape(4,4) print(x) x.shape [[ 0. 1. 2. 3.] [ 4. 5. 6. 7.] [ 8. 9. 10. 11.] [12. 13. 14. 15.]] (4, 4) np.add.reduceat(x, [0, 3, 1, 2, 0]) #[0+4+8,1+5+9,2+6+10,3+7+11] # [12,13,14,15] # [4, 5, 6, 7] # [8, 9, 10, 11] # [0+4+8+12,1+5+9+13,2+6+10+14,3+7+11+15] array([[12., 15., 18., 21.], [12., 13., 14., 15.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [24., 28., 32., 36.]]) 指定轴执行函数 ufunc会在所有的元素上进行执行,但很多时候我们只希望指定轴执行函数.这时候就可以使用如下接口 np.apply_along_axis(func1d, axis, arr, *args, **kwargs) 沿给定轴对一维切片应用函数,函数的第一个参数必须为一维数组.其他参数可以在后面放入 def my_func(a,n): return (a[0] + a[-1]) * n b = np.array([[1,2,3], [4,5,6], [7,8,9]]) np.apply_along_axis(my_func, 0, b,n=0.25) array([2. , 2.5, 3. ]) np.apply_over_axes(func, a, axes) 在多个轴上重复应用一个函数,函数的值为res = func(a, axis) a = np.arange(24).reshape(2,3,4) print(a) print(a.shape) [[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]]] (2, 3, 4) np.apply_over_axes(np.sum, a, [0,2]) array([[[ 60], [ 92], [124]]]) np.sum(a,axis=0) array([[12, 14, 16, 18], [20, 22, 24, 26], [28, 30, 32, 34]]) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-07-01 15:58:34 "},"数学与统计应用篇/结语.html":{"url":"数学与统计应用篇/结语.html","title":"结语","keywords":"","body":"结语 python的优雅语法和平缓的学习曲线让它在众多候选语言中脱颖而出,成为了当前最受欢迎的开源科学计算语言.本篇恐怕也是本文除了语法篇外个人最看重的一篇.因为本人的是数据科学专业出身,写这篇一个目的也是为了让学校的学弟学妹们可以有个参考和查询的工具. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-18 17:16:40 "},"术语表.html":{"url":"术语表.html","title":"术语表","keywords":"","body":"术语表 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2018-06-08 10:23:02 "}}